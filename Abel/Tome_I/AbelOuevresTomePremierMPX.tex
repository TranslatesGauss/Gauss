\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{multirow}
\usepackage{graphicx}

\begin{document}
%1
MÉTHODE GÉNÉRALE POUR TROUVER DES FONETIONS I'UNE SEULE QUANTITÉ VARIABLE, LORSQU'UNE PROPIRÉTÉ DE CES FONCTIONS EST EXPRIMÉE PAR UNE ÉQUATION ENTRE IEUX VARIABLES.
Magazin for Naturvidenskaberue, Aargang I, Bind 1, Christiania 1823.
Soient \(x\) et \(y\) deux quantités variables indépendantes, \(\alpha, \beta, \gamma, \delta\) etc. des fonctions données de \(x\) et \(y\), et \(\varphi, f, F\) etc. des fonctions cherchées entre lesquelles une relation est exprimée par une équation \(V=0\), contenant d'une manière quelconque les quantités \(x, y, \varphi \alpha, f \beta, F_\gamma\) etc. et leurs différentielles. On pourra, en général, à l'aide de cette seule équation, trouver toutes les fonctions inconnues dans les cas où le problème est possible.

Pour trouver l'une des fonctions, il est clair qu'on doit chercher ure équation où cette fonction soit la seule inconnue et par conséquent chasser toutes les antres. Cherchons donc d'abord à chasser une fonction incomnue par exemple \(\varphi \propto\) et ses différentielles. Les quantités \(x\) et \(y\) étant indépendantes, on peut regarder l'une d'elles, ou une fonction donnée des deux, comme constante. On peut donc différentier l'équation \(V=0\) par rapport à l'une des variables \(x\), en considérant \(\alpha\) comme constánt, et dans ce cas l'autre variable \(y\) doit être considérée comme fonction de \(x\) et de \(a\). Or en différentiant l'équation \(V=0\) plusieurs fois de suite, en supposant \(\alpha\) constant, il ne se trouvera pas dans les équations résultantes, d'autres fonctions de \(\alpha\) que celles qui sont comprises dans l'équation \(V=0\), savoir \(\varphi \alpha\) et ses différentielles. Donc si la fonction \(V\) contient 
%2
on obtiendra, en différentiant l'équation \(V=0 n+1\) fois de suite dans la - supposition de \(\alpha\) constant, les \(n+2\) équations suivantes:
\[
\quad V=0, d V=0, d^2 V=0, \ldots d^{n+1} V=0 \text {. }
\]

Éliṇinatié de ces \(n+2\) équations les \(n+1\) quantités inconnues
\[
\varphi \alpha, \operatorname{dec} \alpha, d^{\prime} \varphi \alpha \text { etc., }
\]
il en résultera une équation \(V_1=0\) qui ne contiendra ni la fonction \(q \alpha\) ni ses différentielles, mais seulement les fonctions \(f_\beta \beta, F_\gamma^{\prime}\), etc. et leurs différentielles.

Cette équation \(V_{-1}=0\) pourra maintenant être traitée de la même manière, par rapport à l'une des autres fonctions incomnues \(f \beta\), et l'on obtiendra une équation \(V_2=0\) qui ne contiendra ni \(\rho \alpha\) ou ses différentielles, ni \(f \beta\) ou ses différentielles, mais seulement \(F_\gamma\) etc. et les différentielles de ces fonctions.

De cette manière, on peut continuer l'élimination des fonctions inconnues, jusqu'à ce qu'on soit parvenu à une équation qui ne contienne qu'une seule fonction incomnue avec ses différentielles, et en regardant maintenant l'une des quantités variables comme constante, on a, entre la fonction inconuue et l'autre variable, une équation différentielle d'où l'on pourra tirer cette fonction par intégration.

On peut remarquer, qu'il suffit d'éliminer jusqu'à ce qu'on ait obtenu une équation qui ne contienne que deux fonctions inconnues et leurs différentielles; car, si par exemple ces fonctions sont \(q \alpha\) et \(f_i \beta\), on pourra, en supposant \(\beta\) constant, exprimer \(x\) et \(y\) en fonction de \(\alpha\) à l'aide des deux équations \(\alpha=\alpha\) et \(\beta=c\), et arriver de cette manière à une équation différentielle entre \(\varphi \alpha\) et \(\alpha\), d'où l'on pourra par conséquent déduire \(\varphi \alpha\). De la même manière, on trouvera une équation entre \(f \beta\) et \(\beta\) en déterminant \(x\) et \(y\) par les équations \(\alpha=c\) et \(\beta=\beta\). Ces fonctions étant ainsi trouvées, on trouvera aisément les autres fonctions à l'aide des équations qui restent.

De cette manière, on pourra donc en général trouver toutes les fonctions inconnues, toutes les fois que le problème sera possible. Pour s'en rendre compte il faut substituer les valeurs trouvées dans l'équation donnée, et voir si elle est satisfaite.

Ce qui précède dépend, comme nous venons de le voir, de la différentiation d'une fonction de \(x\) et \(y\) par rapport à \(x\), en supposant constante une fonction donnée de \(x\) et \(y ; y\) est donc fonction de \(x\) et dans les différentielles
%3
se trouvent les expressions \(\frac{d y}{d x}, \frac{d^2 y}{d x^2}, \frac{d^3 y}{d x^3}\), etc. Ces expressions se trouvent aisément en différentiant l'équation \(\alpha=c\) par rapport à \(x\), et en supposant \(y\) fonction de \(x\). En effet, on obtiendra les équations suivantes:
\[
\begin{gathered}
\frac{d \alpha}{d x}+\frac{d \alpha}{d y} \frac{d y}{d x}=0 \\
\frac{d^2 \alpha}{d x^2}+2 \frac{d^2 \alpha}{d x d y} \frac{d y}{d x}+\frac{d^2 \alpha}{d y^2} \frac{d y^2}{d x^2}+\frac{d \alpha}{d y} \frac{d^2 y}{d x^2}=0 \text { etc. }
\end{gathered}
\]
d'où l'on tire
\[
\begin{gathered}
\frac{d y}{d x}=-\frac{\frac{d \alpha}{d x}}{\frac{d \alpha}{d y}} \\
\frac{d^2 y}{d x^2}=-\frac{\frac{d^2 \alpha}{d x^2}}{\frac{d \alpha}{d y}}+2 \frac{\frac{d^2 \alpha}{d x d y} \frac{d \alpha}{d x}}{\left(\frac{d \alpha}{d y}\right)^2}-\frac{\frac{d^2 \alpha}{d y^2}\left(\frac{d \alpha}{d x}\right)^2}{\left(\frac{d \alpha}{d y}\right)^3} \text { etc. }
\end{gathered}
\]

La méthode générale de résoudre l'équation \(V=0\) est applicable dans tous les cas où l'élimination peut s'effectuer, mais il peut arriver que cela ne soit pas possible, et alors il faut avoir recours an calcul des différences; mais pour n'être pas trop long, je passerai ce cas sous silence, d'autant plus qu'on peut voir dans le traité du calcul différentiel et du calcul intégral de M. Lacroix t. III, p. 208, comment on doit s'y prendre.
Nous allons appliquer la théorie générale à quelques exemples.
1. Trouver la fonction \(\varphi\) qui satisfasse à l'équation
\[
\varphi \alpha=f(x, y, \varphi \beta, \varphi \gamma)
\]
\(f\) étant une fonction quelconque donnée.
En différentiant cette équation par rapport à \(x\), en supposant \(\alpha\) constant, on aura
\[
0=f^{\prime} x+f^{\prime} y \frac{d y}{d x}+f^{\prime}(\varphi \beta) \varphi^{\prime} \beta\left(\frac{d \beta}{d x}+\frac{d \beta}{d y} \frac{d y}{d x}\right)+f^{\prime}(\varphi \gamma) \varphi^{\prime} \gamma\left(\frac{d \gamma}{d x}+\frac{d \gamma}{d y} \frac{d y}{d x}\right),
\]
or nous avons vu que
\[
\frac{d y}{d x}=-\frac{\frac{d \alpha}{d x}}{\frac{d \alpha}{d y}}
\]
cette valeur étant substituée dans l'équation ci-dessus, on obtiendra, après
%4
avoir multiplié par \(\frac{d \alpha}{d y}\) :
\[
0=f^{\prime} x \frac{d \alpha}{d y}-f^{\prime} y \frac{d \alpha}{d x}+f^{\prime}(\varphi \beta) \varphi^{\prime} \beta\left(\frac{d \beta}{d x} \frac{d \alpha}{d y}-\frac{d \alpha d \beta}{d x d y}\right)+f^{\prime}(\varphi \gamma) \varphi^{\prime} \gamma\left(\frac{d \gamma}{d x} d y-\frac{d \alpha d \gamma}{d x d y}\right) .
\]

Faisant maintenant \(\gamma\) constant, déterminant \(x\) et \(y\) en \(\beta\) par les deux équations \(\gamma=c, \beta=\beta\) et substituant leurs valeurs, on obtiendra entre \(\varphi \beta\) et \(\beta\) une équation différentielle du premier ordre, d'où l'on tirera la fonction \(\varphi \beta\)..
Soit
\[
f(x, y, \varphi \beta, \varphi \gamma)=\varphi \beta+\varphi \gamma
\]

On aura
\[
f^{\prime \prime} x=0, f^{\prime} y=0, f^{\prime}(\varphi \beta)=1, f^{\prime}(\varphi \%)=1 .
\]

L'équation deviendra donc
\[
0=\varphi^{\prime} \beta\left(\frac{d \beta}{d x} \frac{d \alpha}{d y}-\frac{d \alpha}{d x} \frac{d \beta}{d y}\right)+\varphi^{\prime} \gamma\left(\frac{d y}{d x} \frac{d \alpha}{d y}-\frac{d \alpha}{d x} \frac{d \gamma}{d y}\right)
\]
on tire de là en intégrant
\[
\varphi \beta=\varphi^{\prime} \gamma \int \frac{\frac{d \alpha}{d x} \frac{d \gamma}{d y}-\frac{d \alpha}{d y} \frac{d \gamma}{d x}}{\frac{d \beta}{d x} \frac{d \alpha}{d y}-\frac{d \alpha}{d x} \frac{d \beta}{d y}} d \beta .
\]

On voit aisément que sans diminuer la généralité du problème on peut faire \(\beta=x\) et \(\gamma=y\); on aura ainsi
\[
\frac{d \beta}{d x}=1, \frac{d \beta}{d y}=0, \frac{d \gamma}{d x}=0, \frac{d \gamma}{d y}=1
\]

Donc, ayant
on en conclut
\[
\varphi \alpha=\varphi x+\varphi y
\]
\[
\varphi x=\varphi^{\prime} y \int \frac{\frac{d \alpha}{d x}}{\frac{d \alpha}{d y}} d x
\]
où y est supposé constant après la différentiation.
Appliquons cela à la recherche du logarithme. On a
donc
\[
\log (x y)=\log x+\log y
\]
\[
\alpha=x y, \frac{d \alpha}{d x}=y, \frac{d \alpha}{d y}=x
\]
%5
substituant ces valeurs on obtient
donc
\[
\varphi x=\varphi^{\prime} y \int \frac{y}{x} d x=c \int \frac{d x}{x}
\]
\[
\log x=c \int \frac{d x}{x} \text {. }
\]

Si l'on veut trouver are tang \(x\), on a
\[
\operatorname{arctang} \frac{x+y}{1-x y}=\operatorname{arctang} x+\operatorname{arctang} y
\]
donc:
\[
\alpha=\frac{x+y}{1-x y}
\]
et par suite
\[
\begin{aligned}
& \frac{d \alpha}{d x}=\frac{1}{1-x y}+\frac{y(x+y)}{(1-x y)^2}=\frac{1+y^2}{(1-x y)^2} \\
& \frac{d \alpha}{d y}=\frac{1}{1-x y}+\frac{x(y+x)}{(1-x y)^2}=\frac{1+x^2}{(1-x y)^2} .
\end{aligned}
\]

On tire de lat
\[
\frac{\frac{d \alpha}{d x}}{\frac{d \alpha}{d y}}=\frac{1+y^2}{1+x^2}
\]
par conséquent
\[
\varphi x=\varphi^{\prime} y \int \frac{1+y^2}{1+x^2} d x
\]
d'où
arc tang \(x=c \int \frac{d x}{1+x^2}=\int \frac{d x}{1+x^2}\), en faisant \(c=1\).
Supposons maintenant
\[
f(x, y, \varphi \beta, \varphi \gamma)=\varphi \beta \cdot \varphi \gamma=\varphi x \cdot \varphi y
\]
en faisant \(\beta=x, \gamma=y\). On aura
\[
\begin{gathered}
f^{\prime} x=f^{\prime} y=0, f^{\prime}(\varphi x)=\varphi y, f^{\prime}(\varphi y)=\varphi x, \\
\frac{d \beta}{d x}=\frac{d y}{d y}=1, \frac{d \beta}{d y}=\frac{d y}{d x}=0 .
\end{gathered}
\]

L'équation deviendra done
\[
\varphi y: \varphi^{\prime} x \frac{d c}{d y}-\varphi x \cdot \varphi^{\prime} y \frac{d \alpha}{d x}=0
\]
%6
done
\[
\frac{f^{\prime} x}{f^{\prime} x}=\frac{\tau^{\prime} y}{\varphi^{\prime} y} \frac{\frac{d \alpha}{d x}}{\frac{d \alpha}{d y}}
\]
et en intégrant
\[
\log \varphi x=\frac{\varphi^{\prime} y}{\varsigma^y} \int \frac{\frac{d \alpha}{d x}}{\frac{d \alpha}{d y}} d x
\]

Soit
\[
\int \frac{\frac{d \alpha}{d x}}{\frac{d \alpha}{d y}} d x=T
\]
on aurac
\[
\varphi x=e^{c x} \text {. }
\]

Soit par exemple \(\alpha=x+y\), on aura \(\frac{d \alpha}{d x}=1=\frac{d \alpha}{d y}\), donc et
\[
T=\int d x=x
\]
\[
\varphi x=e^{c x} .
\]

Soit \(\alpha=x y\), on aura
\[
\frac{d \alpha}{d x}=y, \frac{d \alpha}{d y}=x, \quad T=y \int \frac{d x}{x}
\]
done
c'est-à-dire
\[
\begin{aligned}
& \varphi x=e^{c \log x}, \\
& \varphi x=x^c .
\end{aligned}
\]

Si l'on cherche la résultante \(R\) de deux forces égales \(P\), dont les directions font un angle égal à \(2 x\), on trouvera que \(R=P \varphi x\), où \(\varphi x\) est une fonction qui satisfait à l'équation
\[
\varphi x \cdot \varphi y=\varphi(x+y)+\varphi(x-y) \cdot *)
\]

Pour déterminer cette fonction, il faut différentier l'équation par rapport à \(x\), en supposant \(y+x=\) const., et l'on aura
\[
\varphi^{\prime} x \cdot \varphi y+\varphi x \cdot \varphi^{\prime} y \frac{d y}{d x}=\varphi^{\prime}(x-y)\left(1-\frac{d y}{d x}\right) .
\]
*) Voyez Poissom traité de mécanique t. I, p. 14.
%7
Mais de l'équation \(x+y=c\) on tire \(\frac{d y}{d x}=-1\); substituant cette valeur, on obtient
\[
\varphi^{\prime} x \cdot \varphi y-\varphi x \cdot \varphi^{\prime} y=2 \varphi^{\prime}(x-y)
\]

Différentiant maintenant par rapport à \(x\), en supposant \(x-y=\) const., on aura
\[
\varphi^{\prime \prime} x \cdot \varphi y+\varphi^{\prime} x \cdot \varphi^{\prime} y \frac{d y}{d x}-\varphi^{\prime} x \cdot \varphi^{\prime} y-\varphi x \cdot \varphi^{\prime \prime} y \frac{d y}{d x}=0
\]
or l'équation \(x-y=c\) donne \(\frac{d y}{d x}=1\), donc
\[
\varphi^{\prime \prime} x \cdot \varphi y-\varphi x \cdot \varphi^{\prime \prime} y=0
\]

La supposition de \(y\) constant dome
\[
\varphi^{\prime \prime} x+c \varphi x=0
\]
d'où l'on tire en intégrant
\[
\boldsymbol{\varphi} x=\alpha \cos (\beta x+\gamma)
\]
\(\alpha, \beta\) et \(\gamma\) étant des constantes. En déterminant celles-ci par les conditions du problème, on trouvera
\[
\alpha=2, \beta=1, \gamma=0
\]
done
\[
\varphi x=2 \cos x, \text { et par suite } R=2 P \cos x
\]
2. Déterminer les trois fonctions \(\varphi, f\) et \(\psi\) ' qui satisfassent à l'équation
\[
\psi \alpha=F\left(x, y, \varphi x, \Psi^{\prime} x, \ldots f y, f^{\prime} y, \ldots\right)
\]
où \(\dot{c}\) est une fonction donnée de \(x\) et de \(y\), et \(F\) une fonction domnée des quantités entre les parenthèses.

Différentiant l'équation par rapport à \(x\), en supposant \(\alpha\) constant, et écrivant ensuite \(-\frac{\frac{d \alpha}{d x}}{\frac{d \alpha}{d y}}\) an lien de \(\frac{d y}{d x}\), on obtiendra \[ \frac{\frac{d \alpha}{d x}}{\frac{d \alpha}{d y}}=\frac{F^{\prime \prime} x+F^{\prime \prime}(r x) r^{\prime} x+\ldots}{F^{\prime} y+F^{\prime}(f y) f^{\prime} y+\ldots} . \]
%8
\(\mathrm{Si}\) dans cette équation on fait \(y\) constant, on a une équation différentielle entre \(\varphi \cdot x\) et \(x\), d'où l'on peut tirer \(\varphi x\), et si l'on fait \(x\) constant, on a une équation différentielle d'où l'on peut tirer \(f y\); ces deux fonctions étant trouvées, la fonction \(\psi / \alpha\) se trouvera sans difficulté par l'équation proposée.
Exemples. 'Trouver les trois fonctions qui satisfassent à l'équation
\[
\psi(x+y)=\psi x \cdot f^{\prime} y+f y \cdot \psi^{\prime} x .
\]
() a ici
\[
F\left(x, y, \varphi x, \varphi^{\prime} x, f y, f^{\prime} y\right)=\varphi x \cdot f^{\prime} y+f y \cdot \varphi^{\prime} x
\]
done:
\[
\begin{gathered}
F^{\prime \prime} x=F^{\prime \prime} y=0, \quad F^{\prime}(\boldsymbol{\varsigma} x)=f^{\prime} y, \quad F^{\prime}\left(\boldsymbol{\varphi}^{\prime} x\right)=f y \\
F^{\prime \prime}(f y)=\boldsymbol{\varsigma}^{\prime} x, \quad F^{\prime}\left(f^{\prime} y\right)=\boldsymbol{\varphi} x
\end{gathered}
\]
de pliss
\[
\alpha=x+y
\]
done
\[
\frac{d a}{d x}=1, \frac{d a}{d y}=1
\]

Ces valeurs étant substituées, on aura
\[
1=\frac{f^{\prime} y \cdot \tau^{\prime} x+f y \cdot f^{\prime \prime} \cdot x}{\tau^{\prime} x \cdot f^{\prime} y+\tau \cdot x \cdot f^{\prime \prime} y}
\]
ou bien
\[
\varphi x \cdot f^{\prime \prime} y-f y \cdot \varphi^{\prime \prime} x=0 .
\]

Faisant \(y\) constant, on trouvera
\[
\varsigma x=a \sin (b x+c)
\]
et si l'on fait \(x\) constant,
\[
f y=a^{\prime} \sin \left(b y+c^{\prime}\right) .
\]

On tire de lit
\[
\begin{aligned}
& \varphi^{\prime} x=a b \cos (b x+c) \\
& f^{\prime} y=a^{\prime} b \cos \left(b y+c^{\prime}\right) .
\end{aligned}
\]

Ces valeurs étant substituées dans l'équation proposée, on obtiendra
\[
\begin{gathered}
\psi(x+y)=a a^{\prime} b\left(\sin (b x+c) \cos \left(b y+c^{\prime}\right)+\sin \left(b y+c^{\prime}\right) \cos (b x+c)\right) \\
=a a^{\prime} b \sin \left(b(x+y)+c+c^{\prime}\right) .
\end{gathered}
\]
%9
Les trois fonctions cherchées sont donc
\[
\begin{aligned}
& \varphi x=a \sin (b x+c) \\
& f y=a^{\prime} \sin \left(b y+c^{\prime}\right), \\
& \psi a=a a^{\prime} b \sin \left(b \alpha+c+c^{\prime}\right) .
\end{aligned}
\]

Si l'on fait \(a=a^{\prime}=b=1\) et \(c=c^{\prime}=0\), on aura
\[
\begin{aligned}
& \varphi x=\sin x, f y=\sin y, \quad \psi \alpha=\sin \alpha, \\
& \sin (x+y)=\sin x \cdot \sin ^{\prime} y+\sin y \cdot \sin ^{\prime} x .
\end{aligned}
\]
et par suite
\[
\sin (x+y)=\sin x \cdot \sin ^{\prime} y+\sin y \cdot \sin ^{\prime} x .
\]

Trouver les trois fonctions qui sont déterminées par l'équation
\[
\psi(x+y)=f(x y)+\varphi(x-y) \text {. }
\]

Différentiant par rapport à \(x\), en supposant \(x+y\) constant, on aura
\[
0=f^{\prime}(x y)(y-x)+2 \varphi^{\prime}(x-y)
\]

Maintenant pour trouver \(\varphi\), soit \(x y=c\) et \(x-y=\alpha\), on aura
\[
\varphi^{\prime} \alpha=k \alpha
\]
done
\[
\varphi \alpha=k^{\prime}+\frac{k}{2} \alpha^2
\]

Pour trouver \(f\), soit \(x y=\beta\) et \(x-y=c\), on aura
\[
\begin{gathered}
f^{\prime} \beta=c^{\prime}, \\
f \beta=c^{\prime \prime}+c^{\prime} \beta .
\end{gathered}
\]
done
\[
f \beta=c^{\prime \prime}+c^{\prime} \beta \text {. }
\]

Ces valeurs de \(\varphi \alpha\) et \(f \beta\) étant substituées dans l'équation donnée, on obtiendra
\[
\psi(x+y)=c^{\prime \prime}+c^{\prime} x y+k^{\prime}+\frac{k}{2}(x-y)^2 .
\]

Pour déterminer \(\psi\), soit \(x+y=\alpha\), d'où l'on tire \(y=\alpha-x\), d'où
\[
\psi \alpha=c^{\prime \prime}+c^{\prime} x(\alpha-x)+k^{\prime}+\frac{k}{2}(2 x-\alpha)^2=c^{\prime \prime}+\frac{k}{2} \alpha^2+k^{\prime}+x \alpha\left(c^{\prime}-2 k\right)+\left(2 k-e^{\prime}\right) x^8 .
\]

Pour que cette équation soit possible, il faut que \(x\) disparaisse; alors on aura
\[
2 k-c^{\prime}=0, \text { et } c^{\prime}=2 k \text {. }
\]

Cette valeur étant substituée, on obtient
\[
\psi \alpha=k^{\prime}+c^{\prime \prime}+\frac{k}{2} \alpha^2, f \beta=c^{\prime \prime}+2 k \beta, \Upsilon_i=k^{\prime}+\frac{k}{2} \gamma^2,
\]
qui sont les trois fonctions cherchées.
%10
Comme dernier exemple je prendrai le suivant: Déterminer les fonctions \(\varphi\) et \(f\) par l'équation
\[
\varphi(x+y)=\varphi x \cdot f y+f x \cdot \varphi y .
\]

En supposant \(x+y=c\), et en différentiant, on obtiendra
\[
0=\varphi^{\prime} x \cdot f y-\varphi x \cdot f^{\prime} y+f^{\prime} x \cdot \varphi y-f x \cdot \varphi^{\prime} y .
\]

Supposons de plus que \(f(0)=1\) et \(\varphi(0)=0\), nous aurons en posant \(y=0\) :
\[
0=\varphi^{\prime} x-\varphi x \cdot c+f x \cdot c^{\prime}
\]
done
\[
f x=\operatorname{k} \varphi x+k^{\prime} \varphi^{\prime} x \text {. }
\]

Substituant cette valeur de \(f x\), et faisant \(y\) constant, on aura
et en intégrant,
\[
\varphi^{\prime \prime} x+a \varphi^{\prime} x+b \varphi x=0
\]
\[
\varphi x=c^{\prime} e^{\alpha x}+c^{\prime \prime} e^{\alpha^{\prime} x} .
\]

Comnaissant \(q x\), on connaît aussi \(f x\), et en substituant les valeurs de ces fonctions, on pourra déteminer les valeurs des quantités constantes. On peut supposer
\[
c^{\prime}=-c^{\prime \prime}=\frac{1}{2 \sqrt{-1}}, \alpha=-\alpha^{\prime}=\sqrt{-1}
\]
ce qui donnera
\[
\varphi x=\frac{e^{x \sqrt{-1}}-e^{-x} \sqrt{-1}}{2 \sqrt{-1}}=\sin x, \quad f x=\cos x
\]
%11
II.
SOLUTION DE QUELQUES PROBLÈMES À L'AIDE D'INTÉGRALES DÉFINIES.
Magazin for Naturvidenskaberne, Aargang I, Bind , Christiania 1823
1.
C'est bien connu qu'on résout à l'aide d'intégrales définies, beaucoup de problèmes qui autrement ne peuvent point se résondre, on du moins sont très-difficiles à traiter. Elles ont surtont été appliquées avec avantage à la solution de plusieurs problèmes difficiles de la mécanique, par exemple, à celui du mouvement d'une surface élastique, des problèmes de la théorie des ondes etc. Je vais en montrer une nouvelle application en résolvant le problème suivant.
Soit \(C B\) une ligne horizontale, \(A\) un point donné, \(A B\) perpendiculaire à \(B C, A M\) une courbe dont les coordonnées rectangulaires sont \(A P=x, P M=y\). Soit de plus \(A B=a, A M=s\). Si l'on conçoit maintenant qu'un corps se meut sur l'arc \(C A\), la vitesse initiale étant nulle, le temps \(T\) qu'il emploie pour le parcourir dépendra de la forme de la courbe, et de \(a\). Il s’agit de déterminer la courbe \(K C A\) pour que le temps \(T\) soit égal à une fonction donnée de \(a\), p. ex. \(\psi(a\).

Si l'on désigne par \(h\) la vitesse du corps au point \(M\), et par \(t\) le temps qu'il emploie pour parcourir l'arc \(C M\), on a comme on sait
\[
h=\mid B P=\sqrt{a-x}, \quad d t=-\frac{d s}{h},
\]
%12
donc
\[
d t=-\frac{\dot{d s}}{\sqrt{a-x}},
\]
et en intégrant
\[
t=-\int \frac{d s}{\sqrt{a-x}} .
\]

Pour avoir \(T\) on doit prendre l'intégrale depuis \(x=a\) jusqu'd \(x=0\), on a done
\[
T=\int_{x=0}^{x=a} \frac{d s}{\sqrt{a-x}} .
\]

Or comme \(T\) est égal à \(\psi a\), l'équation devient
\[
\psi a=\int_{x=0}^{x=a} \frac{d s}{\sqrt{a-x}} .
\]

An lien de résoudre cette équation, je vais montrer comment on peut tirer \(s\) de l'équation plus générale
\[
\psi a=\int_{x=0}^{x=a} \frac{d s}{(a-x)^x},
\]
où \(n\) est supposé moindre que l'unité, afin que l'intégrale ne devienne pas infinie entre les limites données; \(\psi a\) est une fonction quelconque qui n'est pas infinie quand \(a\) est égal à zéro.
Posons
\[
s=\Sigma \alpha^{(m)} x^m
\]
où \(\Sigma \boldsymbol{\alpha}^{(m)} x^m\) a la valeur suivante:
\[
\Sigma \boldsymbol{\alpha}^{(m)} x^m=\boldsymbol{\alpha}^{\left(m^*\right)} x^{m^{\prime}}+\boldsymbol{\alpha}^{\left(m^*\right)} x^{m^*}+\alpha^{\left(m^m\right)} x^{m^m}+\ldots
\]

En différentiant on obtient
\[
d s=\Sigma m \alpha^{(m)} x^{m-1} d x
\]
done
\[
\frac{d s}{(a-x)^n}=\frac{\operatorname{Sm}^{(m)} x^{m-1} d x}{(a-x)^n}=\operatorname{\sum m} \boldsymbol{c}^{(m)} \frac{x^{m-1} d x}{(a-x)^n}
\]

En intégrant on a
\[
\int_{x=0}^{x=a} \frac{d s}{(a-x)^n}=\int_{x=0}^{x=a} \sum m \alpha^{(m)} \frac{x^{m-1} d x}{(a-x)^n} .
\]

Or
\[
\int \Sigma m \alpha^{(m)} \frac{x^{m-1} d x}{(a-x)^n}=\Sigma m x^{(m)} \int \frac{x^{m-1} d x}{(a-x)^n},
\]
%13
donc, puisque \(\int_{x=0}^{x=a} \frac{d s}{(a-x)^n}=\psi a\) :
\[
\psi a=\operatorname{sm} \alpha^{(m)} \int_0^a \frac{x^{n t-1} d x}{(a-x)^n} .
\]

La valeur de l'intégrale
\[
\int_0^a \frac{x^{m-1} d x}{(a-x)^n}
\]
se trouve aisément de la manière suivante: Si l'on pose \(x=a t\), on a
\[
\begin{aligned}
& x^m=a^m t^m, m x^{m-1} d x=m a^m t^{m-1} d t \\
& (a-x)^n=(a-a t)^n=a^n(1-t)^n,
\end{aligned}
\]
donc
\[
\frac{m x^{m-1} d x}{(a-x)^n}=\frac{m a^{m-n} t^{m-1} d t}{(1-t)^n}
\]
et en intégrant
\[
m \int_0^a \frac{x^{m-1} d x}{(a-x)^n}=m a^{m-n} \int_0^1 \frac{t^{m-1} d t}{(1-t)^n} .
\]

Or on a
\[
\int_0^1 \frac{t^{m-1} d t}{(1-t)^n}=\frac{\Gamma(1-n) \boldsymbol{T} m}{\Gamma(m-n+1)}
\]
où \(\Gamma m\) est une fonction déterminée par les équations
\[
\left.\boldsymbol{I}^{\prime}(m+1)=m \boldsymbol{I}^{\prime} m, \boldsymbol{r}(1)=1{ }^*\right)
\]

En substituant cette valeur pour l'intégrale \(\int_0^1 \frac{t^{m-1} d t}{(1-t)^n}\), et remarquant que \(m I^{\prime} m=I^{\prime}(m+1)\) on a
\[
m \int_0^a \frac{x^{m-1} d x}{(a-x)^n}=\frac{r(1-n) \boldsymbol{r}(m+1)}{r(m-n+1)} a^{m-n} .
\]

En substituant cette valeur dans l'expression pour \(\psi\) ra, on obtient
\[
\psi a=I^{\prime}(1-n) \Sigma \alpha^{(m)} a^{m-n} \frac{r(m+1)}{r(m-n+1)} .
\]

Soit
\[
\psi\left(a=\Sigma \beta^{(k)} a^k\right.
\]
on a
\[
\Sigma \beta^{(k)} a^k=\sum \frac{I^{\prime}(1-n) \Gamma(m+1)}{\Gamma(m-n+1)} \alpha^{(m)} a^{m-n} .
\]
*) Les propriétés de cette fonction remarquable ont été largement développées par M. Legendre dans son ouvrage, Exercices de calcul intégral t. I et II.
%14
Pour que cette équation soit satisfaite il faut que \(m-n=k\), donc \(m=n+k\), et que
done
\[
\beta^{(k)} \doteq \frac{\Gamma(1-n) \Gamma(m+1)}{\Gamma(m-n+1)} \alpha^{(m)}=\frac{\Gamma(1-n) \Gamma(n+k+1)}{\Gamma(k+1)} \alpha^{(m)}
\]

Or on a
\[
\alpha^{(m)}=\frac{\Gamma(k+1)}{\Gamma(1-n) \Gamma(n+k+1)} \rho^{(k)} .
\]
\[
\int_0^1 \frac{t^k d t}{(1-t)^{1-n}}=\frac{I^{\prime} n \cdot r(k+1)}{I^{\prime}(n+k+1)}
\]
par conséquent
\[
\alpha^{(m)}=\frac{\beta^{(k)}}{\Gamma^n \cdot \Gamma^{\prime}(1-n)} \int_0^1 \frac{t^k d t}{(1-t)^{1-n}}
\]

En multipliant par \(x^m=x^{n+k}\) on obtient
d'où
\[
\alpha^{(m)} x^m=\frac{x^n}{I^{\prime} n \cdot \Gamma(1-n)} \int_0^1 \frac{\beta^{(k)}(x t)^k d t}{(1-t)^{1-n}}
\]
\[
\Sigma \alpha^{(m)} x^m=\frac{x^n}{\Gamma n \cdot \Gamma(1-n)} \int_0^1 \frac{\Sigma \beta^{(k)}(x t)^k d t}{(1-t)^{1-n}} .
\]

Mais on a \(\Sigma \boldsymbol{\alpha}^{(m)} x^m=s, \Sigma \beta^{(k)}(x t)^k=\psi(x t)\), done
\[
s=\frac{x^n}{\operatorname{In} \cdot \boldsymbol{\Gamma}(1-n)} \int_0^1 \frac{\psi(x t) d i}{(1-t)^{1-n}} .
\]

En remarquant ensuite qu'on a \(I^{\prime} n \cdot \Gamma(1-n)=\frac{\pi}{\sin n \pi}\), on trouve
\[
s=\frac{\sin n \pi \cdot x^n}{\pi} \int_0^1 \frac{y(x t) d t}{(1-t)^{1-n}} .
\]

De ce qui précède découle ce théorème remarquable:
Si l'on a
\[
\psi a=\int_{x=0}^{x=a} \frac{d s}{(a-x)^n}
\]
on a aussi
\[
s=\frac{\sin n \pi}{x} x^n \int_0^1 \frac{y(x t) d t}{(1-t)^{1-n}} .
\]

Appliquons maintenant cela à l'équation
\[
\psi a=\int_{x=0}^{x=a} \frac{d s}{\sqrt{a-x}}
\]
%15
On a dans ce cas \(n=\frac{1}{2}\), donc \(1-n=\frac{1}{2}\) et par conséquent
\[
s=\frac{\sqrt{x}}{\pi} \int_0^1 \frac{\psi(x t) d t}{\sqrt{1-t}} .
\]

Voilà donc l'équation qui détermine l'arc \(s\) de la courbe cherchée par l'abscisse correspondante \(x\); on en tirera facilement une équation entre les . coordonnées rectangulaires, en remarquant que l'on a \(d s^2=d x^2+d y^2\).
Appliquons maintenant la solution précédente à quelques cas spéciaux.
1) Trouver la courbe qui a la propriété, que le temps qu'un corps emploie pour parcourir un arc quelconque, soit proportionel à la \(n^{\text {ième }}\) puissance de la hauteur que le corps a parcourue.

Dans ce cas on a \(\psi a=c a^n\), où \(c\) est une constante, donc \(\psi(x t)=c x^n t^n\), par suite:
\[
s=\frac{\sqrt{x}}{x} \int_0^1 \frac{c x^n t^n d t}{\sqrt{1-t}}=x^{n+\frac{1}{2}} \frac{c}{x} \int_0^1 \frac{t^n d t}{\sqrt{1-t}}
\]
donc en faisant
\[
\frac{c}{\pi} \int_0^1 \frac{t^n d t}{\sqrt{1-t}}=C
\]
on a
\[
s=C x^{n+\frac{3}{2}}
\]
on tire de lat
\[
d s=\left(n+\frac{1}{2}\right) C x^{n-\frac{1}{2}} d x
\]
et
\[
d s^2=\left(n+\frac{1}{2}\right)^2 C^2 x^{2 n-1} d x^2=d y^2+d x^2,
\]
d'où l'on déduit en posant \(\left(n+\frac{i}{2}\right)^2 C^2=k\)
\[
d y=d x \sqrt{k x^{2 n-1}-1}
\]
l'équation de la courbe cherchée devient donc
\[
y=\int d x \sqrt{k x^{2 n-1}-1} .
\]

Si l'on fait \(n=\frac{1}{2}\), on a \(x^{2 n-1}=1\), donc
\[
y=\int d x \sqrt{k-1}=k^{\prime}+x \sqrt{k-1},
\]
la courbe cherchée est done une droite.
%16
2) Trouver l'équation de l'isochrone.

Puisque le temps doit être indépendant de l'espace parcouru, on \(\psi a=c\) et par conséquent
donc
\[
s=\frac{\sqrt{x}}{x} c \int_0^1 \frac{d t}{\sqrt{1-t}}
\]
où
\[
s=k \sqrt{x}
\]
\[
k=\frac{c}{x} \int_0^1 \frac{d t}{\sqrt{1-t}},
\]
ce qui est l'équation connue de la cycloide.
Nous avons vu que si l'on a
\[
\psi a=\int_{x=0}^{x=a} \frac{d s}{(a-x)^n},
\]
on a alussi
\[
s=\frac{\sin u \pi t}{\pi} x^n \int_0^1 \frac{\psi(x t) d t}{(1-t)^{1-n}} .
\]

On peut aussi exprimer \(s\) d'ume autre manière, que je vais rapporter à cause de sa singularité, savoir
\[
s=\frac{1}{\Gamma(1-n)} \int^n \psi x \cdot d x^n=\frac{1}{\Gamma(1-n)} \frac{d^{-n} \psi x}{d x^{-n}},
\]
c'est-à-dire, si l'on a
\[
\psi a=\int_{x=0}^{x=a} d s(a-x)^n
\]
on a aussi
\[
s=\frac{1}{\Gamma(1+n)} \frac{d^n \psi \cdot x}{d x x^n}
\]
en d'autres termes, on a
\[
\psi\left(\iota=\frac{1}{\Gamma(1+n)} \int_{x=0}^{x=a} \frac{d^{n+1} \psi x}{d x^{n+1}}(a-x)^n d x .\right.
\]

Cette proposition se démontre aisément comme il suit. Si l'on pose
\[
\psi x=\Sigma a^{(m)} x^m
\]
on obtient en différentiant:
\[
\frac{d^k \ell^{\prime} x}{d_1 c^k}=\Sigma a^{(m)} m(m-1)(m-2) \ldots(m-k+1) x^{n-k}
\]
mais
\[
m(m-1)(m-2) \ldots(m-k+1)=\frac{r(m+1)}{\Gamma(m-k+1)}
\]
%17
done
\[
\frac{d^k \psi x}{d x^k}=\Sigma \alpha^{(m)} \frac{\Gamma(m+1)}{\Gamma(m-k+1)} x^{m-k} .
\]

Or on a
\[
\frac{\Gamma(m+1)}{\Gamma(m-k+1)}=\frac{1}{\Gamma(-k)} \int_0^1 \frac{t^m d t}{(1-t)^{1+k}}
\]
par conséquent
\[
\frac{d^k \psi x}{d x^k}=\frac{1}{x^k \Gamma(-k)} \int_0^1 \frac{\boldsymbol{\Sigma} \boldsymbol{\alpha}^{(n)}(x t)^m d t}{(1-t)^{1+k}}
\]
mais \(\Sigma \alpha^{(m)}(x t)^m=\psi(x t)\), donc
\[
\frac{d^k \psi x}{d x^k}=\frac{1}{x^k \boldsymbol{\Gamma}(-k)} \int_0^1 \frac{\psi(x t) d t}{(1-t)^{1+k}} .
\]

En posant \(k=-n\), on en tire
\[
\frac{d^{-n} \psi x}{d x-n}=\frac{x^n}{\Gamma n} \int_0^1 \frac{\psi(x t) d t}{(1-t)^{1-n}} .
\]

Or nous avons vu que
\[
s=\frac{x^n}{\Gamma n \cdot \Gamma(1-n)} \int_0^1 \frac{\psi(x t) d t}{(1-t)^{1-n}},
\]
donc on a
\[
s=\frac{1}{\Gamma(1-n)} \frac{d^{-n} \psi x}{d x^{-n}}
\]
si .
\[
\psi\left(u=\int_{x=0}^{x=a} \frac{d s}{(a-x)^n},\right.
\]
c. q. f. \(d\).

En différentiant \(n\) fois de suite la valeur de \(s\), on obtient
\[
\frac{d^n s}{d x^n}=\frac{1}{\Gamma(1-n)} \psi x
\]
et par conséquent, en faisant \(s=\varphi x\),
\[
\frac{d^n \boldsymbol{\varphi} a}{d \boldsymbol{a}^n}=\frac{1}{\Gamma(1-n)} \int_0^a \frac{\varphi^{\prime} x \cdot d x}{(a-x)^n} .
\]

On doit remarquer que, dans ce qui précède, \(n\) doit toujours être moindre que l'unité.
Si l'on fait \(n=\frac{1}{2}\), on a
\[
\psi\left(\iota=\int_{x=0}^{x=a} \frac{d s}{\sqrt{a-x}}\right.
\]
%18
et
\[
s=\frac{1}{\sqrt{\pi}} \frac{d^{-\frac{1}{2}} \psi x}{d x^{-\frac{1}{2}}}=\frac{1}{\sqrt{\pi}} \int^{\frac{1}{2}} \psi x \cdot d x^{\frac{1}{2}} .
\]

C'est là l'équation de la courbe cherchée, quand le temps est égal à \(\psi a\).
De cette équation on tire
\[
\psi x=\sqrt{\pi} \frac{d \dot{s} s}{d x^{\frac{1}{2}}}
\]
done:
Si l'équation d'une courbe est \(s=\varphi x\), le temps qu'un corps emploie pour en parcourir un arc, dont la hauteur est \(a\), est égal à \(\sqrt{\pi} \frac{d^2 q u}{d a^{\frac{1}{2}}}\).

Je remarquerai enfin que de la même manière, qu'en partant de l'équation
\[
\psi a=\int_{x=0}^{x=a} \frac{d s}{(a-x)^n}
\]
j'ai trouvé \(s\), de même en partant de l'équation
\[
\psi a=\int \varphi(x a) f x \cdot d x
\]
j'ai trouvé la fonction \(\varphi, \psi\) et \(f\) étant des fonctions données, et l'intégrale étant prise entre des limites quelconques; mais la solution de ce problème est trop longù pour être donnée ici.
2.
Valeur de l'expression \(\uparrow(x+y \sqrt{-1})+\uparrow(x-y \sqrt{-1})\).
Lorsque \(\varphi\) est une fonction algébrique, logarithmique, exponentielle ou circulaire, on peut, comme on sait, toujours exprimer la valeur réelle de \(\varphi(x+y \sqrt{-1})+\varphi(x-y \sqrt{-1})\). sous forme réelle et finie. Si au contraire \(\varphi\) conserve sa généralité, on n'a pas que je sache, jusqu'à présent pu l'exprimer sous forme réelle et finie. On peut le faire à l'aide d'intégrales définies de la manière suivante.

Si l'on développe \(\varphi(x+y \sqrt{-1})\) et \(\varphi(x-y \sqrt{-1})\) d'après le théorème de Taylor, on obtient
\[
\begin{aligned}
& \varphi(x+y \sqrt{-1})=\varphi x+\varphi^{\prime} x \cdot y \sqrt{-1}-\vartheta_{1.2}^{\prime \prime} x y^2-\frac{\varphi^{\prime \prime \prime} \cdot x}{1.2 .3} y^3 \sqrt{-1}+\frac{\varphi^{\prime \prime \prime \prime} \cdot x}{1.2 .3 .4} y^4+\cdots \\
& \varphi(x-y \sqrt{-1})=\varphi x-\varphi^{\prime} x \cdot y \sqrt{-1}-\frac{\varphi^{\prime \prime} x}{1.2} y^2+\frac{r^{\prime \prime \prime} \cdot x}{1.2 .3} y^3 \sqrt{-1}+\frac{\tau^{\prime \prime \prime \prime} x}{1.2 .3 .4} y^4-\ldots \\
&
\end{aligned}
\]
%19
done
\[
\varphi(x+y \sqrt{-1})+\varphi(x-y \sqrt{-1})=2\left(\varphi x-\frac{r^{\prime \prime} x}{1.2} y^2+\frac{r^{\prime \prime \prime \prime} x}{1.2 .3 .4} y^4-\ldots\right) .
\]

Pour trouver la somme de cette série, considérons la série
\[
\varphi(x+t)=\varphi x+t \varphi^{\prime} x+\frac{t^2}{1.2} \varphi^{\prime \prime} x+\frac{t^3}{1.2 .3} \varphi^{\prime \prime \prime} x+\ldots
\]

En multipliant les deux membres de cette équation par \(e^{-v^2 t^2} d t\), et prenant ensuite. l'intégrale depuis. \(t=-\infty\) jusqu'à \(t=+\infty\), on aura
\[
\int_{-\infty}^{+\infty} \varphi(x+t) e^{-v^2 t^2} d t=\varphi x \int_{-\infty}^{+\infty} e^{-v^2 t^2} d t+\varphi^{\prime} x \int_{-\infty}^{+\infty} e^{-v^2 t^2} t d t+\frac{1}{2} \varphi^{\prime \prime} x \int_{-\infty}^{+\infty} e^{-v^2 t^2 t^2} d t+\ldots
\]

Or \(\quad \int_{-\infty}^{+\infty} e^{-v^2 t^2} t^{2 n+1} d t=0\), done
\[
\int_{-\infty}^{+\infty} \varphi(x+1) e^{-v^2 t^2} d t=\varphi x \int_{-\infty}^{+\infty} e^{-v^2 t^2} d t+\frac{\varphi^{\prime \prime} x}{1.2} \int_{-\infty}^{+\infty} e^{-v^2 t^2} t^2 d t+\frac{\varphi^{\prime \prime \prime \prime} \cdot x}{1.2 .3 .4} \int_{-\infty}^{+\infty} e^{-v^2 t^2 t^4} d t+\ldots
\]

Considérons l'intégrale
\[
\int_{-\infty}^{+\infty} e^{-v^2 t^2} t^{2 n} d t
\]

Soit \(t=\frac{\alpha}{v}\), on a \(e^{-v^2 t^2}=e^{-\alpha^2}, t^{2 n}=\frac{\alpha^{2 n}}{x^{2 n}}, d t=\frac{d \alpha}{v}\), donc
\[
\int_{-\infty}^{+\infty} e^{-v^2 t^2} t^{2 n} d t=\frac{1}{v^{2 n+1}} \int_{-\infty}^{+\infty} e^{-\alpha^2 \alpha^{2 n}} d \alpha=\frac{T\left(\frac{2 n+1}{2}\right)}{v^{2 n+1}}
\]
\[
\int_{-\infty}^{+\infty} e^{-v^2 t^2} t^{2 n} d t=\frac{1.3 .5 \ldots(2 n-1) \sqrt{\pi}}{2^n v^{2 n+1}}=\frac{\sqrt{\pi}}{v^{2 n+1}} A_n .
\]

Cette valeur étant substituée ci-dessus, on obtient
\[
\int_{-\infty}^{+\infty} \varphi(x+t) e^{-v^2 t^2} d t=\frac{\sqrt{x}}{v}\left(\varphi x+\frac{A_1}{2} \frac{\tau^{\prime \prime} x}{v^2}+\frac{A_2}{2.3 .4} \tau^{r^{\prime \prime \prime \prime} x}+\ldots\right) .
\]

En multipliant par \(e^{-v^2 y^2} v d v\), et prenant l'intégrale depuis \(v=-\infty\) jusqu'à \(v=+\infty\), on obtiendra
\[
\frac{1}{\sqrt{\pi}} \int_{-\infty}^{+\infty} e^{-v^2 y^2} v d v \int_{-\infty}^{+\infty} \varphi(x+t) e^{-v^2 t^2} d t=\varphi x \int_{-\infty}^{+\infty} e^{-v^2 y^2} d v+\frac{A_1 \varphi^{\prime \prime} x}{2} \int_{-\infty}^{+\infty} e^{-v^2 y^2} \frac{d v}{v^2}+\ldots
\]
%20
Soit \(v y=\beta\), on a
\[
\int_{-\infty}^{+\infty} e^{-v^2 y^2} v^{-2 n} d v=y^{2 n-1} \int_{-\infty}^{+\infty} e^{-\beta^2} \beta^{-2 n} d \beta
\]

Or \(\int_{-\infty}^{+\infty} e^{-\beta^2} \beta^{-2 n} d \beta=I^{\prime}\left(\frac{1-2 n}{2}\right)=\frac{(-1)^n 2^n \sqrt{\pi}}{1.3 .5 \ldots(2 n-1)}=\frac{(-1)^n \sqrt{\pi}}{A_n}\), donc
\[
\int_{-\infty}^{+\infty} e^{-v^2 y^2} v^{-2 n} \cdot d v=\frac{(-1)^n \sqrt{\pi} y^{2 n-1}}{A_u}
\]
et par suite
\[
A_n \int_{-\infty}^{+\infty} e^{-v^2 y^2} v^{-2 n} d v=(-1)^n y^{2 n-1} \sqrt{\pi}
\]

En substituant cette valeur, et divisant par \(\frac{\sqrt{\pi}}{2 y}\), on obtiendra
\[
\frac{2 y}{x} \int_{-\infty}^{+\infty} e^{-v^2 y^2} v d v \int_{-\infty}^{+\infty} \varphi(x+t) e^{-v^2 t^2} d t=2\left(\varphi x-\frac{\varphi^{\prime \prime} x}{2} y^2+\frac{\varphi^{\prime \prime \prime \prime} x}{2.3 .4} y^4-\ldots\right)
\]

Le second membre de cette équation est égal à
done
\[
\varphi(x+y \sqrt{-1})+\varphi(x-y \sqrt{-1}),
\]
\[
\varphi(x+y \sqrt{-1})+\varphi(x-y \sqrt{-1})=\frac{2 y}{\pi} \int_{-\infty}^{+\infty} e^{-v^2 y^2} v d v \int_{-\infty}^{+\infty} \varphi(x+t) e^{-v^2 t^2} d t
\]

Posant \(x=0\), on a
\[
\varphi(y \sqrt{-1})+\varphi(-y \sqrt{-1})=\frac{2 y}{\pi} \int_{-\infty}^{+\infty} e^{-v^2 y^2} v d v \int_{-\infty}^{+\infty} \varphi t \cdot e^{-v^2 t^2} d t .
\]

Soit par exemple \(\varphi t=e^t\), on aura
done
\[
\varphi(y \sqrt{-1})+\varphi(-y \sqrt{-1})=e^{y \sqrt{-1}}+e^{-y \sqrt{-1}}=2 \cos y,
\]
\[
\cos y=\frac{y}{x} \int_{-\infty}^{+\infty} e^{-v^2 y^2} v d v \int_{-\infty}^{+\infty} e^{t-v^2 t^2} d t
\]
or \(\int_{-\infty}^{+\infty} e^{t-v^2 t^2} d t=\frac{\sqrt{\pi}}{v} e^{\frac{1}{4 v^2}}\), done
\[
\cos y=\frac{y}{\sqrt{\pi}} \int_{-\infty}^{+\infty} e^{-v^2 y^2+\frac{1}{4 v^2}} d v
\]

Si l'on fait \(v=\frac{t}{y}\), on aura
%21
\[
\cos y=\frac{1}{\sqrt{\pi}} \int_{-\infty}^{+\infty} e^{-t^2+\frac{1}{4} \frac{y^2}{t^2}} d t \text {. }
\]

En donnant d'autres valeurs à \(p t\), on pent déduire la valeur d'autres intégrales définies, mais comme mon but était seulement de déterminer la valeur de \(\varphi(x+y \sqrt{-1})+\varphi(x-y \sqrt{-1})\) je ne m'en occuperai pas.
3.

Nombres de Bernoulli exprimés par des intégrales définies, d'où l'on a ensuite dédunit l'eapression de l'intégrale finie \(\mathbf{\Sigma} q x\).
Si l'on développe la fonction \(1-\frac{u}{2} \cot \frac{u}{2}\) en série suivant les puissances entières de \(u\), en posant
\[
1-\frac{u}{2} \cot \frac{u}{2}=A_1 \frac{u^2}{2}+A_2 \frac{u^4}{2.3 .4}+\ldots+A_n \frac{u^{2 n}}{2.3 .4 . .2 n}+\ldots,
\]
les coefficiens \(A_1, A_2, A_3\) etc. sont, comme on sait, les nombres de Bernoulli.*) On \(\left.\mathrm{a}^{* *}\right)\)
\[
1-\frac{u}{2} \cot \frac{u}{2}=2 u^2\left(\frac{1}{4 \pi^2-u^2}+\frac{1}{4.4 \pi^2-u^2}+\frac{1}{9.4 \pi^2-u^2}+\ldots\right)
\]
et en développant le second membre en série:
\[
\begin{aligned}
1-\frac{u}{2} \cot \frac{u}{2} & =\frac{u^2}{2 \pi^2}\left(1+\frac{1}{2^2}+\frac{1}{3^2}+\ldots\right) \\
& +\frac{u^4}{2^3 \pi^4}\left(1+\frac{1}{2^4}+\frac{1}{3^4}+\ldots\right) \\
& +\frac{u^6}{2^5 \pi^6}\left(1+\frac{1}{2^6}+\frac{1}{3^6}+\ldots\right) \\
& \ldots \ldots \ldots \ldots) \\
& +\frac{u^{2 n}}{2^{2 n-1} \pi^{2 n}}\left(1+\frac{1}{2^{2 n}}+\frac{1}{3^{2 n}}+\ldots\right) \\
& +\cdots \cdots \ldots .
\end{aligned}
\]

En comparant ce développement au précédent, on aura
\[
\frac{A_n}{1.2 .3 \ldots 2 n}=\frac{1}{2^{2 n-1} x^{2 n}}\left(1+\frac{1}{2^{2 n}}+\frac{1}{3^{2 n}}+\ldots\right) \text {. }
\]
*) Voyez Euleri Institutiones calc. diff. p. 426.
**) Voyez Euleri Institutiones calc. diff. p. 423.
%22
Considérons maintenant l'intégrale \(\int_0^{\frac{1}{0}} \frac{t^{2 n-1} d t}{e^t-1}\). On a
\[
\frac{1}{e^t-1}=e^{-t}+e^{-2 t}+e^{-3 t}+\ldots,
\]
done
\[
\int \frac{t^{2 n-1} d t}{e^t-1}=\int e^{-t} t^{2 n-1} d t+\int e^{-2 t} t^{2 n-1} d t+\ldots+\int e^{-k t} t^{2 n-1} d t+\ldots
\]

Or \(\left.\int_0^{\frac{1}{0}} e^{-k t} t^{2 n-1} d t=\frac{\boldsymbol{r}(2 n)}{k^{2 n}} *\right)\), done
\[
\int_0^{\frac{1}{n}} \frac{t^{2 n-1} d t}{e^t-1}=I^{\prime}(2 n)\left(1+\frac{1}{2^{2 n}}+\frac{1}{3^{2 n}}+\ldots\right)
\]
mais d'après ce qui précède, on a
\[
1+\frac{1}{2^{2 n}}+\frac{1}{3^{2 n}}+\ldots=\frac{2^{2 n-1} \pi^{2 n}}{1.2 .3 \ldots 2 n} A_n-\frac{2^{2 n-1} \pi^{2 n}}{\boldsymbol{r}(2 n+1)} A_n,
\]
donc:
\[
\int_0^{\frac{1}{0}} \frac{t^{2 n-1} d t}{e^t-1}=\frac{\Gamma(2 n)}{\Gamma(2 n+1)} 2^{2 n-1} \pi^{2 n} A_n=\frac{2^{2 n-1} \pi^{2 n}}{2 n} A_n,
\]
et par conséquent
\[
A_n=\frac{2 n}{2^{2 n-1} / r^{2 n}} \int_0^{\frac{1}{0}} \frac{t^{2 n-1} d t}{e^t-1} .
\]

En mettant \(t_\pi\) au lieu de \(t\), on obtiendra enfin
\[
A_n=\frac{2 n}{2^{2 n-1}} \int_0^{\frac{1}{0}} \frac{t^{2 n-1} d t}{e^{\pi t}-1} .
\]

Ainsi les nombres de Bernoulli peuvent être exprimés d'une manière très simple, par des intégrales définies.

D'mu autre côté on voit aussi, lorsque \(n\) est un nombre entier, que l'expression \(\int_0^{\frac{1}{n}} \frac{t^{2 n-1} d t}{p^{\prime \prime}-1}\) est toujours rationnelle et égale à \(\frac{2^{2 n-1}}{2 n} \Lambda_n\), ce qui est assez remarquable. Ainsi on aura par. exemple en faisant \(n=1,2,3\) etc.
\[
\begin{aligned}
& \int_0^{\frac{1}{6}} \frac{t d t}{e^{\pi t}-1}=\frac{1}{6}, \\
& \int_0^{\frac{1}{0}} \frac{t^3 d t}{e^{\pi t}-1}=\frac{1}{30} \cdot \frac{2^3}{4}=\frac{1}{15},
\end{aligned}
\]
*) Cette expression se déduit de l'équation fondamentale \(I a=\int_0^1 d x\left(\log \frac{1}{x}\right)^{a-1}\), en y. faisant \(a=2 n\). et \(x=e^{-k t}\). Legendre, Exercices de calc. int. t. I, p. 277 .
%23
\[
\int_0^{\frac{1}{6}} \frac{t^5 d t}{e^{\pi t}-1}=\frac{1}{42} \cdot \frac{2^0}{6}-\frac{8}{63} \text { etc. }
\]

Naintenant à l'aide de ce qui précèrle, on pourra très facilement exprimer la fonction \(\Sigma \varphi x\) par une intégrale définie. On a
\[
\Sigma \varphi x=\int \varphi x \cdot d x-\frac{1}{2} \varphi x+A_1 \frac{\varphi^{\prime} x}{1.2}-A_2 \frac{\varphi^{\prime \prime \prime} \cdot x}{1.2 .3 .4}+\ldots
\]

En substituant les valeurs de \(A_1, A_2, A_3\) etc., on aura
\[
\Sigma \varphi x=\int \varphi x \cdot d x-\frac{1}{2} \varphi x+\frac{\varphi^{\prime} x}{1.2} \int_0^{\frac{1}{0}} \frac{t d t}{e^{\pi t}-1}-\frac{\varphi^{\prime \prime \prime} x}{1.2 \cdot 3 \cdot 2^3} \int_0^{\frac{1}{0}} \frac{t^3 d t}{e^{\pi t}-1}+\ldots
\]
c'est-à-dire
\[
\Sigma \varphi x=\int \varphi x \cdot d x-\frac{1}{2} \varphi x+\int_0^{\frac{1}{0}} \frac{d t}{e^{\pi t}-1}\left(\varphi^{\prime} x \frac{t}{2}-\frac{\varphi^{\prime \prime \prime} x}{1.2 .3} \frac{t^3}{2^3}+\ldots\right)
\]
\(\mathrm{Or}\)
\[
\begin{aligned}
& \varphi\left(x+\frac{t}{2} \sqrt{-1}\right)=\varphi x-\frac{\varphi^{\prime \prime} \cdot x}{1.2} \frac{t^2}{2^2}+\frac{\tau^{\prime \prime \prime \prime} \cdot x}{1.2 .3 .4} \frac{t^4}{2^4}-\ldots \\
& +\sqrt{-1}\left(\varphi^{\prime} x \frac{t}{2}-\frac{\varphi^{\prime \prime \prime} x}{1.2 .3} \frac{t^3}{2^3}+\ldots\right), \\
& \varphi\left(x-\frac{t}{2} \sqrt{-1}\right)=\varphi x-\frac{\tau^{\prime \prime} \cdot x}{1.2} \frac{t^2}{2^2}+\frac{\tau^{\prime \prime \prime \prime} \cdot x}{1.2 .3 .4} \frac{t^4}{2^4}-\ldots \\
& -\sqrt{-1}\left(\varphi^{\prime} x \frac{t}{2}-\frac{\varphi^{\prime \prime \prime} x}{1.2 .3} \frac{t^3}{2^3}+\ldots\right) \\
&
\end{aligned}
\]

On tire de là
\[
\varphi^{\prime} x \cdot \frac{t}{2}-\frac{\varphi^{\prime \prime \prime} x}{1.2 .3} \frac{t^3}{2^3}+\ldots=\frac{1}{2 \sqrt{-1}}\left[\varphi\left(x+\frac{t}{2} \sqrt{-1}\right)-\varphi\left(x-\frac{t}{2} \sqrt{-1}\right)\right] .
\]

Cette valeur étant substituée dans l'expression de \(\Sigma \varphi x\), on obtient
\[
\Sigma \varphi x=\int \tau x \cdot d x-\frac{1}{2} \varphi x+\int_0^{\frac{1}{8}} \frac{\tau\left(x+\frac{t}{2} \sqrt{-1}\right)-\tau\left(x-\frac{t}{2} \sqrt{-1}\right)}{2 \sqrt{-1}} \frac{d t}{e^{\pi t}-1} .
\]

Cette expression de l'intégrale finie d'une fonction quelconque me paraît très remarquable, et je ne crois pas qu'elle ait été trouvée auparavant.
De l'équation précédente on tire
%24
On a ainsi l'expression d'une intégrale définie très générale. Je vais en faire voir l'application à quelques cas particuliers.
1. Soit \(\varphi x=e^x\). Dans ce cas on a
\[
\varphi\left(x+\frac{t}{2} \sqrt{-1}\right)=e^x e^{\frac{t}{2} \sqrt{-1}}=e^x\left(\cos \frac{t}{2}+\sqrt{-1} \sin \frac{t}{2}\right),
\]
done
\[
\frac{\tau\left(x+\frac{t}{2} \sqrt{-1}\right)-\tau\left(x-\frac{t}{2} \sqrt{-1}\right)}{2 \sqrt{-1}}=e^x \sin \frac{t}{2},
\]
et par conséquent
\[
\begin{gathered}
\int_0^{\frac{1}{t}} \frac{\sin \frac{t}{2} d t}{e^{x t}-1}=e^{-x} \Sigma e^x-e^{-x} \int e^x d x+\frac{1}{2} \\
\text { mais } \Sigma e^x-\frac{e^x}{t-1} \text {, et } \int e^x d x=e^x \text {, donc } \\
\int_0^{\frac{1}{0}} \frac{\sin \frac{t}{2} d t}{e^{x t}-1}=\frac{1}{e-1}-\frac{1}{2} .
\end{gathered}
\]

Si l'on fait \(\varphi x=e^{m x}\), on obtiendra de la même manière
\[
\int_0^{\frac{1}{0}} \frac{\sin \frac{n t}{2} d t}{e^{\pi t}-1}=\frac{1}{e^m-1}-\frac{1}{m}+\frac{1}{2}
\]

Si l'on met \(2 t\) à la place de \(t\), on aura
\[
\int_0^{\frac{1}{0}} \frac{\sin m t \cdot d t}{e^{2 \pi t}-1}=\frac{1}{4} \frac{e^m+1}{e^m-1}-\frac{1}{2 m},
\]
formule trouvée d'une autre manière par M. Legendre. (Exerc. de calc. int. t. II, p. 189.)
2. Soit \(\varphi x=\frac{1}{x}\), on trouvera
\[
\frac{\uparrow\left(x+\frac{t}{2} \sqrt{-1}\right)-\uparrow\left(x-\frac{t}{2} \sqrt{-1}\right)}{2 \sqrt{-1}}=-\frac{t}{2\left(x^2+\frac{1}{4} t^2\right)},
\]
et
\[
\int \varphi x \cdot d x=\int \frac{d x}{x}=\log x+C
\]
%25
done
\[
\int_0^{\frac{1}{0}} \frac{t d t}{\left(x^2+1 t^2\right)\left(e^{\pi t}-1\right)}=2 \log x-\frac{1}{x}-2 \Sigma \frac{1}{x}+C .
\]

On détermine \(C^{\prime}\) en posant \(x=1\), ce qui donne
\[
C=3+\int_0^{\frac{1}{0}} \frac{t d t}{\left(1+\frac{1}{4} t^2\right)\left(e^{\pi t}-1\right)} .
\]
3. Soit \(\varphi x=\sin a x\), on aura
\[
\begin{gathered}
\sin \left(a x+\frac{a t}{2} \sqrt{-1}\right)-\sin \left(a x-\frac{a t}{2} \sqrt{-1}\right)=2 \cos a x \cdot \sin \frac{a t}{2} \sqrt{-1}=\cos a x \frac{e^{-\frac{a t}{2}}-e^{\frac{a b}{2}}}{\sqrt{-1}} \\
\Sigma \sin a x=-\frac{\cos \left(a x-\frac{1}{2} a\right)}{2 \sin \frac{1}{2} a}, \int \sin a x \cdot d x=-\frac{1}{a} \cos a x
\end{gathered}
\]
done
\[
\frac{\cos a x}{2} \int_0^{\frac{1}{b t}} \frac{e^{\frac{a t}{2}}-e^{-\frac{a t}{2}}}{e^{\pi t}-1} d t=-\frac{\cos \left(a x-\frac{1}{2} a\right)}{2 \sin \frac{1}{2} a}+\frac{1}{a} \cos a x+\frac{1}{2} \sin a x,
\]
et en écrivant \(2 a\) au lieu de \(a\), et réduisant
\[
\int_0^{\frac{1}{0}} \frac{e^{a t}-e^{-a t}}{e^{\pi t}-1} d t=\frac{1}{a}-\operatorname{cotg} a
\]

En supposant d'autres formes pour la fonction \(\varphi x\) on pourra de la même manière trouver la valeur d'autres intégrales définies.
4.
Sonmution de la série infinie \(S=\uparrow(x+1)-\uparrow(x+2)+\boldsymbol{q}(x+3)-\varphi(x+4)+\cdots\) à l'cuide dintégrales définies.
On voit aisément que \(S\) pourra être exprimé comme il suit,
\[
S=\frac{1}{2} \varphi x+A_1 \varphi^{\prime} x+A_2 \varphi^{\prime \prime} x+A_3 \varphi^{\prime \prime \prime} x+\ldots
\]

Si l'on suppose \(\varphi x=e^{a x}\) on obtient
\[
S=\frac{1}{2} e^{a x}+e^{a x}\left(A_1 a+A_2 a^2+A_3 a^3+\ldots\right) .
\]

Mais on a aussi
\[
S=e^{a x+a}-e^{a x+2 a}+e^{a x+3 a}-\ldots=\frac{e^{a x} e^a}{1+e^a}
\]
%26
done
\[
\frac{e^a}{1+e^a}-\frac{1}{2}=A_1 a+A_2 a^2+A_3 a^3+\ldots
\]

En faisant \(a=c \sqrt{-1}\), on trouve
\[
\frac{e^{c \sqrt{-1}}}{1+e^{c \sqrt{-1}}}-\frac{1}{2}=V-1\left(A_1 c-A_3 c^3+A_5 c^{\tilde{5}}-\ldots\right)+P
\]
où \(P\) désigne la somme de tous les termes réels. Mais
\[
\frac{e^{c \sqrt{-1}}}{1+e^{c \sqrt{-1}}}-\frac{1}{2}=\frac{1}{2} \frac{e^{\frac{c}{z} \sqrt{-1}}-e^{-\frac{c}{2} \sqrt{-1}}}{e^{\frac{c}{2} \sqrt{-1}}+e^{-\frac{c}{2} \sqrt{-1}}}=\frac{1}{2} \sqrt{-1} \operatorname{tang} \frac{1}{2} c
\]
donc
\[
\frac{1}{2} \text { tang } \frac{1}{2} c=A_1 c-A_3 c^3+A_5 c^5-\ldots
\]

Or on a (Legendie Exerc. de calc. int. t. II, p. 186)
done, puisque
\[
\frac{1}{2} \operatorname{tang} \frac{1}{2} c=\int_0^{\frac{1}{0}} \frac{e^{c t}-e^{-c t}}{e^{\pi t}-e^{-\pi t}} d t,
\]
\[
e^{c t}-e^{-c t} \doteq 2\left\{c t+\frac{c^3}{2.3} t^3+\frac{e^5}{2.3 .4 .5} t^5+\ldots\right\},
\]
on obtient
\[
\begin{gathered}
\frac{1}{2} \text { tang } \frac{1}{2} c=A_1 c-A_3 c^3+A_5 c^5-\ldots \\
=2 c \int_0^{\frac{1}{0}} \frac{t d t}{e^{\pi t}-e^{-\pi t}}+2 \frac{c^3}{2.3} \int_0^{\frac{1}{0}} \frac{t^3 d t}{e^{\pi t}-e^{-\pi t}}+2 \frac{e^5}{2.3 .4 .5} \int_0^{\frac{1}{0}} \frac{t^5 d t}{e^{\pi t}-e^{-\pi t}}+\ldots
\end{gathered}
\]

On en conclut,
\[
\begin{aligned}
& A_1=2 \int_0^{\frac{1}{0}} \frac{t d t}{e^{\pi t}-e^{-\pi t}}, \\
& A_3=-\frac{2}{2.3} \int_0^{\frac{1}{0}} \frac{t^3 d t}{e^{\pi t}-e^{-\pi t}}, \\
& A_5=\frac{2}{2.3 .4 .5} \int_0^{\frac{1}{0}} \frac{t^5 d t}{e^{\pi t}-e^{-\pi t}},
\end{aligned}
\]
etc.
En substituant ces valeurs dans l'expression pour \(S\), on trouve
\[
\left.\left.S=\frac{1}{2} \varphi x+2 \int_0^{\frac{2}{6}} \frac{d t}{e^{\pi t}-e^{-n t}}\right\} t \varphi^{\prime} x-\frac{t^3}{2.3} \varphi^{\prime \prime \prime} x+\frac{t^5}{2.3 .4 .5} \varphi^{(V)} x-\ldots\right\}
\]
mais on a
%27
\[
t \varphi^{\prime} x-\frac{t^3}{2.3} \varphi^{\prime \prime \prime} x+\frac{t^5}{2.3 .4 .5} \varphi^{(V)} x-\ldots=\frac{\tau(x+t \sqrt{-1})-\uparrow\left(x-t V^{\prime}-1\right)}{2 \sqrt{-1}},
\]
done
\[
\begin{aligned}
& \varphi(x+1)-\varphi(x+2)+\varphi(x+3)-\varphi(x+4)+\cdots \\
& =\frac{1}{2} \varphi x+2 \int_0^{\frac{1}{n}} \frac{d t}{e^{n t}-e^{-x t}} \frac{\varphi(x+t \sqrt{-1})-\varphi(x-t \sqrt{-1})}{2 \sqrt{-1}} .
\end{aligned}
\]

Si l'on pose \(x=0\), on obtient
\[
\begin{aligned}
& \varphi(1)-\varphi(2)+\varphi(3)-\varphi(4)+\ldots \text { in inf. } \\
& =\frac{1}{2} \varphi(0)+2 \int_0^{\frac{1}{0}} \frac{d t}{e^{\pi t}-e^{-\pi t}} \frac{\varphi(t \sqrt{-1})-\varphi(-t \sqrt{-1})}{2 \sqrt{-1}} .
\end{aligned}
\]

Supposons par exemple \(\varphi x=\frac{1}{x+1}\), on a
\[
\frac{\varphi(t \sqrt{-1})-\varphi(-t \sqrt{-1})}{2 \sqrt{-1}}=-\frac{t}{1+t^2}
\]
done
\[
\frac{1}{2}-\frac{1}{3}+\frac{1}{4}-\frac{1}{5}+\ldots=\frac{1}{2}-2 \int_0^{\frac{1}{v}} \frac{\cdot t d t}{\left(1+t^2\right)\left(e^{3 t}-e^{-\pi t}\right)}
\]
or on a
\[
\frac{1}{2}-\frac{1}{3}+\frac{1}{4}-\frac{1}{5}+\cdots=1-\log 2
\]
par conséquent
\[
\int_0^{\frac{1}{0}} \frac{t d t}{\left(1+t^2\right)\left(e^{\pi t}-e^{-\pi t}\right)}=\frac{1}{2} \log 2-\frac{1}{4}
\]
%28
III.

MÉMOIRE SUR LES ÉQUATIONS ALGÉBRIQUES, OU L'ON DÉMONTRE L'IMPOSSIBILITÉ DE LA RÉSOLUTION DE L'ÉQUATION GÉNÉRALE DU CINQUIÈME DEGRÉ.
Brochure imprimée chez Grondahl, Christiania 1824.
Les gémètres se sont beaucoup occupés de la résolution générale des équations algébriques, et plusieurs d'entre eux ont cherché à en prouver l'impossibilité; mais si je ne me trompe pas, on n'y a pas réussi jusqu'à présent. J'ose donc espérer que les géomètres recevront avec bienveillance ce mémoire qui a pour but de remplir cette lacune dans la théorie des équations algébriques.
Soit
\[
y^5-a y^4+b y^3-c y^2+d y-e=0
\]
l'équation générale du cinquième degré, et supposons qu'elle soit résoluble algébriquement, e'est-à-dire qu'on puisse exprimer y par une fonction des quantités \(a, b, c, d\) et \(e\), formée par des radicaux. Il est clair qu'on peut dans ce cas mettre \(y\) sous la forme:
\[
y=p+p_1 R^{\frac{1}{m}}+p_2 R^{\frac{8}{m}}+\ldots+p_{m-1} R^{\frac{m-1}{m}}
\]
\(m\) étant un nombre premier et \(R, p, p_1, p_2\) etc. des fonctions de la même forme que \(y\), et ainsi de suite jusqu'à ce qu'on parvienne à des fonctions rationnelles des quantités \(a, b, c, d\) et \(e\). On pent aussi supposer qu'il soit impossible d'exprimer \(R^{\frac{1}{m}}\) par une fonction rationnelle des quantités \(a, b\) etc. \(p, p_1, p_2\) etc., et en mettant \(\frac{R}{p_1^m}\) au lieu de \(R\) il est clair qu'on pent faire \(p_1=1\). On aura donc,
%29
\[
y=p+l^{\frac{1}{m}}+p_z l^{\frac{2}{m}}+\ldots+p_{m-1} l^{m-1} .
\]

En substituant cette valeur de y dans l'équation proposée, on obtiendra en réduisant un résultat de cette forme,
\[
P=q+q_1 R^{\frac{1}{m}}+q_2 R^{\frac{2}{m}}+\ldots+q_{m-1} R^{\frac{m-1}{m}}=0
\]
\(q, q_1, q_2\) etc. étant des fonctions rationnelles et entières des quantités \(a, b, c, d, e, p, p_2\) etc. et \(R\). Pour que cette équation puisse avoir lien il faut que \(q=0, q_1=0, q_8=0\) etc. \(q_{m-1}=0\). En effet, en désignant \(R^{\frac{1}{2}}\) par \(z\), on aura les deux équations
\[
z^m-R=0 \text { et } q+q_1 z+\cdots+q_{m-1} z^{m-1}=0 .
\]

Si maintenant les quantités \(q, q_1\) etc. ne sont pas égales à zéro, ces équations ont nécessairement une ou plusieurs racines communes. Soit \(k\) le nombre de ces racines, on sait qu'on peut trouver une équation du degré \(k\) qui a pour racines les \(k\) racines mentionnées, et dans laquelle. tous les coefficiens sont des fonctions rationnelles de \(R, q, q_1\) et \(q_{v^{\prime-1}-1}\). Soit
\[
r+r_1 z+r_2 z^2+\cdots+r_k z^k=0
\]
cette équation. Elle a ces racines communes avec l'équation \(z^m-R=0\); or toutes les racines de cette équation sont de la forme \(\alpha_\mu z, \alpha_\mu\) désignant une des racines de l'équation \(\alpha_\mu^m-1=0\). On aura donc en substituant les équations suivantes,
\[
\begin{gathered}
r+r_1 z+r_2 z^2+\ldots+r_k z^k=0 \\
r+\alpha r_1 z+\alpha^2 r_2 z^2+\cdots+\alpha^k r_k z^k=0 \\
\cdots \cdots \cdots \cdots \cdots \\
r+\alpha_{k-2} r_1 z+\alpha_{k-2}^2 r_2 z^2+\cdots+\alpha_{k-2}^k r_k z^k=0
\end{gathered}
\]

De ces \(k\) équations, on peut tonjours tirer la valeur de \(z\) exprimée par une fonction rationnelle des quantités \(r, r_1, r_2\) etc. \(r_k\), et comme ces quantités sont elles-mêmes des fonctions rationnelles de \(a, b, c, d, e, R \ldots p, p_2\) etc., il s'en suit que \(z\) est aussi une fonction rationnelle de ces dernières quantités; mais cela est contre l'hypothèse. Il faut donc que
\[
q=0, q_1=0 \text { etc: } q_{m-1}=0 \text {. }
\]

Si maintenant ces équations ont lien, il est clair que l'équation proposée est satisfaite par toutes les valeurs qu'on obtiendra pour \(y\), en domnant à \(R^{\frac{1}{m}}\) toutes les valeurs
\[
R^{\frac{1}{2 n}}, \alpha R^{\frac{1}{2 n}}, \alpha^2 R^1, \alpha^3 R^1 \text {, etc. } \alpha^{m-1} R^{\frac{1}{m}}
\]
%30
\(\alpha\) étant une racine de l'équation
\[
\text { e } \quad \alpha_a^{m-1}+\alpha^{m-2}+\cdots+\alpha+1=0 \text {. }
\]

On voit aussi que toutes ces valeiurs de \(y\) sont différentes; car dans le cas contraire on aurait une équation de la même forme que l'équation \(P=0\), et une telle équation conduit comme on vient de le voir à un résultat qui ne peut avoir lieu. Le nombre \(m\) ne peut donc dépasser 5. En désignant done par \(y_1, y_2, y_3, y_4\) et \(y_5\) les racines de l'équation proposée, on alura
\[
\begin{gathered}
y_1=p+R^{\frac{1}{m}}+p_2 R^{\frac{2}{m}}+\ldots+p_{m-1} R^{m-1} \\
y_2^m \\
\ldots+\alpha R^{\frac{1}{m}}+\alpha^2 p_2 R^{\frac{2}{m}}+\ldots+\alpha^{m-1} p_{m-1} R^{\frac{m-1}{m}} \\
y_m=p+\alpha^{m-1} R^{\frac{1}{m}}+\alpha^{m-2} p_2 R^{\frac{2}{m}}+\ldots \ldots \ldots \ldots p_{m-1} R^{\frac{m-1}{m}} .
\end{gathered}
\]

De ces équations on tirera sans peine
\[
\begin{aligned}
p & =\frac{1}{m}\left(y_1+y_2+\ldots+y_m\right), \\
R^{\frac{1}{m}} & =\frac{1}{m}\left(y_1+\alpha^{m-1} y_2+\ldots+\alpha y_m\right), \\
p_2 R^{\frac{2}{m}} & =\frac{1}{m}\left(y_1+\alpha^{m-2} y_2+\ldots+\alpha^2 y_m\right), \\
\cdots & \cdots \cdots \\
p_{m-1} R^{\frac{m-1}{m}} & =\frac{1}{m}\left(y_1+\alpha y_2+\ldots+\alpha^{m-1} y_m\right) .
\end{aligned}
\]

On voit par là que \(p, p_2\) etc. \(p_{m-1}, R\) et \(R^{\frac{1}{m}}\) sont des fonctions rationnelles des racines de l'équation proposée.
Considérons maintenant l'une quelconque de ces quantités, par exemple
R. Soit
\[
R=S+v^{\frac{1}{n}}+S_2 v^{\frac{2}{n}}+\cdots+S_{n-1} v^{\frac{n-1}{n}} \text {. }
\]

En traitant cette quantité de la même manière que \(y\), on obtiendra un résultat pareil savoir que les quantités \(v^{\frac{1}{n}}, v, S, S_2\) etc. sont des fonctions rationnelles des différentes valeurs de la fonction \(R\); et comme celles-ci sont des fonctions rationnelles de \(y_1, y_2\) etc., les fonctions \(\frac{1}{v^n}, v, S, S_z\) etc. le sont de même. En poursuivant ce raisonnement on conclura que toutes
%31
les fonctions irrationnelles contenues dans l'expression de \(y\) sont des fonctions ratiomnelles des racines de l'équation proposée.

Cela posé, il n'est pas difficile d'achever la démonstration. Considérons d'abord les fonctions irrationnelles de la forme' \(R^{\frac{1}{m}}, R\) étant une fonction rationnelle de \(a, b, c, d\) et \(e\). Soit \(R^{\frac{1}{m}}=r, r\) est une fonction rationnelle \(y_1, y_2, y_3, y_4\) et \(y_5\), et \(R\) une fonction symétrique de ces quantités. Maintenant comme il s'agit de la résolution de l'équation générale du cinquième degré, il est clair qu'on peut considérer \(y_1, y_2, y_3, y_4\) et \(y_5\) comme des variables indépendantes; l'équation \(R^{\frac{1}{m}}=r\) doit donc avoir lieu dans cette supposition. Par conséquent on peut échanger les quantités \(y_1, y_2, y_3, y_4\) et \(y_5\) entre elles dans l'équation \(R^{\frac{1}{m}}=r\); or par ce changement \(R^{\frac{1}{m}}\) obtient nécessairement \(m\) valeurs différentes en remarquant que \(R\) est une fonction symétrique. La fonction \(r\) doit.donc avoir la propriété qu'elle obtient \(m\) valeurs différentes en permutant de toutes les manières possibles les cinq variables qu'elle contient. Or pour cela il faut que \(m=5\) ou \(m=2\) en remarquant que \(m\) est un nombre premier. (Voyez un mémoire de M. Cauchy inséré dans le. Journal de l'école polytechnique, XVII \({ }^{\circ}\) Cahier). Soit d'abord \(m=5\). La fonction \(r\) a donc cinq valeurs différentes; et peut par conséquent être mise sous la forme
\[
R^{\frac{1}{5}}=r=p+p_1 y_1+p_2 y_1^2+p_3 y_1^3+p_4 y_1^4
\]
\(\mu, p_1, p_2 \ldots\) étant des fonctions symétriques de \(y_1, y_2\) etc. Cette équation lomme en changeant \(y_1\) en \(y_2\)
\[
p+p_1 y_1+p_2 y_1^2+p_3 y_1^3+p_4 y_1^4=\alpha p+\alpha p_1 y_2+\alpha p_2 y_2^2+\alpha p_3 y_2^3+\alpha p_4 y_2^4
\]
où
\[
\alpha^4+\alpha^3+\alpha^2+\alpha+1=0
\]
mais cette équation ne peut avoir lieu; le nombre \(m\) doit par conséquent être égal à deux. Soit donc
\[
R^{\frac{1}{2}}=r,
\]
1. doit avoir deux valeurs différentes et de signe contraire; on aura donć (voyez le mémoire de M. Cauchy)
\[
R^{\frac{1}{2}}=r=v\left(y_1-y_2\right)\left(y_1-y_3\right) \ldots\left(y_2-y_3\right) \ldots\left(y_4-y_5\right)=v S^{\frac{1}{2}}
\]
\(v\) étant une fonction symétrique.
%32
Considérons maintenant les fonctions irrationnelles de la forme
\[
\left(p+p_1 R^{\frac{1}{\nu}}+p_2 R_1^{\frac{1}{\mu}}+\ldots\right)^{\frac{1}{m}}
\]
\(\nu, p_1, p_2\) etc., \(R, R_1\) etc. étant des fonctions rationnelles de \(a, b, c, d\) et et par conséquent des fonctions symétriques de \(y_1, y_2, y_3, y_4\) et \(y_5\). Comme on l'a vu, on doit avoir \(\nu=\mu=\) etc. \(=2, R=v^2 S, R_1=v_1^2 S\) etc. I La fonction précédente peut donc être mise sous la forme
Soit
\[
\left(p+p_1 S^{\frac{1}{2}}\right)^{\frac{1^{\circ}}{m}}
\]
\[
\begin{aligned}
& r=\left(p+p_1 S^{\frac{1}{2}}\right)^{\frac{1}{m}}, \\
& r_1=\left(p-p_1 S^{\frac{1}{2}}\right)^{\frac{1}{m}},
\end{aligned}
\]
on aura en multipliant,
\[
r r_1=\left(p^2-p_1^2 S\right)^{\frac{1}{m}}
\]

Si maintenant \(r r_1\) n'est pas une fonction symétrique, le nombre \(m\) doit être égal à deux; mais dans ce cas \(r\) aura quatre valeurs différentes, ce qui est impossible; il faut donc que \(r_1\) soit une fonction symétrique. Soit \(v\) cette fonction, on aura
\[
r+r_1=\left(p+p_1 S^{\frac{1}{2}}\right)^{\frac{1}{m}}+v\left(p+p_1 S^{\frac{1}{2}}\right)^{-\frac{1}{m}}=z .
\]

Cette fonction a \(m\) valeurs différentes, il faut donc que \(m=5\), en remarquant que \(m\) est un nombre premier. On aura par conséquent
\[
z=q+q_1 y+q_2 y^2+q_3 y^3+q_4 y^4=\left(p+p_1 S^{\frac{1}{2}}\right)^{\frac{1}{5}}+v\left(p+p_1 S^{\frac{1}{2}}\right)^{-\frac{1}{5}},
\]
\(q, q_1, q_2\) etc. étant des fonctions symétriques de \(y_1, y_2, y_3\) etc. et par conséquent des fonctions rationnelles de \(a, b, c, d\) et \(e\). En combinant cette équation avec l'équation proposée, on en tirera la valeur de \(y\) exprimée par une fonction rationelle de \(z, a, b, c, d\) et \(e\). Or une telle fonction est toujours réductible à la forne
\[
y=P+R^{\frac{1}{5}}+P_8 R^{\frac{2}{5}}+P_3 R^{\frac{3}{5}}+P_4 R^{\frac{4}{5}}
\]
où \(P, R, P_2, P_3\) et \(P_4\) sont des fonctions de la forme \(p+p_1 S^{\frac{1}{2}}, p, p_1\), et \(S\) étant des fonctions rationnelles de \(a, b, c, d\) et \(e\). De cette valeur de \(y\) on tire
%33
\[
R^{\frac{1}{5}}=\frac{1}{5}\left(y_1+\alpha^4 y_2+\alpha^3 y_3+\alpha^2 y_4+\alpha y_5\right)=\left(p+p_1 S^{\frac{1}{2}}\right)^{\frac{1}{5}}
\]
où
\[
\alpha^4+\alpha^3+\alpha^2+\alpha+1=0 .
\]

Or le premier membre a 120 valeurs différentes et le second membre seulement 10; par conséquent \(y\) ne peut avoir la forme que nous venons de trouver; mais nous avons démontré que \(y\) doit nécessairement avoir cette forme, si l'équation proposée est résoluble; nous conchons done
qu'il est impossible de résoudre par des radicaux l'équation générale du cinquième degré.

Il suit immédiatement de ce théorème qu'il est de même impossible de résoudre par des radicaux les équations générales des degrés supérieurs au cinquième.
%34
IV.

L'INTÉGRALE FINIE \(\Sigma \varphi x\) EXPRIMÉE PAR UNE INTÉGRALE 
SIMPLE.

Magazin for Naturvidenskaberne, Aargang III, Bind 2, Christiania 1825.

On pent comme on sait, au moyen du théorème de Parseval exprimer l'intégrale finie \(\Sigma^n \varphi x\) par une intégrale définie double, mais si je ne me trompe, on n'a pas exprimé la même intégrale par une intégrale définie simple. C'est ce qui est l'objet de ce mémoire.

En désignant par \(\varphi x\) une fonction quelconque de \(x\), il est aisé de voir qu'on peut toujours supposer
\[
\varphi x=\int e^{v x} f v \cdot d v
\]
l'intégrale étant prise entre deux limites quelconques de \(v\), indépendantes de \(x\). La fonction \(f v\) désigne une fonction de \(v\), dont la forme dépend de. celle de \(\rho x\). En supposant \(A x=1\), on aura en prenant l'intégrale finie des deux membres de l'équation (1)
\[
\Sigma \varphi x=\int e^{v x} \frac{t v}{e^v-1} d v
\]
où il faut ajouter une constante arbitraire. En prenant une seconde fois l'intégrale finie, on obtiendra
\[
\Sigma^2 \varphi x=\int e^{v x} \frac{f v}{\left(e^v-1\right)^2} d v .
\]

En général on trouvera
\[
\Sigma^n \varphi x=\int e^{v x} \frac{f v}{\left(e^v-1\right)^n} d v .
\]
%35
Pour compléter cette intégrale il faut ajouter au second membre une fonction de la forme
\[
C+C_1 x+C_2 x^2+\ldots+C_{n-1} x^{n-1}
\]
\(C, C_1, C_2\) etc. étant des constantes arbitraires.
Il s'agit maintenant de trouver la valeur de l'intégrale définie \(\int e^{v x} \frac{f v}{\left(e^v-1\right)^n} d v\). Pour cela je me sers d'un théorème dî à M. Legendre (Exerc. de calc. int. t. II, p. 189), savoir que
\[
\frac{1}{4} \frac{e^v+1}{e^v-1}-\frac{1}{2 v}=\int_0^{\frac{1}{0}} \frac{d t \cdot \sin v t}{e^{2 \pi t}-1}
\]

On tire "de cette équation
\[
\frac{1}{e^v-1}=\frac{1}{v}-\frac{1}{2}+2 \int_0^{\frac{1}{v}} \frac{d t \cdot \sin v t}{e^{2 x t}-1} .
\]

En substituant cette valeur de \(\frac{1}{e^v-1}\) dans l'équation (2), on aura
\[
\Sigma \varphi x=\int e^{v x} \frac{f v}{v} d v-\frac{1}{2} \int e^{v x} f v \cdot d v+2 \int_0^{\frac{1}{0}} \frac{d t}{e^{2 \pi t}-1} \int e^{v x} f v \cdot \sin v t \cdot d v .
\]

L'intégrale \(\int e^{v x} f v \cdot \sin v t . d v\) se trouve de la manière suivante. En remplaçant dans l'équation (1) \(x\) successivement par \(x+t \sqrt{-1}\) et \(x-t \sqrt{-1}\), on obtiendra
\[
\begin{aligned}
& \varphi(x+t \sqrt{-1})=\int e^{v x} e^{v t \sqrt{-1}} f v \cdot d v, \\
& \varphi(x-t \sqrt{-1})=\int e^{v x} e^{-v t \sqrt{-1}} f v \cdot d v,
\end{aligned}
\]
d'où l'on tire, en retranchant et divisant par \(2 \sqrt{-1}\),
\[
\int e^{v x} \sin v t \cdot f v \cdot d v=\frac{\tau(x+t \sqrt{-1})-q(x-t \sqrt{-1})}{2 \sqrt{-1}} .
\]

Ainsi l'expression de \(\Sigma(\rho x\) devient
\[
\Sigma \varphi x=\int \varphi x \cdot d x-\frac{1}{2} \varphi x+2 \int_0^{\frac{1}{0}} \frac{d t}{e^{2 \pi t}-1} \frac{\varphi(x+t \sqrt{-1})-\varphi(x-t \sqrt{-1})}{2 \sqrt{-1}} .
\]

Maintenant pour trouver la valeur de l'intégrale générale
\[
\Sigma^n \varphi x=\int e^{v x} f v \frac{d v}{\left(e^v-1\right)^n},
\]
posons
\[
\frac{1}{\left(\rho^v-1\right)^n}=(-1)^{n-1}\left(A_{0, n} p+A_{1, n} \frac{d p}{d v}+A_{2, n} \frac{d^2 p}{d v^2}+\ldots+A_{n-1, n} \frac{d^{n-1} p}{d v^{n-1}}\right)
\]
%36
où \(p\) est égal à \(\frac{1}{e^v-1}, A_{0, n}, A_{1, n} \ldots\) étant des coefficiens numériques qui doivent être déterminés. Si l'on différentie l'équation précédente, on a

Or
\[
\frac{n e^v}{\left(e^v-1\right)^{n+1}}=(-1)^n\left(A_{0, n} \frac{d p}{d v}+A_{1, n} \frac{d^2 p}{d v^2}+\ldots+A_{n-1, n} \frac{d^n p}{d v^n}\right) .
\]
done
\[
\frac{n e^v}{\left(e^v-1\right)^{n+1}}=\frac{n}{\left(e^v-1\right)^n}+\frac{n}{\left(e^v-1\right)^{n+1}},
\]
\[
\begin{aligned}
\frac{n e^v}{\left(e^v-1\right)^{n+1}} & =n(-1)^{n-1}\left(A_{0, n} p+A_{1, n} \frac{d p}{d v}+\ldots+A_{n-1, n} \frac{d^{n-1} p}{d v^{n-1}}\right) \\
& +n(-1)^n\left(A_{0, n+1} p+A_{1, n+1} \frac{d p}{d v}+\cdots+A_{n, n+1} \frac{d^n p}{d v^n}\right)
\end{aligned}
\]

En comparant ces deux expressions de \(\frac{n e^v}{\left(e^v-1\right)^{n+1}}\), on en déduit les équations suivantes:
\[
\begin{aligned}
& A_{0, n+1}-A_{0, n}=0 \quad \text { o: } \Delta A_{0, n}=0 \text {, } \\
& A_{1, n+1}-A_{1, n}=\frac{1}{n} A_{0, n} \quad \text { o: } \quad \Delta A_{1, n}=\frac{1}{n} A_{0, n}, \\
& A_{2, n+1}-A_{2, n}=\frac{1}{n} A_{1, n} \quad \text { o: } \quad 1 A_{2, n}=\frac{1}{n} A_{1, n}, \\
& \ldots \ldots \ldots \ldots \ldots \ldots \\
& A_{n-1, n+1}-A_{n-1, n}=\frac{1}{n} A_{n-2, n} \text { o: } \quad A A_{n-1, n}=\frac{1}{n} A_{n-2, n}, \\
& A_{n, n+1}=\frac{1}{n} A_{n-1, n} \\
&
\end{aligned}
\]
d'où l'on tire
\[
\begin{gathered}
A_{0, n}=1, A_{1, n}=\Sigma \frac{1}{n}, A_{2, n}=\Sigma\left(\frac{1}{n} \Sigma \frac{1}{n}\right), A_{3, n}=\Sigma\left[\frac{1}{n} \Sigma\left(\frac{1}{n} \Sigma \frac{1}{n}\right)\right] \text { etc. } \\
A_{n, n+1} \doteq \frac{1}{n} \frac{1}{n-1} \frac{1}{n-2} \cdots \frac{1}{2} \cdot \frac{1}{1} \cdot A_{0,1}=\frac{1}{\Gamma(n+1)} .
\end{gathered}
\]

Cette dernière équation servira à déterminer les constantes qui rentrent dans les expressions de \(A_{1, n}, A_{2, n}, A_{3, n}\) etc.

Ayant ainsi déterminé les coefficiens \(A_{0, n}, A_{1, n}, A_{2, n}\) etc., on aura, en substituant daus l'équation (3) au lieu de \(\frac{1}{\left(e^v-1\right)^n}\) sa valeur,
\[
\Sigma^n \varphi x=(-1)^{n-1} \int e^{v x} f v \cdot d v\left(A_{0, n} p+A_{1, n} \frac{d p}{d v}+\ldots+A_{n-1, n} \frac{d^{n-1} p}{d v^{n-1}}\right) ;
\]
maintenant on a
%37
\[
p=\frac{1}{v}-\frac{1}{2}+2 \int_0^{\frac{1}{v}} \frac{d t \cdot \sin v t}{e^{z \pi t}-1}
\]
d'où l'on tire en différentiant
\[
\begin{aligned}
& \frac{d p}{d v}=-\frac{1}{v^2}+2 \int_0^{\frac{1}{0}} \frac{t d t \cdot \cos v t}{e^{2 \pi t}-1} \\
& \frac{d^2 p}{d v^2}=\frac{2}{v^3}-2 \int_0^{\frac{1}{0}} \frac{t^2 d t \cdot \sin v t}{e^{2 \pi t}-1} \\
& \frac{d^3 p}{d v^3}=-\frac{2.3}{v^4}-2 \int_0^{\frac{1}{0}} \frac{t^3 d t \cdot \cos v t}{e^{2 \pi t}-1} \text { etc. }
\end{aligned}
\]
done en substituant
\[
\begin{aligned}
\Sigma^n \varphi x & =\int\left(A_{n-1, n} \frac{\Gamma n}{v^n}-A_{n-2, n} \frac{\boldsymbol{T}(n-1)}{v^{n-1}}+\ldots+(-1)^{n-1} A_{0, n} \frac{1}{v}+(-1)^n \cdot \frac{1}{2}\right) e^{v x} f v \cdot d v \\
& +2(-1)^{n-1} \iint_0^{\frac{1}{0}} \frac{P \sin v t \cdot d t}{e^{2 \pi t}-1} e^{v x} f v \cdot d v+2(-1)^{n-1} \iint_0^{\frac{1}{0}} \frac{Q \cos v t \cdot d t}{e^{2 . T t}-1} e^{v x} f v \cdot d v
\end{aligned}
\]

De l'équation \(\varphi x=\int e^{v x} f v \cdot d v\) on tire en intégrant:
\[
\begin{aligned}
& \int \varphi x \cdot d x=\int e^{v x} f v \frac{d v}{v} \\
& \int^2 \varphi x \cdot d x^2=\int e^{v x} f v \frac{d v}{v^2} \\
& \int^3 \varphi x \cdot d x^3=\int e^{v x} f v \frac{d v}{v^3} \text { etc.; }
\end{aligned}
\]
de plus on a
\[
\begin{aligned}
& \int \sin v t \cdot e^{v x} f v \cdot d v=\frac{\varphi(x+t \sqrt{-1})-\varphi(x-t \sqrt{-1})}{2 \sqrt{-1}} \\
& \int \cos v t \cdot e^{v x} f v \cdot d v=\frac{\varphi(x+t \sqrt{-1})+\varphi(x-t \sqrt{-1})}{2}
\end{aligned}
\]
donc on aura en substituant
\[
\begin{aligned}
\Sigma^n \varphi x & =A_{n-1, n} \Gamma n \int^n \varphi x \cdot d \cdot x^n-A_{n-2, n} \Gamma(n-1) \int^{n-1} \varphi x \cdot d \cdot x^{n-1}+\ldots+(-1)^{n-1} \int \varphi x \cdot d x \\
& +(-1)^n \cdot \frac{1}{2} \varphi x+2(-1)^{n-1} \int_0^{\frac{1}{0}} \frac{P d t}{e^{2 \pi t}-1} \frac{\varphi(x+t \sqrt{-1})-\varphi(x-t \sqrt{-1})}{2 \sqrt{-1}} \\
& +2(-1)^{n-1} \int_0^{\frac{1}{0}} \frac{Q d t}{e^{2 \pi t}-1} \frac{\varphi(x+t \sqrt{-1})+\varphi(x-t \sqrt{-1})}{2}
\end{aligned}
\]
où
\[
\begin{aligned}
& P=A_{0, n}-A_{2, n} t^2+A_{4, n} t^4-\ldots \\
& Q=A_{1, n} t-A_{3, n} t^3+A_{5, n} t^5-\ldots
\end{aligned}
\]
%38
En faisant p. ex. \(n=2\), on aura
\[
\begin{array}{r}
\Sigma^2 \varphi x=\iint \varphi x \cdot d x^2-\int \varphi x \cdot d x+\frac{1}{2} \varphi x-2 \int_0^{\frac{1}{0}} \frac{d t}{e^{2 \pi t}-1} \frac{\varphi(x+t \sqrt{-1})-\varphi(x-t \sqrt{-1})}{2 \sqrt{-1}} \\
-2 \int_0^{\frac{1}{0}} \frac{t d t}{e^{2 \cdot \pi t}-1} \frac{\varphi(x+t \sqrt{-1})+\varphi(x-t \sqrt{-1}) .}{2}
\end{array}
\]

Soit p. ex. \(\varphi x=e^{a x}\), on aura
\[
\varphi(x \pm t \sqrt{-1})=e^{a x} e^{ \pm a t \sqrt{-1}}, \int e^{a x} d x=\frac{1}{a} e^{a x}, \iint e^{a x} d x^2=\frac{1}{a^2} e^{a x},
\]
donc, en substituant et divisant par \(e^{a x}\),
\[
\frac{1}{\left(e^\alpha-1\right)^2}=\frac{1}{2}-\frac{1}{a}+\frac{1}{a^2}-2 \int_0^{\frac{1}{v}} \frac{d t \cdot \sin a t}{e^{2 \pi t}-1}-2 \int_0^{\frac{1}{0}} \frac{t d t \cdot \cos a t}{e^{2: t}-1} .
\]

Le cas le plus remarquable est celui où \(n=1\). On a alors, comme on l'a vu précédemment:
\[
\Sigma \varphi x=C+\int \varphi x \cdot d x-\frac{1}{2} \varphi x+2 \int_0^{\frac{1}{4}} \frac{d t}{e^{2 \pi t}-1} \frac{\varphi(x+t \sqrt{-1})-\varphi(x-t \sqrt{-1})}{2 \sqrt{-1}} .
\]

En supposant que les deux intégrales \(\Sigma \varphi x\) et \(\int \varphi x d x\) s'annulent pour \(x=a\), il est clair qu'on aura:
\[
C=\frac{1}{2} \varphi a-2 \int_0^{\frac{1}{0}} \frac{d t}{e^{2 \pi t}-1} \frac{\varphi(a+t \sqrt{-1})-\varphi(a-t \sqrt{-1})}{2 \sqrt{-1}}
\]
done
\[
\begin{aligned}
\Sigma \varphi x=\int \varphi x \cdot d x-\frac{1}{2}(\varphi x-\varphi a) & +2 \int_0^{\frac{1}{0}} \frac{d t}{e^{2 \cdot 2 t}-1} \frac{\varphi(x+t \sqrt{-1})-\varphi(x-t \sqrt{-1})}{2 \sqrt{-1}} \\
& -2 \int_0^{\frac{1}{0}} \frac{d t}{e^{2, n}-1} \frac{\varphi(a+t \sqrt{-1})-\varphi(a-t \sqrt{-1})}{2 \sqrt{-1}}
\end{aligned}
\]

Si l'on fait \(x=\infty\), en supposant que \(\varphi x\) et \(\int \varphi x\). \(d x\). s'amnulent pour cette valeur de \(x\), on aura:
\[
\begin{aligned}
& \varphi a+\varphi(a+1)+\varphi(a+2)+\varphi(a+3)+\ldots \text { in inf. } \\
& =\int_a^{\frac{1}{0}} \varphi x \cdot d x+\frac{1}{2} \varphi a-2 \int_0^{\frac{1}{0}} \frac{d t}{e^{2 \cdot t}-1} \frac{\varphi(a+t \sqrt{-1})-\varphi(a-t \sqrt{-1})}{2 \sqrt{-1}} .
\end{aligned}
\]
%39
Soit p. ex. \(\varphi x=\frac{1}{x^2}\), on aura
\[
\frac{\varphi(a+t \sqrt{-1})-\varphi(a-t \sqrt{-1})}{2 \sqrt{-1}}=\frac{-2 a t}{\left(a^2+t^2\right)^2}
\]
done
\[
\frac{1}{a^2}+\frac{1}{(a+1)^2}+\frac{1}{(a+2)^2}+\ldots=\frac{1}{2 a^2}+\frac{1}{a}+4 a \int_0^{\frac{1}{a}} \frac{t d t}{\left(e^{2 \pi t}-1\right)\left(a^2+t^2\right)^2}
\]
et en faisant \(a=1\)
\[
1+\frac{1}{4}+\frac{1}{9}+\frac{1}{16}+\frac{1}{25}+\ldots=\frac{\pi^2}{6}=\frac{3}{2}+4 \int_0^{\frac{1}{6}} \frac{t d t}{\left(e^{2 \pi t}-1\right)\left(1+t^2\right)^2}
\]
%40
V.
PETITE CONTRIBUTION A LA THÉORIE DE QUELQUES FONCTIONS TRANSCENDANTES.

Présenté à la société royale des sciences à Throndhjem le 22 mars 1826. Imprimé dans Det kongelige norske Videnskabers Selskabs Skrifter t. 2. Throndhjem 1824-1827.
1.
Considérons l'intégrale
\[
p=\int \frac{q d x}{x-a}
\]
\(q\) étant une fonction de \(x\) qui ne contient pas \(a\). En différentiant \(p\) par rapport à \(a\) on trouve
\[
\frac{d p}{d a}=\int \frac{q d x}{(x-a)^2}
\]

Si maintenant \(q\) est choisi tel que \(\int \frac{q d x}{(x-a)^2}\) puisse être exprimé par l'intégrale \(\int \frac{q d x}{x-a}\), on trouvera une équation différentielle linéaire entre \(p\) et \(a\) d'où l'on pourra tirer \(p\) en fonction de \(a\). On ubtiendra ainsi une relation entre plusieurs intégrales prises les unes par rapport à \(x\), les autres par rapport à \(a\). Conme on est conduit par ce procédé à plusieurs théorèmes intéressants, je vais les développer pour un cas très étendu où la réduction mentionnée de l'intégrale \(\int \frac{q d x}{(x-a)^2}\) est possible, savoir le cas où l'on a \(q=\varphi x \cdot e^{f x}, f x\) étant une fonction algébrique rationnelle de \(x\), et \(\varphi x\) étant déterminé par l'équation
\[
\varphi x=k(x+\alpha)^\beta\left(x+\alpha^{\prime}\right)^{\beta^{\prime}}\left(x+\alpha^{\prime \prime}\right)^{\beta^{\prime \prime}} \ldots\left(x+\alpha^{(n)}\right)^{\beta^{(n)}}
\]
%41
où \(\alpha, \alpha^{\prime}, \alpha^{\prime \prime} \ldots\) sont des constantes, \(\beta, \beta^{\prime}, \beta^{\prime \prime} \ldots\) des nombres ratiomnels queleonques. Dans ce cas on a
\[
\begin{aligned}
p & =\int \frac{e^{f x} \rho x \cdot d x}{x-a}, \\
\frac{d p}{d a} & =\int \frac{e^{f x} \boldsymbol{p} x \cdot d x}{(x-a)^2} .
\end{aligned}
\]
2.

La dernière de ces intégrales peut être rérluite de deux manières.
a) Si l'on différentie la quantité \(\frac{e^{f x} \mathrm{f} \cdot x}{x-a}\) on trouve
\[
-\frac{e^{f x} r x \cdot d x}{(x-a)^2}+\frac{\left(e^{f x} \boldsymbol{r}^{\prime} x+e^{f x} f^{\prime} x \cdot(x) d x\right.}{x-a}=d\left(\frac{e^{f x} \rho x}{x-a}\right) .
\]

En intégrant cette équation de sorte que les intégrales s'annulent pour \(x=c\), on obtient
Si l'on différentie l'expression de \(\varphi x\) on obtient
\[
\varphi^{\prime} x=\left(\frac{\beta}{x+\alpha}+\frac{\beta^{\prime}}{x+\alpha^{\prime}}+\frac{\beta^{\prime \prime}}{x+\alpha^{\prime \prime}}+\ldots+\frac{\beta^{(n)}}{x+\alpha^{(n)}}\right) \varphi x=\Sigma \frac{\beta^{(p)}}{x+\alpha^{(p)}} \varphi x,
\]
oì la somme doit être étendue aux valeurs \(p=0,1,2,3 \ldots n\). On tire de là
\[
\frac{\gamma^{\prime} x}{x-a}=\Sigma \frac{\beta^{(p)}}{\left(x+\alpha^{(p)}\right)(x-a)} \psi x
\]
or on a
\[
\frac{\beta^{(p)}}{\left(x+\boldsymbol{\alpha}^{(p)}\right)(x-a)}=-\frac{\beta^{(p)}}{\left(x+\alpha^{(p)}\right)\left(a+\alpha^{(p)}\right)}+\frac{\beta^{(p)}}{(x-a)\left(a+\alpha^{(p)}\right)},
\]
done
\[
\frac{r^{\prime} x}{x-a}=-\varphi x \Sigma \frac{\beta^{(p)}}{\left(x+\alpha^{(p)}\right)\left(a+\alpha^{(p)}\right)}+\frac{\varphi \cdot x}{x-a} \Sigma \frac{\beta^{(p)}}{a+\alpha^{(p)}} .
\]

Considérons maintenant la quantité \(\frac{f^{\prime} x}{x-a}\). 'Comme \(f x\) est une fonction rationnelle de \(x\) on pent faire
\[
f x=\Sigma \gamma^{(p)} x^p+\Sigma \frac{\delta^{(p)}}{\left(x+\varepsilon^{(p)}\right)^{\mu(p)}},
\]
%42
la somme étant étendue à toute valeur entière de \(p\), et \(\boldsymbol{\mu}^{(1)}\) désignant un nombre entier. En différentiant on obtient
\[
f^{\prime} x=\Sigma p \gamma^{(p)} x^{p-1}-\Sigma \frac{\delta^{(p)} \mu^{(p)}}{\left(x+\varepsilon^{(p)}\right)^{\mu(p)+1}}
\]
done:
\[
\frac{f^{\prime} x}{x-\iota}=\Sigma p^{\prime}{ }^{(p)} \frac{x^{p-1}}{x-a}-\Sigma \frac{\delta^{(p)} \mu^{(p)}}{(x-\iota)\left(x+\varepsilon^{(p)}\right)^{\mu^{(p)}+1}} .
\]

Or on a
\[
\frac{x^{p-1}}{x-a}=x^{p-2}+a x^{p-3}+\ldots+a^{p^p} x^{p-p^{\prime}-2}+\ldots+a^{p-2}+\frac{\boldsymbol{a}^{p-1}}{x-a},
\]
donc
\[
\Sigma p \gamma^{(p)} \frac{x^{p-1}}{x-a}=\Sigma \Sigma p^{\gamma^{\prime}(p)} a^{p^{\prime}} x^{p-p^{\prime}-2}+\frac{1}{x-a} \Sigma p^{\gamma^{(p)}} a^{p-1}
\]

Pour réduire l'expression \(\sum \frac{\delta^{(p)} \mu^{(p)}}{(x-a)\left(x+\varepsilon^{(p)}\right)^{\mu^{(p)}+1}}\) posons
\[
\frac{1}{(x-a)(x+c)^m}=\frac{A}{x-a}+\frac{A_1}{x+c}+\frac{A_2}{(x+c)^2}+\cdots+\frac{A_m}{(x+c)^m} ;
\]
si l'on multiplie de part et d'autre par \(x-a\), et qu'on fasse ensuite \(x=a\), on obtient
\[
A=\frac{1}{(a+c)^m} .
\]

Pour trouver \(A_{p^{\prime}}\) on multiplie les deux membres de l'équation par \((x+c)^m\),
\[
\begin{aligned}
\frac{1}{x-a}= & \left(\frac{A}{x-a}+\frac{A_1}{x+a}+\cdots+\frac{A_{p^{\prime}-1}}{(x+c)^{p^{\prime}-1}}\right)(x+c)^m \\
& +A_{p^{\prime}}(x+c)^{m-p^{\prime}}+A_{p^{\prime}+1}(x+c)^{m-p^{\prime}-1}+\ldots,
\end{aligned}
\]
puis 'on différentie \(m-\mu^{\prime}\) fois de suite, ce qui donne
\[
(-1)^{m-p^{\prime}} \frac{1.2 .3 \ldots\left(m-p^{\prime}\right)}{(x-a)^{m-p^{\prime}+1}}=(x+c) R+1.2 .3 \ldots\left(m-p^{\prime}\right) A_{p^{\prime}}
\]

En faisant \(x=-c\), on tire
\[
A_{p^{\prime}}=-\frac{1}{(u+c)^{m-p^{\prime}+1}}
\]
done
\[
\frac{1}{(x-a)(x+c)^m}=\frac{1}{(a+c)^m(x-a)}-\Sigma \frac{1}{(a+c)^{m-p^{\prime}+1}(x+c)^{p^{\prime}}} .
\]
%43
En écrivant maintenant \(\varepsilon^{(p)}\) au lieu de \(c, \wedge^{(p)}+1\) au lieu de \(m\), et multipliant par \(\boldsymbol{\mu}^{(p)} \cdot \delta^{(p)}\) on a
\[
\frac{\mu^{(p)} \delta^{(p)}}{(x-a)\left(x+\varepsilon^{(p)}\right)^{\mu^{(p)}+1}}=\frac{\mu^{(p)} \delta^{(p)}}{\left(a+\varepsilon^{(p)}\right)^{\mu^{(p)}+1}(x-a)}-\Sigma \frac{\mu^{(p)} \dot{\delta}(p)}{\left(a+\varepsilon^{(p)}\right)^{\mu^{(p)}-p^p+2}\left(x+\varepsilon^{(p)}\right)^{p^{\prime}}},
\]
done
\[
\Sigma \frac{\mu^{(p)} \delta^{(p)}}{(x-a)\left(x+\varepsilon^{(p)}\right)^{\mu^{(p)}+1}}=\frac{1}{x-a} \Sigma \frac{\mu^{(p)} \delta^{(p)}}{\left(a+\varepsilon^{(p)}\right)^{\mu^{(p)}+1}}-\Sigma \Sigma \frac{\mu^{(p)} \delta^{(p)}}{\left(a+\varepsilon^{(p)}\right)^{\mu^{(p)}-p^{\prime}+2}\left(x+\varepsilon^{(p)}\right)^{p^{\prime}}}
\]

En substituant dans l'expression de \(\frac{f^{\prime} x}{x-a}\) cette valeur, de même que celle trouvée plus haut pour \(\sum p \gamma^{(p)} \frac{x^{p-1}}{x-a}\), on obtient
\[
\begin{aligned}
\frac{f^{\prime} x}{x-a}= & \frac{1}{x-a}\left(\Sigma p \gamma^{(p)} a^{p-1}-\Sigma \frac{\mu^{(p)} \delta^{(p)}}{\left(a+\varepsilon^{(p)}\right)^{\mu^{(p)}+1}}\right) \\
& +\Sigma \Sigma p \gamma^{(p)} a^{p^{\prime}} x^{p-p^{\prime}-2}+\Sigma \Sigma \frac{\mu^{(p)} \delta(p)}{\left(a+\varepsilon^{(p)}\right)^{\mu^{(p)}-p^{\prime}+2}\left(x+\varepsilon^{(p)}\right)^{p^{\prime}}} \cdot
\end{aligned}
\]

Si l'on multiplie les deux membres de cette équation par \(\varphi x\), et qu'on remarque que le coefficient de \(\frac{1}{x-a}\) est égal ì \(f^{\prime} a\) on a
\[
\frac{\varphi x \cdot f^{\prime} x}{x-a}=\frac{\varphi x \cdot f^{\prime} a}{x-a}+\varphi x \Sigma \Sigma p \gamma^{(p)} a^{p^{\prime}} x^{p-p^{\prime}-2}+\varphi x \Sigma \Sigma \frac{\mu^{(p)} \delta(p)}{\left(a+\varepsilon^{(p)}\right)^{\mu^{(p)}-p^{\prime}+2}\left(x+\varepsilon^{(p)}\right)^{p^p}} .
\]

En y ajoutant la valeur trouvée pour \(\frac{r^{\prime} x}{x-a}\), multipliant ensuite par \(e^{f x} d x\) et intégrant, on en tire
\[
\begin{aligned}
& \int \frac{e^{f x}\left(\boldsymbol{r}^{\prime} x+\tau x \cdot f^{\prime} x\right) d x}{x-a}=\left(f^{\prime} a+\frac{\tau^{\prime} a}{q a}\right) \int \frac{e^{f x} \boldsymbol{\varphi} x \cdot d x}{x-a}+\Sigma \Sigma p \gamma^{(p)} a^{p^{\prime}} \int e^{f x} \varphi x \cdot x^{p-p^{\prime}-2} d x \\
& -\Sigma \frac{\beta^{(p)}}{a+\alpha^{(p)}} \int \frac{e^{f x} \boldsymbol{r} x \cdot d x}{x+\alpha^{(p)}}+\Sigma \Sigma \frac{\mu^{(p)} \delta^{(p)}}{\left(a+\varepsilon^{(p)}\right)^{\mu^{(p)}-p^{\prime}+2}} \int \frac{e^{f x} \boldsymbol{f} x \cdot d x}{\left(x+\varepsilon^{(p)}\right)^{p^{\prime}}} \cdot \\
&
\end{aligned}
\]

Si l'on substitue cette valeur dans l'expression de \(\int \frac{e^{f x} \mathrm{r} x \cdot d x}{(x-a)^2}\) ou \(\frac{d p}{d a}\), et qu'on écrive \(p\) an lien de \(\int \frac{e^{f x} \boldsymbol{r} x \cdot d x}{x-a}\), on trouve
%44
b). Je vais maintenant exposer la seconde méthode de réduction; mais comme celle-ci est assez longue et compliquée quand \(f x\) est. une fonction rationnelle quelconque de \(x\), je me bornerai au cas où \(f x\) est une fonction entière. On a done
\[
f x=\Sigma \gamma^{(p)} x^p
\]

En différentiant l'expression \(\frac{e^{f x} \varphi \cdot x \cdot \psi^{\prime} x}{x-a}\) où
on obtient
\[
\psi x=(x+\alpha)\left(x+\alpha^{\prime}\right) \ldots\left(x+\alpha^{(n)}\right),
\]
\[
-\frac{e^{f x} \tau \cdot x \cdot 2 / x}{(x-a)^2} d x+\frac{e^{f x} \varphi x\left[\psi^{\prime} x+\psi \cdot x\left(\frac{f^{\prime} x}{q \cdot x}+f^{\prime} x\right)\right] d x}{x-a}=d\left(\frac{e^{f x} \varphi x \cdot \psi \cdot x}{x-a}\right) .
\]

Pour réduire cette expression, considérons l'équation
\[
\frac{F^{\prime} x}{x-a}=\frac{F^{\prime}+F^{\prime \prime} \cdot x+\frac{F^{\prime \prime}}{2} x^2+\frac{F^{\prime \prime \prime}}{2 \cdot 3} x^3+\cdots+\frac{F^{(m)}}{2 \cdot 3 \ldots m} x^m}{x-a},
\]
où \(F, F^{\prime}, F^{\prime \prime} \ldots\) désignent les valeurs que prennent \(F x, F^{\prime} x, F^{\prime \prime} x \ldots\) quand on fait \(x=0\). On a ainsi
\[
\begin{gathered}
\frac{F x}{x-a}=\Sigma \frac{F^{(p)}}{2.3 \ldots p} \frac{x^p}{x-a}=\frac{\Sigma \frac{F^{(p)}}{2.3 \ldots p} a^p}{x-d}+\Sigma \Sigma \frac{F^{(p)}}{2.3 \ldots p} a^{p^p} x^{p-p^{\prime}-1} \\
\text { ou, en remarquant que } \Sigma \frac{F^{(p)}}{2.3 \ldots p} a^p=F a, \\
\frac{F x}{x-a}=\frac{F a}{x-a}+\Sigma \Sigma \frac{F^{\left(p+p^{\prime}+1\right)}}{2.3 \ldots\left(p+p^{\prime}+1\right)} a^{p^{\prime}} x^p,
\end{gathered}
\]
où l'on a mis \(p+p^{\prime}+1\) au lieu de \(p\). En différentiant cette formule par rapport ì \(a\) on obtient
\[
\frac{F x}{(x-a)^2}=\frac{F a}{(x-a)^2}+\frac{F^{\prime} a}{x-a}+\Sigma \Sigma_{2.3 \ldots\left(p+p^{\prime}+1\right)} a^{p^{\prime}-1} x^p .
\]

Si dans cette formule on pose \(F x=\psi x\), on a
\[
\text { . } \frac{\psi^{\prime} x}{(x-a)^2}=\frac{\psi^{\prime} a}{(x-a)^2}+\frac{\psi^{\prime} a}{x-a}+\Sigma \Sigma \frac{\left(p^{\prime}+1\right) \psi^{\left(p+p^{\prime}+2\right)}}{2.3 \ldots\left(p+p^{\prime}+2\right)} a^{p^{\prime}} x^p .
\]

En mettant dans la première formule, pour \(F x\) la fonction entière \(\psi^{\prime} x+\psi x\left(\frac{q^{\prime} x}{\gamma^{\prime}}+f^{\prime} x\right)\), on obtient
%45
\[
\begin{aligned}
& \frac{\psi^{\prime} x+\psi x\left(\frac{\rho^{\prime} x}{q x}+f^{\prime} x\right)}{x-a}=\frac{\mu^{\prime} a+\psi\left(\frac{q^{\prime} a}{q a}+f^{\prime} a\right)}{x-a}+\Sigma \Sigma \frac{\psi^{\left(p+p^{\prime}+2\right)}}{2.3 \ldots\left(p+p^{\prime}+1\right)} a^{p^{\prime}} \cdot x^p \\
& +\Sigma \Sigma \frac{\left(y \frac{p^{\prime}}{q}+f^{\prime}\right)^{\left(p+p^{\prime}+1\right)}}{2.3 \cdots\left(p+p^{\prime}+1\right)} a^{p^{\prime} x^p} . \\
&
\end{aligned}
\]

Si l'on substitue ces valeurs dans l'expression de \(d\left(\frac{e^{f x} \gamma(x \cdot \psi / x}{x-a}\right)\), on obtient
\[
\begin{aligned}
& d\left(\frac{e^{f x} \varphi x \cdot \psi \cdot x}{x-a}\right)=-\psi\left(a \frac{e^{f x} \varphi x \cdot d x}{(x-a)^2}+\psi a\left(\frac{\rho^{\prime} a}{\varphi^a}+f^{\prime} a\right) \frac{p^{f x} \varphi^x \cdot d x^{\prime}}{x^{\prime}-a}\right. \\
& +\Sigma \Sigma \frac{(p+1) \psi^{\left(p+p^{\prime}+2\right)}}{2.3 \ldots\left(p+p^{\prime}+2\right)} a^{p^{\prime}} e^{f x} \varphi x \cdot x^p d x \\
& +\Sigma \Sigma \frac{\left(\psi \frac{\varphi^{\prime}}{\varphi}+f^{\prime}\right)^{\left(p+p^{\prime}+1\right)}}{2.3 \ldots\left(p+p^{\prime}+1\right)} a^{p^{\prime}} e^{f x} \varphi x \cdot x^p d x \text {. } \\
&
\end{aligned}
\]

En intégrant cette équation, divisant de part et d'autre par \(\psi \alpha\), et écrivant \(p\) au lieu de \(\int \frac{e^{f x} f^x \cdot d x}{x-a}, \frac{d p}{d a}\) au lieu de \(\int \frac{e^{f x} q x \cdot d x}{(x-a)^2}\), on trouve
\[
\begin{aligned}
& +\Sigma \Sigma \Sigma_{2.3 \ldots\left(p+p^{\prime}+2\right)} \frac{(p+1) \psi^{\left(p+p^{\prime}+2\right)}}{\boldsymbol{q}^p} \int e^{f x} \psi x . x^p d x \\
& +\sum \sum \frac{\left(u^{\prime} \frac{q^{\prime}}{q}+f^{\prime}\right)^{\left(p+p^{\prime}+1\right)}}{2.3 \ldots\left(p+p^{\prime}+1\right)} \frac{a^{p^{\prime}}}{u^{\prime \prime}} \int e^{f x} q x \cdot x^p d x, \\
&
\end{aligned}
\]
oll bien
\[
\frac{d p}{d a}-\left(\frac{\rho^{\prime} a}{q^a}+f^{\prime} a\right) p=\frac{e^{f x} \varphi x \cdot \psi a x}{\psi a\left(a-x^{\prime}\right)}-\frac{e^{f c} \varphi c \cdot \psi c}{\psi(q u(a-c)}+\Sigma \Sigma \varphi\left(p, p^{\prime}\right) \frac{a^{p^{\prime}}}{\psi^{\prime} a} \int e^{f x} \varphi x \cdot x^p d x
\]
(2)
\[
\varphi\left(p, p^{\prime}\right)=\frac{(p+1) \psi^{\left(p+p^{\prime}+2\right)}}{2.3 \ldots\left(p+p^{\prime}+2\right)}+\frac{\left(\psi \frac{\varphi^{\prime}}{\varphi}+f^{\prime}\right)^{\left(p+p^{\prime}+1\right)}}{2.3 \ldots\left(p+p^{\prime}+1\right)}
\]
3.

Les équations (1) et (2) deviennent immédiatement intégrables quand on les multiplie par \(\frac{e^{-f a}}{q a}\); on obtient, de cette manière, en remarquant qu'on a
\[
\int\left(d p-\left(\frac{\varphi^{\prime} a}{\varphi a}+f^{\prime} a\right) p d a\right) \frac{e^{-f a}}{q a}=\frac{p e^{-f a}}{q^a},
\]
%46
les deux formules suivantes:
\[
\begin{aligned}
& \frac{p e^{-f a}}{\varphi a}=e^{f x} \varphi x \int \frac{e^{-f a} d a}{(a-x) \varphi a}-e^{f c} \varphi c \int \frac{e^{-f a} d a}{(a-c) \varphi a} \\
& +\Sigma \Sigma p \gamma^{(p)} \int \frac{e^{-f a} a^{p^{\prime}} d a}{\varphi a} \cdot \int e^{f x} \varphi x \cdot x^{p-p^{\prime}-2} d x-\Sigma \beta^{(p)} \int \frac{e^{-f a} d a}{\left(a+\alpha^{(p)}\right) \varphi a} \cdot \int \frac{e^{f x} \varphi x \cdot d x}{x+\alpha^{(p)}} \\
& +\Sigma \Sigma_1 \mu^{(p)} \delta^{(p)} \int \frac{e^{-f a} d a}{\left(a+\varepsilon^{(p)}\right)^{\mu^{(p)}-p^{\prime}+2} \boldsymbol{p}^a} \cdot \int \frac{e^{f x} \varphi x \cdot d x}{\left(x+\varepsilon^{(p)}\right)^{p^{\prime}}}+C(x), \\
& \frac{p e^{-f a}}{\varphi a}=e^{f x} \varphi x \cdot \psi x \int \frac{e^{-f a} d a}{(a-x) \varphi a \cdot \psi^{\prime \prime} a}-e^{f c} \varphi c \cdot \psi c \int \frac{e^{-f a} d a}{(a-c) \varphi a \cdot \psi^{\prime} a} \\
& +\Sigma \Sigma \varphi\left(p, p^{\prime}\right) \int \frac{e^{-f a} a^{p^{\prime}} d a}{\varphi a \cdot \psi \cdot\left(\psi^{\prime} a\right.} \cdot \int e^{f x} \varphi x \cdot x^p d x+C(x) \text {. } \\
&
\end{aligned}
\]

La quintité \(c\) étant arbitraire, nous ferons dans la première formule \(e^{f c} p c=0\), dans la seconde \(e^{f c} \varphi c \cdot \psi c=0\). Si de plus on suppose que les intégrales prises par rapport à a s'annulent pour \(\frac{e^{-f a}}{q a}=0\), on voit aisément qu'on a \(C(x)=0\); on obtient ainsi, en remettant pour \(p\) sa valeur \(\int \frac{e^{f x} q x \cdot d x}{x-a}\), les deux formules suivantes:

Si dans la première de ces formules, \(f x\) est une fonction entière, on a \(\delta^{(p)}=0\), done
\[
\begin{aligned}
& \frac{e^{-f a}}{\rho a} \int \frac{e^{f x} \rho x \cdot d x}{x-a}-e^{f x} \varphi x \cdot \int \frac{e^{-f a} d a}{(a-x) \Psi a} \\
& =\Sigma \Sigma\left(p+p^{\prime}+2\right) \boldsymbol{y}^{\left(p+p^{\prime}+2\right)} \int \frac{e^{-f a} a^{p^{\prime}} d a}{q a} \cdot \int e^{f x} \psi x^d \cdot x^p d x \\
& -\Sigma \beta^{(p)} \int \frac{e^{-f a} d a}{\left(a+\alpha^{(p)}\right) \boldsymbol{\psi} \alpha} \cdot \int \frac{e^{f x} \boldsymbol{\varphi} x d x}{x+\boldsymbol{\alpha}^{(p)}} \text {. } \\
&
\end{aligned}
\]
%47
4.

Je vais maintenant appliquer les formules générales à quelques cas spéciaux.
a) Si l'on fait \(\varphi a=1\), la formule (3) domme

Si de plus \(f x\) est une fonction entière, on a \(\delta^{(p)}=0\); dans ce cas la formule devient
(6) \(e^{-f a} \int \frac{e^{f x} d x}{x-a}-e^{f x} \int \frac{e^{-f a} d a}{a-x}=\Sigma \Sigma\left(p+p^{\prime}+2\right) y^{\left(p+p^{\prime}+2\right)} \cdot \int e^{-f a} a^{p^{\prime}} d a \cdot \int e^{j x} x^p d x\).
En développant le second membre, on obtient
\[
\begin{aligned}
e^{-f a} \int \frac{e^{f x} d x}{x-a}-e^{f x} \int \frac{e^{-f a} d a}{a-x}=2 \gamma^{(2)} \int e^{-f a} d a \cdot \int e^{f x} d x & \\
& +3 y^{(3)}\left(\int e^{-f a} a d a \cdot \int e^{f x} d x+\int e^{-f a} d a \cdot \int e^{f x} x d x\right) \\
& +4 y^{(4)}\left(\int e^{-f a} a^2 d a \int e^{f x} d x+\int e^{-f a} a d a \cdot \int e^{f x} x d x\right. \\
& \left.+\int e^{-f a} d a \cdot \int e^{f x} x^2 d x\right) \\
& +\ldots \ldots \ldots \ldots \\
& +n y^{(n)}\left(\int e^{-f a} a^{n-2} d a \cdot \int e^{f x} d x+\int e^{-f a} a^{n-3} d a \cdot \int e^{f x} x d x+\ldots\right. \\
& \left.+\int e^{-f a} d a \cdot \int e^{f x} x^{n-2} d x\right)
\end{aligned}
\]

Si par exemple \(f x=x^n\), on a \(\gamma^{(2)}=\gamma^{(3)}=\ldots=\gamma^{(n-1)}=0, \gamma^{(n)}=1\); la formule ci-dessus devient
\[
\begin{aligned}
& e^{-a^n} \int \frac{e^{x^n} d x}{x-a}-e^{x^n} \int \frac{e^{-a^n} d u}{a-x}=n\left(\int e^{-a^n} a^{n-2} d a \cdot \int e^{x^n} d x\right. \\
& \left.+\int e^{-a^n} a^{n-3} d a \cdot \int e^{x^n} x d x+\ldots+\int e^{-a^n} d a \cdot \int e^{x^n} x^{n-2} d x\right)
\end{aligned}
\]
par exemple pour \(n=2, n=3\), on a respectivement
\[
\begin{aligned}
& e^{-a^2} \int \frac{e^{x^3} d x}{x-a}-e^{x^2} \int \frac{e^{-a^2} d u}{a-x}=2 \int e^{-a^2} d u \cdot \int e^{x^2} d x \\
& e^{-a^3} \int \frac{e^{x^3} d x}{x-a}-e^{x^3} \int \frac{e^{-a^3} d u}{a-x}=3\left(\int e^{-a^3} a d a \cdot \int e^{x^3} d x+\int e^{-a^3} d u \cdot \int e^{x^3} x d x\right) .
\end{aligned}
\]
%48
b) Posons maintenant dans la formule (3) \(f x=0\), nous aurons
\[
\varphi x \int \frac{d a}{(a-x) \tau u}-\frac{1}{\tau^u} \int \frac{\varphi x \cdot d x}{x-a}=\Sigma \beta^{(p)} \int \frac{d a}{\left(a+\alpha^{(p)}\right) \tau a} \cdot \int \frac{\tau x \cdot d x}{x+\alpha^{(p)}},
\]
ou bien, en développant le second membre,
où il faut se rappeler qu'on a
\[
\begin{aligned}
& \varphi x=(x+\alpha)^\beta\left(x+\alpha^{\prime}\right)^{\beta^{\prime}} \cdots\left(x+\alpha^{(n)}\right)^{\beta^{(n)}} \cdots \\
& \varphi\left(t=(a+\alpha)^\beta\left(a+\alpha^{\prime}\right)^{\beta^{\prime}} \cdots\left(a+\alpha^{(n)}\right)^{\beta^{(n)}} .\right.
\end{aligned}
\]
c) En faisant daus la formule (4) \(f x=0\), on obtient
\((8)\)
\[
\begin{aligned}
& \text { où } \varphi\left(p, \mu^{\prime}\right)=\frac{(p+1) \psi^{\left(p+p^{\prime}+2\right)}}{2.3 \ldots\left(p+p^{\prime}+2\right)}+\frac{\left(\psi^{\frac{\varphi^{\prime}}{\varphi}}\right)^{\left(p+p^{\prime}+1\right)}}{2.3 \ldots\left(p+p^{\prime}+1\right)}, \\
& \psi x=(x+\alpha)\left(x+\alpha^{\prime}\right) \ldots\left(x+\alpha^{(n)}\right) \text {. } \\
&
\end{aligned}
\]
d) Posons dans la formule (8) \(\beta=\beta^{\prime}=\ldots=\beta^{(n)}=m\), nous aurons
\[
\begin{aligned}
& \psi x=(\psi x)^m, \quad \psi x \cdot \psi x=(\psi x)^{m+1}, \\
& \vee^{\prime} x=m(\psi x)^{m-1} \psi^{\prime} x, \quad \frac{\psi x \cdot q^{\prime} x}{f^{\prime} x}=m \psi^{\prime} x, \\
& \left(\psi \frac{p^{\prime}}{\uparrow}\right)^{\left(p+p^{\prime}+1\right)}=m \psi^{\left(p+p^{\prime}+2\right)} \\
&
\end{aligned}
\]
done en posant
\[
\psi x=k+k^{\prime} x+k^{\prime \prime} x^2+\ldots+k^{(n)} x^n
\]
nous avons
\[
\varphi\left(p, p^{\prime}\right)=\frac{\left(p+1+m\left(p+p^{\prime}+2\right)\right) \psi^{\left(p+p^{\prime}+2\right)}}{2.3 \cdots\left(p+p^{\prime}+2\right)}=\left(p+1+m\left(p+p^{\prime}+2\right)\right) k^{\left(p+p^{\prime}+2\right)} .
\]

En substituant ces valeurs, on trouve
\[
\begin{aligned}
& \frac{1}{\left(\psi(a)^m\right.} \int \frac{(\psi x)^m d x}{x-a}-(\psi x)^{m+1} \int \frac{d u}{(a-x)\left(\psi(a)^{m+1}\right.} \\
& \quad=\Sigma \Sigma k^{\left(p+p^{\prime}+2\right)}\left(1+1+m\left(p+p^{\prime}+2\right)\right) \int \frac{u^{p^{\prime}} d a}{\left(\psi(u)^{m+1}\right.} \cdot \int(\psi x)^m x^p d x
\end{aligned}
\]
%49
Le cas où \(m=-\frac{1}{2}\) a cela de remarquable, que les intégrales par rapport à \(x\) et à a prennent la même forme; en effet on a
\[
(\psi a)^{m+1}=(\psi a)^{\frac{1}{j}}=\sqrt{\psi a}, \frac{1}{(\psi a)^m}=\sqrt{\psi a},
\]
done
\[
\sqrt{\psi a} \int \frac{d x}{(x-a) \sqrt{\ell^{\prime} \cdot x}}-\sqrt{\psi x} \int \frac{d a}{(a-x) \sqrt{\psi \cdot a}}=\frac{1}{2} \Sigma \Sigma\left(p-p^{\prime}\right) k^{\left(p+p^{\prime}+2\right)} \int \frac{a^{p^{\prime}} d a}{\sqrt{\psi / a}} \cdot \int \frac{x^p d x}{\sqrt{\psi^{\prime} x}} .
\]

Si l'on suppose, par exemple que \(\psi x=1+\alpha x^n\), on a \(k^{(n)}=\alpha ; k^{\left(p+p^{\prime}+2\right)}\) sera égal à zéro, à moins que \(p+p^{\prime}+2=n\), c'est-à-rlire que \(p=n-p^{\prime}-2\); donc
\[
\begin{aligned}
\sqrt{1+\alpha a^n} \int \frac{d x}{(x-a) \sqrt{1+\alpha x^n}}-\sqrt{1+\alpha x^n} \int \frac{d u}{(a-x) \sqrt{1+\alpha a^n}} \\
=\frac{\alpha}{2} \Sigma\left(n-2 p^{\prime}-2\right) \int \frac{a^{p^{\prime}} d a}{\sqrt{1+\alpha a^n}} \cdot \int \frac{x^{n-p^{\prime}-2} d x}{\sqrt{1+\alpha x^n}}
\end{aligned}
\]

En développant le second membre, on a
\[
\begin{aligned}
\sqrt{1+\alpha a^n} & \int \frac{d x}{(x-a) \sqrt{1+\alpha x^n}}-\sqrt{1+\alpha x^n} \int \frac{d a}{(a-x) \sqrt{1+\alpha a^n}} \\
& =\frac{\alpha}{2}(n-2)\left[\int \frac{d a}{\sqrt{1+\alpha a^n}} \cdot \int \frac{x^{n-2} d x}{\sqrt{1+\alpha x^n}}-\int \frac{a^{n-2} d a}{\sqrt{1+\alpha a^n}} \cdot \int \frac{d x}{\sqrt{1+\alpha x^n}}\right] \\
& +\frac{\alpha}{2}(n-4)\left[\int \frac{a d a}{\sqrt{1+\alpha a^n}} \cdot \int \frac{x^{n-3} d x}{\sqrt{1+\alpha x^n}}-\int \frac{a^{n-3} d a}{\sqrt{1+\alpha a^n}} \cdot \int \frac{x d x}{\sqrt{1+\alpha x^n}}\right] \\
& +\frac{\alpha}{2}(n-6)\left[\int \frac{a^2 d a}{\sqrt{1+\alpha a^n}} \cdot \int \frac{x^{n-4} d x}{\sqrt{1+\alpha x^n}}-\int \frac{a^{n-4} d a}{\sqrt{1+\alpha a^n}} \cdot \int \frac{x^2 d x}{\sqrt{1+\alpha x^n}}\right] \\
& +\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots
\end{aligned}
\]

Par exemple si \(n=3\), on a
\[
\begin{aligned}
\sqrt{1+\alpha a^3} & \int \frac{d x}{(x-a) \sqrt{1+\alpha x^3}}-\sqrt{1+\alpha x^3} \int \frac{d u}{(a-x) \sqrt{1+\alpha a^3}} \\
& =\frac{\alpha}{2}\left[\int \frac{d a}{\sqrt{1+\alpha \iota^3}} \cdot \int \frac{x d x}{\sqrt{1+\alpha x^3}}-\int \frac{a d a}{\sqrt{1+\alpha a^3}} \cdot \int \frac{d x}{\sqrt{1+\alpha x^3}}\right]
\end{aligned}
\]

Comme second exemple je prends
\[
\psi x=\left(1-x^2\right)\left(1-\alpha x^2\right)
\]
alors on a \(k=1, k^{\prime}=0=k^{\prime \prime \prime}, k^{\prime \prime}=-(1+\alpha), k^{\prime \prime \prime}=\alpha\). Si l'on écrit - a pour \(a\), la formule devient
%50
\[
\begin{aligned}
& \sqrt{\left(1-a^2\right)\left(1-\alpha a^2\right)} \int \frac{d x}{(x+a) \sqrt{\left(1-x^2\right)\left(1-\alpha \cdot x^2\right)}} \\
& -\sqrt{\left(1-x^2\right)\left(1-a x^2\right)} \int \frac{d a}{(a+x) \sqrt{\left(1-a^2\right)\left(1-\alpha a^2\right)}} \\
& =\alpha \int \frac{d a}{\sqrt{\left(1-a^2\right)\left(1-a a^2\right)}} \cdot \int \frac{x^2 d x}{\sqrt{\left(1-x^2\right)\left(1-a x^2\right)}} \\
& -u \int \frac{a^2 d a}{\sqrt{\left(1-a^2\right)\left(1-a a^2\right)}} \cdot \int \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-\alpha \cdot x^2\right)}} \text {. } \\
&
\end{aligned}
\]

En posant
\[
x=\sin \varphi, \quad a=\sin \psi,
\]
on a
\[
\begin{aligned}
& \sqrt{\left(1-x^2\right)\left(1-\alpha x^2\right)}=\cos \varphi \sqrt{1-\alpha \sin ^2 \varphi} \\
& \sqrt{\left(1-a^2\right)\left(1-\alpha a^2\right)}=\cos \psi \sqrt{1-\alpha \sin ^2 \psi} \\
& \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-\alpha x^2\right)}}=\frac{d \varphi}{\sqrt{1-\alpha \sin ^2 \varphi}}, \\
& \frac{d a}{\sqrt{\left(1-a^2\right)\left(1-\alpha a^2\right)}}=\frac{d \psi}{\sqrt{1-\alpha \sin ^2 \psi}}, \\
& \frac{x^2 d x}{\sqrt{\left(1-x^2\right)\left(1-\alpha x^2\right)}}=\frac{\sin ^2 \varphi d \varphi}{\sqrt{1-\alpha \sin ^2 \varphi}}, \\
& \frac{a^2 d a}{\sqrt{\left(1-a^2\right)\left(1-\alpha a^2\right)}}=\frac{\sin ^2 \psi d \psi}{\sqrt{1-\alpha \sin ^2 \psi}} .
\end{aligned}
\]

En substituant ces valeurs, on trouve
\[
\begin{aligned}
& \cos \psi \sqrt{1-\alpha \sin ^2 \psi} \int \frac{d \varphi}{\left(\sin \varphi+\sin \psi^{\prime}\right) \sqrt{1-\alpha \sin ^2 \varphi}} \\
& -\cos \varphi \sqrt{1-\alpha \sin ^2 \varphi} \int \frac{d \psi}{(\sin \psi+\sin \varphi) \sqrt{1-\alpha \sin ^2 \psi}} \\
& =\alpha \int \frac{d \psi^{\prime \prime}}{\sqrt{1-\alpha \sin ^2 \psi}} \cdot \int \frac{\sin ^2 \varphi d \varphi}{\sqrt{1-\alpha \sin ^2 \varphi}}-\alpha \int \frac{\sin ^2 \psi d \psi}{\sqrt{1-\alpha \sin ^2 \psi}} \cdot \int \frac{d \varphi}{\sqrt{1-\alpha \sin ^2 \varphi}} \cdot \\
&
\end{aligned}
\]

Cette formule répond à celle que M. Legendre a domnée dans ses Exercices de calcul intégral t. I p. 136, et elle peut en être déduite.
e) Si dans la formule (5) on pose \(f x=x\), on obtient
%51
d'où en développant le second membre on tire
\[
\begin{aligned}
e^x \varphi x & \int \frac{e^{-a} d a}{(a-x) \uparrow a}-\frac{e^{-a}}{\varphi a} \int \frac{e^x \varphi^x \cdot d x}{x-a}=\beta \int \frac{e^{-a} d a}{(a+\alpha) \varphi a} \cdot \int \frac{e^x \varphi^x \cdot d x}{x+\alpha} \\
& +\beta^{\prime} \int \frac{e^{-a} d a}{\left(a+\alpha^{\prime}\right) \varphi a} \cdot \int \frac{e^x \uparrow x \cdot d x}{x+\alpha^{\prime}}+\cdots+\beta^{(n)} \int \frac{e^{-a} d a}{\left(a+\alpha^{(n)}\right) \uparrow a} \cdot \int \frac{e^x \varphi^x \cdot d x}{x+\alpha^{(n)}}
\end{aligned}
\]

Par exemple si \(\varphi x=\sqrt{x^2-1}\), on a \(\beta=\beta^{\prime}=\frac{1}{2}, \alpha=1, \alpha^{\prime}=-1\), donc
\[
\begin{aligned}
& e^x \sqrt{x^2-1} \int \frac{e^{-a} d a}{(a-x) \sqrt{a^2-1}}-\frac{e^{-a}}{\sqrt{a^2-1}} \int \frac{e^x d x \sqrt{x^2-1}}{x-a} \\
& \quad=\frac{1}{2} \int \frac{e^{-a} d a}{(a+1) \sqrt{a^2-1}} \cdot \int \frac{e^x d x \sqrt{x^2-1}}{x+1}+\frac{1}{2} \int \frac{e^{-a} d a}{(a-1) \sqrt{a^2-1}} \cdot \int \frac{e^x d x \sqrt{x^2-1}}{x-1} .
\end{aligned}
\]
f) En posant dans la formule (4) \(\beta=\beta^{\prime}=\beta^{\prime \prime}=\ldots=\beta^{(n)}=m\), on a \(\varphi x=(\psi x)^m, \varphi x \cdot \psi x \doteq(\psi x)^{m+1}\), done
\[
\begin{aligned}
\frac{e^{-f a}}{\left(\psi^{\prime} a\right)^m} \int \frac{e^{f x}(\psi x)^m d x}{x-a} & -e^{f x}(\psi x)^{m+1} \int \frac{e^{-f a} d a}{(a-x)\left(\psi^{\prime} a\right)^{m+1}} \\
& =\Sigma \Sigma \varphi\left(p, p^{\prime}\right) \int \frac{e^{-f a} a^{p^{\prime}} d a}{\left(\psi^{\prime} a\right)^{m+1}} \cdot \int e^{f x}\left(\psi^{\prime} x\right)^m x^p d x .
\end{aligned}
\]

Or on trouve
\[
\varphi\left(p, p^{\prime}\right)=\frac{f^{\left(p+p^{\prime}+2\right)}}{2.3 \ldots\left(p+p^{\prime}+1\right)}+\left(p+1+m\left(p+p^{\prime}+2\right)\right) \frac{\psi^{\left(p+p^{\prime}+2\right)}}{2.3 \ldots\left(p+p^{\prime}+2\right)}
\]
donc, en faisant
\[
\begin{aligned}
& f x=\gamma+\gamma^{\prime} x+\gamma^{\prime \prime} x^2+\cdots+\gamma^{\left(n^{\prime}\right)} x^{n^{\prime}}, \\
& \psi x=k+k^{\prime} x+k^{\prime \prime} x^2+\cdots+k^{(n)} x^n \text {, } \\
&
\end{aligned}
\]
on a
\[
\varphi\left(p, p^{\prime}\right)=\left(p+p^{\prime}+2\right) \gamma^{\left(p+p^{\prime}+2\right)}+\left(p+1+m\left(p+p^{\prime}+2\right)\right) k^{\left(p+p^{\prime}+2\right)}
\]

Par conséquent on a
\[
\begin{aligned}
& \frac{e^{-f a}}{\left(U^{\prime}(a)^m\right.} \int \frac{e^{f x}\left(\psi^{\prime} x\right)^m d x}{x-a}-e^{f x}(\psi x)^{m+1} \int \frac{e^{-f a} d a}{(a-x)\left(\psi^{\prime} a\right)^{m+1}} \\
& \quad=\Sigma \Sigma\left[\left(p+p^{\prime}+2\right) y^{\left(p+p^{\prime}+2\right)}\right. \\
& \left.\quad+\left(p+1+m\left(p+p^{\prime}+2\right)\right) k^{\left(p+p^{\prime}+2\right)}\right] \int \frac{e^{-f a} a^{p^{\prime}} d a}{\left(\mu^{\prime \prime}(a)^{m+1}\right.} \cdot \int e^{f x}(\psi x)^m x^p d x .
\end{aligned}
\]
%52
Si l'on fait \(m=-\frac{1}{2}\), on trouve
\[
\begin{aligned}
& e^{-f a} \sqrt{\psi a} \int \frac{e^{f x} d x}{(x-a) \sqrt{\mu^{\prime} x}}-e^{f x} \sqrt{\psi \cdot x} \int \frac{e^{-f a} d a}{(a-x) \sqrt{\mu^{\prime} a}} \\
& =\Sigma \Sigma\left[\left(p+p^{\prime}+2\right) \gamma^{\left(p+p^{\prime}+2\right)}+\frac{1}{2}\left(p-p^{\prime}\right) k^{\left(p+p^{\prime}+2\right)}\right] \int \frac{e^{-f a} a^{p^{\prime}} d a}{\sqrt{\psi a}} \int \frac{e^{f x} x^p d x}{\sqrt{\psi^{\prime} x}} .
\end{aligned}
\]

Soit par exemple \(f x=x\) et \(\psi x=1-\dot{x}^2\), on a
done
\[
\gamma^{\left(p+p^{\prime}+2\right)}=0, \quad \frac{1}{2}\left(p-p^{\prime}\right) k^{\left(p+p^{\prime}+2\right)}=0
\]
\[
e^{-a} \sqrt{1-a^2} \int \frac{e^x d x}{(x-a) \sqrt{1-x^2}}=e^x \sqrt{1-x^2} \int \frac{e^{-a} d a}{(a-x) \sqrt{1-a^2}} .
\]

En écrivant \(-a\) au lieu de \(a\), on obtient
\[
e^a \sqrt{1-a^2} \int \frac{e^x d x}{(x+a) \sqrt{1-x^2}}=e^x \sqrt{1-x^2} \int \frac{e^a d a}{(a+x) \sqrt{1-a^2}}
\]
en posant \(x=\sin \varphi\), et \(a=\sin \psi\), on trouve
\[
\cos \psi e^{\sin \psi} \int \frac{e^{\sin \varphi} d \varphi}{\sin \varphi+\sin \psi^{\prime}}=\cos \varphi e^{\sin \varphi} \int \frac{e^{\sin \psi} d \psi^{\prime}}{\sin \psi^{\prime}+\sin \varphi-},
\]
les intégrales devant s'amnuler pour \(\varphi=\frac{\pi}{2}, \psi=\frac{\pi}{2}\).

Je vais maintenant faire une antre application des équations générales. Nous avons jusqu’à présent regardé \(x\) et \(a\) comme des indéterminées, sans nous occuper des valeurs spéciales de ces quantités qui simplifieraient les formules. Nous allons maintenant chercher de telles valeurs.
a) Considérons en premier lieu l'équation (5). Le premier membre de cette équation contient deux intégrales, mais comme chacune d'elles est multipliée par une quantité dépendant respectivement de \(a\) et de \(x\), il est clair qu'on pent donner à ces quantités des valeurs telles, que les intégrales disparaissent, ou l'une, ou toutes les deux, \(\cdot\)pourvu seulement que chacune des équations \(\frac{e^{-f a}}{q a}=0, e^{f x} \varphi x=0\), ait au moins deux racines différentes; car nous avons déjà supposé que les intégrales s'ammulent pour des valeurs de \(x\) et de a qui satisfont ì ces équations.

Supposons d'abord \(e^{f x} p x=0\), nous aurons après avoir multiplié par \(e^{f a} \varphi a\),
%53
\[
\begin{gathered}
\int \frac{e^{f x} \varphi \cdot x \cdot d x}{x-a}=e^{f a} \varphi a \Sigma \Sigma\left(p+p^{\prime}+2\right) \gamma^{\left(p+p^{\prime}+2\right)} \int \frac{e^{-f a} a^{p^{\prime}} d a}{\varphi a} \cdot \int e^{f x} \varphi x \cdot x^p d x \\
-e^{f a} \varphi a \Sigma \beta^{(p)} \int \frac{e^{-f a} d a}{\left(a+\alpha^{(p)}\right) \varphi a} \int \frac{e^{f x} \varphi^x \cdot d x}{x+\alpha^{(p)}} \\
\left(x=x^{\prime}, x=x^{\prime \prime}, a=a^{\prime}\right),
\end{gathered}
\]
les équations entre parenthèses indiquant les limites entre lesquelles les intégrales doivent être prises; ces limites doivent satisfaire aux équations
\[
e^{f x^{\prime}} \varphi x^{\prime}=0, e^{f x^{\prime \prime}} \varphi x^{\prime \prime}=0 ; \frac{e^{-f a^{\prime}}}{\varphi a^{\prime}}=0 .
\]

De la formule précédente découle le théorème suivant:
"La valeur de l'intégrale \(\int \frac{e^{f x} \uparrow \cdot x \cdot d x}{x-a}\), entre des limites qui annulent la "fonction \(e^{f x} \varphi x\) peut être exprimée par des intégrales des formes suivantes:
\[
\int e^{f x} \varphi x \cdot x^p d x, \int \frac{e^{-f a} a^{p^p} d a}{\varphi a}, \int \frac{e^{f x} \varphi x \cdot d x}{x+\alpha^{(p)}}, \int \frac{e^{-f a} d a}{\left(a+\alpha^{(p)}\right) \uparrow a},
\]
"les intégrales par rapport à \(x\) étant prises entre les mêmes limites que la "première intégrale."

Ce théorème a cela de remarquable, que la même réduction est impossible, quand l'intégrale \(\int \frac{e^{f x} f^x \cdot d x}{x-a}\) est prise entre des limites indéterminées. En posant \(f x=0\), on obtient
\[
\begin{gathered}
\int \frac{\rho^x \cdot d x}{x-a}=-\varphi a \Sigma \beta^{(p)} \int \frac{d a}{\left(a+\alpha^{(p)}\right) \wp a} \cdot \int \frac{\varphi x \cdot d x}{x+\alpha^{(p)}} \\
\left(x=x^{\prime}, x=x^{\prime \prime}, a=a^{\prime}\right) .
\end{gathered}
\]

Si l'on pose \(\varphi x=1\), on aura
\[
\begin{gathered}
\int \frac{e^{f x} d x}{x-a}=e^{f a} \Sigma \Sigma\left(p+p^{\prime}+2\right) \gamma^{\left(p+p^{\prime}+2\right)} \int e^{-f a} a^{p^{\prime}} d a \cdot \int e^{f x} x^p d x . \\
\left(x=x^{\prime}, x=x^{\prime \prime}, a=a^{\prime}\right) .
\end{gathered}
\]

Supposons maintenant qu'on donne en même temps à a une valeur qui annule la quantité \(\frac{e^{-f a^{\circ}}}{q^a}\), et soit \(a^{\prime \prime}\) cette valeur, la formule (13) donnera
\[
\begin{aligned}
& \Sigma \boldsymbol{\beta}^{(p)} \int \frac{e^{-f a} d a}{\left(a+\alpha^{(p)}\right) \uparrow a} \cdot \int \frac{e^{f x} \varphi x \cdot d x}{x+\alpha^{(p)}} \\
& =\Sigma \Sigma\left(p+p^{\prime}+2\right) \gamma^{\left(p+p^{\prime}+2\right)} \int \frac{e^{-f a} a^{p^{\prime}} d a}{\boldsymbol{f}^a} \cdot \int e^{f x} \varphi x \cdot x^p d x \\
& \left(x=x^{\prime}, x=x^{\prime \prime} ; a=a^{\prime}, a=a^{\prime \prime}\right) .
\end{aligned}
\]
%54
En supposant \(f x=k x\), on en tire
\[
\begin{gathered}
\Sigma \beta^{(p)} \int \frac{e^{-k a} d a}{\left(a+\alpha^{(p)}\right) \varphi^a} \cdot \int \frac{e^{k x} \varphi^x \cdot d x}{x+\alpha^{(p)}}=0 \\
\left(x=x^{\prime}, \quad x=x^{\prime \prime} ; \quad a=a^{\prime}, \quad a=a^{\prime \prime}\right) .
\end{gathered}
\]

En faisant \(k=0\), on obtient
\[
\begin{gathered}
\sum \beta^{(x)} \int \frac{d a}{\left(a+\alpha^{(p)}\right) \uparrow a} \cdot \int \frac{\varphi x \cdot d x}{x+\alpha^{(p)}}=0 \\
\left(x=x^{\prime}, x=x^{\prime \prime} ; a=a^{\prime}, a=a^{\prime \prime}\right) .
\end{gathered}
\]

Posons par exemple \(p x=\sqrt{x^2-1}=\sqrt{(x-1)(x+1)}\), on a
\[
\beta=\beta^{\prime}=\frac{1}{2} ; \quad \alpha=-1, \alpha^{\prime}=1 ; x^{\prime}=1, x^{\prime \prime}=-1 ; a^{\prime}=\infty, a^{\prime \prime}=-\infty ;
\]
done
\[
\begin{gathered}
\int \frac{d a}{(a-1) \sqrt{a^2-1}} \cdot \int \frac{d x \sqrt{x^2-1}}{x-1}+\int \frac{d a}{(a+1) \sqrt{a^2-1}} \cdot \int \frac{d x \sqrt{x^2-1}}{x+1}=0 \\
\left(x^{\prime}=1, x^{\prime \prime}=-1 ; a^{\prime}=+\infty, a^{\prime \prime}=-\infty\right),
\end{gathered}
\]
ce qui a lien en effet, car on a
\[
\begin{aligned}
& \int \frac{d a}{(a-1) \sqrt{a^2-1}}=-\sqrt{\frac{a+1}{a-1}=0} \quad\left(a^{\prime}=+\infty, a^{\prime \prime}=-\infty\right), \\
& \int \frac{d a}{(a+1) \sqrt{a^2-1}}=-\sqrt{\frac{a-1}{a+1}=0} \quad\left(a^{\prime}=+\infty, a^{\prime \prime}=-\infty\right) .
\end{aligned}
\]

Si dans la formule (16) on fait \(\varphi x=1\), on obtient
\[
\begin{gathered}
\Sigma \Sigma\left(p+p^{\prime}+2\right) \gamma^{\left(p+p^{\prime}+2\right)} \int e^{-f a} a^{p^{\prime}} d a \cdot \int e^{f x} x^p d x=0 \\
\left(x=x^{\prime}, x=x^{\prime \prime} ; \quad a=a^{\prime}, a=a^{\prime \prime}\right) .
\end{gathered}
\]
b) Considérons en second lieu la formule (4). En supposant \(e^{f x} \varphi x \cdot \psi x=0\), on trouve après avoir multiplié par \(e^{f a} \varphi a\)
\[
\begin{gathered}
\int \frac{e^{f x} \tau x \cdot d x}{x-a}=e^{f a} \varphi a \Sigma \Sigma \varphi\left(p, p^{\prime}\right) \int \frac{e^{-f a} a^{p^{\prime}} d a}{\varphi a \cdot \psi \cdot u} \cdot \int e^{f x} \varphi x \cdot x^p d x \\
\left(x=x^{\prime}, x=x^{\prime \prime} ; a=a^{\prime}\right),
\end{gathered}
\]
oì l'on a
\[
e^{f x^{\prime}} \psi x^{\prime} \cdot \psi x^{\prime}=0, e^{f x^{\prime \prime}} \psi x^{\prime \prime} \cdot \psi \cdot x^{\prime \prime}=0, \frac{e^{-f a^{\prime}}}{\psi a^{\prime}}=0
\]
%55
Cette formule se traduit en théorème comme suit:
"La valeur de l'intégrale \(\int \frac{e^{f x} \uparrow x \cdot d x}{x-a}\), prise entre des limites qui annu"lent la quantité \(e^{f x} \varphi x . \psi x\), peut être exprimée par des intégrales de ces "formes: \(\int \frac{e^{-f a} a^{p^{\prime}} d a}{\tau a \cdot \psi a}, \int e^{f x} \varphi x \cdot x^p d x\)."

Pour des valeurs indéterminées de \(x\) an contraire, cette réduction de \(\int \frac{e^{f x} \boldsymbol{\varphi} x \cdot d x}{x-a}\) est impossible.
En faisant \(\beta=\beta^{\prime}=\ldots=\beta^{(n)}=m\), on obtient la formule suivante
\[
\begin{gathered}
\int \frac{e^{f x}\left(\psi^{\prime} \cdot x\right)^m d x}{x-a}=e^{f a}(\psi a)^m \Sigma \Sigma \varphi\left(p, p^{\prime}\right) \int \frac{e^{-f a} a^{p^{\prime}} d a}{(\psi a)^{m+1}} \cdot \int e^{j x}(\psi x)^m x^p d x \\
\left(x=x^{\prime}, x=x^{\prime \prime} ; a=\dot{a}^{\prime}\right),
\end{gathered}
\]
où
\[
\psi x=(x+\alpha)\left(x+\alpha^{\prime}\right) \ldots\left(x+\alpha^{(n)}\right) .
\]

Si de plus on suppose \(f x=0\), on obtient
\[
\begin{gathered}
\int \frac{(\psi x)^m d x}{x-a}=(\psi a)^m \Sigma \Sigma \varphi\left(p, p^{\prime}\right) \int \frac{a^{p^{\prime}} d a}{(\psi a)^{m+1}} \cdot \int(\psi x)^m x^p d x \\
\left(x=x^{\prime}, x=x^{\prime \prime} ; \quad a=a^{\prime}\right) .
\end{gathered}
\]

On a donc le théorème suivant, qui n'est qu'un cas spécial du précédent:
"La valeur de l'intégrale \(\int \frac{\left(\psi^{\prime} x\right)^m d x}{x-a}\), prise entre des limites qui satis"font à-l'équation \((\psi x)^{m+1}=0\), peut être exprimée par des intégrales des "formes \(\int \frac{a^{p^{\prime}} d a}{(\psi / a)^{m+1}}, \int(\psi x)^m x^p d x, \psi x\) étant une fonction entière de \(x . "\)
En faisant \(m=-\frac{1}{2}\), on obtient
\[
\begin{aligned}
\int \frac{d x}{(x-a) \sqrt{\psi^{\prime} x}}= & \frac{1}{2 \sqrt{\psi u}} \Sigma \Sigma\left(p-p^{\prime}\right) k^{\left(p+p^{\prime}+2\right)} \int \frac{a^{p^{\prime}} d a}{\sqrt{\psi a}} \cdot \int \frac{x^p d x}{\sqrt{\psi^{\prime} \cdot x}} \\
& \left(x=x^{\prime}, x=x^{\prime \prime} ; a=a^{\prime}\right),
\end{aligned}
\]
d'où le théorème suivant:
%56
Cette formule se traduit en théorème comme suit:
"La valeur de l'intégrale \(\int \frac{e^{f x} \uparrow x \cdot d x}{x-a}\), prise entre des limites qui annu"lent la quantité \(e^{f x} \varphi x . \psi x\), peut être exprimée par des intégrales de ces "formes: \(\int \frac{e^{-f a} a^{p^{\prime}} d a}{\tau a \cdot \psi a}, \int e^{f x} \varphi x \cdot x^p d x\)."

Pour des valeurs indéterminées de \(x\) an contraire, cette réduction de \(\int \frac{e^{f x} \boldsymbol{\varphi} x \cdot d x}{x-a}\) est impossible.
En faisant \(\beta=\beta^{\prime}=\ldots=\beta^{(n)}=m\), on obtient la formule suivante
\[
\begin{gathered}
\int \frac{e^{f x}\left(\psi^{\prime} \cdot x\right)^m d x}{x-a}=e^{f a}(\psi a)^m \Sigma \Sigma \varphi\left(p, p^{\prime}\right) \int \frac{e^{-f a} a^{p^{\prime}} d a}{(\psi a)^{m+1}} \cdot \int e^{j x}(\psi x)^m x^p d x \\
\left(x=x^{\prime}, x=x^{\prime \prime} ; a=\dot{a}^{\prime}\right),
\end{gathered}
\]
où
\[
\psi x=(x+\alpha)\left(x+\alpha^{\prime}\right) \ldots\left(x+\alpha^{(n)}\right) .
\]

Si de plus on suppose \(f x=0\), on obtient
\[
\begin{gathered}
\int \frac{(\psi x)^m d x}{x-a}=(\psi a)^m \Sigma \Sigma \varphi\left(p, p^{\prime}\right) \int \frac{a^{p^{\prime}} d a}{(\psi a)^{m+1}} \cdot \int(\psi x)^m x^p d x \\
\left(x=x^{\prime}, x=x^{\prime \prime} ; \quad a=a^{\prime}\right) .
\end{gathered}
\]

On a donc le théorème suivant, qui n'est qu'un cas spécial du précédent:
"La valeur de l'intégrale \(\int \frac{\left(\psi^{\prime} x\right)^m d x}{x-a}\), prise entre des limites qui satis"font à-l'équation \((\psi x)^{m+1}=0\), peut être exprimée par des intégrales des "formes \(\int \frac{a^{p^{\prime}} d a}{(\psi / a)^{m+1}}, \int(\psi x)^m x^p d x, \psi x\) étant une fonction entière de \(x . "\)
En faisant \(m=-\frac{1}{2}\), on obtient
\[
\begin{aligned}
\int \frac{d x}{(x-a) \sqrt{\psi^{\prime} x}}= & \frac{1}{2 \sqrt{\psi u}} \Sigma \Sigma\left(p-p^{\prime}\right) k^{\left(p+p^{\prime}+2\right)} \int \frac{a^{p^{\prime}} d a}{\sqrt{\psi a}} \cdot \int \frac{x^p d x}{\sqrt{\psi^{\prime} \cdot x}} \\
& \left(x=x^{\prime}, x=x^{\prime \prime} ; a=a^{\prime}\right),
\end{aligned}
\]
d'où le théorème suivant:
%56
"lent la fonction \(\psi x\), peut être exprimée par des intégrales de la fur"me \(\int \frac{x^p d x}{\sqrt{\psi x}}\)."

Faisons par exemple \(\psi x=\left(1-x^2\right)\left(1-\alpha x^2\right)\), nous aurons \(x^{\prime}=1, x^{\prime}=-1\), \(x^{\prime}=\sqrt{\frac{1}{a}}, x^{\prime}=-\sqrt{\frac{1}{a}} ; a^{\prime}=1,-1, \sqrt{\frac{1}{a}},-\sqrt{\frac{1}{a}} ;\) donc
\[
\begin{aligned}
\sqrt{\left(1-a^2\right)}\left(1-\alpha a^2\right) \int \frac{d x}{(x-a) \sqrt{\left(1-x^2\right)\left(1-\alpha x^2\right)}} & =\int \frac{d a}{\sqrt{\left(1-a^2\right)\left(1-\alpha u^2\right)}} \cdot \int \frac{x^2 d x}{\sqrt{\left(1-x^2\right)\left(1-\alpha x^2\right)}} \\
- & \alpha \int \frac{a^2 d a}{\sqrt{\left(1-a^2\right)\left(1-a u^2\right)}} \cdot \int \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-\alpha x^2\right)}} \\
& \left(x=1, x=-1 ; a= \pm 1, \pm \sqrt{\frac{1}{\alpha}}\right) \\
& \left(x=1, x= \pm \sqrt{\frac{1}{\alpha}} ; a= \pm 1, \pm \sqrt{\frac{1}{\alpha}}\right) \\
& \left(x=-1, x= \pm \sqrt{\frac{1}{\alpha}} ; a= \pm 1, \pm \sqrt{\frac{1}{\alpha}}\right) \\
& \left(x=\sqrt{\frac{1}{\alpha}}, x=-\sqrt{\frac{1}{\alpha}} ; a= \pm 1, \pm \sqrt{\frac{1}{\alpha}}\right) .
\end{aligned}
\]

Si dans la formule (22) on suppose \(\psi x=1-x^{2 n}\), on trouve
\[
\begin{gathered}
\int \frac{\left(1-x^{2 n}\right)^m d x}{x-a}=\left(1-a^{2 n}\right)^m \Sigma \Sigma \varphi\left(p, p^{\prime}\right) \int\left(1-x^{2 n}\right)^m x^p d x \cdot \int \frac{a^{p^{\prime}} d a}{\left(1-a^{2 n}\right)^{m+1}} \\
(x=1, x=-1, \quad a=1),
\end{gathered}
\]
où \(m+1\) doit être moindre que l'unité, e'est-à-dire que \(m<0\). On a
\[
\varphi\left(p, p^{\prime}\right)=\left(p+1+m\left(p+p^{\prime}+2\right)\right) k^{\left(p+p^{\prime}+2\right)}:
\]
puisque \(k^{\left(p+p^{\prime}+2\right)}=0\), à moins que \(p+p^{\prime}+2=2 n\), et comme \(k^{2 n}=-1\), on en tire
\[
\varphi\left(p, p^{\prime}\right)=-(p+1+2 m n) \text {. }
\]

L'intégrale \(\int\left(1-x^{2 n}\right)^m x^p d x\) peut être exprimée par la fonction \(I\). On a en effet
%57
\[
\int_{+\mathrm{r}}^{-1}\left(1-x^{2 n}\right)^m x^p d x=-\int_0^1\left(1-x^{2 n}\right)^m x^p d x+\int_0^{-1}\left(1-x^{2 n}\right)^m x^p d x
\]

Mais on a
\[
\int_0^{-1}\left(1-x^{2 n}\right)^m x^p d x=(-1)^{p+1} \int_0^1\left(1-x^{2 n}\right)^m x^p d x
\]
comme on le voit en mettant \(-x\) au lieu de \(x\). Donc
\[
\int_{+1}^{-1}\left(1-x^{2 n}\right)^m x^p d x=\left((-1)^{p+1}-1\right) \int_0^1\left(1-x^{2 n}\right)^m x^p d x
\]
c'est-à-dire qu'on a
\[
\begin{aligned}
& \int_{+1}^{-1}\left(1-x^{2 n}\right)^m x^{2 p} d x=-2 \int_0^1\left(1-x^{2 n}\right) x^{2 p} d x \\
& \int_{+1}^{-1}\left(1-x^{2 n}\right)^m x^{2 p+1} d x=0 .
\end{aligned}
\]

Or on déduit aisément d'une formule connue (Legendre Exercices de calcul intégral t. I p. 279) l'équation suivante
on a done
\[
\int_0^1\left(1-x^{2 n}\right)^m x^{2 p} d x=\frac{\boldsymbol{r}(m+1) \boldsymbol{T}\left(\frac{1+2 p}{2 n}\right)}{2 n \boldsymbol{r}\left(m+1+\frac{1+2 p}{2 n}\right)}
\]
\[
\int_{+1}^{-1}\left(1-x^{2 n}\right)^m x^{2 n} d x=-\frac{\Gamma(m+1) \Gamma\left(\frac{1+2 p}{2 n}\right)}{n \Gamma\left(m+1+\frac{1+2 p}{2 n}\right)}
\]

En substituant cette valeur, et écrivant ensuite \(-m\) pour \(m\), on obtient (24) \(\int \frac{d x}{(x-a)\left(1-x^{2 n}\right)^m}=\frac{\Gamma(-m+1)}{u\left(1-a^{2 n}\right)^m} \Sigma(2 p+1-2 m n) \frac{\Gamma\left(\frac{1+2 p}{2 n}\right)}{\Gamma\left(-m+1+\frac{1+2 p}{2 n}\right)} \int \frac{a^{2 n-2 p-2} d u}{\left(1-u^{2 n}\right)^{1-m}}\)
\[
(x=1, x=-1 ; a=1) \text {. }
\]

Si l'on fait \(m=\frac{1}{2}\), on trouve
\[
\begin{gathered}
\int \frac{d x}{(a-a) \sqrt{1-x^{2 n}}}=\frac{\Gamma\left(\frac{1}{2}\right)}{n \sqrt{1-a^{2 n}}} \Sigma(2 p+1-n) \frac{\Gamma\left(\frac{1+2 p}{2 n}\right)}{\Gamma\left(\frac{1}{2}+\frac{1+2 p}{2 n}\right)} \int \frac{a^{2 n-2 p-2} d u}{\sqrt{1-a^{2 n}}} \\
(x=1, x=-1 ; a=1, a=a) .
\end{gathered}
\]
%58
Par exemple si \(n=3\), on trouve
\[
\begin{aligned}
& \int \frac{d x}{(x-a) \sqrt{1-x^6}}=-\frac{2}{3} \frac{\Gamma\left(\frac{1}{2}\right) \Gamma\left(\frac{1}{6}\right)}{\Gamma\left(\frac{2}{3}\right) \sqrt{1-a^6}} \int \frac{a^4 d a}{\sqrt{1-a^6}}+\frac{2}{3} \frac{\Gamma\left(\frac{1}{2}\right) \Gamma\left(\frac{5}{6}\right)}{\Gamma\left(\frac{1}{3}\right) \sqrt{1-a^6}} \int \frac{d u}{\sqrt{1-a^6}} \\
& (x=1, x=-1 ; a=1) \text {. } \\
&
\end{aligned}
\]

Or on a \(\boldsymbol{T}\left(\frac{1}{2}\right)=\sqrt{\pi}\), en substituant cette valeur on obtient
\[
\begin{gathered}
\int \frac{d x}{(x-a) \sqrt{1-x^6}=-}-\frac{2}{3} \frac{\sqrt{x}}{\sqrt{1-a^6}} \frac{\Gamma\left(\frac{1}{6}\right)}{\Gamma\left(\frac{2}{3}\right)} \int \frac{a^4 d a}{\sqrt{1-a^6}}+\frac{2}{3} \frac{\sqrt{\pi}}{\sqrt{1-a^6}} \frac{\Gamma\left(\frac{5}{6}\right)}{\Gamma\left(\frac{4}{3}\right)} \int \frac{d a}{\sqrt{1-a^6}} \\
(x=1, x=-1 ; a=1) .
\end{gathered}
\]

Dans ce qui précède nous avons supposé \(e^{f x} \varphi x \cdot \psi x=0\); supposons maintenant qu'on ait en même temps \(\frac{e^{-f a}}{q a}=0\), et désignons par \(a^{\prime \prime}\) une valeur de a qui satisfait à cette condition. L'équation (4) devient dans ce cas:
\[
\begin{gathered}
\Sigma \Sigma \varphi\left(p, p^{\prime}\right) \int \frac{e^{-f a} a^{p^{\prime}} d a}{\Psi^a \cdot \psi^{\prime}(a} \cdot \int e^{f x} \varphi x \cdot x^p d x=0 \\
\left(x=x^{\prime}, \quad x=x^{\prime \prime} ; \quad a=a^{\prime}, \quad a=a^{\prime \prime}\right) .
\end{gathered}
\]

Si \(f x=0\), on a
\[
\begin{aligned}
& \Sigma \Sigma \varphi\left(p, p^{\prime}\right) \int \frac{a^{p^{\prime}} d a}{\varphi a \cdot \psi^{\prime} a} \cdot \int \varphi x \cdot x^p d x=0 \\
& \left(x=x^{\prime}, \quad x=x^{\prime \prime} ; \quad a=a^{\prime}, \quad a=a^{\prime \prime}\right) .
\end{aligned}
\]

Supposons que \(\beta, \beta^{\prime}, \beta^{\prime \prime} \ldots\) soient négatifs, mais que leurs valeurs absolues soient moindres que l'unité, nous awrons \(\varphi x \cdot \psi x=0\) poui \(x=-\alpha^{(r)}\), et \(\frac{1}{\rho a}=0\) pour \(a=-\alpha^{(q)}\). On obtient ainsi la formule suivante
\[
\begin{gathered}
\sum \Sigma \varphi\left(p, p^{\prime}\right) \int \frac{a^{p^{\prime}} d a}{\psi^{\prime \prime a}} \cdot \int \frac{x^p d x}{\uparrow x}=0 \\
\left(x=-\alpha^{(p)}, x=-\alpha^{\left(p^{\prime}\right)} ; a=-\alpha^{(q)}, a=-\alpha^{\left(q^{\prime}\right)}\right),
\end{gathered}
\]
où l'on a fait
\[
\begin{aligned}
& \Psi x=(x+\alpha)^\beta\left(x+\alpha^{\prime}\right)^{\beta^{\prime}}\left(x+\alpha^{\prime \prime}\right)^{\beta^{\prime \prime}} \ldots \\
& \psi\left(a=(\alpha+\alpha)^{1-\beta}\left(\alpha+\alpha^{\prime}\right)^{1-\beta^{\prime}}\left(\alpha+\alpha^{\prime \prime}\right)^{1-\beta^{\prime \prime}} \ldots .,\right.
\end{aligned}
\]
\(\beta, \beta^{\prime}, \beta^{\prime \prime} \ldots\) étant positifs et moindres que l'unité.
%59
En faisant \(\beta=\beta^{\prime}=\beta^{\prime \prime}=\cdots=\frac{1}{2}\), on obtient
\[
\begin{gathered}
\Sigma \Sigma\left(p-p^{\prime}\right) k^{\left(p+p^{\prime}+2\right)} \int \frac{a^{p^{\prime}} d a}{\sqrt{\varphi} a} \cdot \int \frac{x^p d x}{\sqrt{q x}}=0 \\
\left(x=-\alpha^{(p)}, x=-\alpha^{\left(p^{\prime}\right)} ; \quad a=-\alpha^{(q)}, a=-\alpha^{\left(q^{\prime}\right)}\right) .
\end{gathered}
\]

Dans cette formule on a
\[
\boldsymbol{\varphi} x=(x+\alpha)\left(x+\alpha^{\prime}\right)\left(x+\alpha^{\prime \prime}\right) \cdots=k+k^{\prime} x+k^{\prime \prime} x^2+\cdots
\]

Par exemple si l'on pose \(\varphi x=(1-x)(1+x)(1-c x)(1+c x)\), on a \(\alpha=1, \alpha^{\prime}=-1, \alpha^{\prime \prime}=\frac{1}{c}, \alpha^{\prime \prime \prime}=-\frac{1}{c}\), donc
\[
\begin{aligned}
& \int \frac{d a}{\sqrt{\left(1-a^2\right)\left(1-c^2 a^2\right)}} \cdot \int \frac{x^2 d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}=\int \frac{a^2 d a}{\sqrt{\left(1-a^2\right)\left(1-c^2 a^2\right)}} \cdot \int \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}} \\
& (x=1, \quad x=-1 ; \quad a=1, \quad a=-1) \\
& \left(x=1, \quad x=-1 ; \quad a=1, \quad a=\frac{1}{c}\right) \\
& \left(x=1, \quad x=-1 ; \quad a=1, \quad a=-\frac{1}{c}\right) \\
& \left(x=1, \quad x=-1 ; \quad a=\frac{1}{c}, a=-\frac{1}{c}\right) \\
& \left(x=1, \quad x=\frac{1}{c} ; a=1, \quad a=\frac{1}{c}\right) \\
& \left(x=1, \quad x=\frac{1}{c} ; a=1, \quad a=-\frac{1}{c}\right) \\
& \left(x=1, \quad x=\frac{1}{c} ; a=\frac{1}{c}, a=-\frac{1}{c}\right) \\
& \left(x=\frac{1}{c}, x=-\frac{1}{c} ; a=\frac{1}{c}, a=-\frac{1}{c}\right) \\
&
\end{aligned}
\]

Désignons par \(F x\) la valeur de l'intégrale \(\int \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}\) prise depuis \(x=0\), et par \(E x\) celle de \(\int \frac{x^2 d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}\) depuis \(x=0\), nous aurons
\[
\begin{aligned}
& \int_\alpha^{\alpha^{\prime}} \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}=F \alpha^{\prime}-F \alpha \\
& \int_\alpha^{\alpha^{\prime}} \frac{x^2 d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}=E \alpha^{\prime}-E \alpha .
\end{aligned}
\]
%60
En substituant ces valeurs, on aura la formule suivante
\[
F(1) E\left(\frac{1}{c}\right)=E(1) F\left(\frac{1}{c}\right)
\]

On n'obtient pas d'antres relations quel que soit le système de limites qu'on emploie, excepté, seulement les systèmes qui donnent des identités, savoir le \(1^{\text {er }}\), le \(5^{\text {ième }}\) ét le \(8^{\text {ième }}\).

Si l'on désigne en général par \(F(p, x)\) la valeur de l'intégrale \(\int \frac{x^p d x}{\sqrt{f^x}}\) prise d'une limite inférieure arbitraire, on a
\[
\int_\alpha^{a^{\prime}} \frac{x^p d x}{\sqrt{\rho x}}=F\left(p, \alpha^{\prime}\right)-F^{\prime}(p, \alpha)
\]

En substituant cette valeur dans la formule (28), on obtient la suivante:
\[
\text { 9) } \begin{aligned}
& \Sigma \Sigma\left(p-p^{\prime}\right) k^{\left(p+p^{\prime}+2\right)} F(p, \alpha) F^{\prime}\left(p^{\prime}, \alpha^{\prime}\right)+\Sigma \Sigma\left(p-p^{\prime}\right) k^{\left(p+p^{\prime}+2\right)} F\left(p, \alpha^{\prime \prime}\right) F\left(p^{\prime}, \alpha^{\prime \prime \prime}\right) \\
= & \Sigma \Sigma\left(p-p^{\prime}\right) k^{\left(p+p^{\prime}+2\right)} F(p, \alpha) F^{\prime}\left(p^{\prime}, \alpha^{\prime \prime \prime}\right)+\Sigma \Sigma\left(p-p^{\prime}\right) k^{\left(p+p^{\prime}+2\right)} F\left(p, \alpha^{\prime \prime}\right) F\left(p^{\prime}, \alpha^{\prime}\right) .
\end{aligned}
\]

De cette formule on peut en déduire beaucoup d'autres plus spéciales en supposant \(\varphi x\) paire on impaire, mais pour ne pas m'étendre trop au long je les passe sous silence.

Il faut se rappeler que \(\alpha, \alpha^{\prime}, \alpha^{\prime \prime}, \alpha^{\prime \prime \prime}\) peuvent désigner des racines quelconques de l'équation \(\varphi x=0\). On peut aussi supposer \(\alpha=\alpha^{\prime}, \alpha^{\prime \prime}=\alpha^{\prime \prime \prime}\).
%61
VI.

RECHERCHE DES FONCTIONS DE DEUX QUANTITÉS VARIABLES INDÉPENUANTES \(x\) ET \(y\), TELLES QUE \(f(x, y)\), QUI ONT LA PROPRIÉTÉ QUE \(f(z, f(x, y))\) EST UNE FONCTION SYMÉTRIQUE DE \(z, x\) ET \(y\).
Journal für die reine und angewandte Mathematik, herausgegeben von Crelle, Bd. I, Berlin 1826.
Si l'on désigne p. ex. les fonctions \(x+y\) et \(x y\) par \(f(x, y)\), on a pour la première, \(f(z, f(x, y))=z+f(x, y)=z+x+y\), et pour la seconde, \(f(z, f(x, y))=z f(x, y)=z x y\). La fonction \(f(x, y)\) a donc dans l'un et l'autre cas la propriété remarquable que \(f(z, f(x, y))\) est une fonction symétrique des trois variables indépendantes \(z, x\) et \(y\). Je vais chercher dans ce mémoire la forme générale des fonctions qui jouissent de cette propriété.
L'éruation fondamentale est celle-ci:
(1) \(\quad f(z, f(x, y))=\) une fonction symétrique de \(x, y\) et \(z\).

Une fonction symétrique reste la même lorsqu'oin y échange entre elles d'une manière quelconque, les quantités variables dont elle dépend. On a donc les équations suivantes:
\((2)\)
\[
\begin{aligned}
& f(z, f(x, y))=f(z, f(y, x)), \\
& f(z, f(x, y))=f(x, f(z, y)), \\
& f(z, f(x, y))=f(x, f(y, z)), \\
& f(z, f(x, y))=f(y, f(x, z)), \\
& f\left(z, f(x, y)^g\right)=f(y, f(z, x)) .
\end{aligned}
\]
%62
La première équation ne peut avoir lieu à moins qu'on n'ait
\[
f(x, y)=f(y, x)
\]
c'est-à-dire que \(f(x, y)\) doit être une fonction symétrique de \(x\) et \(y\). Par cette raison les équations (2) se réduisent aux deux suivantes:
\[
\begin{aligned}
& f(z, f(x, y))=f(x, f(y, z)), \\
& f(z, f(x, y))=f(y, f(z, x)) .
\end{aligned}
\]

Soit pour abréger \(f(x, y)=r, f(y, z)=v, f(z, x)=s\), on aura
\[
f(z, r)=f(x, v)=f(y, s) .
\]

En différentiant successivement par rapport à \(x, y, z\), on aura
\[
\begin{aligned}
& f^{\prime} r \frac{d r}{d x}=f^{\prime} s \frac{d s}{d x}, \\
& f^{\prime} v \frac{d v}{d y}=f^{\prime} r \frac{d r}{d y}, \\
& f^{\prime} s \frac{d s}{d z}=f^{\prime} v \frac{d v}{d z} .
\end{aligned}
\]

Si l'on multiplie ces équations membre à membre et qu'on divise les produits par \(f^{\prime} r \cdot f^{\prime} \cdot \cdot f^{\prime} s\), on obtiendra cette équation
\[
\frac{d r}{d x} \frac{d v}{d y} \frac{d s}{d z}=\frac{d r}{d y} \frac{d v}{d z} \frac{d s}{d x}
\]
ou bien
\[
\frac{d v}{d x} \frac{\frac{d v}{d y}}{\frac{d v}{d z}}=\frac{d v}{d y} \frac{\frac{d s}{d x}}{\frac{d s}{d z}}
\]

Si l'on fait \(z\) invariable, \(\frac{d v}{d y}: \frac{d v}{d z}\) se réduira à une fonction de \(y\) seule. Soit \(\varphi y\) cette fonction, on aura en même temps \(\frac{d s}{d x}: \frac{d s}{d z}=\varphi x\); car s est la même fonction de \(z\) et \(x\) que \(v\) l'est de \(z\) et \(y\). Donc
\[
\frac{d r}{d x} \varphi y=\frac{d r}{d y} \varphi x
\]

On en tirera, en intégrant, la valeur générale de \(r\),
\[
r=\psi\left(\int \varphi x \cdot d x+\int \varphi y \cdot d y\right)
\]
%63
\(\psi\) étant une fonction arbitraire. En écrivant pour abréger \(\varphi x\) pour \(\int \varphi x d x\), et \(\varphi y\) pour \(\int \varphi y d y\), on aura
\[
r=\psi(\varphi x+\varphi y) \text {, on } f(x, y)=\psi(\varphi x+\varphi y) \text {. }
\]

Voilà donc la forme que doit avoir la fonction cherchée. Mais elle ne peut pas dans toute sa geénéralité satisfaire à l'équation (4). En effet l'équation (5), qui donne la forme de la fonction \(f(x, y)\), est beancoup plus générale que l'équation (4), à laquelle elle doit satisfaire. Il s'agit donc des restrictions auxquelles l'équation geénérale est assujettie. On a
\[
f(z, r)=\psi(\varphi z+\varphi r)
\]

Or \(r=\psi(\varphi x+\varphi y)\), done
\[
f(z, r)=\psi(\varphi z+\varphi \psi(\varphi x+\varphi y)) .
\]

Cette expression doit être symétrique par rapport ì \(x, y\) et \(z\). Donc
\[
\varphi z+\varphi \psi(\varphi x+\varphi y)=\varphi x+\varphi \psi(\varphi y+\varphi z) .
\]

Soit \(\varphi z=0\) et \(\varphi y=0\), on aura
\[
\varphi \psi \varphi x=\varphi x+\varphi \psi(0)=\varphi x+c,
\]
donc en faisant \(\varphi x=p\),
\[
\varphi \psi p=p+c
\]

En désignant donc par \(\varphi_1\) la fonction inverse de celle qui est exprimée par \(\varphi\), de sorte que
on trouvera
\[
\begin{gathered}
\varphi \varphi_1 x=x \\
\psi p=\varphi_1(p+c) .
\end{gathered}
\]

La forme générale de la fonction cherchée \(f(x, y)\) sera donc
\[
f(x, y)=\varphi_1(c+\varphi x+\varphi y)
\]
et cette fonction a en effet la propriété demandée. On tire de la
\[
\varphi f(x, y)=c+\varphi x+\varphi y
\]
our, en mettant \(\psi x-c\) à la place de \(\varphi x\), et par conséquent \(\psi \prime y-c\) à la place de \(\uparrow ! y\) et \(\psi f(x, y)-c\) à la place de \(\varphi f(x, y)\),
\[
\psi f(x, y)=\psi x+\psi y \text {. }
\]
%64
Cela donne le théorème suivant:
Lorsqu'une fanction \(f(x, y)\) de deux quantités variables indépendantes \(x\) et \(y\) a la propriété que \(f(z, f(x, y))\) est une fonction symétrique de \(x\), \(y\) et \(z\), il y aura toujours une fonction \(\psi\) pour laquelle on a
\[
\psi f(x, y)=\psi x+\psi y \text {. }
\]

La fonction \(f(x, y)\) étant donnée, on trouvera aisément la fonction \(\psi x\). En effet on aura en différentiant l'équation ci-dessus, par rapport à \(x\) et par rapport à \(y\), et faisant pour abréger \(f(x, y)=r\)
\[
\begin{aligned}
& \psi^{\prime} r \frac{d r}{d x}=\psi^{\prime} x \\
& \psi^{\prime} r \frac{d r}{d y}=\psi^{\prime} y
\end{aligned}
\]
done en éliminant \(\psi^{\prime} r\)
\[
\frac{d r}{d y} \psi^{\prime} x=\frac{d r}{d x} \psi^{\prime} y
\]
d'où
\[
\psi^{\prime} x=\psi^{\prime} y \frac{\frac{d r}{d x}}{\frac{d r}{d y}} .
\]

Multipliant donc par \(d x\) et intégrant, on aura
\[
\psi x=\psi^{\prime} y \int \frac{\frac{d r}{d x}}{\frac{d r}{d y}} d x
\]

Soit par exemple
\[
\dot{r}=f(x, y)=x y,
\]
il se trouvera une fonction \(\psi\) pour laquelle
\[
\psi(x y)=\psi x+\psi y .
\]

Cormme \(r=x y\), on a \(\frac{d r}{d x}=y, \frac{d r}{d y}=x\), done
\[
\psi x=\psi^{\prime} y \int \frac{y}{x} d x=y \psi^{\prime} y \cdot \log c x
\]
ou, puisque la quantité y est supposée constante,
\[
\psi x=a \log c x .
\]
%65
Cela dome \(\psi^{\prime \prime} y=a \log c y, \quad \psi(x y)=a \log c x y\); on doit donc avoir:
\[
a \log c x y=a \log c x+a \log c y,
\]
ce qui a effectivement lieu pour \(c=1\).
Par un procédé semblable au précédent, on peut en général trouver dès fonctions de deux quantités variables, qui satisfassent à des équations données à trois variables. En effet, par des différentiations successives par rapport aux différentes quantités variables, on trouvera des équations, desquelles on peut éliminer autant de fonctions inconnues qu'on voudra, jusqu'à ce qu'on soit parvenu à une équation qui ne contienne qu'une seule fonction inconnue. Cette équation sera une équation différentielle partielle à deux variables indépendantes. L'expression que donne cette équation contiendra donc un certain nombre de fonctions arbitraires d'une seule quantité variable. Lorsque les fonctions inconnues trouvées de cette manière seront substituées dans l'équation donnée, on trouvera une équation entre plusieurs fonctions d'une seule quantité variable. Pour trouver ces fonctions, on doit différentier de nouveau et l'on parviendra ainsi à des équations différentielles ordinaires, al moyen desquelles on trouvera les fonctions, qui ne sont plus arbitraires. De cette manière on trouvera la forme de toutes les fonctions inconnues, à moins qu'il ne soit impossible de satisfaire à l'équation donnée.
%66
VII.

DÉMONSTRATION DE L'IMPOSSIBILITÉ IE LA RÉSOLUTION ALGÉBRIQUE DEs ÉQUATIONS GÉNÉRALES QUI PASSENT LE QUATRIÈME DEGRÉ.
Journal fiir die reine und angewandte Mathematik, herausgegeben von Crclle, Bd. 1, Berlin 1826.
On peut, comme on sait, résondré les équations générales jusqu'au quatrième degré, mais les équations d'un degré plus élevé, seulement dans des cas particuliers, et, si je ne me trompe, on n'a pas encore répondu d'une manière satisfaisante à la question: "Est-il possible de résoudre en général les équations qui passent le quatrième degré?" Ce mémoire a pour but de répondre à cette question.

Résoudre algébriquement une équation ne vent dire autre chose, que d'exprimer ses racines par des fonctions algébriques des coefficiens. Il faut donc considérer d'abord la forme générale des fonctions algébriques, et chercher ensuite s'il est possible de satisfaire à l'équation donnée, en mettant l'expression d'une fonction algébrique au lieu de l'inconnue.
\(\$ 1\).
Siur la forme générale des fonctions algébriques.
Soient \(x^{\prime}, x^{\prime \prime}, x^{\prime \prime} \ldots\) un nombre fini de quantités quelconques. On dit que \(v\) est une fonction clgélrique de ces quantités, s'il est possible d'exprimer \(v\) en \(x^{\prime}, x^{\prime \prime}, x^{\prime \prime \prime} \ldots\) à l'aide des opérations suivantes: 1) par l'addition; 2) par la multiplication, soit de quantités dépendant de \(x^{\prime}, x^{\prime \prime}, x^{\prime \prime \prime} \ldots\), soit de quantités qui n’en dépendent pas; 3) par la division; 4) par l'extraction de racines d'indices premiers. Parni ces opé-
%67
rations nous n'avons pas compté la soustraction, l'élévation à des puissances entières et l'extraction de racines de degrés composés, car elles sont évidemment comprises dans les quatre opérations mentionnées.

Lorsque la fonction \(v\) peut se former par les trois premières des opérations ci-dessus, elle est dite algébrique et rationnelle, ou seulement rationnelle; et si les deux premières opérations sont seules nécessaires, elle est dite algébrique, rationnelle et entière, ou seulement entière.

Soit \(f\left(x^{\prime}, x^{\prime \prime}, x^{\prime \prime \prime} \ldots\right)\) une fonction quelconque qui peut s'exprimer par la somme d'un nombre fini de termes de la forme
\[
A x^{\prime m_1} x^{m_{m_2}} \ldots \ldots
\]
où \(A\) est une quantité indépendante de \(x^{\prime}, x^{\prime \prime}\) etc. et où \(m_1, m_2\) etc. désignent des nombres entiers positifs; il est clair que les deux premières opérations ci-dessus sont des cas particuliers de l'opération désignée par \(f\left(x^{\prime}, x^{\prime \prime}, x^{\prime \prime \prime} \ldots\right)\). On peut donc considérer les fonctions entières, suivant leur définition, comme résultant d'un nombre limité de répétitions de cette opération. En désignant par \(v^{\prime}, v^{\prime \prime}\), \(v^{\prime \prime \prime}\) etc. plusieurs fonctions des quantités \(x^{\prime}, x^{\prime \prime} x^{\prime \prime \prime} \ldots\) de la même forme que \(f\left(x^{\prime}, x^{\prime \prime} \ldots\right)\), la fonction \(f\left(v^{\prime}, v^{\prime \prime} \ldots\right)\) sera évidemment de la même forme que \(f\left(x^{\prime}, x^{\prime \prime} \ldots\right)\). Or \(f\left(v^{\prime}, v^{\prime \prime} \ldots\right)\) est l'expression générale des fonctions qui résultent de l'opération \(f\left(x^{\prime}, x^{\prime \prime} \ldots.\right)\) deux fois répétée. On trouvera donc toujours le même résultat en répétant cette opération antant de fois qu'on voudra. Il suit de lì, que toute fonction entière de plusieurs quantités \(x^{\prime}, x^{\prime \prime} \ldots\). peut être exprimée par une somme de plusieurs termes de la forme \(A x^{\prime m_1} x^{\prime \prime m_2} \ldots \ldots\)

Considérons maintenant les fonctions rationnelles. Lorsque \(f\left(x^{\prime}, x^{\prime \prime} \ldots\right)\) et \(\varphi\left(x^{\prime}, x^{\prime \prime} \ldots\right)\) sont deux fonctions entières, il est évident, que les trois premières opérations sont des cas particuliers de l'opération désignée par
\[
\frac{f\left(x^{\prime}, x^{\prime \prime} \ldots\right)}{\varphi\left(x^{\prime}, x^{\prime \prime} \ldots\right)}
\]

On peut donc considérer une fonction rationnelle comme le résultat de la répétition de cette opération. Si l'on désigne par \(v^{\prime}, v^{\prime \prime}, v^{\prime \prime \prime}\) etc. plusieurs fonctions de la forme \(\frac{f\left(x^{\prime}, x^{\prime \prime} \ldots\right)}{q\left(x^{\prime}, x^{\prime \prime} \ldots\right)}\), on voit aisément que la fonction \(\frac{f\left(v^{\prime}, v^{\prime \prime} \ldots\right)}{q\left(v^{\prime}, v^{\prime \prime} \ldots\right)}\) peut être réduite à la même forme. Il suit de là, que toute fonction rationnelle de plusieurs quantités \(x^{\prime}, x^{\prime \prime} \ldots\) peut toujours être réduite à la forme
\[
\frac{f\left(x^{\prime}, x^{\prime \prime} \ldots\right)}{\boldsymbol{\tau}\left(x^{\prime}, x^{\prime \prime} \ldots\right)}
\]
où le numérateur et le dénominateur sont des fonctions entières.
%68
Enfin nous allons chercher la forme générale des fonctions algébriques. Désignons par \(f\left(x^{\prime}, x^{\prime \prime} \ldots\right)\) une fonction rationnelle quelconque, il est clair que toute fonction algébrique peut être composée à l'aide de l'opération désignée par \(f\left(x^{\prime}, x^{\prime \prime} \ldots\right)\) combinée avec l'opération \(\sqrt[m]{r}\), où \(m\) est un nombre premier. Donc, si \(p^{\prime}, p^{\prime \prime} \ldots\) sont des fonctions rationnelles de \(x^{\prime}, x^{\prime \prime} \ldots\),
\[
p_1=f\left(x^{\prime}, x^{\prime \prime} \ldots \sqrt[n^{\prime}]{p^{\prime}}, \sqrt[n^*]{p^{\prime \prime}} \ldots\right)
\]
sera la forme générale des fonctions algébriques de \(x^{\prime}, x^{\prime \prime} \ldots\), dans lesquelles l'opération exprimée par \(\sqrt[m]{r}\) affecte seulement des fonctions rationnelles. Les fonctions de la forme \(p_1\) seront dites fonctions algébriques du premier ordre. En désignant par \(p_1^{\prime}, p_1{ }^{\prime \prime} \ldots\) plusieurs quantités de la forme \(p_1\), l'expression
\[
p_2=f\left(x^{\prime}, x^{\prime \prime} \ldots \sqrt[n^{\prime}]{p^{\prime}}, \sqrt[n^{\prime \prime}]{p^{\prime \prime}} \ldots \sqrt[n_1^{\prime}]{p_1^{\prime}}, \sqrt[n_1^{\prime \prime}]{p_1^{\prime \prime}} \ldots\right)
\]
sera la forme générale des fonctions algébriques de \(x^{\prime}, x^{\prime \prime} \ldots\), dans lesquelles l'opération \(\sqrt[m]{r}\) affecte seulement des fonctions rationnelles, et des fonctions algébriques du premier ordre. Les fonctions de la forme \(p_z\) seront dites fonctions algébriques du deuxième ordie. De la même manière l'expression
dans laquelle \(p_2^{\prime}, p_2{ }^{\prime \prime} \ldots\) sont des fonctions du deuxième ordre, sera la forme générále des fonctions algébriques de \(x^{\prime}, x^{\prime \prime} \ldots\), dans lesquelles l'opération \(\sqrt[m]{r}\) n'affecte que des fonctions rationnelles, et des fonctions algébriques du premier et du deuxième ordre.

En continuant de cette manière, on obtiendra des fonctions algébriques du troisième, du quatrième .... du \(\mu^{\text {ième }}\) ordre, et il est clair, que l'expression des fonctions du " \({ }^{i \text { ime }}\) ordre, sera l'expression générale des fonctions algébriques.

Donc en désignant par " l'ordre d'une fonction algébrique quelconque et par \(v\) la fonction même, on aura
\[
v=f\left(r^{\prime}, r^{\prime \prime} \ldots \sqrt[n^{\prime}]{p^{\prime}}, \sqrt[n^n]{p^{\prime \prime}} \ldots\right)
\]
%69
où \(p^{\prime}, p^{\prime \prime} \ldots\) sont des fonctions de l'ordre, \(\boldsymbol{\mu}-1 ; r^{\prime}, r^{\prime \prime} \ldots\) des fouctions de l'ordre, \(1-1\) ou des ordres moins élevés, et \(n^{\prime}, n^{\prime \prime} \ldots\) des nombres premiers; \(f\) désigne toujours une fonction rationnelle des quantités comprises entre les parenthèses.

On pent évidemment supposer qu'il est impossible d'exprimer l'une des quantités \(\sqrt[n^{\prime}]{p^{\prime}}, \sqrt[n^*]{p^{\prime \prime}} \ldots\) par une fonction rationnelle des autres et des quantités \(r^{\prime}, r^{\prime \prime} \ldots\); car dans le cas contraire, la fonction \(v\) aurait cette forme plus simple,
\[
v=f\left(r^{\prime}, r^{\prime \prime} \ldots \sqrt[n^{\prime}]{p^{\prime}}, \sqrt[n^*]{p^{\prime \prime}} \ldots\right)
\]
unité. En réduisant de cette manière l'expression de \(v\) autant que possible, on parviendrait, on à nue expression irréductible, ou à une expression de la forme
\[
v=f\left(r^{\prime}, r^{\prime \prime}, r^{\prime \prime \prime} \ldots\right)
\]
mais cette fonction serait seulement de l'ordre \(\mu-1\), tandis que \(v\) doit être du \(\mu^{\text {ième }}\) ordre, ce qui est une contradiction.

Si dans l'expression de \(v\) le nombre des quantités \(\sqrt[n^{\prime}]{p^{\prime}}, \sqrt[n^{\prime \prime}]{p^{\prime \prime}} \ldots\) est égal à \(m\), nous dirons que la fonction \(v\) est du \(\mu^{\text {ième }}\) ordre et du \(m^{i e m e}\) degré. On voit donc qu'une fonction de l'ordre \(\mu\) et du degré 0 est la même chose qu'une fonction de l'ordre " -1 , et qu'une fonction de l'ordre 0 est la même chose qu'une fonction rationnelle.
Il suit de là, qu’on peut poser
\[
v=f\left(r^{\prime}, r^{\prime \prime} \ldots \sqrt[n]{p}\right)
\]
où \(p\) est une fonction de l'ordre,\(\mu-1\), mais \(r^{\prime} ; r^{\prime \prime} \ldots\) des fonctions du \(\mu^{\text {ième }}\) ordre et tout au plus du degré \(m-1\), et qu'on peut tonjours supposer qu'il est impossible d'exprimer \(\sqrt[n]{p}\) par une fonction rationnelle de ces quantités.

Dans ce qui précède nous avons vu qu'une fonction rationnelle de plusieurs quantités peut toujours être réduite à la forme
\[
\frac{s}{t},
\]
oì \(s\) et \(t\) sont des fonctions entières des mêmes quantités variables. On
%70
conclut de là que \(v\) peut toujours être exprimé comme il suit,
\[
v=\frac{\tau\left(r^{\prime}, r^{\prime \prime} \ldots \sqrt[n]{p}\right)}{\tau\left(r^{\prime}, r^{\prime \prime} \ldots \sqrt[n]{p}\right)}
\]
où \(\varphi\) et \(\tau\) désignent des fonctions entières des quantités \(r^{\prime}, r^{\prime \prime} \ldots\) et \(\sqrt[n]{r}\). En vertu de ce que nous avons trouvé plus haut, toute fonction entière de plusieurs quantités \(s, r^{\prime}, r^{\prime \prime} \ldots\) peut s'exprimer par la forme
\[
t_0+t_1 s+t_2 s^2+\cdots+t_m s^m
\]
\(t_0, t_1 \ldots t_m\) étant des fonctions entières de \(r^{\prime}, r^{\prime \prime}, r^{\prime \prime \prime} \ldots\) sans \(s\). On peut donc poser
\[
v=\frac{t_0+t_1 p^{\frac{1}{n}}+t_2 p^{\frac{2}{n}}+\cdots+t_m p^{\frac{m}{n}}}{v_0+v_1 p^{\frac{1}{n}}+v_2 p^{\frac{2}{n}}+\cdots+v_m p^{\frac{m^{\prime}}{n}}}=\frac{T}{V},
\]
où \(t_0, t_1 \ldots t_m\) et \(v_0, v_1 \ldots v_{m^{\prime}}\) - sont des fonctions entières de \(r^{\prime}, r^{\prime \prime}\), \(r^{\prime \prime \prime}\) etc.
Soient \(V_1, V_2 \ldots V_{n-1}\) les \(n-1\) valeurs de \(V\) qu'on trouve en mettant successivement \(\alpha p^{\frac{1}{n}}, \alpha^2 p^{\frac{1}{n}}, \alpha^3 p^{\frac{1}{n}} \ldots \alpha^{n-1} p^{\frac{1}{n}}\) au lieu de \(p^{\frac{1}{n}}, \alpha\) étant une racine différente de l'unité de l'équation \(\alpha^n-1=0\); on trouvera en multipliant le numérateur et le dénominateur de \(\frac{T}{V}\) par \(V_1 V_2 V_3 \ldots V_{n-1}\)
\[
v=\frac{T V_1 V_2 \ldots V_{n-1}}{V V_1 V_2 \ldots V_{n-1}}
\]

Le produit \(V V_1 \ldots V_{n-1}\) peut, comme on sait, s'exprimer par une fonction entière de \(p\) et des quantités \(r^{\prime}, r^{\prime \prime} \ldots\), et le produit \(T V_1 \ldots V_{n-1}\) est, comme on le voit, une fonction entière de \(\sqrt[n]{p}\) et de \(r^{\prime}, r^{\prime \prime} \ldots\) En supposant ce produit égal ì
\[
s_0+s_1 p^{\frac{1}{n}}+s_2 p^{\frac{2}{n}}+\cdots+s_k p^{\frac{k}{n}}
\]
on trouve
\[
v=\frac{s_0+s_1 p^{\frac{1}{n}}+s_2 p^{\frac{2}{n}}+\cdots+s_k p^{\frac{k}{n}}}{m}
\]
ou, en écrivant \(q_0, q_1, q_2 \ldots\) an lien de \(\frac{s_0}{m}, \frac{s_1}{m}, \frac{s_2}{m}\) etc.,
%71
\[
v=q_0+q_1 p^{\frac{1}{n}}+q_2 p^{\frac{2}{n}}+\cdots+q_k p^{\frac{k}{n}}
\]
où \(q_0, q_1 \ldots q_k\) sont des fonctions rationnelles des quantités \(p, r^{\prime}, r^{\prime \prime} \ldots\) etc.
Soit \(\mu\) un nombre entier quelconque, on peut toujours poser
\[
\mu=a n+\alpha,
\]
\(a\) et \(\alpha\) étant deux nombres entiers, et \(\alpha<n\). Il suit de là, que
\[
p^{\frac{\mu}{n}}=p^{\frac{a n+\alpha}{n}}=p^a p^{\frac{\alpha}{n}}
\]

En mettant donc cette expression au lieu de \(p^{\frac{\mu}{n}}\) dans l'expression de \(v\), on obtiendra
\[
v=q_0+q_1 p^{\frac{1}{n}}+q_2 p^{\frac{2}{n}}+\cdots+q_{n-1} p^{\frac{n-1}{n}}
\]
\(q_0, q_1, q_2\) étant encore des fonctions rationnelles de \(p, r^{\prime}, r^{\prime \prime} \ldots\), et par conséquent des fonctions du \(\mu^{\text {ième }}\) ordre et au plus du degré \(m-1\), et telles qu'il soit impossible d'exprimer \(p^{\frac{1}{n}}\) rationnellement par ces quantités.

Dans l'expression de \(v\) ci-dessus, on peut toujours faire \(q_1=1\). Car si \(q_1\) n'est pas nul, on obtiendra, en faisant \(p_1=p q_1^n\),
\[
p=\frac{p_1}{q_1^n}, \quad p^{\frac{1}{n}}=\frac{p_1^{\frac{1}{n}}}{q_1}
\]
done
\[
v=q_0+p_1^{\frac{1}{n}}+\frac{q_2}{q_1^2} p_1{ }^n+\cdots+\frac{q_{n-1}}{q_1^{n-1}} p_1^{\frac{n-1}{n}},
\]
expression de la même forme que la précédente, sauf que \(q_1=1\). Si \(q_1=0\), soit \(q_\mu\) une des quantités \(q_1, q_2 \ldots q_{n-1}\), qui ne soit pas nulle, et soit \(q_\mu^n p^\mu=p_1\). On déduit de là \(q_\mu^\alpha p^{\frac{\alpha \mu}{n}}=p_1{ }^{\frac{\alpha}{n}}\). Done en prenant deux nombres entiers \(\alpha\) et \(\beta\), qui satisfassent à l'équation \(\alpha \mu-\beta n=\prime_1^{\prime}, \prime^{\prime}\) étant un nombre entier, on aura
\[
q_\mu^{\prime \prime} p^{\frac{\beta n+\mu^{\prime}}{n}}=p_1^{\frac{\alpha}{n}} \text { et } p^{\mu^{\prime}}=q_u^{-u} p^{-\beta} p_1^{\frac{\alpha}{n}}
\]

En vertu de cela et en remarquant que \(q_u p^n=p_1{ }^n\), \(v\) anra la forme
\[
v=q_0+p_1^{\frac{1}{n}}+q_2 p_1{ }^2+\cdots+q_{n-1} p_1{ }^{n-1}
\]
%72
De tout ce qui précède on conclut: \(\mathrm{Si} v\) est une fonction algébrique de l'ordre \(\mu\) et du degré \(m\), on peut toujours poser:
\[
v=q_0+p^{\frac{1}{n}}+q_z p^{\frac{2}{n}}+q_3 p^{\frac{3}{n}}+\cdots+q_{n-1} p^{-\frac{n-1}{n}}
\]
\(n\) étant un nombre premier, \(q_0, q_2 \ldots q_{n-1}\) des fonctions algébriques de l'ordre " et du degré \(m-1\) an plus, \(p\)-une fonction algébrique de l'ordre,\(\mu-1\), et telle que \(p^{\frac{1}{n}}\) ne puisse s'exprimer rationnellement en \(q_0, q_1 \ldots q_{n-1}\).
§ II.
Propriétes des fonctions algélriques qui satisfont à une équation donné. .
Soit
\[
c_0+c_1 y+c_2 y^2+\cdots+c_{r-1} y^{r-1}+y^r=0
\]
une équation quelconque du degré \(r\), où \(c_0, c_1 \ldots\) sont des fonctions rationnelles de \(x^{\prime}, x^{\prime \prime} \ldots, x^{\prime}, x^{\prime \prime} \ldots\) étant des quantités indépendantes quelconques. Supposons qu'on puisse satisfaire à cette équation, en mettant au lieu de \(y\) une fonction algébrique de \(x^{\prime}, x^{\prime \prime} \ldots\) Soit
\[
y=q_0+p^{\frac{1}{n}}+q_2 p^{\frac{2}{n}}+\cdots+q_{n-1} p^{\frac{n-1}{n}}
\]
cette fonction. En substituant cette expression de \(y\), dans l'équation proposée, on olotiendra, en vertu de ce qui précède, une expression de la forme
\[
r_0+r_1 p^{\frac{1}{n}}+r_2 p^{\frac{2}{n}}+\cdots+r_{n-1} p^{\frac{n-1}{n}}=0
\]
où \(r_0, r_1, r_2 \ldots r_{n-1}\) sont des fonctions rationnelles des quantités \(p, q_0, q_1 \ldots q_{n-1}\).
Or je dis que l'équation (3) ne peut avoir lieu, à moins qu'on n'ait séparement
\[
r_0=0, r_1=0 \ldots r_{n-1}=0
\]

En effet, dans le cas contraire, on aurait en posant \(p^{\frac{1}{n}}=z\) les deux équations
et
\[
z^n-p=0
\]
\[
r_0+r_1 z+r_2 z^2+\cdots+r_{n-1} z^{n-1}=0
\]
%73
qui auraient une ou plusieurs racines communes. Soit \(k\) le nombre de ces racines, on peut, comme on sait, trouver une équation qui a pour racines les \(k\) racines mentionnées, et dont les coefficiens sont des fonctions rationnelles de \(p, r_0, r_1 \ldots r_{n-1}\). Soit
\[
s_0+s_1 z+s_2 z^2+\cdots+s_{k-1} z^{k-1}+z^k=0
\]
cette équation, et
\[
t_0+t_1 z+t_2 z^2+\cdots+t_{\mu-1} z^{\mu-1}+z^\mu
\]
un facteur de son premier membre, où \(t_0, t_1\) ete. sont des fonctions rationnelles de \(p, r_0, r_1 \ldots r_{n-1}\), on aura de même
\[
t_0+t_1 z+t_2 z^2+\cdots+t_{\mu-1} z^{\mu-1}+z^\mu=0
\]
et il est clair qu'on peut supposer qu’il est impossible de trouver une équation de la même forme d'un degré moins élevé. Cette équation a ses " racines communes avec l'équation \(z^n-p=0\). (Or toutes les racines de l'équation \(z^n-p=0\), sont de la forme \(\alpha z\), où \(\alpha\) est une racine quelconque de l'unité. Donc en remarquant que " ne peut être moindre que 2, parce qu'il est impossible d'exprimer \(z\) en fonction rationnelle des quantités \(p, r_0, r_1 \ldots r_{n-1}\), il s'ensuit, que deux équations de la forme
et
\[
t_0+t_1 z+t_2 z^2+\cdots+t_{\mu-1} z^{\mu-1}+z^\mu=0,
\]
\[
t_0+\alpha t_1 z+\alpha^2 t_2 z^2+\cdots+\alpha^{\mu-1} t_{\mu-1} z^{\mu-1}+\alpha^\mu z^\mu=0
\]
doivent avoir lieu. De ces équations on tire, en éliminant \(z^\mu\),
\[
t_0\left(1-\alpha^\mu\right)+t_1\left(\alpha-\alpha^\mu\right) z+\cdots+t_{\mu-1}\left(\alpha^{\mu-1}-\alpha^\mu\right) z^{\mu-1}=0 .
\]

Mais cette équation étant du degré ,,-1 , et l'équation
\[
z^\mu+t_{\mu-1} z^{\mu-1}+\cdots=0
\]
étant irréductible, et par conséquent \(t_0\) ne pouvant être égal à zéro, on doit avoir \(a^\mu-1=0\), ce qui n'a pas lieu. On doit donc avoir
\[
r_0=0, r_1=0 \ldots r_{n-1}=0 \text {. }
\]

Maintenant, ces équations ayant lieu, il est clair que l'équation proposée sera satisfaite par toutes les valeurs de \(y\) qu'on. obtient en attribuant à \(p^{\frac{1}{n}}\) toutes les valeurs \(u p^{\frac{1}{n}}, \alpha^2 p^{\frac{1}{n}} \ldots \alpha^{n-1} p^{\frac{1}{n}}\). On voit aisément que toutes 
%74
ces valeurs de \(y\) seront différentes entre elles; car dans le cas contraire on aurait une équation de la même forme que (3), mais une telle équation conduit, comme on vient de le voir, à des contradictions.

En désignant donc par \(y_1, y_2 \ldots y_n \quad n\) racines différentes de l'équation (1), on aura
\[
\begin{aligned}
& y_1=q_0+p^{\frac{1}{n}}+q_2 p^{\frac{2}{n}}+\cdots+q_{n-1} p^{\frac{n-1}{n}} \\
& y_2=q_0+\alpha p^{\frac{1}{n}}+\alpha^2 q_2 p^{\frac{2}{n}}+\cdots+\alpha^{n-1} q_{n-1} p^{\frac{n-1}{n}} \\
& \ldots \ldots \ldots \ldots \ldots \\
& y_n=q_0+\alpha^{n-1} p^{\frac{1}{n}}+\alpha^{n-2} q_2 p^{\frac{2}{n}}+\cdots+\alpha q_{n-1} p^{\frac{n-1}{n}}
\end{aligned}
\]

De ces \(n\) équations on tirera sans peine
\[
\begin{aligned}
q_0 & =\frac{1}{n}\left(y_1+y_2+y_3+\cdots+y_n\right), \\
p^{\frac{1}{n}} & =\frac{1}{n}\left(y_1+\alpha^{n-1} y_2+\alpha^{n-2} y_3+\cdots+\alpha y_n\right), \\
q_2 p^{\frac{2}{n}} & =\frac{1}{n}\left(y_1+\alpha^{n-2} y_2+\alpha^{n-4} y_3+\cdots+\alpha^2 y_n\right), \\
\cdots \cdots \cdots \cdots \cdots & \cdots \cdots \\
q_{n-1} p^{\frac{n-1}{n}} & =\frac{1}{n}\left(y_1+\alpha y_2+\alpha^2 y_3+\cdots+\alpha^{n-1} y_n\right) .
\end{aligned}
\]

On voit par là que toutes les quantités \(p^{\frac{1}{n}}, \eta_0, q_2 \ldots q_{n-1}\) sont des fonctions rationnelles des racines de l'équation proposée. En effet on a
\[
q_\mu=n^{\mu-1} \frac{y_1+\alpha^{-\mu} y_2+\alpha^{-2 \mu} y_3+\cdots+\alpha^{-(n-1) \mu} y_n}{\left(y_1+\alpha^{-1} y_2+\alpha^{-2} y_8+\cdots+\alpha^{-(n-1)} y_n\right)^\mu} .
\]

Considérons maintenant l'équation générale du degré \(m\),
\[
0=a+a_1 x+a_2 x^2+\cdots+a_{m-1} x^{m-1}+x^m,
\]
et supposons qu'elle soit résoluble algébriquement. Soit
\[
x=s_0+v^{\frac{1}{n}}+s_2 v^{\frac{2}{n}}+\cdots+s_{n-1} v^{\frac{n-1}{n}}
\]
en vertu de ce qui précède, les quantités \(v, s_0, s_2\) etc. peuvent s'exprimer rationnellement en \(x_1, x_2 \ldots x_m\), en désignant par \(x_1, x_2 \ldots x_m\) les racines de l'équation proposée.
%75
Considérons l'une quelconque des quantités \(v, s_0, s_2\) etc. par exemple \(v\). Si l'on désigne par \(v_1, v_2 \ldots v_{n^{\prime}}\) les valeurs différentes de \(v\), qu'on trouve lorsqu'on échange entre elle les racines \(x_1, x_2 \ldots x_m\) de toutes les manières possibles, on pourra former une équation du degré \(n^{\prime}\) dont les coefficiens sont des fonctions rationnelles de \(a, a_1 \ldots a_{n-1}\), et dont les racines sont les quantités \(v_1, v_2 \ldots v_{n^{\prime}}\), qui sont des fonctions rationnelles des quantités \(x_1, x_2 \ldots x_m\).
Donc si l'on pose
\[
v=t_0+u^{\frac{1}{v}}+t_2 u^{\frac{2}{v}}+\cdots+t_{\nu-1} u^{\frac{v-1}{v}}
\]
toutes les quantités \(u^{\frac{1}{v}}, t_0, t_2 \ldots t_{\nu-1}\) seront des fonctions rationnelles de \(v_1, v_2 \ldots v_{n^{\prime}}\), et par conséquent de \(x_1, x_2 \ldots x_m\). En traitant les quantités \(u, t_0, t_2\) etc. de la même manière, on en conclut que
si une équation est résoluble algébriquement, on peut toujours donner à la racine une forme telle, que toutes les fonctions algébriques dont elle est composée puissent s'exprimer par des fonctions rationnelles des racines de l'équation proposée.
§ III.
Sur le nombre des valeurs différentes qu'une fonction de plusieurs quntités peut acquérir, lorsqu'ón échange entre elles les quantités quielle renferme.
Soit \(v\) une fonction rationnelle de plusieurs quantités indépendantes \(x_1, x_2 \ldots x_n\). Le nombre des valeurs différentes dont cette fonction est susceptible par l'échange des quantités dont elle dépend, ne peut surpasser le produit \(1.2 .3 \ldots n\). Soit " ce produit.
Soit maintenant
la valeur qu'une fonction quelconque \(v\) reçoit, lorsqu'on y substitue \(x_a, x_b, x_c, x_d\) etc. au lieu de \(x_\alpha, x_\beta, x_\gamma, x_\delta\) etc., il est clair qu'en désignant par \(A_1, A_2 \ldots A_\mu\) les diverses permutations en nombre de " que l'on pent former avec les indices \(1,2,3 \ldots n\), les valeurs différentes de \(v\) pourront être exprimées par
\[
v\left(\begin{array}{l}
A_1 \\
A_1
\end{array}\right), \quad v\left(\begin{array}{l}
A_1 \\
A_2
\end{array}\right), \quad v\left(\begin{array}{l}
A_1 \\
A_3
\end{array}\right) \ldots v\left(\begin{array}{l}
A_1 \\
A_u
\end{array}\right) .
\]
%76
Supposons que le nombre des valeurs différentes de \(v\) soit moindre que ", il faudra que plusieurs valeurs de \(v\) soient égales entre elles, en sorte qu'on ait par exemple
\[
v\left(\begin{array}{l}
A_1 \\
A_1
\end{array}\right)=v\left(\begin{array}{l}
A_1 \\
A_2
\end{array}\right)=\cdots=v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)
\]

Si l'on fait subir à ces quantités la substitution désignée par \(\left(\begin{array}{l}A_1 \\ A_{m+1}\end{array}\right)\), on aura cette nouvelle série de valeurs égales
\[
v\left(\begin{array}{l}
A_1 \\
A_{m+1}
\end{array}\right)=v\left(\begin{array}{l}
A_1 \\
A_{m+2}
\end{array}\right)=\cdots=v\left(\begin{array}{l}
A_1 \\
A_{2 m}
\end{array}\right)
\]
valeurs qui sont différentes des premières, mais en même nombre. En chang'eant de nouveau ces quantités par la substitution désignée par \(\left(\begin{array}{l}A_1 \\ A_{2 m+1}\end{array}\right)\), on aura un nouveau système de quantités égales, mais différentes des précédentes. En continuant ce procédé jusqu’à ce qu'on ait épuisé toutes les permutations possibles, les "" valeurs de \(v\) seront partagées en plusieurs systèmes, dont chacun contiendra un nombre de \(m\) valeurs égales. Il suit de là que si l'on représente le nombre des valeurs différentes de \(v\) par ", nombre égal à celui des systèmes, on aura
\[
m=1.2 .3 \ldots n,
\]
c'est-a-dire:
Le nombre des valeurs différentes qu'une fonction de \(n\) quantités peut acquérir par toutes les substitutions possibles entre ces quantités, est nécessairement un diviseur du produit 1.2.3..n. Cela est comnu.

Soit maintenant \(\left(\begin{array}{c}A_1 \\ A_m\end{array}\right)\) une substitution quelconque. Supposons qu'en appliquant celle-ci plusieurs fois de suite à la fonction \(v\) on obtienne la suite des valeurs.
\[
v, v_1, v_2 \ldots v_{p-1}, v_p,
\]
il -est clair que \(v\) sera nécessairement répété plusieurs fois. Lorsque \(v\) revient après un nombre \(p\) de substitutions, nous disons que \(\left(\begin{array}{l}A_1 \\ A_m\end{array}\right)\) est une substitution récurrente de l'ordie \(p\). On a donc cette série périodique
\[
v, v_1, v_2 \ldots v_{p-1}, v, v_1, v_2 \ldots
\]
on bien, si l'on représente par \(v\left(\begin{array}{l}A_1 \\ A_m\end{array}\right)^r\) la valeur de \(v\) qu'on obtient après
%77
avoir répété \(r\) fois de suite la substitution désignée par \(\left(\begin{array}{l}A_1 \\ A_m\end{array}\right)\), on a la série
\[
v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^0, v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^1, v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^2 \ldots v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^{p-1}, v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^0 \ldots
\]

Il suit de lì que
\[
\begin{aligned}
& v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^{\alpha p+r}=v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^r \\
& v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^{\alpha p}=v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^0=v .
\end{aligned}
\]

Or soit \(p\) le plus grand nombre premier contenu dans \(n\), si le nombre des valeurs différentes de \(v\) est moindre que \(p\), il faut qu'entre \(p\) valeurs quelconques, deux soient égales entre elles.
Il faut donc que des \(p\) valeurs,
\[
v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^0, v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^1, v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^2 \ldots v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^{p-1}
\]
deux soient égales entre elles. Soit par exemple
\[
v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^r=v\left(\begin{array}{l}
A_1 \\
A_n
\end{array}\right)^{r^{\prime}}
\]
on en conclut que
\[
v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^{r+p-r}=v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^{r^{\prime}+r-r}
\]

Écrivant \(r\) an lien de \(r^{\prime}+p-r\) et remarquant que \(v\left(\begin{array}{l}A_1 \\ A_m\end{array}\right)^p=v\), on en tire
\[
v=v\left(\begin{array}{l}
A_1 \\
A_{i n}
\end{array}\right)^r
\]
oì \(r\) évirlemment n'est pas multiple de \(p\). La valeur de \(v\) n'est done pas changée par la substitution \(\left(\begin{array}{l}A_1 \\ A_n\end{array}\right)^r\), ni par conséquent non plus par la répétition de la même substitution. On a done
\[
v=v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^{r \alpha}
\]
\(\alpha\) étant un nombre entier. Maintenant si \(p\) est un nombre premier, on pourra évidemment toujours trouver deux nombres entiers \(\alpha\) et \(\beta\) tels que
\[
r \alpha=p \beta+1,
\]
%78
done
et puisque
\[
v=v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^{p \beta+1}
\]
on alura
\[
v=v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)^{p \beta}
\]
\[
v=v\left(\begin{array}{l}
A_1 \\
A_m
\end{array}\right)
\]

La valeur de \(v\) ne sera done pas changée par la substitution récurrente \(\left(\begin{array}{l}A_1 \\ A_m\end{array}\right)\) de l'ordre \(p\).
Or il est clair que
sont des substitutions récurrentes de l'ordre \(p\), lorsque \(p\) est le nombre des indices \(\alpha, \beta, \gamma \ldots \eta\). La valeur de \(v\) ne sera donc pas changée non plus par la combinaison de ces deux substitutions. Ces deux substitutions sont évidemment équivalentes à cette unique
\[
\left(\begin{array}{l}
\alpha \beta \gamma \\
\gamma \alpha \beta
\end{array}\right)
\]
et celle-ci aux deux suivantes, appliquées successivement,
\[
\left(\begin{array}{l}
\alpha \beta \\
\beta \alpha
\end{array}\right) \text { et }\left(\begin{array}{l}
\beta \gamma \\
\gamma \beta
\end{array}\right) \text {. }
\]

La valeur de \(v\) ne sera donc pas changée par la combinaison de ces deux substitutions. Done
de mêmè
\[
v=v\left(\begin{array}{c}
\alpha \beta \\
\beta \alpha
\end{array}\right)\left(\begin{array}{l}
\beta \gamma \\
\gamma \beta
\end{array}\right)
\]
d'où l'on tire
\[
v=v\left(\begin{array}{l}
\beta \gamma \\
\gamma \beta
\end{array}\right)\left(\begin{array}{l}
\gamma \delta \\
\delta \gamma
\end{array}\right)
\]
\[
v=v\left(\begin{array}{l}
\alpha \beta \\
\beta \alpha
\end{array}\right)\left(\begin{array}{l}
\gamma \delta \\
\delta \gamma
\end{array}\right)
\]

On voit par là que la fonction \(v\) n'est pas changée par deux substitutions successives de la forme \(\left(\begin{array}{c}\alpha \beta \\ \beta \alpha\end{array}\right), \alpha\) et \(\beta\) étant deux indices quelcon-
%79
ques. Si l'on désigne une telle substitution par le nom de transposition, on peut conclure qu'une valeur quelconque de \(v\) ne sera pas changée par un nombre pair de transpositions, et que par conséquent toutes les valeurs de \(v\) qui résultent d'un nombre impair de transpositions sont égales. Tout échange des élémens d'une fonction peut s'opérer à l'aide d'un certain nombre de transpositions; done la fonction \(v\) ne peut avoir plus de deux valeurs différentes. De là on tire le théorème suivant:
Le nombre des valeurs différentes que peut obtenir une fonction de \(n\) quantités, ne peut être abaissé au dessous du plus grand nombre premier qui ne(surpasse) pas \(n\), à moins qu'il ne se rédluise à 2 ou à 1 . Il est done impossible de trouver une fonction de 5 quantités qui ait 3 ou 4 valeurs différentes.

La démonstration de ce théorème est prise d'un mémoire de M. Cauchy inséré dans le \(17^{\text {ième }}\) cahier du Journal de l'école polytechnique p. 1.

Soient \(v\) et \(v^{\prime}\) deux fonctions dont chacune ait deux valeurs différentes, il suit de ce qui précède qu'en désignant par \(v_1\), \(v_2\) et \(v_1{ }^{\prime}, v_2{ }^{\prime}\) ces doubles valeurs, les deux expressions
\[
v_1+v_z \text { et } v_1 v_1^{\prime}+v_2 v_2^{\prime}
\]
seront des fonctions symétriques. Soit
on en tire
\[
v_1+v_2=t \text { et } v_1 v_1^{\prime}+v_2 v_2^{\prime}=t_1
\]
\[
v_1=\frac{t v_2^{\prime}-t_1}{v_2^{\prime}-v_1^{\prime}}
\]

Soit maintenant le nombre des 'quantités \(x_1, x_2 \ldots x_m\) égal à cinq, le produit
\[
\varphi=\left(x_1-x_2\right)\left(x_1-x_3\right)\left(x_1-x_4\right)\left(x_1-x_5\right)\left(x_2-x_3\right)\left(x_3-x_4\right)\left(x_2-x_5\right)\left(x_3-x_4\right)\left(x_3-x_5\right)\left(x_4-x_5\right)
\]
sera évidemment une fonction qui a deux valeurs différentes; la seconde valeur étant la même fonction avec le signe opposé. Donc en posant \(v_1{ }^{\prime}=0\), on aura \(v_2{ }^{\prime}=-0\). L'expression de \(v_1\) sera done
\[
v_1=\frac{t_1+\varrho t}{2 \varrho}
\]
oı bien
\[
v_1=\frac{1}{2} t+\frac{t_1}{2 \varrho^3} \varphi
\]
où \(\frac{1}{2} t\) est une fonction symétrique; a a deux valeurs qui ne différent que par le signe, de sorte que \(\frac{t_1}{2 q^2}\) est également une fonction symétrique.
%80
Donc, en posant \(\frac{1}{2} t=p\) et \(\frac{t_1}{2 \varrho^2}=q\), il s'ensuit que toute fonction de cinq quantités qui a deux valeurs différentes pourra être mise sous la forme \(p+q \varphi\), où \(p\) et \(q\) sont deux fonctions symétriques et \(\rho=\left(x_1-x_2\right)\left(x_1-x_3\right) \ldots\left(x_4-x_5\right)\).
Pour atteindre notre but nous avons encore besoin de la forme générale des fonctions de cinq quantités qui ont cinq valeurs différentes. On peut la trouver comme il suit:

Soit \(v\) une fonction rationnelle des quantités \(x_1, x_2, x_3, x_4, x_5\), qui ait la propriété d'être invariable lorsqu'on échange entre elles quatre des cinq quantités, par exemple \(x_2, x_3, x_4, x_5\). Dans cette condition \(v\) sera évirlemment symétrique par rapport à \(x_2, x_3, x_4, x_5\). On pent donc exprimer \(v\) par une fonction rationnelle de \(x_1\) et par des fonctions symétriques de \(x_2, x_3, x_4, x_5\). Mais toute fonction symétrique de ces quantités peut s'exprimer par une fonction rationnelle des coefficiens d'une équation du quatrième degré, dont les racines sont \(x_2, x_3, x_4, x_5\). Done en posant
\[
\left(x-x_2\right)\left(x-x_3\right)\left(x-x_4\right)\left(x-x_5\right)=x^4-p x^3+q x^2-r x+s,
\]
la fonction \(v\) pent s'exprimer rationnellement en \(x_1, p, q, r, s\). Mais si l'on pose
\[
\left(x-x_1\right)\left(x-x_2\right)\left(x-x_3\right)\left(x-x_4\right)\left(x-x_5\right)=x^5-a x^4+b x^3-c x^2+d x-e,
\]
on alura
\[
\begin{aligned}
& \left(x-x_1\right)\left(x^4-p x^3+q x^3-r x+s\right)=x^5-a x^4+b x^3-c x^2+d x-e \\
& =x^5-\left(p+x_1\right) x^4+\left(q+p x_1\right) x^3-\left(r+q x_1\right) x^2+\left(s+r x_1\right) x-s x_1,
\end{aligned}
\]
d'où l'on tire
\[
\begin{aligned}
p & =a-x_1 \\
q & =b-a x_1+x_1^2 \\
r & =c-b x_1+a x_1^3-x_1^3 \\
 s & =d-c x_1+b x_1^2-a x_1^3+x_1^4
\end{aligned}
\]
la fonction \(v\) peut done s'exprimer ratiomellement en \(x_1, a, b, c, d\). Il suit de là que la fonction \(v\) peut être mise sous la forme
\[
v=\frac{t}{\tau \cdot x_1}
\]
oì \(t\) et \(f x_1\) sont deux fonctions entières de \(x_1, a, b, c, d\). En multipliant
%81
on alura

Or \(\varphi x_2 \cdot \varphi x_3 \cdot \varphi x_4 \cdot \varphi x_5\) est, conme on le voit, me fonction entière et symétrique de \(x_2, x_3, x_4, x_5\). On peut done exprimer ce produit en fonction entière de \(p, q, r, s\) et par suite en fonction entière de \(x_1, a, b, c, d\). Le numérateur de la fraction ci-dessus est donc une fonction entière des mêmes quantités; le dénominateur est une fonction symétrique de \(x_1, x_2, x_3, x_4, x_3\) et par conséquent il peut s'exprimer en fonction ratiomelle de \(a, b, c, d, c\). On peut done poser
\[
v=r_0+r_1 x_1+r_2 x_1^2+\cdots+r_m x_1^m .
\]

En multipliant l'équation
\[
x_1^5=a x_1^4-b x_1^3+c x_1^2-d x_1+e
\]
successivement par \(x_1^{-}, x_1^2 \ldots x_1^{m-5}\), il est clair qu'on obtiendra \(m-4\) équations, desquelles on tirera pour \(x_1^5, x_1^6 \ldots x_1^m\) des expressions de la forme
\[
\alpha+\beta x_1+z_1^2+d x_1^3+\varepsilon x_1^4
\]
où \(\alpha, \beta, \gamma, d\), \& sont des fonctions rationnelles de \(", b, c, d, e\).
On peut donc réduire \(v\) à la forme
\[
v=r_0+r_1 x_1+r_2 x_1^2+r_3 x_1^3+r_4 x_1^4
\]
où \(r_0, r_1, r_2\) etc. sont des fonctions ratiomelles de \(a, b, c, d\), e, c'est-à-dire des fonctions symétriques de \(x_1, x_2, x_3, x_1, x_3\).

Voilà la forme générale des fonctions qui ne sont pas altérées lorsqu'on y échange entre elles les quantités \(x_2, x_3, x_*, x_2\). Ou elles ont cinq valeurs différentes, ou elles sont symétriques.

Soit maintenant \(v\) une fonction rationnelle de \(x_1, x_2, x_3, x_1, x_5\), qui ait les cinq valeurs suivantes \(v_1, v_2, v_3, v_4, v_5\). Considérons la fonction \(x_1^m v\). En y échangeant entre elles de toutes les manières possibles les quatre quantités \(x_2, x_3, x_1, x_5\), la fonction \(x_1^m v\) aura toujours une des valeurs suivantes
\[
x_1^m v_1, x_1^m v_2, x_1^m v_3, x_1^n v_{\downarrow}, x_1^m v_5 .
\]
Q. je dis, que le nombre des valeurs distinctes de \(x_1^m v\) résultant de ces changements sera moindre que cinq. En effet, si toutes les cinq valeurs
%82
avaient lieu, on tirerait de ces valeurs en échangeant \(x_1\). successivement avec \(x_2, x_3, x_4, x_5, 20\) valeurs nouvelles, qui seraient nécessairement différentes entre elles et des précédentes. La fonction aurait donc en tout 25 valeurs différentes, ce qui est impossible, car 25 n'est pas diviseur du produit 1.2.3.4.5. En désignant done par \(\boldsymbol{\mu}\) le nombre des valeurs que pent prendre \(v\) lorsqu'on y échange entre elles les quantités \(x_2, x_3, x_4, x_5\) de toutes les manières possibles, \(\boldsymbol{\mu}\) doit avoir l'une des quatre valeurs suivantes \(1,2,3,4\).
1. Soit \(\mu=1\), d'après ce qui précède \(v\) sera de la forme (a).
2. Soit,\(u=4\), la somme \(v_1+v_2+v_3+v_4\) sera une fonction de la forme (a). Or on a \(v_5=\left(v_1+v_2+v_3+v_4+v_5\right)-\left(v_1+v_2+v_3+v_4\right)=\) une fonction symétrique moins \(\left(v_1+v_2+v_3+v_4\right)\); donc \(v_5\) est de la forme (a).
3. Soit \(\mu=2, v_1+v_2\) sera une fonction de la forme (a). Soit done
\[
v_1+v_2=r_0+r_1 x_1+r_2 x_1^2+r_3 x_1^3+r_4 x_1^4=\varphi x_1 .
\]

En échangeant successivement \(x_1\) avec \(x_2, x_3, x_4, x_5\), on aura
\[
\begin{aligned}
& v_1+v_2=\varphi x_1, \\
& v_2+v_3=\varphi x_2, \\
& \cdots \cdot \cdot \cdot \cdot \cdot \\
& v_{m-1}+v_m=\varphi x_{m-1}, \\
& v_m+v_1=\varphi x_m,
\end{aligned}
\]
où \(m\) est un des nombres \(2,3,4,5\). Pour \(m=2\), on aura \(\varphi x_1=\varphi x_2\), ce qui est impossible, car le nombre des valeurs de \(\varphi x_1\) doit être cinq. Pour \(m=3\) on aura
\[
v_1+v_2=\varphi x_1, \quad v_2+v_3=\varphi x_2, \quad v_3+v_1=\varphi x_3,
\]
d'où l'on tire
\[
2 v_1=\varphi x_1-\varphi x_2+\varphi x_3 .
\]

Mais le second membre de cette équation a plus de 5 valeurs, car il en a 30. On prouvera de la même manière que \(m\) ne peut être égal à 4 ni à 5. Il suit de là que " \(\boldsymbol{u}\) n'est pas égal ì 2.
4. Soit \(\mu=3\). Dans ce cas \(v_1+v_2+v_3\) et par conséquent \(v_4+v_5\) \(=\left(v_1+v_2+v_3+v_4+v_5\right)-\left(v_1+v_2+v_3\right)\) aura cinq valeurs. Mais on vient de voir que cette supposition est inadmissible. Donc \(\boldsymbol{\mu}\) ne peut non plus être égal à 3 .
%83
De tout cela on déduit ce théorème:
Toute fonction rationnelle de cinq quantités, qui a cinq valeurs différentes, aura nécessairement la forme
\[
r_0+r_1 x+r_2 x^2+r_3 x^3+r_4 x^4
\]
où \(r_0, r_1, r_2\) etc. sont des fonctions symétriques, et \(x\) l'une quelconque des cinq quantités.

De l'équation
\[
r_0+r_1 x+r_2 x^2+r_3 x^3+r_4 x^4=v
\]
on déduira aisément, en faisant usage de l'équation proposée, pour la valeur de \(x\), une expression de la forme suivante
\[
x=s_0+s_1 v+s_2 v^2+s_3 v^3+s_4 v^4,
\]
où \(s_0, s_1, s_2\) etc., de même que \(r_0, r_1, r_2\) etc., sont des fonctions symétriques.

Soit \(v\) une fonction rationnelle qui ait \(m\) valeurs différentes \(v_1, v_2\), \(v_3 \ldots v_m\). En posant
\[
\begin{aligned}
& \left(v-v_1\right)\left(v-v_2\right)\left(v-v_3\right) \cdots\left(v-v_m\right) \cdot \\
& =q_0+q_1 v+q_2 v^2+\cdots+q_{m-1} v^{m-1}+v^m=0,
\end{aligned}
\]
on sait que \(q_0, q_1, q_2 \ldots\) sont des fonctions symétriques, et que les \(m\) racines de l'équation sont \(v_1, v_2, v_3 \ldots v_m\). Or je dis, qu'il est impossible d'exprimer la valeur de \(v\) comme racine d'une équation de la même forme, mais d'un degré moins élevé. En effet soit
\[
t_0+t_1 v+t_2 v^2+\cdots+t_{\mu-1} v^{\mu-1}+v^\mu=0
\]
une telle équation, \(t_0, t_1\) etc. étant des fonctions symétriques, et soit \(v_1\) une valeur de \(v\) qui satisfasse à cette équation, on aura
\[
v^\mu+t_{\mu-1} v^{\mu-1}+\cdots=\left(v-v_1\right) P_1 .
\]

En échangeant entre eux les élémens de la fonction, on trouvera la série suivante d'équations:
\[
\begin{aligned}
& v^\mu+t_{\mu-1} v^{\mu-1}+\cdots=\left(v-v_z\right) P_2, \\
& v^\mu+t_{\mu-1} v^{\mu-1}+\cdots=\left(v-v_3\right) P_3, \\
& \left.\cdots \cdots \cdots \cdot \cdots \cdot \cdots \cdot v_m\right) P_m .
\end{aligned}
\]
%84
On en conclut que \(, \cdot-v_1, v-v_2, v-v_3 \ldots v-v_m\) seront des facteurs de \(v^\mu+t_{\mu-1} v^{\mu-1}+\cdots\) et que par conséquent " doit nécessairement être égal à \(m\). On en tire le théorème suivant:
Lorsqu'une fouction de plusieurs quantités a \(m\). valeurs différentes, on peut toujours trouver une équation du degré \(m\), dont les coefficiens soient des fonctions symétriques, et qui ait ces valeurs pour racines; mais il est impossible de trouver une équation de la même forme d'un degrré moins élevé qui ait une ou plusieurs de ces valeurs pour racines.
§ IV.

Démonstration de limpossibilité de la vésolution gémérale de léquation du cinquième dequé.

En vertu des propositions trouvées plus haut on peut énoncer ce théorème:
"Il est impossible de résoudre en général les équations du cinquième "degré."
D'après le S II, toutes les fonetions algébriques dont une expression algébrique des racines est composée, peuvent s'exprimer par des fonctions rationnelles des racines de l'équation proposée.

Comme il est impossible d'exprimer d'une manière générale la racine d'une équation par une fonction rationnelle des coefficiens, on doit avoir
\[
R^{\frac{1}{m}}=v,
\]
oì \(m\) est un nombre premier et \(R\) une fonction rationnelle des coefficiens de l'équation proposée, r’est-à-dire une fonction symétrique des racines; \(v\) est une fonction ratiomelle des racines. On en concht.
\[
v^m-R=0
\]

En vertu du § II, il est impossible d'abaisser le degré de cette équation; la fonction \(v\) doit donc, d'après le dernier théorème du paragraphe précédent, avoir \(m\) valeurs différentes. Le nombre \(m\) devant être diviseur du produit 1.2.3.4.5, ce nombre peut être égal ì 2 oul à 3 ou à 5 . Or (\$ III) il n'existe pas de fonction de cinq variables qui ait 3 valeus: il faut donc qu'on ait \(m=5\), on \(m=2\). Soit \(m=5\), on aura, ainsi qu'il résulte du paragraphe précédent
%85
d'oì
\[
\bar{J} k=r_0+r_1 x+r_2 x^2+r_3 x^3+r_4 x^4,
\]
\[
r=s_0+s_1 R^{\frac{1}{5}}+s_2 R^{\frac{2}{5}}+s_3 R^{\frac{3}{5}}+s_4 R^{\frac{4}{5}}
\]

On en tire ( \(\$\) II)
\[
s_1 l^1=\frac{1}{5}\left(x_1+u^4 x_2+u^3 x_3+a^2 x_4+u x_3\right)
\]
où \(a^5=1\). Cette équation est impossible, attendu que le second membre a 120 valeurs et que pourtant il doit être racine d'une équation du cinquiène degré \(z^5-s_1^5 R=0\). On doit done avoir \(m=2\).
On aura done (\$ II)
\[
\sqrt{R}=p+q s,
\]
oì \(l\) et \(q\) sont des fonctions symétriques, et
\[
s=\left(x_1-x_2\right) \ldots\left(x_4-x_5\right) .
\]

On en tire, en échangeant \(x_1\) et \(x_2\) entre elux,
\[
-\sqrt{R}=p-q s
\]
d'où l'on dérluit \(p=0\) et \(V R=q s\). On voit par là, que toute fonction algébrique du premiè ordre qui se trouve dans l'expression de la racine, doit nécessairement avoir la forme \(\alpha+\beta / s^2=a+\beta s\), où \(\alpha\) et \(\beta\) sont des fonctions symétriques. Or il est impossible d'exprimer les racines par une fonction de la forme \(\alpha+\beta / R\); il doit done \(y\) avoir une équation de la forme
\[
\sqrt[m]{\alpha+\beta \sqrt{s^2}}=v
\]
où \(\alpha\) et \(\beta\) ne sont pas nuls, \(m\) est un nombre premier, \(\alpha\) et \(\beta\) sont des fonctions symétriques, et \(r\) est une fonction ratiomelle des racines. Cela donne
\[
\sqrt[m]{\alpha+\beta s}=v_1, \sqrt[m]{\alpha-\beta s}=v_2,
\]
oì \(r_1\) et \(r_2\) sont des fonctions ratiomelles. On aura en multipliant \(v_1\) par \(v_2\),
\[
r_1 v_2=\sqrt[m]{\alpha^2-\beta^2 s^2}
\]

Or \(\alpha^2-\beta^2 s^2\). est une fonction symétrique. Si maintemant \(\sqrt[m]{\alpha^2-\beta^2 s^2}\)
%86
n'est pas une fonction symétrique, le nombre \(m\), d'après. ce qui précède, doit être égal à deux. Mais dans ce cas \(v\) sera égal à \(\sqrt{\alpha+\beta \sqrt{s^2}} ; v\) aura donc quatre valeurs différentes, ce qui est impossible.

Il faut donc que \(\sqrt[m]{\alpha^2-\beta^2 s^2}\) soit une fonction symétrique. Soit \(\dot{\gamma}\) cette fonction, on aura
\[
v_2 v_1=\gamma, \text { et } v_2=\frac{\gamma}{v_1} \cdot \cdot
\]

Soit
\[
v_1+v_z=\sqrt[m]{\alpha+\beta \sqrt{s^2}}+\frac{\gamma}{\sqrt{\alpha+\beta} \sqrt{s^2}}=p=\sqrt[m]{R}+\frac{\gamma}{\sqrt[m]{R}}=R^{\frac{1}{m}}+\frac{\gamma}{R} R^{\frac{m-1}{m}} .
\]

Désignons par \(p_1, p_2, p_3 \ldots p_m\) les valeurs différentes de \(p\) qui résultent de la substitution successive de \(\alpha R^{\frac{1}{m}}, \alpha^2 R^{\frac{1}{m}}, \alpha^3 R^{\frac{1}{m}} \ldots \alpha^{m-1} R^{\frac{1}{m}}\) at la place de \(R^{\frac{1}{m}}, \alpha\) satisfaisant à l'équation
\[
\alpha^{m-1}+\alpha^{m-8}+\cdots+\alpha+1=0
\]
et faisons le produit
\[
\left(p-p_1\right)\left(p-p_2\right) \cdots\left(p-p_m\right)=p^m-A p^{m-1}+A_1 p^{m-8}-\cdots=0 .
\]

On voit sans peine que \(A, A_1\) etc. sont des fonctions rationnelles des coefficiens de l'équation proposée et par conséquent des fonctions symétriques des racines. Cette équation est évidemment irréductible. Il faut donc d'après le dernier théorème du paragraphe précédent que \(p\), consideré comme fonction des racines, ait \(m\) valeurs différentes. On en conclut que \(m=5\). Mais dans ce cas \(p\) sera de la forme (a) du paragraphe précédent. Donc on aura
\[
\sqrt[5]{R}+\frac{\gamma}{\sqrt[5]{R}}=r_0+r_1 x+r_8 x^2+r_3 x^3+r_4 x^4=p
\]
d'où
\[
x=s_0+s_1 p+s_2 p^2+s_3 p^3+s_4 p^4
\]
c'est-à-dire, en mettant \(R^{\frac{1}{5}}+\frac{\gamma}{R} R^{\frac{4}{5}}\) à la place de \(p\),
\[
x=t_0+t_1 R^{\frac{1}{5}}+t_2 R^{\frac{2}{5}}+t_3 R^{\frac{3}{5}}+t_4 R^{\frac{4}{5}}
\]
%87
oì \(t_{1,} t_1, t_2\) etc. sont des fonctions rationnelles de \(R\) et des coefticiens de l'équation proposée. On en tire (\$ II)
\[
t_1 R^{\frac{1}{5}}=\frac{1}{3}\left(x_1+\alpha^4 x_2+\alpha^3 x_3+\alpha^2 x_4+\alpha x_5\right)=p^{\prime},
\]
où
\[
\alpha^4+\alpha^3+\alpha^2+\alpha+1=0
\]

De l'équation \(p^{\prime}=t_1 R^{\frac{1}{5}}\) on tire \(p^{\prime 5}=t_1^5 R\). Or \(t_1^5 R\) étant de la forme \(u+u^{\prime} \sqrt{s^2}\) on aura \(p^{\prime 5}=u+u^{\prime} \mid s^2\), ce qui donne
\[
\left(p^{\prime 5}-u\right)^2=u^{\prime 2} s^2
\]

Cette équation donne \(p^{\prime}\) par une équation du dixième legré, dont tous les coefficiens sont des fonctions symétriques; mais d'après le dernier théorème du paragraphe précédent cela est impossible; car puisque
\[
p^{\prime}=\frac{1}{5}\left(x_1+\alpha^4 x_2+\alpha^3 x_3+\alpha^2 x_4+\alpha x_5\right),
\]
\(p^{\prime}\) aurait 120 valeurs différentes, ce qui est une contradiction.
Nous concluons donc qu’il est impossible de résoudre algébriquement l'équation générale du cinquième degré.

Il suit immédiatement de ce théorème, qu’il est de même impossible de résoudre algébriquement les équations générales des degrés supérieurs au cinquième. Donc les équations des quatre premiers degrés sont les seules qui puissent être résolues algébriquement d'une manière générale.
APPENITICE.
ANALYsE DU MÉMOIRE PRÉCÉDENT.
Bulletin des sciences math., astr., phys. et chim. publié par le \(\mathbf{B}^{\text {on }}\) de Férussac, t. 6, p. 347; Paris 1826.
L'auteur démontre, dans ce mémoire, qu’il est impossible de résoudre algébriquement l'équation générale du cinquième degré; car toute fonction
%88
algébrique des coefficiens de la proposée, étant substituée à la place de l'incomnue, conduit à une absurdité. Dans un premier paragraphe, l'auteur cherche l'expression geénérale des fonctions algébriques de plusieurs quiantités, d'après la définition qu'une fonction algébrique résulte, \(1^{\circ}\) d'additions, .20 de multiplications, \(3^{\circ}\) de divisions, et \(4^{\circ}\) d'extractions de racines dont les exposans sont des nombres premiers. Les soustractions, les élévations aux puissances et l'extraction des racines avec des exposans composés rentrent dans les opérations précédentes. D’où il résulte, \(1^{\circ}\) que toute fonction rationnelle et entière des quantités \(x_1, x_2, x_3\) etc. c'est-à-dire, toute fonction qui peut être formée au moyen des deux premières opérations mentionnées, peut s'exprimer par une somme d'un nombre fini de termes de la forme \(A x_1^{{ }^{{ }^{m_2}}}{ }^2{ }_2{ }^{{ }^{m_2}} \ldots, \ldots, A\) étant une constante et \(m_1, m_2, \ldots\) des nombres entiers; \(2^{\circ}\) que toute fonction rationnelle des mêmes quantités, c'est-à-dire, toute fonction qui peut être formée au moyen des trois prenières opérations, pent s'exprimer par un quotient de deux fonctions entières: ' ' que toute fonction algébrique peut être formée par des répétitions des opérations indiquées par
\[
p^{\prime}=f\left(x_1, x_2, x_3 \ldots p_1^{\frac{1}{n_1}}, p_2^1{ }^1, \ldots\right),
\]
oì \(f\) désigne une fonction rationnelle des quantités entre les parenthèses; \(p_1, \nu_2, \ldots\) des fonctions rationnelles de \(x_1, x_2 \ldots\). , et \(n_1, n_2 \ldots\) des nombres premiers. On nommera, pour abréger, fonction algébrique du premier ordre, une fonction telle que \(p^{\prime}\). Si maintenant on formait une nouvelle fonction dans laquelle des fonctions du premier ordre entrassent de la même manière que \(p_1, p_2 \ldots\) entrent dans \(p^{\prime}\), on aurait une fonction celgébrique du second ordre; et, en généiral, une fonction de l'ordre " serait celle qui pourrait contenir des fonctions de tous les ordres, jusqu'à l'ordre, \(\boldsymbol{\mu}-\mathbf{1}\), combinées entre elles algébriquement. Bien entendu que cette fonction de l'ordre " ne peut pas s'abaisser à un ordre inférieur, par des réductions des fonctions qui la composent. 'En outre, si cette même fonction de l'ordre " contient m quantités de cet ordre, on dira qu'elle est du mème degré: et en la désignant par \(v\), on pourra poser
\[
v=q_0+\mu^1+q_2 p^2+\cdots+q_{n-1} p^{n-1}
\]
c'est-à-dire que l'on a ce premier théorème: Toute fonction algébrique v de l'ordie "et du degré \(m\), peut être représentée par. lu formule (2), oì " est un nombre premier, q,1, \(q_2, \ldots q_{n-1}\) des fonctions algébriques de l'ordie "n et du degré mi-1 tout an plus, et \(p\) une fonction alyélnique de l'ordie " -1,
%89
telle qu'il est impossible d'exprimer \(\nu^1{ }^1\) par une fonction rationnelle de 1, , qon \(q_3 \ldots q_{n-1}\).

Après avoir ainsi trouvé l'expression générale des fonctions algébriques, l'auteur considère, dans - un deuxième paragraphe, une équation quelconque dont les coefficiens sont des fonctions rationnelles des quantités \(x_1, x_2 \ldots\) et qu'on suppose résoluble algébriquement. En désignant donc par y l'incomne, et par
\[
\uparrow\left(x_1, x_2, x_3 \ldots y\right)=0
\]
l'équation même, il faut que le premier membre se réduise à zéro, en mettant pour y une certaine fonction de la forme (2). Par cette substitution l'équation (3) se changera en une autre de la forme
\[
r_0+r_1 p^{\frac{1}{n}}+r_2 p^{\frac{2}{n}}+\cdots+r_{n-1} p^{\frac{n-1}{n}}=0
\]
oì \(r_0, r_1, r_2, r_3 \ldots\) sont des fonctions ratiomelles de \(x_1, x_2, x_3 \ldots\) et de \(q_0\), \(q_2, q_3 \ldots\) Cette équation entraine les suivantes:
\[
r_0=0, r_1=0, r_z=0, \ldots r_{n-1}=0
\]
car dans le cas contraire, l'équation (4) pourrait donner la valeur de \(p^{\frac{1}{n}}\) en fonction rationnelle de \(p, r_0, r_1 \ldots r_{n-1}\), ce qui est contre l'énoncé du théorème précédent. Si les équations (5) ont lieu, l'équation (4) et par suite l'équation (3), seront de même satisfaites par toutes les valeurs de y qu'on obtiendra en mettant, au lieu de \(p^{\frac{1}{n}}\) les \(n-1\) valeurs \(\alpha p^{\frac{1}{n}}, \alpha^2 p^{\frac{1}{n}}, \ldots \alpha^{n-1} p^{\frac{1}{n}}\), où \(a\) est une racine imaginaire de l'unité. Par là on aura les valeurs de \(n\) racines de l'équation (3), savoir
\[
\begin{gathered}
y_1=q_0+p^{\frac{1}{n}}+q_2 p^{\frac{2}{n}}+\cdots+q_{n-1} \nu^{\frac{n-1}{n}} \\
y_2=q_0+\alpha p^{\frac{1}{n}}+\alpha^2 q_2 p^{\frac{2}{n}}+\cdots+\alpha^{n-1} q_{n-1} p^{\frac{n-1}{n}} \\
\ldots \ldots \ldots \ldots \ldots \ldots \\
y_n=q_0+\alpha^{n-1} p^1+\alpha^{n-2} q_2 p^{\frac{1}{n}}+\cdots \cdots+\alpha q_{n-1} p^{\frac{n-1}{n}}
\end{gathered}
\]
ces équations donnent les \(n\) quantités \(p^{\frac{1}{n}}, q_0, q_2 \ldots q_{n-1}\) en fonctions rationnelles des racines \(y_1, y_2 \ldots y_n\).

Si maintenant \(f^{\prime} x=0\) est une équation algébrique générale, résoluble rlgébriquement, et \(x_1, x_2 \ldots\) les racines de cette équation, on doit avoir
%90
\[
x=s_0+v^{\frac{1}{n}}+s_2 v^{\frac{\dot{z}}{n}}+\cdots+s_{n-1} v^{\frac{n-1}{n}}
\]
cette formule étant analogue à la formule (2). D'après ce qu'on vient de voir \(v^{\frac{1}{n}}, s_0, s_2 \ldots s_{n-1}\) seront des fonctions rationnelles des racines de l'équation proposée. Cela posé, considérons l'une quelconque des quantités \(v, s_0, s_2 \ldots s_{n-1}\), par exemple \(v\); en désignant par \(n^{\prime}\) le nombre de toutes les valeurs différentes de \(v\), qu'on obtiendra en échangeant entre elles de toutes les manières possibles les racines de l'équation proposée, on pent former une équation du degré \(n^{\prime}\) qui ait toutes ces valeurs pour racines, et dont les coefficiens soient des fonctions rationnelles et symétriques des valeurs de \(v\), et par suite res fonctions rationnelles de \(x_1, x_2 \ldots\) En faisant done
\[
v=t_0+u^{\frac{1}{v}}+t_2 u^{\frac{2}{\nu}}+\cdots+t_{v-1} u^{\frac{\nu-1}{\nu}}
\]
toutes les quantités \(u, t_0, t_2 \ldots t_{\nu-1}\) seront des fonctions rationnelles des valeurs de \(v\), et par suite de \(x_1, x_2 \ldots\) En poursuivant ce raisomnement, on établira le théorème suivant:

Deuxième théorème: Si une équation algébrique est résoluble algébriquement, on peut toujours donner à la racine une forme telle, que toutes les expressions algébriques dont elle est composée pourront s'bxprimer par des fonctions rationnelles des racines de l'équation proposée.

Dans le troisième paragraphe on démontre, d'après un mémoire de \(\mathrm{M}\). Cauchy, inséré dans le cahier XVII \({ }^e\) du Journal de l'École Polytechnique, que, \(1^{\circ}\) le nombre des valeurs d'une fonction rationnelle de \(n\) quantités, ne peut s'abaisser au-dessous du plus grand nombre premier contenu dans \(n\), sans devenir égal à 2 ou à \(1 ; 2^{\circ}\) que toute fonction rationnelle qui a deux valeurs différentes aura la forme
\[
p+q\left(x_1-x_2\right)\left(x_1-x_3\right) \cdots\left(x_2-x_3\right) \cdots\left(x_3-x_4\right) \cdots
\]
et que, si elle contient 5 quantités, elle deviendra
\[
\begin{gathered}
p+q\left(x_1-x_2\right)\left(x_1-x_3\right)\left(x_1-x_4\right)\left(x_1-x_5\right)\left(x_2-x_3\right)\left(x_2-x_4\right) \\
\left(x_2-x_5\right)\left(x_3-x_4\right)\left(x_3-x_5\right)\left(x_4-x_5\right),
\end{gathered}
\]
où \(p\) et \(q\) sont des fonctions invariables.
On démontre ensuite que tonte fonction rationnelle de cinq quantités qui a cinq valeurs différentes peut être mise sous la forme
%91
\[
v=r_0+r_1 x+r_2 x^2+r_3 x^3+r_4 x^4,
\]
où \(r_0, r_1 \ldots r_4\) sont des fonctions invariables, et \(x\) une des cinq quantités en question.
En combinant cette équation avec l'équation
\[
\begin{aligned}
\left(x-x_1\right)\left(x-x_2\right)\left(x-x_3\right)\left(x-x_4\right)\left(x-x_5\right) & \\
= & x^5-a x^4+b x^3-c x^2+d x-e=0,
\end{aligned}
\]
on en peut tire; les valeurs de \(x\) sous la forme
\[
x=s_0+s_1 v+s_2 v^2+s_3 v^3+s_4 v^4
\]
\(s_0, s_1 \ldots\) étant des fonctions invariables de \(x_1, x_2 \ldots\) Finalement on arrive à ce théorème connu: Troisième théorème: Si une fonction rationnelle de plusieurs quantités \(x_1, x_2 \ldots a m\) valeurs différentes, on pourra toujours trouver une équation du degré \(m\) dont tous les coefficiens sont des fonctions invariables de \(x_1, x_2\)... et qui ont les \(m\) valeurs de la fonction pour racines; mais il est impossible de trouver une équation de la même forme d'un degré moins élevé, qui aura une ou plusieurs de ces valeurs pour racines.

Au moyen des théorèmes établis dans les trois premiers paragraphes, l'auteur démontre ensuite, dans le quatrième, qu'il est impossible de résoudre algébriquement l'équation générale du cinquième degré.

En effet, en supposant que l'équation générale du cinquième degré soit résoluble algébriquement, on pourra, en vertu du théorème (1), exprimer toutes les fonctions algébriques dont une racine est composée, par des fonctions rationnelles des racines; donc, puisqu'il est impossible d'exprimer une racine d'une équation générale par une fonction rationnelle des coefficiens, il faut qu'on ait
\[
R^{\frac{1}{m}}=v
\]
où \(R^{\frac{1}{m}}\) est une des fonctions du premier ordre qui se trouvent dans l'expression de la racine, \(\boldsymbol{l}\) étant une fonction rationnelle des coefficiens de l'équation proposée, c'est-à-dire, une fonction invariable des racines, et \(v\) une fonction rationnelle des mêmes racines. Cette équation donne \(v^m-\boldsymbol{R}=0\); et pour \(v, m\) valeurs différentes, résultant du changement des racines entre elles. Maintenant le nombre des valeurs d'une fonction rationnelle de cinq variables, doit être diviseur du produit 2.3.4.5; il faut donc que \(m\), qui est un nombre premier, soit un des trois nombres \(2,3,5\); mais selon le
%92
théorème cité de M. Cauchy, le nombre 3 sera exclu, et par conséquent il ne restera pour \(m\) que les deux valeurs 5 et 2 .
1. Soit d'abord \(m=5\); on aura, d'après ce qu'on a vu précédemment,
\[
v=\boldsymbol{R}^{\frac{1}{5}}=r_0+r_1 x+r_2 x^2+r_3 x^3+r_4 x^4
\]
et de là
\[
x=s_0+s_1 R^{\frac{1}{5}}+s_2 R^{\frac{8}{5}}+s_3 R^{\frac{3}{5}}+s_4 R^{\frac{4}{5}},
\]
\(s_0, s_1, \ldots\) étant, de même que \(R\), des fonctions invariables des racines. Cette valeur dome, selon ce qui a été établi dans le deuxième paragraphe, pour \(s_1 R^{\frac{1}{5}}\), une fonction rationnelle des racines, savoir:
\[
s_1 R^{\frac{1}{5}}=\frac{1}{5}\left(x_1+\alpha^4 x_2+\alpha^3 x_3+\alpha^2 x_4+\alpha x_5\right)=z,
\]
\(\alpha\) étant une racine imaginaire de l'équation \(\alpha^5-1=0\); mais cela est impossible, car le second membre a 120 valeurs différentes, tandis qu'il doit être racine de l'équation \(z^5-s_1^5 R=0\), qui n'est que du cinquième degré. Le nombre \(m\) ne peut donc être égal à 5 .
2. Soit \(m=2\). Alors \(v\) aura deux valeurs qui, selon ce que M. Cauchy a démontré, doivent avoir la forme
\[
v=p+q s=\sqrt{R}
\]
où
\[
s=\left(x_1-x_2\right)\left(x_1-x_3\right) \cdots\left(x_4-x_5\right)
\]
et \(p\) et \(q\) sont des fonctions invariables.
En échangeant entre elles les deux racines \(x_1\) et \(x_2\), on aura \(p-q s=-\mid R\), et par conséquent \(p=0\), et par suite
\[
\sqrt{l}=q s .
\]

De la il suit que toutes les fonctions algébriques du premier ordre qui se trouvent dans l'expression de la racine, doivent être de la forme \(\alpha+\beta / s^2\), vù \(\alpha\) et \(\beta\) sont des fonctions invariables. "Maintenant il est impossible d'exprimer une racine de l'équation générale du cinquième degré, par une fonction de cette forme; par conséquent il faut qu'il y ait, dans l'expression de la racine, des fonctions du denxième ordre, et qui doivent contenir un radical de la forme
%93
\[
V_{\alpha+\beta}^m s^2=v
\]
où \(\beta\) n'est pas égal à zéro; \(m\) est un nombre premier et \(v\) une fonction rationnelle des racines. En changeant \(x_1\) en \(x_2\) on aura
\[
\sqrt[m]{\alpha-\beta \sqrt{s^2}}=v_1
\]
ce qui dome \(v v_1=\sqrt[n]{\alpha^2-\beta^2 s^2}\). Maintenant \(\alpha^2-\beta^2 s^2\) est une fonction invariable; si donc \(v v_1\) n'est pas de même une fonction invariable, il faut que \(m\) soit égal à 2 ; mais alors on aura \(v=\sqrt{\alpha+\beta \sqrt{s^2}}\), ce qui donne pour \(v\) quatre valeurs différentes; or cela est impossible: done il faut que \(v v_1\) soit une fonction invariable. Soit cette fonction représentée par \(\%\), on aura \(v_1=\frac{\gamma}{v}\). Cela posé, considérons l'expression
\[
v+v_1=\sqrt[m]{\alpha+\beta \sqrt{s^2}}+\frac{\gamma}{\sqrt{\alpha+\beta \sqrt{s^2}}}=p=\sqrt[n]{R}+\frac{\gamma}{\sqrt[n]{h}} .
\]

Cette valeur de \(p\) peut être racine d'une équation du \(m^{\text{ième}}\) degré, et, comme cette équation sera nécessairement irréductible, \(p\) aura \(m\) valeurs différentes; donc \(m\) sera égal à 5.
Alors on aura
\[
R^{\frac{1}{5}}+\gamma R^{-\frac{1}{5}}=r_0+r_1 x+r_2 x^2+r_3 x^3+r_4 x^4=p,
\]
d'où
\[
x=s_0+s_1 p+\cdots+s_4 p^4=t_0+t_1 R^{\frac{1}{5}}+t_2 R^{\frac{2}{5}}+t_3 R^{\frac{3}{5}}+t_4 R^{\frac{4}{5}}
\]
\(t_0, t_1 \ldots t_4\) étant des fonctions invariables. De là on tire, comme auparavant,
\[
\begin{gathered}
t_1 R^{\frac{1}{5}}=\frac{1}{3}\left(x_1+\alpha^4 x_2+\alpha^3 x_3+\alpha^2 x_4+\alpha x_5\right)=y, \\
y^5=t_1^5 R=1_1^5\left(\alpha+\beta / s^2\right)
\end{gathered}
\]
et
\[
\left(y^5-\alpha t_1^5\right)^2-t_1^{10} \beta^2 s^2=0 .
\]
%94
Cette équation, dont les coefficiens sont des fonctions invariables, est du dixième degré par rapport à \(y\); mais cela est contraire au théorème (3), parce que \(y\) a 120 valeurs différentes.

Nous concluons donc en dernier lieu, qu’il est impossible de résoudre algébriquement l'équation générale du cinquième degré. De là il suit immédiatement qu’il est, en général, impossible de résoudre algébriquement les équations générales d'un degré supérieur au quatrième.
%95
VIII.

REMARQUE SUR LE MÉMOIRE N0 4 DU PREMIER CAHIER DU JOURNAL DE M. CRELLE.
Journal für die reine und angewandte Mathematik, herausgegeben von C'relle, Bd. I, Berlin 1826.
L'objet du mémoire est de trouver l'effet d'une force sur trois points domnés. Les résultats de l'auteur sont très justes, quand les trois points ne sont pas placés sur une même ligne droite; mais dans ce cas ils ne le sont pas. Les trois équations, par lesquelles les trois inconnues \(Q, Q^{\prime}, Q^{\prime \prime}\) se déteminent, sont les suivantes
\[
\left\{\begin{array}{l}
P=Q+Q^{\prime}+Q^{\prime \prime}, \\
Q^{\prime} b \sin \alpha=\prime^{\prime \prime} c \sin \beta, \\
Q \alpha \sin \alpha=-Q^{\prime \prime} c \sin (\alpha+\beta) .
\end{array}\right.
\]

Celles-ci ont lieu pour des valeurs quelconques de \(P, a, b, c, a\) et \(\beta\). Elles donnent en général, comme l'auteur l'a trouvé,
(2)
\[
\left\{\begin{array}{l}
Q=-\frac{-b c \sin (\alpha+\beta)}{r} P, \\
Q^{\prime}=\frac{a c \sin \beta}{r} P, \\
Q^{\prime \prime}=\frac{a b \sin \alpha}{r} P,
\end{array}\right.
\]
où
\[
r=a b \sin \alpha+a c \sin \beta-b c \sin (\alpha+\beta) .
\]

Or les équations (2) cessent d'être déterminées lorsque l'une ou l'autre des
%96
quantités \(Q, Q^{\prime}, Q^{\prime \prime}\) prend la forme \(\frac{11}{0}\), ce qui a lieu, comme on le voit aisément pour
\[
\alpha=\beta=180^{\circ} \text {. }
\]

Dans ce cas il faut recourir aux équations fondamentales (1), qui doment alors
\[
\begin{aligned}
& P=Q+Q^{\prime}+Q^{\prime \prime} \\
& Q^{\prime} b \sin 180^{\circ}=Q^{\prime \prime} c \sin 180^{\circ} \\
& Q a \sin 180^{\circ}=-Q^{\prime \prime} c \sin 360^{\circ} .
\end{aligned}
\]

Or les deux dernières équations sont identiques puisque
\[
\sin 180^{\circ}=\sin 360^{\circ}=0 .
\]

Done daus le cas où
\[
\alpha=\beta=180^{\circ}
\]
il n'existe qu'une seule équation, savoir
\[
P=Q+Q^{\prime}+Q^{\prime \prime}
\]
et, par suite, les valeurs de \(Q, Q^{\prime}, Q^{\prime \prime}\) ne peuvent alors se tirer des équations établies par l'auteur.
%97
IX.

RÉSOLUTION D'UN PROBLÈME DE MECANIQUE.

Journal für die reine und angewandte Mathematik, herausgegeben von Crelle, Bd. I, Berlin 1826.

Soit \(B D M A\) une courbe quelconque. Soit \(B C\) une droite horizontale et \(C A\) une droite verticale. Supposons qu'un point sollicité par la pesanteur se meuve sur la courbe, un point quelconque \(D\) étant son point de départ. Soit \(\tau\) le temps qui s'est écoulé quand le mobile est parvenu à un point donné \(A\), et soit a la hauteur \(E A\). La quantité \(\boldsymbol{\tau}\) sera une certaine fonction de \(a\), qui dépendra de la forme de la courbe. Réciproquement la forme de la courbe dépendra de cette fonction. Nous allons examiner comment, à l'aide d'une intégrale définie, on peut trouver l'équation de la courbe pour laquelle \(\tau\) est une fonction continue donnée de \(a\).

Soit \(A M=s, A P=x\), et soit \(t\) le temps que le mobile emploie à parcourir l'are \(D M\). D'après les règles de la mécanique on a \(-\frac{d s}{d t}=\sqrt{a-x}\), donc \(d t=-\frac{d s}{\sqrt{a-x}}\). Il s'ensuit, lorsqu'on prend l'intégrale depuis \(x=a\) jusqu'à \(x=0\),
\[
\tau=-\int_a^0 \frac{d s}{\sqrt{a-x}}=\int_0^a \frac{d s}{\sqrt{a-x}}
\]
\(\int_\alpha^\beta\) désignant que les limites de l'intégrale sont \(x=\alpha\) et \(x=\beta\). Soit maintenant
\[
\tau=\varphi a
\]
%98
la fonction donnée, on aura
\[
\varphi a=\int_0^a \frac{d s}{\sqrt{a-x}}
\]
équation de laquelle on doit tirer \(s\) en fonction de \(x\). Au lieu de cette équation, nous allons considérer cette autre plus générale
\[
\varphi a=\int_0^a \frac{d s}{(a-x)^n}
\]
de laquelle nous chercherons à déduire l'expression de \(s\) en \(x\). Désignons par \(I\) ' \(\alpha\) la fonction
\[
I^{\prime} \alpha=\int_0^1 d x\left(\log \frac{1}{x}\right)^{\alpha-1}
\]
on a comme on sait
\[
\int_0^1 y^{\alpha-1}(1-y)^{\beta-1} d y=\frac{\boldsymbol{\Gamma} \alpha \cdot \boldsymbol{\Gamma} \beta}{\boldsymbol{\Gamma}(a+\beta)}
\]
oì \(\alpha\) et \(\beta\) rloivent être supérieurs à zéro. Soit \(\beta=1-n\), on trouvera
\[
\int_0^1 \frac{y^{\alpha-1} d y}{(1-y)^n}=\frac{\boldsymbol{\Gamma} \alpha \cdot \boldsymbol{\Gamma}(1-n)}{\boldsymbol{\Gamma}(\boldsymbol{\alpha}+1-n)}
\]
d'où l'on tire, en faisant \(z=a y\),
\[
\int_0^a \frac{z^{\alpha-1} d z}{(a-z)^n}=\frac{\Gamma \alpha \cdot \Gamma(1-n)}{\Gamma(\alpha+1-n)} a^{\alpha-n}
\]

En multipliant par \(\frac{d a}{(x-a)^{1-n}}\) et prenant l'intégrale depuis 'a=0 jusqu'à \(a=x\), on trouve
\[
\int_0^x \frac{d a}{(x-a)^{1-n}} \int_0^a \frac{z^{\alpha-1} d z}{(a-z)^n}=\frac{\Gamma \alpha \cdot \Gamma(1-n)}{\Gamma(\alpha+1-n)} \int_0^x \frac{a^{\alpha-n} d a}{(x-a)^{1-n}} .
\]

En faisant \(a=x y\), on aura
\[
\int_0^x \frac{a^{\alpha-n} d a}{(x-a)^{1-n}}=x^\alpha \int_0^1 \frac{y^{\alpha-n} d y}{(1-y)^{1-n}}=x^\alpha \frac{\Gamma(\alpha-n+1) \Gamma n}{\Gamma(\alpha+1)},
\]
donc
\[
\int_0^x \frac{d a}{(x-a)^{1-n}} \int_0^a \frac{z^{\alpha-1} d z}{(a-z)^n}=I^{\prime} n \cdot I^{\prime}(1-n) \frac{\Gamma \alpha}{\Gamma(\alpha+1)} x^\alpha
\]
%99
Or d'après une propriété connue de la fonction \(r\), on a
\[
\Gamma(\alpha+1)=\alpha \Gamma
\]
on aura done en substituant:
\[
\int_0^x \frac{d a}{(x-a)^{1-n}} \int_0^a \frac{z^{\alpha-1} d z}{(a-z)^n}=\frac{x^\alpha}{\alpha} \operatorname{Tn} \cdot \Gamma^{\prime}(1-n) .
\]

En multipliant par \(\alpha \varphi \alpha . d \alpha\), et intégrant par rapport à \(\alpha\), on trouve
\[
\int_0^x \frac{d a}{(x-a)^{\mathrm{r}-n}} \int_0^a \frac{\left(\int \varphi \alpha \cdot \alpha z^{\alpha-1} d \alpha\right) d z}{(a-z)^n}=\operatorname{T} n \cdot \boldsymbol{I}^{\prime}(1-n) \int \varphi \alpha \cdot x^\alpha d \alpha .
\]

Soit
\[
\int \varphi \alpha \cdot x^\alpha d \alpha=f x
\]
on en tire en différentiant,
\[
\int \varphi \alpha \cdot \alpha x^{\alpha-1} d \alpha=f^{\prime} x
\]
done
\[
\int \varphi \alpha \cdot \alpha z^{\alpha-1} d \alpha=f^{\prime} z
\]
par conséquent
\[
\int_0^x \frac{d a}{(x-a)^{1-n}} \int_0^a \frac{f^{\prime} z \cdot d z}{(a-z)^n}=I^{\prime} n \cdot I^{\prime}(1-n) f x
\]
ou, puisque \(\boldsymbol{T} n \cdot T(1-n)=\frac{\pi}{\sin n \pi}\),
\[
f x=\frac{\sin u \pi}{\pi} \int_0^x \frac{d a}{(x-a)^{1-n}} \int_0^a \frac{f^{\prime} z \cdot d z}{(a-z)^n} .
\]

A l'aide de cette équation, il sera facile de tirer la valeur de \(s\) de l'équation
\[
\varphi a=\int_0^a \frac{d s}{(a-x)^n}:
\]

Qu'on multiplie cette équation par \(\frac{\sin n \pi}{\pi} \frac{d a}{(x-a)^{1-n}}\), et qu'on prenne l'intégrale depuis \(a=0\) jusqu'd \(a=x\), on aura
\[
\frac{\sin w \pi}{\pi} \int_0^x \frac{q u \cdot d a}{(x-a)^{1-n}}=\frac{\sin n \pi}{\pi} \int_0^x \frac{d a}{(x-a)^{1-n}} \int_0^a \frac{d s}{(a-x)^n},
\]
donc en vertu de l'équation (1)
%100
\[
s=\frac{\sin \theta \pi}{x} \int_0^x \frac{\varphi a \cdot d a}{(x-a)^{1-n}} .
\]

Soit maintenant \(n=\frac{1}{2}\), on obtient
\[
\varphi a=\int_0^a \frac{d s}{\sqrt{a-x}}
\]
et
\[
s=\frac{1}{\pi} \int_0^x \frac{\varphi a \cdot d a}{\sqrt{x-a}} .
\]

Cette équation donne l'are \(s\) par l'abscisse \(x\), et par suite la courbe est entièrement déterminée.
Nous allons appliquer l'expression trouvée ì quelques exemples.
I. Soit
\[
\varphi a=\alpha_0 a^{\mu_n}+\alpha_1 a^{\mu_1}+\cdots+\alpha_m a^{\mu_m}=\Sigma \alpha a^\mu
\]
la valeur de \(s\) sera
\[
s=\frac{1}{\pi} \int_0^x \frac{d a}{\sqrt{x-a}} \Sigma \alpha \alpha^\mu=\frac{1}{\pi} \Sigma\left(\alpha \int_0^x \frac{a^\mu d a}{\sqrt{x-a}}\right) .
\]

Si l'on fait \(a=x y\), on aura
\[
\int_0^x \frac{a^\mu d a}{\sqrt{x-a}}=x^{\mu+\frac{1}{2}} \int_0^1 \frac{y^\mu d y}{\sqrt{1-y}}=x^{\mu+1} \frac{\Gamma(\mu+1) \Gamma\left(\frac{1}{2}\right)}{\Gamma\left(\mu+\frac{3}{2}\right)},
\]
done
\[
s=\frac{\boldsymbol{\Gamma}\left(\frac{1}{2}\right)}{\pi} \Sigma \frac{\alpha \boldsymbol{\Gamma}(\mu+1)}{\boldsymbol{\Gamma}\left(\mu+\frac{3}{2}\right)} x^{\mu+\frac{1}{2}}
\]
ou, puisque \(\boldsymbol{l}^{\prime}\left(\frac{1}{2}\right)=\sqrt{\pi}\),
\[
s=\sqrt{\frac{x}{\pi}}\left[\alpha_0 \frac{\boldsymbol{T}\left(\mu_0+1\right)}{\boldsymbol{\Gamma}\left(\boldsymbol{\mu}_0+\frac{8}{2}\right)} x^{\mu_0}+\alpha_1 \frac{\boldsymbol{\Gamma}\left(\mu_1+1\right)}{\boldsymbol{\Gamma}\left(\mu_1+\frac{8}{2}\right)} x^{\mu_1}+\cdots+\alpha_m \frac{\boldsymbol{\Gamma}\left(\mu_m+1\right)}{\boldsymbol{\Gamma}\left(\mu_m+\frac{8}{2}\right)} x^{\mu_m}\right] .
\]

Si l'on suppose p. ex. que \(m=0, \mu_0=0\), c'est-à-dire que la courbe cherchée soit isochrone, on trouve
\[
s=\sqrt{\frac{x}{\pi}} \alpha_0 \frac{\Gamma(1)}{\Gamma\left(\frac{3}{2}\right)}=\frac{\alpha_0}{\frac{1}{2} \Gamma\left(\frac{1}{2}\right)} \sqrt{\frac{x}{\pi}}=\frac{2 \alpha_0}{x} \sqrt{x},
\]
or \(s=\frac{2 \alpha_0}{\pi} \sqrt{x}\) est l'équation connue de la cycloide.
%101
II. Soit
, \(a\) depuis \(a=0\) jusqu'à, \(a=a_0\), égal à \(\varphi_0 a\) \(\varphi a\) depuis \(a=a_0\) jusqu'd \(a=a_1\), égal à \(\varphi_1 a\) \(\varphi a\) depuis \(a=a_1\) jusqu'à \(a=a_2\), égal à \(\varphi_2 a\)
\(\varphi a\) depuis \(a=a_{m-1}\) jusqu'à \(a=a_m\), égal à \(\varphi_m a\), on aura
\[
\begin{aligned}
\pi s & =\int_0^x \frac{\varphi_0 a \cdot d a}{\sqrt{a-x}}, \text { depuis } x=0 \text { jusqu'd } x=a_0, \\
\pi s & =\int_0^{a_0} \frac{\varphi_0 a \cdot d a}{\sqrt{a-x}}+\int_{a_0}^x \frac{\varphi_1 a \cdot d a}{\sqrt{a-x}} \text {, depuis } x=a_0 \text { jusqu'd } x=a_1, \\
\pi s & =\int_0^{a_0} \frac{\varphi_0 a \cdot d a}{\sqrt{a-x}}+\int_{a_0}^{a_1} \frac{\varphi_1 a \cdot d a}{\sqrt{a-x}}+\int_{a_1}^x \frac{\varphi_2 a \cdot d a}{\sqrt{a-x}} \text {, depuis } x=a_1 \text { jusqu'd } x=a_2, \\
& \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \int_{a_{m-2}}^{a_{m-1}} \frac{\varphi_{m-1} a \cdot d a}{\sqrt{a-x}}+\int_{a_{m-1}}^x \frac{\varphi_m a \cdot d a}{\sqrt{a-x}},
\end{aligned}
\]
depuis \(x=a_{m-1}\) jusqu'd \(x=a_m\),
où il faut remarquer que les fonctions \(\varphi_0 a, \varphi_1 a, \varphi_2 a \ldots \varphi_m a\) doivent être telles que
\[
\varphi_0 a_0=\varphi_1 a_0, \varphi_1 a_1=\varphi_2 a_1, \varphi_2 a_2=\varphi_3 a_2, \text { etc. }
\]
car la fonction \(\varphi a\) doit nécessairement être continue.
%102
X.

DÉMONSTRATION D'UNE EXPRESSION DE LAQUELLF LA FORMULE BINOME EST UN CAS PARTICULIER.
Journal für die reine und angewandte Mathematik, herausgegeben von Crelle, Bd. 1, Berlin 1826.
Cette expression est la suivante:
\[
\begin{gathered}
(x+\alpha)^n=x^n+\frac{n}{1} \alpha(x+\beta)^{n-1}+\frac{n(n-1)}{1.2} \alpha(\alpha-2 \beta)(x+2 \beta)^{n-2}+\cdots \\
+\frac{n(n-1) \cdots(n-\mu+1)}{1.2 \cdots \mu} \alpha(\alpha-\mu \beta)^{\mu-1}(x+\mu \beta)^{n-\mu}+\cdots \\
+\frac{n}{1} \alpha(\alpha-(n-1) \beta)^{n-2}(x+(n-1) \beta)+\alpha(\alpha-n \beta)^{n-1}
\end{gathered}
\]
\(x, \alpha\) et \(\beta\) sont des quantités quelconques, \(n\) est un nombre entier positif.
Lorsque \(n=0\), l'expression donne
\[
(x+\alpha)^0=x^0
\]
qu'il fallait. Or on pent, comme il suit, démontrer que si l'expression subsiste pour \(n=m\), elle doit aussi subsister pour \(n=m+1\), c'est-à-dire qu'elle est vraie en général.
Soit
\[
\begin{gathered}
(x+\alpha)^m=x^m+\frac{m}{1} \alpha(x+\beta)^{m-1}+\frac{m(m-1)}{1.2} \alpha(\alpha-2 \beta)(x+2 \beta)^{m-2}+\cdots \\
+\frac{m}{1} \alpha(\alpha-(m-1) \beta)^{m-2}(x+(m-1) \beta)+\alpha(\alpha-m \beta)^{m-1} .
\end{gathered}
\]

En multipliant par \((m+1) d x\) et intégrant, on trouve
%103
\[
\begin{gathered}
(x+\alpha)^{m+1}=x^{m+1}+\frac{m+1}{1} \alpha(x+\beta)^m+\frac{(m+1) m}{1.2} \alpha(\alpha-2 \beta)(x+2 \beta)^{m-1}+\cdots \\
+\frac{m+1}{1} \alpha(\alpha-m \beta)^{m-1}(x+m \beta)+C
\end{gathered}
\]
\(C\) étant la constante arbitraire. Pour trouver sa valeur posons \(x=-(m+1) \boldsymbol{\beta}\), les deux dernières équations domneront
\[
\begin{gathered}
(\alpha-(m+1) \beta)^m=(-1)^m\left[(m+1)^m \beta^m-m^m \alpha \beta^{m-1}\right. \\
+\frac{m}{2}(m-1)^{m-1} \alpha(\alpha-2 \beta) \beta^{m-2}-\frac{m(m-1)}{2.3}(m-2)^{m-2} \alpha\left(\alpha-3 \beta^2 \beta^{m-3}+\cdots\right], \\
(\alpha-(m+1) \beta)^{m+1}=(-1)^{m+1}\left[(m+1)^{m+1} \beta^{m+1}-(m+1) m^m \alpha \beta^m\right. \\
\left.+\frac{(m+1) m}{2}(m-1)^{m-1} \alpha(a-2 \beta) \beta^{m-1}-\cdots\right]+C .
\end{gathered}
\]

Multipliant la première de ces équations par \((m+1) \boldsymbol{\beta}\) et ajoutant le produit à la seconde, on trouve
ou bien
\[
C=(\alpha-(m+1) \beta)^{m+1}+(m+1) \beta(\alpha-(m+1) \beta)^m
\]
\[
C=\alpha(\alpha-(m+1) \beta)^n .
\]

Il s'ensuit que l'équation proposée subsiste de même pour \(n=m+1\). Or elle a lieu pour \(n=0\); donc elle aura lieu pour \(n=0,1,2,3\) etc. c'est-à-dire pour toute valeur entière et positive de \(n\).

Si l'on fait \(\beta=0\), on obtient la formule binome. Si l'on fait \(\alpha=-x\), on trouve
\[
\begin{aligned}
0=x^n-\frac{n}{1} x(x+\beta)^{n-1} & +\frac{n(n-1)^{\circ}}{1.2} x(x+2 \beta)^{n-1} \\
& -\frac{n(n-1)(n-2)}{1.2 .3} x(x+3 \beta)^{n-1}+\cdots
\end{aligned}
\]
ou en divisant par \(x\),
\[
\begin{aligned}
0=x^{n-1}-\frac{n}{1}(x+\beta)^{n-1} & +\frac{n(n-1)}{1.2}(x+2 \beta)^{n-1} \\
& -\frac{n(n-1)(n-2)}{1.2 .3}(x+3 \beta)^{n-1}+\cdots
\end{aligned}
\]
ce qui est d'ailleurs connu; car le second membre de cette équation n'est autre chose que
\[
(-1)^n \boldsymbol{I}^n\left(x^{n-1}\right)
\]
en faisant la différence constante égale à \(\boldsymbol{\beta}\).
%104
XI.

SUR L'INTÉGRATION DE LA FORMULE DIFFÉRENTIELLE \(\frac{\varrho d x}{\sqrt{R}}, \quad R\) ET \(\varrho\) ÉTANT DES FONCTIONS ENTIÈRES.
Journal für die reine und angewandte Mathematik, herausgegeben von Crelle, Bd. 1, Berlin 1826.
1.
Si l'on différentie par rapport à \(x\) l'expression
(1)
\[
z=\log \frac{p+q \sqrt{R}}{p-q \sqrt{R}},
\]
où \(p, q\) et \(R\) sont des fonctions entières d'une quantité variable \(x\), on obtiendra
\[
d z=\frac{d p+d(q \sqrt{R})}{p+q \sqrt{R}}-\frac{d p-d(q \sqrt{R})}{p-q \sqrt{R}}
\]
ou
\[
d z=\frac{(p-q \sqrt{R})[d p+d(q \sqrt{R})]-(p+q \sqrt{R})[d p-d(q \sqrt{R})]}{p^2-q^2 R},
\]
c'est-à-dire,
\[
d z=\frac{2 p d(q \sqrt{R})-2 d p \cdot q \sqrt{R}}{p^2-q^2 R} .
\]

Or
\[
d(q \sqrt{R})=d q \sqrt{R}+\frac{1}{2} q \frac{d R}{\sqrt{R}}
\]
done par substitution
\[
d z=\frac{p q d R+2(p d q-q d p) R}{\left(p^2-q^2 R\right) \sqrt{R}}
\]
%105
par conséquent, en fáaisant
\[
\begin{gathered}
p q \frac{d R}{d x}+2\left(p \frac{d q}{d x}-q \frac{d p}{d x}\right) R=M \\
p^2-q^2 R=N
\end{gathered}
\]
on allia
\[
d z=\frac{M d x}{N \sqrt{R}}
\]
où, comme on le voit aisément, \(M\) et \(N\) sont des fonctions entières de \(x\).
Or, \(z\) étant égal à \(\log \frac{p+q \sqrt{R}}{p-q \sqrt{R}}\), on aura en intégrant
\[
\int \frac{M d x}{N \sqrt{R}}=\log \frac{p+q \sqrt{R}}{p-q \sqrt{R}} .
\]

Il s'ensuit que dans la différentielle \(\frac{\varrho d_x x}{\sqrt{R}}\) on pent trouver une infinité de formes différentes pour la fonction rationnelle \(\rho\), qui rendent cette différentielle intégrable par des logarithmes, savoir par une expression de la forme \(\log \frac{p+q \sqrt{R}}{p-q \sqrt{R}}\). Ja fonction \(\varrho\) contient, comme on le voit par les équations (2), outre \(R\), encore deux fonctions indéterminées \(p\) et \(q\); c'est par ces fonctions qu'elle sera déterminée.

On peut renverser la question et demander s'il est possible de supposer les fonctions \(p\) et \(q\) telles, que \(\varrho\) on \(\frac{M}{N}\) prenne une forme déterminée donnée. La solution de ce problème conduit à une foule de résultats intéressants, que l'on doit considérer comme autant de propriétés des fonctions de la forme \(\int \frac{\varrho d x}{\sqrt{R}}\). Dans ce mémoire je me bornerai au cas où \(\frac{M}{N}\) est une fonction entière de \(x\), en essayant de résoudre ce problème général:
"Trouver toutes les différentielles de la forme \(\frac{\varrho d x}{\sqrt{R}}\), où \(\varrho\) et \(\boldsymbol{h}\) sont "des fonctions entières de \(x\), dont les intégrales puissent s'exprimer "par une fonction de la forme \(\log \frac{p+q \sqrt{R}}{p-q \sqrt{R}}\).
%106
2.
En différentiant l'équation
on obtient
\[
N=p^2-q^2 R
\]
\[
d N=2 \mu d p-2 q d q \cdot R-q^2 d R
\]
donc en multipliant par \(p\),
\[
p d N=2 \mu^2 d p-2 \mu q d \eta \cdot R-\mu \eta^2 d R
\]
c'est-à-dire, lorsqu'on remet à la place de \(p^2\) sa valeur \(N+q^2 l\),
oll
\[
p d N=2 N d p+2 q^2 d p \cdot R-2 p q d q \cdot R-p q^2 d R
\]
\[
p d N=2 N d p-q[2(p d q-q d p) R+p q d R]
\]
donc, puisque (2)
\[
2(p d q-q d p) R+p q d R=M d x
\]
on a
on bien
\[
p d N=2 N d p-q M d x
\]
\[
q M=2 N \frac{d p}{d i v}-p \frac{d N}{d x}
\]
done
\[
\frac{M}{N}=\left(2 \frac{d p}{d x}-p \frac{d N}{N d x}\right): \dot{q}
\]

Maintenant \(\frac{M}{N}\) doit être une fonction entière de \(x\); en désignant cette fonction par \(\varphi\), on aura
\[
q \varphi=2 \frac{d p}{d x}-\mu \frac{d N}{N d x}
\]

Il s'ensuit que \(p \frac{d N}{N d x}\) doit être une fonction entière de \(x\). En faisant
\[
N=(x+a)^m\left(x+a_1\right)^{m_1} \cdots\left(x+a_n\right)^{m_n}
\]
on aura
\[
\frac{d N}{N d x}=\frac{m}{x+a}+\frac{m_1}{x+a_1}+\cdots+\frac{m_n}{x+a_n}
\]
%107
donc l'expression
\[
p\left(\frac{m}{x+a}+\frac{m_1}{x+a_1}+\cdots+\frac{m_n}{x+a_n}\right)
\]
doit de même être une fonction entière, ce qui ne peut avoir lieu à moins que le produit \((x+a) \cdots\left(x+a_n\right)\) ne soit facteur de \(p\). Il faut done que
\[
p=(x+a) \cdots\left(x+a_n\right) p_1,
\]
\(p_1\) étant une fonction entière. \(\mathrm{Or}^*\)
\[
N=p^2-q^2 R
\]
done
\[
(x+a)^m \cdots\left(x+a_n\right)^{m_n}=p_1^2(x+a)^2\left(x+a_1\right)^2 \cdots\left(x+a_n\right)^2-q^2 R .
\]

Comme \(R\) n'a pas de facteur de la forme \((x+a)^2\), et comme on pent toujours supposer que \(p\) et \(q\) n'ont pas de facteur commun, il est clair que et que
\[
\begin{gathered}
m=m_1=\cdots=m_n=1, \\
R=(x+a)\left(x+a_1\right) \cdots\left(x+a_n\right) R_1,
\end{gathered}
\]
\(R_1\) étant une fonction entière. On a donc
\[
N=(x+a)\left(x+a_1\right) \cdots\left(x+a_n\right), \quad R=N R_1,
\]
c'est-à-dire que \(N\) doit être facteur de \(R\). On a de même \(p=N_{p_1}\). En substituant ces valeurs de \(R\) et de \(p\) dans les équations (2), on trouvera les deux équations suivantes
(6)
\[
\begin{gathered}
p_1^3 N-q^2 R_1=1, \\
M=p_1 q \frac{d R}{d x}+2\left(p \frac{d q}{d x}-q \frac{d p}{d x}\right) R_1=\omega .
\end{gathered}
\]

La première de ces équations détermine la forme des fonctions \(p_1, q, N\) et \(l_1\); celles-ci étant déterminées, la seconde équation donnera ensuite la fonction e. On peut aussi trouver cette dernière fonction par l'équation (5).
3.
Maintenant tout dépend de l'équation
\[
p_1^2 N-q^2 R_1=1 \text {. }
\]

Cette équation peut bien être résolue par la méthode ordinaire des coefti
%108
ciens indéterminés, mais l'application de cette méthode serait ici extrêmement prolixe, et ne conduirait guère à un résultat général. Je vais done prendre une autre route, semblable à celle qu'on emploie pour la résolution des équations indéterninées du second degré à deux inconmues. I La seule différence est, qu'au lieu de nombres entiers, on aura à traiter des fonctions entières. Comme dans la suite nous aurons souvent besoin de parler du degré d'une fonction, je me servirai de la lettre d' pour désigner ce degré, en sorte que \(\& P\) désignera le degré de la fonction \(P\), par exemple,
\[
\begin{gathered}
\delta\left(x^m+a x^{m-1}+\cdots\right)=m, \\
\delta\left(\frac{x^5+c x}{x^3+e}\right)=2, \\
\delta\left(\frac{x+e}{x^2+k}\right)=-1, \text { etc. }
\end{gathered}
\]

D’ailleurs, il est clair que les équations suivantes auront lieu:
\[
\begin{aligned}
& \delta(P Q)=\delta P+\delta Q, \\
& \delta\left(\frac{P}{Q}\right)=\delta P-\delta Q, \\
& \delta\left(P^m\right)=m \delta P ;
\end{aligned}
\]
de plus
\[
\delta\left(P+P^{\prime}\right)=\delta P
\]
si \(\delta P^{\prime}\) est moindre que \(\delta P\). De même je désignerai, pour abréger, la partie entière d'une fonction rationnelle \(u\) par \(E u\), en sorte que
\[
u=E u+u^{\prime}
\]
où f'u' est négatif. Il est clair que
\[
E\left(s+s^{\prime}\right)=E s+E s^{\prime}
\]
donc, lorsque d's' est négatif,
\[
E\left(s+s^{\prime}\right)=E s .
\]

Relativement à ce signe, on aura le théorème suivant:
"Lorsque les trois fonctions rationnelles \(u\), \(v\) et \(z\) ont la propriété que
\[
u^2=v^2+z
\]
%109
"oll aura, si \(d^{\prime} z<d^2\)
\[
E_{\prime \prime}= \pm E v
\]

En effet, on a par détinition
\[
\begin{aligned}
& u=E u+u^{\prime}, \\
& v=E v+v^{\prime},
\end{aligned}
\]
\(\delta u^{\prime}\) et \(\delta v^{\prime}\) étant négatifs; donc en substituant ces valeurs daus l'équation \(u^2=v^2+z\)
\[
(E u)^2+2 u^{\prime} E u+u^{\prime 2}=(E v)^2+2 v^{\prime} E v+v^{\prime 2}+z
\]

Il s'ensuit
\[
(E u)^2-(E v)^2=z+v^{\prime 2}-u^{\prime 2}+2 v^{\prime} E v-2 u^{\prime} E u=t
\]
on bien,
\[
(E u+E v)(E u-E v)=t .
\]

On voit aisément que \(\delta t<\delta v\); an contraire \(\delta(E u+k v)(E u-E v)\) est au moins égal à \(\delta v\), si \((E u+E v)(E u-E v)\) n’est pas égal à zéro. Il faut done nécessairement que \((E u+E v)(E u-E v)\) soit nul, ce qui donne
\[
E u= \pm E v \text { } . \text { q. f. d. }
\]

Il est clair que l'équation (7) ne samait subsister à moins qu'on l'ait c'est-à-dire, d'où
\[
\begin{gathered}
\delta\left(N p_1^2\right)=\delta\left(R_1 q^2\right), \\
\delta N+2 \delta p_1=\delta_1+2 \delta^{\prime} q,
\end{gathered}
\]
\[
\delta\left(N R_1\right)=2\left(\delta q-\delta p_1+\delta R_1\right)
\]

Le plus grand exposant de la fonction \(R\) doit donc etre un nombre pair. Soit \(\delta N=n-m, \delta R_1=n+m\).
4.
Cela posé, an lien de l'équation
\[
p_1^2 N-q^2 R_1=1
\]
je vais proposer la suivante
\[
p_1^2 N-q^2 R_1=i
\]
%110
où \(v\) est une fonction entière dont le degré est moindre que \(\frac{\delta N+\delta R_1}{2}\). Cette équation, comme on le voit, est plus générale; elle peut être résolue par le même procédé.

Soit \(t\) la partie entière de la fonction fractionnaire \(\frac{R_1}{N}\), et soit \(t^{\prime}\) le reste; cela posé, on aura
\[
R_1=N t+t^{\prime}
\]
et il est clair que \(t\) doit être du degré \(2 m\), lorsque \(\delta N=n-m\) et \(\$ R_1=n+m\). En substituant cette expression de \(R_1\) dans l'équation (8), on en tirera
\[
\left(p_1^2-q^2 t\right) N-q^2 t^{\prime}=v
\]

Soit maintenant
\[
t=t_1^2+t_1^{\prime}
\]
on peut toujours déterminer \(t_1\) de manière que le degré de \(t_1{ }^{\prime}\) soit moindre que \(m\). A cet effet, faisons
\[
\begin{aligned}
& t=\alpha_0+\alpha_1 x+\cdots+\alpha_{2 m} x^{2 m}, \\
& t_1=\beta_0+\beta_1 x+\cdots+\beta_m x^m, \\
& t_1^{\prime}=\gamma_0+\gamma_1 x+\cdots+\gamma_{m-1} x^{m-1}
\end{aligned}
\]
cela posé, l'équation (11) donnera
\[
\begin{gathered}
\alpha_{2 m} x^{2 m}+\alpha_{2 m-1} x^{2 m-1}+\alpha_{2 m-2} x^{2 m-2}+\cdots+\alpha_{m-1} x^{m-1}+\cdots+\alpha_1 x+\alpha_0 \\
=\beta_m^2 x^{2 m}+2 \beta_m \beta_{m-1} x^{2 m-1}+\left(\beta_{m-1}^2+2 \beta_m \beta_{m-2}\right) x^{2 m-2}+\cdots \\
+\gamma_{m-1} x^{m-1}+\gamma_{m-2} x^{m-2}+\cdots+\gamma_1 x+\gamma_0 .
\end{gathered}
\]

De cette équation on déduira, en comparant les coefficiens entre eux,
\[
\begin{aligned}
\alpha_{2 m} & =\beta_m^2, \\
\alpha_{2 m-1} & =2 \beta_m \beta_{m-1}, \\
\alpha_{2 m-2} & =2 \beta_m \beta_{m-2}+\beta_{m-1}^2, \\
\alpha_{2 m-3} & =2 \beta_m \beta_{m-3}+2 \beta_{m-1} \beta_{m-2}, \\
\alpha_{2 m-4} & =2 \beta_m \beta_{m-4}+2 \beta_{m-1} \beta_{m-3}+\beta_{m-2}^2, \\
\ldots \ldots \ldots \ldots & \ldots \ldots \ldots \\
\alpha_m & =2 \beta_m \beta_0+2 \beta_{m-1} \beta_1+2 \beta_{m-2} \beta_2+\cdots \\
\gamma_{m-1} & =\alpha_{m-1}-2 \beta_{m-1} \beta_0-2 \beta_{m-2} \beta_1 \ldots \ldots
\end{aligned}
\]
%111
\[
\begin{aligned}
\gamma_{m-2} & =\alpha_{m-2}-2 \beta_{m-2} \beta_0-2 \beta_{m-3} \beta_1-\cdots \cdots \\
\cdots \cdots \cdots & \ldots \ldots \\
\gamma_2 & =\alpha_2-2 \beta_2 \beta_0-\beta_1^2, \\
\gamma_1 & =\alpha_1-2 \beta_1 \beta_0 \\
\gamma_0 & =\alpha_0-\beta_0^2 .
\end{aligned}
\]

Les \(m+1\) premières équations domnent toujours, comme il est aisé de le voir, les valeurs des \(m+1\) quantités \(\boldsymbol{\beta}_m, \boldsymbol{\beta}_{m-1} \cdots \boldsymbol{\beta}_0\), et les \(m\) dernières équations domment les valeurs de \(\gamma_0, \gamma_1^{\prime}, \gamma_2^{\prime} \ldots \gamma_{m-1}^{\prime}\). L'équation supposée (11) est done toujours possible.

Substituant dans l'équation (10), au lieu de \(t\), sa valeur tirée de l'équation (11), on aura
\[
\left(p_1^2-q^2 t_1^2\right) N-q^2\left(N t_1^{\prime}+t^{\prime}\right)=v
\]
d'où l'on tire.
\[
\left(\frac{p_1}{q}\right)^2=t_1^2+t_1^{\prime}+\frac{t^{\prime}}{N}+\frac{v}{q^2 N} .
\]

En remarquant que
\[
\delta\left(t_1^{\prime}+\frac{t^{\prime}}{N}+\frac{v}{q^2 N}\right)<\delta t_1
\]
on aura, par ce qui précède,
done
\[
E\left(\frac{p_1}{q}\right)= \pm E t_1= \pm t_1
\]
\[
\mu_1= \pm t_1 q+\beta, \text { où } \delta_\beta<\delta_q,
\]
ou bien, comme on peut prendre \(t_1\) avec le signe qu'on voudra,
\[
p_1=t_1 q+\beta \text {. }
\]

En substituant cette expression, an lieu de \(p_1\) daus l'équation (12), elle se changera en
\[
\left(\beta^2+2 \beta t_1 q\right) N-q^2 s=v,
\]
où, pour abréger, on a fait
\[
N t_1^{\prime}+t^{\prime}=s
\]

De cette équation il est facile de tirer
%112
\[
\left(\frac{q}{\beta}-\frac{t_1 N}{s}\right)^2=\frac{N\left(t_1^2 N+s\right)}{s^8}-\frac{v}{s \beta^2}
\]
ou, puisque \(t_1^2 N+s=R_1\left(\operatorname{car} R_1=t N+t^{\prime}, s=N t_1^{\prime}+t^{\prime}\right.\), et \(\left.t=t_1^2+t_1{ }^{\prime}\right)\),
\[
\left(\frac{q}{\beta}-\frac{t_1 N}{s}\right)^2=\frac{R_1 N}{s^2}-\frac{v}{s \beta^2} \text {. }
\]

Soit maintenant
\[
R_1 N=r^2+r^{\prime} \text {, où } \delta^{\prime} r^{\prime}<\delta^{\prime} r^{\prime}
\]
on alla
\[
\left(\frac{q}{\beta}-\frac{t_1 N}{s}\right)^2=\left(\frac{r}{s}\right)^2+\frac{r^{\prime}}{s^2}-\frac{v}{s \beta^2} .
\]

Or, on voit aisément que
\[
\delta\left(\frac{r^{\prime}}{s^2}-\frac{v}{s \beta^2}\right)<\delta\left(\frac{r}{s}\right)
\]
rone
\[
E\left(\frac{q}{\beta}-\frac{t_1 N}{s}\right)=E\left(\frac{r}{s}\right)
\]
et par suite
\[
E\left(\frac{q}{\beta}\right)=E\left(\frac{r+t_1 N}{s}\right)
\]
done en faisant
\[
E\left(\frac{r+t_1 N}{s}\right)=2 \mu
\]
on alura
\[
q=2 \mu \beta+\beta_1 \text {, où } \delta \beta_1<\delta / .
\]

En substituant cette expression de \(q\) dans l'équation (13), on aura
\[
\beta^2 N+2 \beta t_1 N\left(2 \mu \beta+\beta_1\right)-s\left(4 u^2 \beta^2+4 \mu \beta_1 \beta+\beta_1^2\right)=v
\]
c'est-à-dire,
\[
\beta^2\left(N+4 \mu t_1 N-4 s \mu^2\right)+2\left(t_1 N-2 \mu s\right) \beta \beta_1-s \beta_1^2=v .
\]

Faisant pour abréger
\[
\begin{aligned}
& s_1=N+4 \mu t_1 N-4 s \mu^2, \\
& t_1 N-2 \mu s=-r_1,
\end{aligned}
\]
on obtient
\[
s_1 \beta^2-2 r_1 \beta \gamma_1-s \beta_1^2=v
\]

Puisque \(E\left(\frac{r+t_x N}{s}\right)=2 \mu\), on a
%113
\[
r+t_1 N=2 s i \iota+\varepsilon \text {, où } d^{\prime} \varepsilon<\delta s,
\]
par suite la dernière des équations (14) donnera
\[
r_1=r-\varepsilon \text {. }
\]

En multipliant l'expression de \(s_1\) par \(s\), on obtient
\[
s s_1=N s+4 u t_1 N s-4 s^2 u^2=N s+t_1^2 N^2-\left(2 s u-t_1 N\right)^2 .
\]

Or \(2 s \mu-t_1 N=r_1\), donc
\[
s s_1=N s+t_1^2 N^2-r_1^2, \text { et } r_1^2+s s_1=N\left(s+t_1^2 N\right)
\]
de plus on a
\[
s+t_1^2 N=R_1
\]
done
\[
r_1^2+s s_1=N R_1=l i
\]
1)'après ce qui précède on a \(R=r^2+r^{\prime}\), donc
\[
r^2-r_1^2=s s_1-r^{\prime},\left(r+r_1\right)\left(r-r_1\right)=s s_1-r^{\prime} .
\]

Or puisque \(\delta r^{\prime}<\delta r\), il suit de cette équation que
\[
\delta\left(s s_1\right)=\delta\left(r+r_1\right)\left(r-r_1\right),
\]
c'est-à-dire, puisque \(r-r_1=\varepsilon\), où \(\delta^{\prime} \varepsilon<\delta r\),
\[
\delta s+\delta s_1=d r+d \varepsilon
\]

Or d's > d's, donc
\[
s_1<d_r
\]

On a de plus \(s=N t_1{ }^{\prime}+t^{\prime}\), où \(\delta t^{\prime}<\delta N\) et \(\delta t_1{ }^{\prime}<\delta t_1\), donc
\[
\delta s<d^{\prime} N+\delta^{\prime} t_1 \text {. }
\]

Mais \(R=N\left(s+t_1^2 N\right)\), par conséquent,
\[
\delta R=2 \delta t_1+2 \delta N,
\]
et puisque \(d R=2 \delta^{\prime} r=2 \delta^{\circ} r_1\), on aura
\[
\delta t_1+\delta N=\delta r_1
\]
(On en conclut
\[
\omega_s<d_1 .
\]
%114
L'équation \(p_1^2 N-q^2 R_1=v\) est donc transformée en celle-ci:
où
\[
s_1 \beta^2-2 r_1 \beta \beta_1-s \beta_1^z=\imath,
\]
\[
\delta_1=\frac{1}{2} \delta R=n, \quad \delta_1<\delta_\beta, \quad \delta_s<n, \quad \delta_1<n .
\]

On obtient cette équation, comme on vient de le voir, en faisant
\[
\begin{aligned}
& \mu_1=t_1 q+\beta, \\
& q=2 \mu \beta+\beta_1,
\end{aligned}
\]
\(t_1\) étant déterminé par l'équation
\[
t=t_1^2+t_1^{\prime}, \text { où } \delta t_1^{\prime}<\delta t_1, t=E\left(\frac{R_1}{N}\right),
\]
et " par l'équation,
\[
2 u=E\left(\frac{r+t_1 N}{s}\right)
\]
où
\[
r^2+r^{\prime}=R_1 N, s=N t_1^{\prime}+R_1-N t
\]

De plus on a
\[
\left\{\begin{array}{l}
r_1=2 u s-t_1 N \\
s_1=N+4 \mu t_1 N-4 s \mu^2 \\
r_1^2+s s_1=R_1 N=R .
\end{array}\right.
\]

Il s'agit maintenant de l'équation (15).
5.
Résolution de l'équation: \(s_1 \beta^2-2 r_1 \beta \beta_1-s \beta_1^2=v\), oì \(\delta s<\delta r_1, \delta s_1<\delta r_1\),
\[
\delta v<\delta r_1, \delta \beta_1<\delta \beta \text {. }
\]

En divisant l'équation
\[
s_1 \beta^2-2 r_1 \beta_1 \beta_1-s \beta_1^2=v
\]
par \(s_1 \beta_1^2\), on obtient
\[
\frac{\beta^2}{\beta_1^2}-2 \frac{r_1}{s_1} \beta_1-\frac{s}{s_1}=\frac{0}{s_1 \beta_1^2}
\]
done
\[
\left(\frac{\beta}{\beta_1}-\frac{r_1}{s_1}\right)^2=\left(\frac{r_1}{s_1}\right)^2+\frac{s}{s_1}+\frac{v}{s_1 \beta_1^2} \text {. }
\]
%115
On tire de là, en remarquant que \(\delta\left(\frac{s}{s_1}+\frac{v}{s_1 \beta_1^2}\right)<\delta\left(\frac{r_1}{s_1}\right)\),
donc
\[
E\left(\frac{\beta}{\beta_1}-\frac{r_1}{s_1}\right)= \pm E\left(\frac{r_1}{s_1}\right)
\]
\[
E\left(\frac{\beta}{\beta_1}\right)=E\left(\begin{array}{l}
r_1 \\
s_1
\end{array}\right) \cdot(1 \pm 1)
\]
où l'on doit prendre le signe + , car l'antre signe donnerait \(E\left(\begin{array}{l}\beta \\ \beta_1\end{array}\right)=0\); done
\[
E\left(\frac{\beta}{\beta_1}\right)=2 E\left(\frac{r_1}{s_1}\right)
\]
par conséquent, en faisant
\[
E\left(\frac{r_1}{s_1}\right)=\mu_1
\]
on allra
\[
\beta=2 \beta_1, u_1+\beta_2 \text {, où } \delta \beta_2<\delta \beta_1 \text {. }
\]

Substituant cette valeur de \(\beta\) dans l'équation proposée, on a
\[
s_1\left(\beta_2^2+4 \beta_1 \beta_2 \mu_1+4 \mu_1^2 \beta_1^2\right)-2 v_1 \beta_1\left(\beta_2+2 \mu_1 \beta_1\right)-s \beta_1^2=v,
\]
ou bien
\[
s_2 \beta_1^2-2 r_2 \beta_1 \beta_2-s_1 \beta_2^2=-v
\]
où
\[
r_2=2 \mu_1 s_1-r_1, \quad s_2=s+4 r_1 \mu_1-4 s_1 \mu_1^2 .
\]

L'équation \(E\left(\frac{r_1}{s_1}\right)=\|_1\) donne
\[
r_1=\mu_1 s_1+\varepsilon_1 \text {, où } \delta \varepsilon_1<\delta s_1 .
\]

On obtient par là,
\[
\begin{aligned}
& r_2=r_1-2 \varepsilon_1, \\
& s_2=s+4 \varepsilon_1 \prime_1,
\end{aligned}
\]
done, comme il est facile de le voir,
\[
\delta r_2=\delta r_1, \quad \delta s_2<\delta r_2 .
\]

L'équation (19) a par conséquent la même forme que l'équation (20); on peut donc appliquer à celle-ci la même opération, c'est-à-dire en faisant
%116
\[
\mu_2=E\left(\frac{r_2}{s_2}\right), \quad r_2=s_2 \mu_2+\varepsilon_2, \quad \beta_1=2 \mu_1 \beta_2+\beta_3,
\]
on aura
\[
s_3 \beta_2^{2^{\circ}}-2 r_3 \rho_2 \beta_3-s_2 \beta_3^2=v
\]
où
\[
\begin{gathered}
r_3=2 \mu_2 s_2-r_2=r_2-2 \varepsilon_2, \\
s_3=s_1+4 r_2 \mu_2-4 s_2 \mu_2^2=s_1+4 \varepsilon_2, \mu_2, \\
\delta \beta_3<\delta \beta_2 .
\end{gathered}
\]

En continuant ce procédé, on obtiendra, après \(n-1\) transformations, cette équation:
\[
\begin{gathered}
s_n \beta_{n-1}^2-2 r_n \beta_{n-1} \beta_n-s_{n-1} \beta_n^2=(-1)^{n-1} v, \\
\text { où } \delta \beta_n<\delta \beta_{n-1} .
\end{gathered}
\]

Les quantités \(s_n, r_n, \beta_n\), sont déterminées par les équations suivantes:
\[
\begin{aligned}
\beta_{n-1} & =2 \prime_n \beta_n+\beta_{n+1}, \\
\mu_n & =E\left(\frac{r_n}{s_n}\right), \\
r_n & =2 u_{n-1} s_{n-1}-r_{n-1}, \\
s_n & =s_{n-2}+4 r_{n-1} \mu_{n-1}-4 s_{n-1} !_{n-1}^2 .
\end{aligned}
\]

A ces équations on peut ajouter celles-ci:
\[
\begin{aligned}
& r_n=\mu_n s_n+\varepsilon_n, \\
& r_n=r_{n-1}-2 \varepsilon_{n-1}, \\
& s_n=s_{n-2}+4 \varepsilon_{n-1}, \mu_{n-1} .
\end{aligned}
\]
\(\mathrm{Or}_1\), les nombres \(\delta \beta, \delta \beta_1, \delta \boldsymbol{\beta}_2 \ldots \delta \boldsymbol{\beta}_n\), etc. formant une série décroissante, on doit nécessairement, après un certain nombre de transformations, trouver un \(\beta_n\) égal à zéro. Soit donc
\[
\beta_m=0
\]
l'équation (21) domnera, en posant \(n=m\),
\[
s_m \beta_{m-1}^2=(-1)^{m-1} v
\]

Voila l'équation générale de condition pour la résolubilité de l'équation (19); \(s_m\) dépend des fonctions \(s, s_1, r_1\), et \(\beta_{m-1}\) doit être pris de manière ì satisfaire à la condition
%117
\[
d s_m+2 \delta \beta_{m-1}<\delta r .
\]

L'équation (22) fait voir, que pour tous les \(s, s_1\) et \(r_1\), on peut trouver une infinité de valeurs de \(v\), qui satisfont à l'équation (19).

En substituant dans l'équation proposée, an lieu de \(v\), sa valeur \((-1)^{m-1} s_m \beta_{m-1}^2\), on obtiendra
\[
s_1 \beta^2-2 r_1 \beta \beta_1-s \beta_1^2=(-1)^{m-1} s_m \beta_{m-1}^2,
\]
équation toujours résoluble. On voit aisément que \(\beta\) et \(\beta_1\) ont le facteur commun \(\beta_{m-1}\). Donc, si l'on suppose que \(\beta\) et \(\beta_1\) n'ont pas de facteur commun, \(\beta_{m-1}\) sera indépendant de \(x\). On peut donc faire \(\beta_{m-1}=1\), d'où résulte cette équation,
\[
s_1 \beta^2-2 r_1 \beta \beta_1-s \beta_1^2=(-1)^{m-1} s_m .
\]

Les fonctions \(\beta, \beta_1, \beta_2 \ldots\) sont déterminées par l'équation
\[
\beta_{n-1}=2 u_n \beta_n+\beta_{n+1}
\]
en posant successivement \(n=1,2,3 \ldots m-1\) et en remarquant que \(\boldsymbol{\beta}_m=0\). On obtient par là
\[
\begin{aligned}
& \beta_{m-2}=2 \|_{m-1} \beta_{m-1}, \\
& \beta_{m-3}=2 u_{m-2} \beta_{m-2}+\beta_{m-1}, \\
& \beta_{m-4}=2, \prime_{m-3} \beta_{m-3}+\beta_{m-2}, \\
& \text {........... } \\
& \beta_3=2 \prime_4 \beta_4+\beta_5, \\
& \beta_2=2 \mu_3 \beta_3+\beta_4 \text {, } \\
& \beta_1=2 \mu_2 \beta_2+\beta_3, \\
& \beta=2 \mu_1 \beta_1+\beta_2 \text {. } \\
&
\end{aligned}
\]

Ces équations domnent
\[
\begin{aligned}
& \frac{\beta}{\beta_1}=2 \mu_1+\frac{1}{\frac{\beta_1}{\beta_2}}, \\
& \frac{\beta_1}{\beta_2}=2_1 \prime_2+\frac{1}{\frac{\beta_2}{\beta_3}} \\
& \ldots \ldots \ldots
\end{aligned}
\]
%118
\[
\begin{aligned}
& \frac{\beta_{m-3}}{\beta_{m-2}}=2 \mu_{m-2}+\frac{1}{\frac{\beta_{m-2}}{\beta_{m-1}}}, \\
& \frac{\beta_{m-2}}{\beta_{m-1}}=2 \mu_{m-1} .
\end{aligned}
\]

On en tire par des substitutions successives:
\[
\frac{\beta}{\mu_1}=2 \mu_1+\frac{1}{2 \mu_2}+\frac{1}{2 \mu_3}+\cdot \ddots+\frac{1}{2 \mu_{m-2}}+\frac{1}{2 \mu_{m-1}} .
\]

On aura donc les valeurs de \(\beta\) et de \(\beta_1\) en transformant cette fraction continue en fraction ordinaire.
6.
En substituant dans l'équation
\[
p_1^2 N-q^2 R_1=v
\]
pour \(r\) sa valeur \((-1)^{m-1} s_m\), on aura
où
\[
p_1^2 N-q^2 R_1=(-1)^{m-1} s_m
\]
done
\[
\begin{aligned}
& q=2_1 \mu \beta+\beta_1 \\
& p_1=t_1 q+\beta
\end{aligned}
\]
\[
\frac{p_1}{q}=t_1+\frac{\beta}{q}=t_1+\frac{1}{\frac{q}{\beta}}
\]
or
\[
\frac{q}{\beta}=2,1+\frac{\beta_1}{\beta}
\]
par conséquent,
\[
\frac{p_1}{q}=t_1+\frac{1}{2 \mu}+\frac{1}{2 \mu_1}+\frac{1}{2 \mu_2}+\ddots \ddots+\frac{1}{2 u_{m-1}} .
\]

L'équation
\[
r_1^3 N-q^2 R_1=v
\]
%119
domne
\[
\begin{aligned}
& \left(\frac{p_1}{q}\right)^2=\frac{R_1}{N}+\frac{v}{q^2 N} \\
& \frac{p_1}{q}=V \frac{R_1}{N}+\frac{v}{q^2 N}
\end{aligned}
\]
done en supposant \(m\) infini
\[
\frac{p_1}{q}=\sqrt{\frac{h_1}{\Lambda}}
\]
done
\[
V_N^{R_1}=t_1+\frac{1}{2 \mu+\frac{1}{2 \mu_1}+\frac{1}{2 \mu_2}+\frac{1}{2 \mu_3}+\text { etc. }}
\]

On trouve done les valeurs de \(p_1\) et de \(q\) par la transformation de la fonction \(\sqrt{\frac{R_1}{N}}\) en fiaction continue.*)
7
Soit maintenant \(v=a\), l'on aura
\[
s_n=(-1)^{i n-1} u
\]

Donc si l'éruation
\[
p_1^2 N-q^2 R_1=a
\]
,est résoluble, il faut qu'au moins une des quantités,
\[
s, s_1, s_2 \ldots s_m \text {, etc. }
\]
soit indépendante de \(x\).
D'autre part, lorsqu'une de ces quantités est indépendante de \(x\), il est toujours possible de trouver deux fonctions entières \(\mu_1\) et \(q\) qui satisfassent à cette équation. En effet, lorsque \(s_m=0\), on aura les valeurs de \(\mu_1\) et de \(q\) en transformant la fiaction continue
*) L'équation ci-dessus n'exprime pas une égalité absolue. Elle indique seulement d'une manière abregé, comment on peut trouver les quantités \(t_1, \mu, \mu_1, \mu_2 \ldots\) Si toutefois la fraction continue a une valeur, celle-ci scra toujours egale it \(V_v^{R_1}\).
%120
\[
\frac{p_1}{q}=t_1+\frac{1}{2 \mu}+\frac{1}{2 \mu_1}+\frac{1}{2 \mu_2}+\ddots \ddots+\frac{1}{2 \mu_{m-1}}
\]
en firaction ordinaire. Les fonctions \(s, s_1\), \(s_2\), etc., sont en général, comme il est aisé de le voir, du degré \(n-1\), lorsque \(N R_1\) est du degré \(2 n\). l'équation de condition
\[
s_m=u,
\]
domnera donc \(n-1\) équations entre les coefticiens des fonctions \(N\) et \(R_1\); il n'y a donc que \(n+1\) de ces coéfticiens qu'on puisse prendre arbitrairement, les autres sont déterminés par les équations de condition.
8.
De ce qui précède, il s'ensuit qu'on trouve toutes les valeurs de \(h_1\) et de \(N\), qui rendent la différentielle \(\frac{o d x}{\sqrt{R_1 N}}\) intégrable par une expressiou de la forme
\[
\log \frac{p+q \sqrt{ } R_1 N}{p-q \sqrt{ } R_1 N}
\]
en faisant successivement les quantités \(s, s_1, s_2 \ldots s_m\), indépendantes de \(x\). Puisque \(\mu=\mu_1 N\), on a de même,
\[
\int \frac{g d x}{\sqrt{R_1 N}}=\log \frac{p_1 \sqrt{ }+q \sqrt{R_1}}{p_1 \sqrt{ }-q \sqrt{R_1}}
\]
ou bien
en sllpposant \(s_m\) égal à llle constante.
Jues quantités \(K_1, N, p_1\) et \(q\) étant ainsi déterminées, on trouve 0 .
%121
par l'équation (5). Cette équation domne, en mettant \(p_1 N\) au lieu de \(p\), et \(\varrho\) au lieu de \(\frac{M}{N^{-}}\),
\[
\rho=\left(p_1 \frac{d N}{d x}+2 N \frac{d p_1}{d x}\right): q
\]

Il s'ensuit que
\[
\delta \varrho=\delta p_1+\delta N-1-\delta q=\delta p-\delta q-1 .
\]

Or on a vu que \(\delta p-\delta q=n\), donc
\[
\delta \varrho=n-1 .
\]

Donc si la fonction \(R\) ou \(R_1 N\) est du degré \(2 n\), la fonction \(\varrho\) sera nécessairement du degré \(n-1\).
9.
Nous avons vu plus haut que
\[
R=R_1 N
\]
mais on peut toujours supposer que la fonction \(N\) est constante. En effet on a
\[
\int \frac{\varrho d x}{\sqrt{R_1 N}}=\log \frac{p_1 \sqrt{N}+q \sqrt{R_1}}{p_1 \sqrt{N}-q \sqrt{R_1}}
\]
et par conséquent,
\[
\int \frac{\varrho d x}{\sqrt{R_1 N}}=\frac{1}{2} \log \left(\frac{p_1 \sqrt{N}+q \sqrt{R_1}}{p_1 \sqrt{ }-q \sqrt{R_1}}\right)^2=\frac{1}{2} \log \frac{p_1^2 N+q^2 R_1+2 p_1 q \sqrt{R_1 N}}{p_1^2 N+q^2 R_1-2 p_1 q \sqrt{R_1 N}}
\]
ou, en faisant \(p_1^2 N+q^2 R_1=p^{\prime}\) et \(2 p_1 q=q^{\prime}\),
\[
\int \frac{2 \varrho d x}{\sqrt{R}}=\log \frac{p^{\prime}+q^{\prime} \sqrt{R}}{p^{\prime}-q^{\prime} \sqrt{R}} .
\]

Il est clair que \(p^{\prime}\), et \(q^{\prime}\) n'ont pas de facteur commin; on peut donc toujours poser
\[
N=1 \text {. }
\]

Au lieu de l'équation \(p_1^2 N-q_2 R_1=1\), on a alors celle-ci,
\[
p^{\prime 2}-q^{\prime 2} R=1
\]
%122
dont on obtient la solution en faisant \(N=1\) et mettant \(R\) an lieu de \(R_1\). Ayant \(N=1\), on voit aisément que
\[
t=R ; t_1=r ; R=r^2+s
\]
done
\[
\begin{aligned}
& \frac{p^{\prime}}{q^{\prime}}=r+\frac{1}{2 \mu}+\frac{1}{2 \mu_1}+\frac{1}{2 \mu_2}+\cdot \ddots+\frac{1}{2 \mu_{m-1}}, \\
& R=r^2+s, \\
& " \prime=E\left(\frac{r}{s}\right), \quad r=s_{\imath} \boldsymbol{u}+\varepsilon, \\
& r_1=r-2 \varepsilon, \quad s_1=1+4 \varepsilon \prime \prime, \\
& \mu_1=E\left(\frac{r_1}{s_1}\right), \quad r_1=s_1 \mu_1+\varepsilon_1, \\
& r_2=r_1-2 \varepsilon_1, s_2=s+4 \varepsilon_1, \prime_1 \text {, } \\
& \ldots \ldots \ldots \ldots \ldots \\
& \mu_n=E\left(\begin{array}{l}
r_n \\
s_n
\end{array}\right), \quad \cdot r_n=\prime_n s_n+\varepsilon_n, . \\
& r_{n+1}=r_n-2 \varepsilon_n, s_{n+1}=s_{n-1}+4 \varepsilon_n \prime_n \text {, } \\
& \ldots \ldots \ldots \ldots \ldots \\
& \mu_{m-1}=E\left(\frac{r_{m-1}}{s_{m-1}}\right), \quad r_{m-1}=\mu_{m-1} s_{m-1}+\varepsilon_{m-1}, \\
& r_m=r_{m-1}-2 \varepsilon_{m-1}, s_m=s_{m-2}+4 \varepsilon_{m-1} \mu_{m-1}=a \text {. } \\
&
\end{aligned}
\]

Ayant déterminé les quantités \(R, v,\|,\|_1 \ldots, \|_{m-1}\) par ces équations, on aura
\[
\begin{gathered}
\int \frac{\varrho d x}{\sqrt{R}}=\log \frac{p^{\prime}+q^{\prime} \sqrt{R}}{p^{\prime}-q^{\prime} \sqrt{R}} \\
\varrho=\frac{2}{q^{\prime}} \frac{d p^{\prime}}{d x},
\end{gathered}
\]
ce qui résulte de l'équation (5) en y posant \(N=1\).
%123
10.

On peut donner à l'expression \(\log \frac{p_1 \sqrt{ }+q \sqrt{R_1}}{p_1 \sqrt{\Lambda}-q \sqrt{R_1}}\) une forme plus simple, savoir,
\[
\begin{aligned}
\log \frac{p_1 \sqrt{N}+q \sqrt{R_1}}{p_1 \sqrt{\Lambda}-q \sqrt{R_1}}=\log \frac{t_1 \sqrt{\Lambda}+\sqrt{R_1}}{t_1 \sqrt{N}-\sqrt{R_1}} \\
+\log \frac{r_1+\sqrt{R}}{r_1-\sqrt{R}}+\log \frac{r_2+\sqrt{R}}{r_2-\sqrt{R}}+\cdots+\log \frac{r_m+\sqrt{R}}{r_m-\sqrt{R}}
\end{aligned}
\]
ce qu'on peut démontrer comme il suit. Soit
\[
\frac{\alpha_m}{\beta_m}=t_1+\frac{1}{2 \mu}+\frac{1}{2 \mu_1}+\cdot \ddots+\frac{1}{2 \mu_{m-1}},
\]
on a par la théorie des firactions continues,
(a)
(b)
\[
\begin{aligned}
& \alpha_m=\alpha_{m-2}+2 \prime_{m-1} \alpha_{m-1}, \\
& \beta_m=\beta_{m-2}+2 \prime_{m-1} \beta_{m-1} .
\end{aligned}
\]

De ces équations on tire, en éliminant " \({ }_{m-1}\),
donc
\[
\alpha_m \beta_{m-1}-\beta_m \alpha_{m-1}=-\left(\alpha_{m-1} \beta_{m-2}-\beta_{m-1} \alpha_{m-2}\right),
\]
\[
\alpha_m \beta_{m-1}-\beta_m \alpha_{m-1}=(-1)^{m-1}
\]
ce qui est commu.
Les deux équations (a) et (b) donnent encore
\[
\begin{aligned}
& \alpha_m^2=\alpha_{m-2}^2+4 \alpha_{m-1} \alpha_{m-2} \prime_{m-1}+4 \prime_{m-1}^2 \alpha_{m-1}^2, \\
& \beta_m^2=\beta_{m-2}^2+4 \beta_{m-1} \beta_{m-2} \prime_{m-1}+4 u_{m-1}^2 \beta_{m-1}^2 .
\end{aligned}
\]

Il s'ensuit que
\[
\begin{gathered}
\alpha_m^2 N-\beta_m^2 R_1=\alpha_{m-2}^2 N-\beta_{m-2}^2 R_1 \\
+4 \mu_{m-1}\left(\alpha_{m-1} \alpha_{m-2} N-\beta_{m-1} \beta_{m-2} R_1\right)+4 \mu_{m-1}^2\left(\alpha_{m-1}^2 N-\beta_{m-1}^2 R_1\right)
\end{gathered}
\]
()r on a
\[
\begin{gathered}
\alpha_m^2 N-\beta_m^2 R_1=(-1)^{m-1} s_m \\
\alpha_{m-1}^2 N-\beta_{m-1}^2 R_1=(-1)^{m-2} s_{m-1} \\
\alpha_{m-2}^2 N-\beta_{m-2}^2 R_1=(-1)^{m-3} s_{m-2}
\end{gathered}
\]
%124
donc, en substituant,
\[
s_m=s_{m-2}+4(-1)^{m-1} \mu_{m-1}\left(\alpha_{m-1} \alpha_{m-2} N-\beta_{m-1} \beta_{m-2} R_1\right)-4 \mu_{m-1}^2 s_{m-1} \cdot
\]

Mais, d'après ce qui précède, on a
done
\[
s_m=s_{m-2}+4 \mu_{m-1} r_{m-1}-4 s_{m-1} \mu_{m-1}^2,
\]
\[
r_{m-1}=(-1)^{m-1}\left(\alpha_{m-1} \alpha_{m-2} N-\beta_{m-1} \beta_{m-2} R_1\right)
\]

Soit
\[
z_m^{\prime}=\alpha_m \sqrt{N}+\beta_m \sqrt{R_1}, \quad \text { et } z_m^{\prime}=\alpha_m \sqrt{N}-\beta_m \sqrt{R_1},
\]
on aura en multipliant,
\[
z_m z_{m-1}^{\prime}=\alpha_m \alpha_{m-1} N-\beta_m \beta_{m-1} R_1-\left(\alpha_m \beta_{m-1}-\alpha_{m-1} \beta_m\right) \sqrt{N R_1}
\]
mais on vient de voir qu'on a
\[
\alpha_m \beta_{m-1}-\alpha_{m-1} \beta_m=(-1)^{m-1}, \quad \alpha_m \alpha_{m-1} N-\beta_m \beta_{m-1} R_1=(-1)^m r_m
\]
on tire de la
\[
z_m z_{m-1}^{\prime}=(-1)^m\left(r_m+\sqrt{R}\right)
\]
et de la même manière,
\[
z_m{ }^{\prime} z_{m-1}=(-1)^m\left(r_m-\sqrt{K}\right)
\]
on en tire en divisant,
\[
\frac{z_m}{z_m^{\prime}} \frac{z_{m-1}^{\prime}}{z_{m-1}}=\frac{r_m+\sqrt{R}}{r_m-\sqrt{R}}
\]
ou, en multipliant par \(\frac{z_{m-1}}{z_{m-1}^{\prime}}\),
\[
\frac{z_m}{z_m^{\prime}}=\frac{r_m+\sqrt{R}}{r_m-\sqrt{R}} \frac{z_{m-1}}{z_{m-1}^{\prime}}
\]

En faisant successivement \(m=1,2,3 \ldots m\), on aura,
\[
\begin{gathered}
\frac{z_1}{z_1^{\prime}}=\frac{r_1+\sqrt{R}}{r_1-\sqrt{R}} \frac{z_0}{z_0^{\prime}} \\
\frac{z_2}{z_2^{\prime}}=\frac{r_2+\sqrt{R}}{r_2-\sqrt{R}} \frac{z_1}{z_1^{\prime}} \\
\ldots \ldots \ldots \ldots
\end{gathered}
\]
%125
\[
\frac{z_m}{z_m^{\prime}}=\frac{r_m+\sqrt{R}}{r_m-\sqrt{R}} \frac{z_{m-1}}{z_{m-1}^{\prime}}
\]
d'où l'on tire,
\[
\frac{z_m}{z_{m^{\prime}}}=\frac{z_0}{z_0{ }^{\prime}} \frac{r_1+\sqrt{R}}{r_1-\sqrt{R}} \frac{r_2+\sqrt{R}}{r_2-\sqrt{R}} \frac{r_3+\sqrt{R}}{r_3-\sqrt{R}} \cdots \frac{r_m+\sqrt{R}}{r_m-\sqrt{R}} .
\]

Or on a
\[
\begin{aligned}
& z_0=\alpha_0 \sqrt{N}+\beta_0 \sqrt{R_1}=t_1 \sqrt{N}+\sqrt{R_1} \\
& z_0^{\prime}=\alpha_0 \sqrt{N}-\beta_0 \sqrt{R_1}=t_1 \sqrt{N}-\sqrt{R_1}
\end{aligned}
\]
et
\[
\frac{z_m}{z_m{ }^{\prime}}=\frac{\alpha_m \sqrt{N}+\beta_m \sqrt{R_1}}{\alpha_m \sqrt{N}-\beta_m \sqrt{R_1}}
\]
done
\[
\frac{\alpha_m \sqrt{N}+\beta_m \sqrt{R_1}}{\alpha_m \sqrt{N}-\beta_m \sqrt{R_1}}=\frac{t_1 \sqrt{N}+\sqrt{R_1}}{t_1 \sqrt{N}-\sqrt{R_1}} \cdot \frac{r_1+\sqrt{R}}{r_1-\sqrt{R}} \cdot \frac{r_2+\sqrt{R}}{r_2-\sqrt{R}} \cdots \frac{r_m+\sqrt{R}}{r_m-\sqrt{R}},
\]
et en prenant les logarithmes
\[
\begin{gathered}
\log \frac{\alpha_m \sqrt{N}+\beta_m \sqrt{R_1}}{\alpha_m \sqrt{N}-\beta_m \sqrt{R_1}} \\
=\log \frac{t_1 \sqrt{N}+\sqrt{R_1}}{t_1 \sqrt{N}-\sqrt{R_1}}+\log \frac{r_1+\sqrt{R}}{r_1-\sqrt{R}}+\log \frac{r_2+\sqrt{R}}{r_2-\sqrt{R}}+\cdots+\log \frac{r_m+\sqrt{R}}{r_m-\sqrt{R}},
\end{gathered}
\]
ce qu’il fallait démontrer.
11.
En différentiant l'expression \(z=\log \frac{\alpha_m \sqrt{N}+\beta_m \sqrt{R_1}}{\alpha_m \sqrt{N}-\beta_m \sqrt{R_1}}\), on aura, après les réductions convenables,
\[
d z=\frac{2\left(\alpha_m d \beta_m-\beta_m d \alpha_m\right) N R_1-\alpha_m \beta_m\left(R_1 d N-N d R_1\right)}{\left(\alpha_m^2 N-\beta_m^2 R_1\right) \sqrt{N R_1}}
\]

Or on a
\[
\alpha_m^2 N-\beta_m^2 R_1=(-1)^{m-1} s_m
\]
done en faisant
\[
(-1)^{m-1} \varrho_m=2\left(\alpha_m \frac{d \beta_m}{d x}-\beta_m \frac{d \alpha_m}{d x}\right) N R_1-\alpha_m \beta_m\left(\frac{R_1 d N-N d R_1}{d x}\right)
\]
%126
on alura
\[
d z=\frac{\varrho_m}{s_m} \frac{d x}{\sqrt{N R_1}},
\]
et
\[
z=\int \frac{\varrho_m}{s_m} \frac{d x}{\sqrt{ } N K_1}
\]
done
\[
\int \frac{\varrho_m}{s_m} \frac{d x^x}{\sqrt{N R_1}}=\log \frac{\alpha_m \sqrt{\Lambda}+\beta_m \sqrt{R_1}}{\alpha_m \sqrt{ } \Lambda-\beta_m \sqrt{ } R_1}
\]
on bieu
\[
\int \frac{\varrho_m}{s_m} \frac{d x}{\sqrt{ } R}=\log \frac{t_1 \sqrt{N}+\sqrt{R_1}}{t_1 \sqrt{N}-\sqrt{R_1}}+\log \frac{r_1+\sqrt{R}}{r_1-\sqrt{ } R}+\cdots+\log \frac{r_m+\sqrt{R}}{r_m-\sqrt{ } R} .
\]

Dans cette expression \(\varepsilon_n\) est tout au plus du degré \((n-1)\) et \(\rho_m\) est nécessairement du degré \(\left(n-1+\delta s_m\right)\), ce dont on peut se convaincre de la manière suivante. En différentiant l'équation
\[
\alpha_m^2 N-\beta_m^2 R_1=(-1)^{m-1} s_m,
\]
on trouvera la suivante
\[
2 \alpha_m d \alpha_m N+\alpha_m^2 d N-2 \beta_m d \beta_m \cdot R_1-\beta_m^2 d R_1=(-1)^{m-1} d s_m,
\]
ou, en multipliant par \(\alpha_m N\),
\[
\alpha_m^2 N\left(2 N d \alpha_m+\alpha_m d N\right)-2 \alpha_m \beta_m d \beta_m N R_1-\beta_m^2 \alpha_m N d R_1=(-1)^{m-1} \alpha_m N d s_m .
\]

Mettant ici à la place de \(\alpha_m^2 N\), sa valeur tirée de l'équation (29), on aura
\[
\begin{aligned}
(-1)^{m-1} s_m\left(2 N d \alpha_m+\alpha_m d N\right)+\beta_m[ & 2 N R_1 \beta_m d \alpha_m+\alpha_m \beta_m R_1 d N-2 \alpha_m d \beta_m N R_1 \\
& \left.-\beta_m \alpha_m N d R_1\right]=(-1)^{m-1} \alpha_m N d s_m,
\end{aligned}
\]
c'est-à-dire,
\[
\begin{array}{r}
\beta_m\left[2\left(\alpha_m d \beta_m-\beta_m d \alpha_m\right) N K_1-\alpha_m \beta_m\left(K_1 d N-N d R_1\right)\right] \\
=(-1)^{m-1}\left[s_m\left(2 N d \alpha_m+\alpha_m d N\right)-\alpha_m N d s_m\right] .
\end{array}
\]

En vertu de l'équation (27) le premier membre de cette équation est égal à \(\beta_m(-1)^{m-1} \Theta_m d x\); donc on aura
\[
\beta_m \varrho_m=s_m\left(\frac{2 N d \alpha_m}{d x}+\frac{\alpha_m d N}{d x}\right)-\alpha_m \frac{N d s_m}{d x} .
\]
%127
Puisque \(\delta s_m<n\), le second membre de cette équation sera nécessairement du degré \(\left(\delta s_m+\delta N+\delta \alpha_m-1\right)\), comme il est facile de le voir; donc
\[
\delta \omega_m=\delta s_m+\delta N+\delta \alpha_m-\delta \beta_m-1
\]

Or de l'équation (29) il suit que
done
\[
2 \delta \alpha_m+\delta N=2 \delta \beta_m+\delta R_1
\]
\[
\delta \varrho_m=\delta s_m+\frac{\delta N+\delta R_1}{2}-1
\]
ou, puisque \(\delta N+\delta R_1=2 n\),
\[
\delta \varrho_m=\delta s_m+n-1
\]
c'est-à-dire que \(\varrho_m\) est nécessairement du degré \(\left(\delta s_m+n-1\right)\). Il suit de là que la fonction \(\frac{\varrho_m}{s_m}\) est du degré \((n-1)\).
Faisant dans la formule \((28) N=1\), on aura \(t_1=r\), et par conséquent
\[
\int \frac{\varrho_m d x}{s_m \sqrt{R}}=\log \frac{r+\sqrt{R}}{r-\sqrt{R}}+\log \frac{r_1+\sqrt{R}}{r_1-\sqrt{R}}+\cdots+\log \frac{r_m+\sqrt{R}}{r_m-\sqrt{R}},
\]
où, suivant l'équation (30),
\[
\beta_m \varrho_m=2 s_m \frac{d \alpha_m}{d x}-\alpha_m \frac{d s_m}{d x} .
\]

L'équation (28) dome, en faisant \(s_m=a\),
\[
\begin{gathered}
\int \frac{\varrho_m d x}{a \sqrt{R}}=\log \frac{t_1 \sqrt{N}+\sqrt{R_1}}{t_1 \sqrt{N}-\sqrt{ } R_1}+\log \frac{r_1+\sqrt{R}}{r_1-\sqrt{R}}+\cdots+\log \frac{r_m+\sqrt{R}}{r_m-\sqrt{R}} \\
\text { où } \beta_m \varrho_m=a\left(2 N \frac{d \boldsymbol{c}_m}{d x}+\alpha_m \frac{d N}{d x}\right)
\end{gathered}
\]
et lorsque \(N=1\),
\[
\begin{gathered}
\int \frac{\varrho_m d x}{\sqrt{R}}=\log \frac{r+\sqrt{R}}{r-\sqrt{R}}+\log \frac{r_1+\sqrt{R}}{r_1-\sqrt{R}}+\cdots+\log \frac{r_m+\sqrt{R}}{r_m-\sqrt{R}}, \\
\text { où } \varrho_m=\frac{2}{\beta_m} \frac{d a_n}{d x} .
\end{gathered}
\]

D'après ce qui précède, cette formule a la même généralité que la for-
%128
mule (32), et donne toutes les intégrales de la forme \(\int \frac{\varrho d x}{\sqrt{R}}\), où \(\varrho\) et \(R\) sont des fonctions entières, qui sont exprimables par une fonction logarithmique de la forme \(\log \frac{p+q \sqrt{R}}{p-q \sqrt{R}}\).
12.
Dans l'équation (28) la fonction \(\frac{\varrho_m}{s_m}\) est donnée par l'équation (30). Mais on peut exprimer cette fonction d'une manière plus commode à l'aide des quantités \(t_1, r_1, r_2\), etc. \(\mu, \mu_1, \mu_2\), etc. En effet, soit
\[
z_m=\log \frac{r_m+\sqrt{R}}{r_m-\sqrt{R}},
\]
on aura en différentiant,
\[
d z_m=\frac{d r_m+\frac{1}{2} \frac{d R}{\sqrt{R}}}{r_m+\sqrt{R}}-\frac{d r_m-\frac{1}{2} \frac{d R}{\sqrt{R}}}{r_m-\sqrt{R}}
\]
ou en réduisant,
\[
d z_m=\frac{r_m d R-2 R d r_m}{r_m^2-R} \frac{1}{\sqrt{R}} .
\]

Or nous avons trouvé plus haut
\[
s_m=s_{m-2}+4 u_{n-1} r_{m-1}-4 s_{n-1} u_{m-1}^2,
\]
done en multipliant par \(s_{m-1}\),
\[
s_m s_{m-1}=s_{m-1} s_{m-2}+4 \mu_{n-1} s_{m-1} r_{m-1}-4 s_{m-1}^2 \mu_{m-1}^2,
\]
c'est-à-dire,
\[
s_m s_{m-1}=s_{m-1} s_{m-2}+r_{m-1}^2-\left(2 s_{m-1} \prime_{m-1}-r_{m-1}\right)^2
\]

Mais on a
\[
r_n=2 s_{m-1} \prime_{m-1}-r_{m-1},
\]
donc en substituant cette quantité,
\[
s_m s_{m-1}=s_{m-1} s_{m-2}+r_{m-1}^2-r_m^2,
\]
d'où l'on déduit par transposition,
\[
r_m^8+s_m s_{m-1}=r_{m-1}^8+s_{m-1} s_{m-8} .
\]
%129
Il suit de cette équation que \(r_m^{\cdot 2}+s_m s_{m-1}\) a la même valeur pour tous les \(m\) et par conséquent que
\[
r_m^2+s_m s_{m-1}=r_1^2+s s_1
\]
or nous avons vu plus haut que \(r_1^2+s s_1=R\), et par suite,
\[
R=r_m^2+s_m s_{m-1} \text {. }
\]

Substituant cette expression pour \(R\) dans l'équation \(\left(33^{\prime}\right)\), on aura après les réductions convenables
\[
d z_m=\frac{2 d v_m}{\sqrt{R}}-\frac{d s_m}{s_m} \frac{r_m}{\sqrt{R}}-\frac{d s_{m-1}}{s_{m-1}} \frac{r_m}{\sqrt{R}}
\]
mais puisque \(r_m=2 s_{m-1} \|_{m-1}-r_{m-1}\), le terme \(-\frac{d s_{m-1}}{s_{m-1}} \frac{r_m}{\sqrt{R}}\) se transforme en \(-2 \mu_{m-1} \frac{d s_{m-1}}{\sqrt{R}}+\frac{d s_{m-1}}{s_{m-1}} \frac{r_{m-1}}{\sqrt{R}}\). On obtient done
\[
d z_m=\left(2 d r_m-2 u_{m-1} d s_{m-1}\right) \frac{1}{\sqrt{R}}-\frac{d s_m}{s_m} \frac{r_m}{\sqrt{R}}+\frac{d s_{m-1}}{s_{m-1}} \frac{r_{m-1}}{\sqrt{R}},
\]
et en intégrant
\[
\int \frac{d s_m}{s_m} \frac{r_m}{\sqrt{R}}=-z_m+\int\left(2 d r_m-2 \mu_{m-1} d s_{m-1}\right) \frac{1}{\sqrt{R}}+\int \frac{d s_{m-1}}{s_{m-1}} \frac{r_{m-1}}{\sqrt{R}} .
\]

Cette expression est, comme on le voit, ume formule de réduction pour les intégrales de la forme \(\int \frac{d s_m}{s_m} \frac{r_m}{\sqrt{R}}\). Car elle donne l'intégrale \(\int \frac{d s_m}{s_m} \frac{r_m}{\sqrt{R}}\) par une autre intégrale de la même forme et par une intégrale de la forme \(\int \frac{t d x}{\sqrt{R}}\) où \(t\) est une fonction entière. Mettant dans cette formule à la place de \(m\) sncessivement \(m, m-1, m-2 \ldots 3,2,1\), on obtiendra \(m\) équations semblables, dont la somme dumera la formule suivante (en remarquant que \(r_0=2 s ı-r_1=t_1 N\) en vertu de l'équation \(r_1+t_1 N=2 s ı\) )
\[
\begin{gathered}
\int \frac{d s_m}{s_m} \sqrt{n}=-\left(z_1+z_2+z_3+\cdots+z_m\right)+\int \frac{d s}{s} \frac{t_1 N}{\sqrt{R}} \\
+\int 2\left(d r_1+d r_2+\cdots+d r_m+\mu d s-\mu_1 d s_1-\cdots-\mu_{m-1} d s_{m-1}\right) \frac{1}{\sqrt{R}} .
\end{gathered}
\]
(On pent encore réduires l'intégrale \(\int_s^{d i} \sqrt{N}\). Lin différentiant l'expression
%130
\[
z=\log \frac{t_1 \sqrt{N}+\sqrt{R_1}}{t_1 \sqrt{N}-\sqrt{R_1}}
\]
on aura après quelques réductions,
()r on a
\[
d z=\frac{-2 d t_1 N R_1-t_1\left(R_1 d N-N d R_1\right)}{\left(t_1^2 N-R_1\right) \sqrt{R}}
\]
\[
R_1=t_1^2 N+s
\]
substituant donc cette valeur de \(R_1\) dans l'équation ci-dessus, on trouve
\[
d z=\left(2 N d t_1+t_1 d N\right) \frac{1}{\sqrt{R}}-\frac{d s}{8} \frac{t_1 N}{\sqrt{R}}
\]
ronc en intégrant
\[
\int \frac{d_s}{s} \frac{t_1 N}{\sqrt{R}}=-z+\int\left(2 N d t_1+t_1 d N\right) \frac{1}{\sqrt{R}} .
\]

L'expression de \(\int \frac{d s_m}{s_m} \frac{r_m}{\sqrt{R}}\) se transforme par là en celle-ci,
\[
\begin{gathered}
\int \frac{d s_{m b}}{s_m} \frac{r_m}{\sqrt{R}}=-\left(z+z_1+z_2+\cdots+z_m\right) \\
+\int \frac{2}{\sqrt{R}}\left(N d t_1+\frac{1}{2} t_1 d N+d r_1+\cdots+d r_m-\mu d s-\mu_1 d s_1-\cdots-\mu_{m-1} d s_{m-1}\right),
\end{gathered}
\]
o11, en mettant à la place des quantités \(z, z_1, z_2 \ldots\) leurs valeurs,
\[
\begin{aligned}
& =\int \frac{2}{\sqrt{R}}\left(N d t_1+\frac{1}{2} t_1 d N+d_1+\cdots+d_{r_n}+\mu d s-\mu_1 d s_1-\cdots-\mu_{m-1} d s_{m-1}\right) \\
& -\log \frac{t_1 \sqrt{N}+\sqrt{R_1}}{t_1 \sqrt{N}-\sqrt{R_1}}-\log \frac{r_1+\sqrt{k}}{r_1-\sqrt{k}} \log \frac{r_9+\sqrt{R}}{r_2-\sqrt{R}}-\cdots-\log \frac{r_m+\sqrt{R}}{r_m-\sqrt{R}} . \\
&
\end{aligned}
\]

Cette formule est entièrement la même que la formule (28); elle donne
\[
\begin{gathered}
\frac{\varrho_m}{s_m} d x=-\frac{r_m d s_n}{s_m} \\
+2\left(N d t_1+\frac{1}{2} t_1 d N+d l_1+\cdots+d_m-\mu d s-\cdots-\mu_{m-1} d s_{m-1}\right) .
\end{gathered}
\]

Mais l'expression ci-dessus dispense du calcul res fonctions \(\|_m\) et \(\beta_m\).
%131
Si maintenant \(s_m\) est indépendant de \(x\), l'intégrale \(\int \frac{d s_m}{s_m} \frac{r_m}{\sqrt{R}}\) disparaît et l'on obtient la formule suivante:
\[
\text { 38) } \begin{aligned}
& \int \frac{2}{\sqrt{R}}\left(\frac{1}{2} t_1 d N+N d t_1+d r_1+\cdots+d r_m-\| d s-\cdots-\mu_{m-1} d s_{m-1}\right) \\
= & \log \frac{t_1 \sqrt{ } N+\sqrt{ } R_1}{t_1 \sqrt{N}-\sqrt{R_1}}+\log \frac{r_1+\sqrt{R}}{r_1-\sqrt{R}}+\log \frac{r_2+\sqrt{R}}{r_2-\sqrt{R}}+\cdots+\log \frac{r_n+\sqrt{R}}{r_m-\sqrt{R}} .
\end{aligned}
\]

Si dans l'expression (36) on fait \(N=1\), on a \(t_1=r\), et par suite
\[
\begin{array}{r}
\int \frac{d s_m}{s_m} \frac{r_m}{\sqrt{R}=} \frac{2}{\sqrt{R}}\left(d r+d r_1+\cdots+d r_m-\mu d s-\cdots-\mu_{m-1} d s_{m-1}\right) \\
-\log \frac{r+\sqrt{R}}{r-\sqrt{R}}-\log \frac{r_1+\sqrt{R}}{r_1-\sqrt{R}}-\cdots-\log \frac{r_m+\sqrt{R}}{r_m-\sqrt{R}}
\end{array}
\]
et si l'on fait \(s_n=a\) :
\[
\begin{gathered}
\int \frac{2}{\sqrt{\boldsymbol{R}}}\left(d r+d r_1+\cdots+d r_m-\mu d s-\mu_1 d s_1-\cdots-\mu_{m-1} d s_{m-1}\right) \\
=\log \frac{r+\sqrt{R}}{r-\sqrt{R}}+\log \frac{r_1+\sqrt{R}}{r_1-\sqrt{R}}+\cdots+\log \frac{r_m+\sqrt{R}}{r_m-\sqrt{R}}
\end{gathered}
\]

En vertu de ce qui précède, cette formule a la même généralité que (38); elle dome par conséquent toutes les intégrales de la forme \(\int \frac{t d x}{\sqrt{R}}\), où \(t\) est une fonction entière, qui peuvent être exprimées par une fonction de la forme \(\log \frac{p+q \sqrt{R}}{p-q \sqrt{R}}\).
13.
Nous avons vil ci-dessus que
\[
\sqrt{\frac{k_1}{N}}=t_1+\frac{1}{2 \mu}+\frac{1}{2 \mu_1}+\frac{1}{2 \mu_n}+\frac{1}{2 \mu_3}+:
\]
donc, lorsque \(N=1\),
%132
\[
\sqrt{R}=r+\frac{1}{2 \mu}+\frac{1}{2 \mu_1}+\frac{1}{2 \mu_2}+\frac{1}{2 \mu_3}+\cdots
\]
Mais lorsqu'une des quantités \(s, s_1, s_2 \ldots\) est indépendante de \(x\), la fraction continue devient périodique. On peut le démontrer comme il suit.
On a.
\[
r_{m+1}^2+s_m s_{m+1}=R=r^2+s
\]
donc, lorsque \(s_m=a\),
\[
r_{m+1}^2-r^2=s-a s_{m+1}=\left(r_{m+1}+r\right)\left(r_{m+1}-r\right) .
\]
\(O_1 \cdot \delta_{m+1}=\delta r, \delta s<\delta r, \quad \delta_{m+1}<\delta r\), donc cette équation ne peut subsister a moins qu'on n'ait en même temps,
\[
r_{m+1}=r, \quad s_{m+1}=\frac{s}{a} .
\]

Or, puisque \(\boldsymbol{\mu}_{m+1}=E\left(\begin{array}{c}r_{m+1} \\ s_{m+1}\end{array}\right)\) on a de même
\[
\mu_{m+1}=a E\left(\frac{r}{s}\right)
\]
mais \(E\left(\frac{r}{s}\right)=\|\), donc
\[
\mu_{m+1}=r_i \prime
\]

On a de plus
\[
s_{m+2}=s_m+4 \mu_{m+1} r_{m+1}-4 \mu_{m+1}^2 s_{m+1}
\]
donc ayant \(s_m=a, r_{m+1}=r, \mu_{m+1}=a_i\), , on en conclut
\[
s_{n+2}=n\left(1+4 \mu r-4 \mu^2 s\right)
\]
or \(s_1=1+4 \mu \nu-4 \mu^2 s\), donc
\[
s_{n+2}=u s_1
\]

On a de nême
\[
r_{m+2}=2 \prime \prime \prime+1 s_{m+1}-r_{m+1}=2,1 s-r
\]
donc, puisque \(r_1=2 u s-r\)
%133
d'où l'on tire
\[
\mu_{m+2}=E\left(\frac{r_{m+2}}{s_{m+2}}\right)=\frac{1}{n} E\left(\frac{r_1}{s_1}\right)
\]
done
\[
\mu_{n+2}=\frac{\mu_1}{a} .
\]

Fu continuant ce procédé on voit sans peine qu’on aura en général
\[
\left\{\begin{array}{l}
r_{m+n}=r_{n-1}, \quad s_{m+n}=r^{+1} s_{n-1}, \\
\prime_{m+n}=a \mp 1, \prime_{n-1} .
\end{array}\right.
\]

Le signe supérieur doit être pris lorsque \(n\) est pair et le signe inférieur dans le eas contraire.
Mettant dans l'équation
\[
r_m^2+s_{m-1} s_m=r^2+s
\]
\(a\) à la place de \(s_n\), on amra
\[
\left(r_m-r\right)\left(r_m+r\right)=s-r s_{m-1} .
\]

Il s'ensuit que
\[
r_m=r, \quad s_{m-1}=\frac{s}{r} .
\]
(O) on a \(\mu_m=E\left(\frac{r_m}{s_m}\right)\), donc
\[
\mu_m=\frac{1}{a} E r
\]
c'est-à-dire
\[
\mu_m=\frac{1}{\prime \prime} r
\]

On a de plus
\[
r_m+r_{m-1}=2 \cdot s_{m-1} \prime_{m-1},
\]
c'est-à-dire, puisque \(r_m=r, s_{m-1}=\frac{s}{a}\),
\[
r+r_{n-1}=\frac{2 s}{a} \mu_{n-1} .
\]

Mais \(r+r_1=2 s ! \prime\), donce
\[
r_{m-1}-r_1=\frac{2 s}{a}\left(\prime_{m-1}-r_{11}\right) .
\]
%134
(O) a
\[
r_{m-1}^2+s_{m-1} s_{m-2}=r_1^2+s s_1,
\]
c'est-à-dire, puisque \(s_{m-1}=\frac{s}{a}\),
\[
\left(r_{m-1}+r_1\right)\left(r_{m-1}-r_1\right)=\frac{s}{a}\left(a s_1-s_{m-2}\right) .
\]

Or nous avous vu que
\[
r_{m-1}-r_1=\frac{2 s}{n}\left(\mu_{m-1}-a, \prime\right),
\]
donc en substituant,
\[
2\left(r_{m-1}+r_1\right)\left(\prime_{m-1}-a_1 \prime\right)=a s_1-s_{m-2} .
\]
('ette équation dome, en remarquant que \(\delta^{\prime}\left(r_{m-1}+r_1\right)>\delta\left(a s_1-s_{m-2}\right)\),
\[
\prime_{m-1}=a_1 \prime, s_{m-2}=a_1
\]
et par conséquent.
\[
r_{m-1}=r_1 \text {. }
\]

P’ar un procédé semblable on trouvera aisément,
\[
r_{m-2}=r_{2,}, \quad s_{m-3}=\frac{1}{a} s_2, \quad \mu_{m-2}=\frac{\mu_1}{a},
\]
et en geénéral
\[
\left\{\begin{array}{l}
r_{m-n}=r_n, \quad s_{m-n}=a^{ \pm 1} s_{n-1}, \\
\prime_{m-n}=a^{\mp 1},_{n-1} .
\end{array}\right.
\]
14.
A. Soit \(m\) un nombre pair, \(2 k\).

Dans ce cas on voit aisément, en vertu des équations (41) et (42), que les quantités \(r, r_1^{-}, r_2 \ldots s, s_1, s_2 \ldots, \mu_1, \mu_2 \ldots\) forment les séries suivantes:
%135
B. Soit \(m\) un nombre impair, \(2 k-1\).

Dans ce cas l'éruatiou
\[
s_{m-n}=a^{ \pm 1} s_{n-1} \text { oll } \quad s_{2 k-n-1}=a^{ \pm 1} s_{n-1}
\]
domie, poir \(n=k\),
\[
s_{k-1}=a^{ \pm 1} s_{k-1}, \text { donc } \quad \iota=1 \text {. }
\]

Les quantités \(r, r_1\) etc. \(s, s_1\) etc.,\(\|,\|_1\) etc. forment les séries suivantes:
\[
\begin{array}{ccccccccccccc}
0 & 1 & \ldots & k-2 & k-1 & k & k+1 & \ldots & 2 k-2 & 2 k-1 & 2 k & 2 k+1 & \text { etc. } \\
r & r_1 & \ldots & r_{k-2} & r_{k-1} & r_{k-1} & r_{k-2} & \ldots & r_1 & r & r & r_1 & \text { etc. } \\
s & s_1 & \ldots & s_{k-2} & s_{k-1} & s_{k-2} & s_{k-3} & \ldots & s & 1 & s & s_1 & \text { etc. } \\
\prime \prime & \prime_1 & \ldots & \mu_{k-2} & \prime_{k-1} & \mu_{k-2} & \mu_{k-3} & \ldots & \prime & . & \| & \mu_1 & \text { etc. }
\end{array}
\]

On voit par là que, lorsqu'une des quantités \(s, s_1, s_2 \ldots\) est indépendante de \(x\), la firaction continue résultant de \(V R\) est toujours périodique et de la forme suivante, lorsque \(s_m=a\) :
\[
\begin{aligned}
& V k=r+\frac{1}{2 \mu}+\frac{1}{2 \mu_1}+ \\
& \begin{array}{r}
+\frac{1}{2 \mu_1}+\frac{1}{2 a \mu}+\frac{1}{\frac{2 r}{a}+\frac{1}{2 a \mu}+\frac{1}{\frac{2 \mu_1}{a}}+\cdot \cdot+\frac{1}{2 \mu}+\frac{1}{2 r}+\frac{1}{2 \mu}+} .
\end{array} \\
&
\end{aligned}
\]

Lorsque \(m\) est impair, on a de plus \(~ \iota=1\), et par suite
\[
V R=r+\frac{1}{2 \mu}+\frac{1}{2 \mu_1}+\ddots \ddots+\frac{1}{2 \mu_1}+\frac{1}{2 \mu}+\frac{1}{2 r}+\frac{1}{2 \mu}+\frac{1}{2 \mu_1}+\ddots .
\]

Iar réciproque a également lien; c'est-à-dire que, lorsque la fraction continue résultant de \(\mathbb{R}\) a la forme ci-desins, \(s_n\) sera indépendant de \(x\). En effet, soit
%136
\[
\prime_m=\frac{r}{a} \text {, }
\]
on tire de l'équation \(r_m=s_m,_m+\varepsilon_m\),
\[
r_m=\frac{r}{a} s_m+\varepsilon_m \text {. }
\]

Or, puisque \(r_m=r_{m-1}-2 \varepsilon_{m-1}\), où \(d^{\varepsilon_{m-1}}\left\langle\omega^{\prime}\right.\), il est clair que
\[
r_m=r+\gamma_m \text {, où } d_{\boldsymbol{i}_m^{\prime}}<\boldsymbol{d}_r \text {. }
\]

On en tire
\[
r\left(1-\frac{s_m}{a}\right)=\varepsilon_m-\hat{\gamma}_m^{\prime}
\]
et par conséquent \(s_m=0\), ce qu’il fallait démontrer. En combinant cela avec ce qui précède, on trouve la proposition suivante:
"Lorsyu'il est possible de trouver pour o une fonction entière telle, que
\[
\int \frac{0 d x}{\sqrt{R}}=\log \frac{y+\sqrt{R}}{y-\sqrt{R}},
\]
"la traction continue résultant de \(/ R\) est périodique, et a la forme suivante:
\[
V R=r+\frac{1}{2 \mu}+\frac{1}{2 \mu_1}+\cdot \cdot+\frac{1}{2 \mu_1}+\frac{1}{2 \mu}+\frac{1}{2 \mu}+\frac{1}{2 \mu}+\frac{1}{2 \mu_1}+\text { etc. }
\]
"et réciproquement, lorsque la fraction continue résultant de \(V R\) a cette "forme, il est toujours possible de trouver pour \& une fonction entière qui "satisfasse à l'équation,
\[
\int \frac{\varrho d x}{\sqrt{R}}=\log \frac{y+\sqrt{R}}{y-\sqrt{R}} .
\]
"La fonction \(y\) est donnée par l'expression suivante:
\[
\begin{array}{r}
y=r+\frac{1}{2 \mu}+\frac{1}{2 \mu_1}+\frac{1}{2 \mu_2}+\ddots \\
\ddots+\frac{1}{2 \mu}+\frac{1}{2 r}
\end{array} .
\]
%137
Dans cette proposition est contenue la solution complète du problème proposé au commencement de ce mémoire.
15.
Nous venons de voir que, lorsque \(s_{2 k-1}\) est indépendant de \(x\), on aura toujours \(s_k=s_{k-2}\), et lorsque \(s_{2 k}\) est indépendant de \(x\), on aura \(s_k=c s_{k-1}\), où \(c\) est constant. La réciproque a également lieu, ce qu'on peut démontrer conme il suit.
I. Soit d'abord \(s_k=s_{k-2}\), on a
\[
r_{k-1}^2+s_{k-1} s_{k-2}=r_k^2+s_k s_{k-1}
\]
or \(s_k=s_{k-2}\), done
\[
r_k=r_{k-1} \text {. }
\]

De plus
\[
\begin{gathered}
r_k=\mu_k s_k+\varepsilon_k, \\
r_{k-2}=\mu_{k-2} s_{k-2}+\varepsilon_{k-2},
\end{gathered}
\]
done
\[
r_k-r_{k-2}=s_k\left(\mu_k-\mu_{k-2}\right)+\varepsilon_k-\varepsilon_{k-2} .
\]

Mais
\[
r_k=r_{k-1}, \quad r_{k-2}=r_{k-1}+2 \varepsilon_{k-2},
\]
donc, en substituant, on trouve
\[
0=s_k\left(\mu_k-\mu_{k-2}\right)+\varepsilon_k+\varepsilon_{k-8} .
\]

Cette équation donne, en remarquant que \(\delta \varepsilon_k<\delta s_k, \quad \delta \varepsilon_{k-8}<\delta s_{k-2}\),
\[
\mu_k=\mu_{k-2}, \quad \varepsilon_k=-\varepsilon_{k-2} \text {. }
\]

Or \(r_{k+1}=r_k-2 \varepsilon_k\), donc, en vertu de la dernière équation,
\[
r_{k+1}=r_{k-1}+2 \varepsilon_{k-2},
\]
et, puisque \(r_{k-1}=r_{k-2}-2 \varepsilon_{k-2}\), on en conclut
\[
r_{k+1}=r_{k-2} \text {. }
\]
%138
On a
\[
r_{k+1}^2+s_k s_{k+1}=r_{k-2}^2+s_{k-2} s_{k-3},
\]
donc, puisque \(r_{k+1}=r_{k-2}, s_k=s_{k-2}\), ol \(a\) aussi
\[
s_{k+1}=s_{k-3} \text {. }
\]

En combinant cette équation avec celles-ci,
\[
r_{k+1}=\mu_{k+1} s_{k+1}+\varepsilon_{k+1}, \quad r_{k-3}=\mu_{k-3} s_{k-3}+\varepsilon_{k-3},
\]
on obtiendra
\[
r_{k+1}-r_{k-3}=s_{k+1}\left(\mu_{k+1}-\mu_{k-3}\right)+\varepsilon_{k+1}-\varepsilon_{k-3} .
\]

Or on a \(r_{k+1}=r_{k-2}\), et \(r_{k-2}=r_{k-3}-2 \varepsilon_{k-3}\), jar conséquent
\[
0=s_{k+1}\left(\mu_{k+1}-\mu_{k-3}\right)+\varepsilon_{k+1}+\varepsilon_{k-3} .
\]

Il s'ensuit que
\[
\prime_{k+1}=\mu_{k-3}, \varepsilon_{k+1}=-\varepsilon_{k-3} .
\]

En continuant de cette manière, on voit aisément qu’on aura en général
\[
r_{k+n}=r_{k-n-1}, \quad \prime_{k+n}=\boldsymbol{\mu}_{k-n-2}, \quad s_{k+n}=s_{k-n-2} .
\]

En posant dans la dernière équation \(n=k-1\), on trouvera
\[
s_{2 k-1}=s_{-1} \text {. }
\]

Or il est clair que \(s_{-1}\) est la même chose que 1 ; car on a en général
\[
R=r_m^2+s_m s_{m-1}
\]
donc en faisant \(m=0\),
\[
R=r^2+s s_{-1}
\]
mais \(k=r^2+s\), donc \(s_{-1}=1\), et par conséquent
\[
s_{2 k-1}=1 \text {. }
\]
II. Soit en second lien \(s_k=c s_{k-1}\), on a
\[
\begin{gathered}
r_k=\mu_k s_k+\varepsilon_k, \\
r_{k-1}=\mu_{k-1} s_{k-1}+\varepsilon_{k-1},
\end{gathered}
\]
%139
donc
\[
r_k-r_{k-1}=s_{k-1}\left(c \mu_k-\mu_{k-1}\right)+\varepsilon_k-\varepsilon_{k-1} .
\]

Or \(r_k-r_{k-1}=-2 \varepsilon_{k-1}\), done
\[
0=s_{k-1}\left(c_i \mu_k-\mu_{k-1}\right)+\varepsilon_k+\varepsilon_{k-1} .
\]

Cette équation donne
\[
\mu_k=\frac{1}{c} \mu_{k-1}, s_k=-\varepsilon_{k-1} .
\]

Done des équations
\[
r_k-r_{k-1}=-2 \varepsilon_{k-1}, \quad r_{k+1}-r_k=-2 \varepsilon_k,
\]
on déduit en ajoutant
\[
r_{k+1}=r_{k-1} \text {. }
\]

On a de plus
\[
r_{k+1}^2+s_k s_{k+1}=r_{k-1}^2+s_{k-1} s_{k-2},
\]
et, puisque \(r_{k+1}=r_{k-1}\) et \(s_k=c s_{k-1}\), on en conclut
\[
s_{k+1}=\frac{1}{c} s_{k-2} \text {. }
\]

En continuant de cette manière, on aura,
\[
s_{2 k}=c^{ \pm 1}
\]
c'est-à-dire que \(s_{2 k}\) est indépendant de \(x\).
Cette propriété des quantités \(s, s_1, s_2\) etc. fait voir que l'équation \(s_{2 k}=a\) est identique avec l'équation \(s_k=a^{ \pm 1} s_{k-1}\) et que l'équation \(s_{2 k-1}=1\) est identique avec l'équation \(s_k=s_{k-2}\). Il s'ensuit que, lorsqu'on cherche la forme de \(R\), qui convient à l'équation \(s_{2 k}=a\), on pent aul lieu de cette équation poser \(s_k=a^{ \pm 1} s_{k-1}\), et que, lorsqu'on cherche la forme de \(R\) qui convient à l'équation \(s_{2 k-1}=1\), il suffit de faire \(s_k=s_{k-2}\), ce qui abrége beancoup le calcul.
16.
En vertu des équations (41) et (42) on pent domner à l'expression (40) une forme plus simple.
%140
a) Lorsque \(m\) est pair et égal à \(2 k\), on a
(43) \(\left\{\begin{array}{l}\int \frac{2}{\sqrt{R}}\left(d r+d r_1+\cdots+d_{r_{k-1}}+\frac{1}{2} d r_k-\mu d s-\mu_1 d s_1-\cdots-\mu_{k-1} d s_{k-1}\right) \\ =\log \frac{r+\sqrt{R}}{r-\sqrt{R}}+\log \frac{r_1+\sqrt{R}}{r_1-\sqrt{R}}+\cdots+\log \frac{r_{k-1}+\sqrt{R}}{r_{k-1}-\sqrt{R}}+\frac{1}{2} \log \frac{r_k+\sqrt{R}}{r_k-\sqrt{R}}\end{array}\right.\)
b) Lorsque \(m\) est impair et égal à \(2 k-1\), on a
(44) \(\left\{\begin{array}{c}\int \frac{2}{\sqrt{R}}\left(d r+d r_1+\cdots+d_{r_{k-1}}-\mu d s-\mu_1 d_{s_1}-\cdots-\mu_{k-2} d_{s_{k-2}-\frac{1}{2} \mu_{k-1}} d s_{k-1}\right) \\ =\log \frac{r+\sqrt{R}}{r-\sqrt{R}}+\log \frac{r_1+\sqrt{R}}{r_1-\sqrt{R}}+\cdots+\log \frac{r_{k-1}+\sqrt{R}}{r_{k-1}-\sqrt{R}} .\end{array}\right.\)
17.
Pour appliquer ce qui précède à un exemple, prenons l'intégrale
\[
\int \frac{\varrho d x}{\sqrt{x^4+\alpha x^3+\beta x^2+\gamma x+\delta}} .
\]

On a ici \(\delta R=4\), done les fonctions \(s, s_1, s_2, s_3 \ldots\) sont du premier degré, et par suite l'équation \(s_m=\) const. ne donne qu'une senle équation de condition entre les quantités, \(\alpha, \beta, \gamma, \delta, \varepsilon\).
Faisant
\[
x^4+\alpha x^3+\beta x^2+\gamma x+\delta=\left(x^2+a x+b\right)^2+c+e x
\]
on alura
\[
r=x^2+a x+b, s=c+e x .
\]

Pour abréger le calcul, nous ferons \(c=0\). Dans ce cas on a \(s=e x\), et par conséquent,
\[
\mu=E\left(\frac{r}{s}\right)=E\left(\frac{x^2+a x+b}{e x}\right)
\]
c'est-à-dire
\[
\prime \prime=\frac{x}{e}+\frac{a}{e}, \quad \varepsilon=b
\]

De plus
\[
r_1=r-2 \varepsilon=x^2+a x+b-2 b=x^2+a x-b,
\]
%141
\[
\begin{gathered}
s_1=1+4 \varepsilon \mu=1+4 b \frac{x+a}{e}=\frac{4 b}{e} x+\frac{4 a b}{e}+1 \\
\mu_1=E\left(\frac{r_1}{s_1}\right)=E \frac{x^2+a x-b}{\frac{4 b}{e} x+\frac{4 a b}{e}+1}=\frac{e}{4 l^{\prime}} x-\frac{e^2}{16 b^2}, \\
\varepsilon_1=r_1-\mu_1 s_1=\frac{a e}{4 b}+\frac{e^2}{16 b^2}-b, \\
s_2=s+4 \varepsilon_1 \prime_1=\left(\frac{a e^2}{4 b^2}+\frac{e^3}{16 b^3}\right) x-\frac{e^2}{4 b^2}\left(\frac{a e}{4 b}+\frac{e^2}{16 b^2}-b\right) .
\end{gathered}
\]

Soit maintenant en premier lieu \(s_1\) constant. Alors l'équation
\[
s_1=\frac{4 b}{e} x+\frac{4 a b}{e}+1
\]
donne
\[
h=0,
\]
par conséquent,
\[
\begin{gathered}
r=x^2+a x \\
\int \frac{2}{\sqrt{R}}\left(d r-\frac{1}{2} u d s\right)=\log \frac{r+\sqrt{R}}{r-\sqrt{R}}
\end{gathered}
\]
our, puisque \(, \iota=\frac{n+a}{e}, s=e x\),
\[
\int \frac{(3 x+a) d x}{\sqrt{\left(x^2+a x\right)^2+e x}}=\log \frac{x^2+a x+\sqrt{R}}{x^2+a x-\sqrt{k}} .
\]

Cette intégrale se trouve aussi facilement en divisant le numérateur et le dénominateur de la différentielle par \(\sqrt{x}\).

Soit en deuxième lieu \(s_2\) constant. Dans ce cas la formule (43) dome, \(k\) étant égal à l'unité,
\[
\int \frac{2}{\sqrt{R}}\left(d r+\frac{1}{2} d r_1-\mu d s\right)=\log \frac{r+\sqrt{R}}{r-\sqrt{R}}+\frac{1}{2} \log \frac{r_1+\sqrt{R}}{r_1-\sqrt{k}} .
\]

Or l'équation \(s_2=\) const. domne \(s_1=c s\), donc
\[
\frac{4 b}{e} x+\frac{4 a b}{e}+1=c e x .
\]
%142
L'équation de condition sera donc \(\frac{4 a b}{e}+1=0\), c'est-à-dire
\[
e=-4 a b
\]
done
\[
R=\left(x^2+a x+b\right)^2-4 a b x
\]

De plus, ayant \(, \prime=\frac{x+a}{e}, \quad r=x^2+a x+b, \quad r_1=x^2+a x-b\), on aura la formule,
\[
\int \frac{(4 x+a) d x}{\sqrt{\left(x^2+a x+b\right)^2-4 a b x}}=\log \frac{x^2+a x+b+\sqrt{R}}{x^2+a x+b-\sqrt{R}}+\frac{1}{2} \log \frac{x^2+a x^2-b+\sqrt{R}}{x^2+a x-b-\sqrt{R}} .
\]

Soit en troisième lien \(s_3\) constant. Cette équation domne \(s=s_2\), c'est-àdire
\[
\frac{a e}{4 l}+\frac{e^2}{16 l^2}-b=0
\]

On en tire
\[
e=-2 b\left(a \pm \sqrt{a^2+4 b}\right)
\]

La formule (44) domne par conséquent, puisque \(k=2\),
\[
\begin{aligned}
& \int \frac{\left(5 x+\frac{3}{2} a \mp \frac{1}{2} \sqrt{\left.a^2+4 b\right) d x}\right.}{\sqrt{\left(x^2+(a x+b)^2-2 b x\left(a \pm \sqrt{\left.a^2+4 b\right)}\right.\right.}} \\
& \quad=\log \frac{x^2+a x+b+\sqrt{R}}{x^2+a x+b-\sqrt{R}}+\log \frac{x^2+a x-b+\sqrt{R}}{x^2+a x-b-\sqrt{R}} .
\end{aligned}
\]

Si par exemple \(a=0, b=1\), on aura cette intégrale:
\[
\int \frac{(5 x-1) d x}{\sqrt{\left(x^2+1\right)^2-4 x}}=\log \frac{x^2+1+\sqrt{\left(x^2+1\right)^2-4 x}}{x^2+1-\sqrt{\left(x^2+1\right)^2-4 x}}+\log \frac{x^2-1+\sqrt{\left(x^2+1\right)^2-4 x}}{x^2-1-\sqrt{\left(x^2+1\right)^2-4 x}} .
\]

Soit en quatrième lieu \(s_4\) constant. Cela donne \(s_2=c s_1\), c'est-à-dire
\[
\left(\frac{a e^2}{4 b^2}+\frac{e^3}{16 b^3}\right) x-\frac{e^2}{4 b^2}\left(\frac{a e}{4 b}+\frac{e^2}{16 b^2}-b\right)=\frac{4 c b}{e} x+\left(\frac{4 a b}{e}+1\right) c .
\]

On en tire, en comparant les coefticiens et éliminant ensuite \(c\),
\[
\frac{e}{16 b^3}(e+4 a b)^2=-\frac{e}{b}\left(\frac{a p}{4 b}+\frac{p^2}{16 b^2-b}-b\right)
\]
%143
\[
\begin{gathered}
(e+4 a b)^2=16 b^3-e(e+4 a b) \\
e^2+6 a b e=8 b^3-8 a^2 b^2 \\
e=-3 a b \mp \sqrt{8 b^3+a^2 b^2}=-b\left(3 a \pm \sqrt{\left.a^2+8 b\right) .}\right.
\end{gathered}
\]

En vertu de cette expression la formule (43) donne,
\[
\begin{aligned}
\int \frac{\left(6 x+\frac{8}{2} a-\frac{1}{2} \sqrt{a^2}+8 b\right) d x}{\sqrt{\left(x^2+a x+b\right)^2-b\left(3 a+\sqrt{\left.a^2+8 b\right) x}\right.}}=\log \frac{x^2+a x+b+\sqrt{ } R}{x^2+a x+b-\sqrt{R}} \\
+\log \frac{x^2+a x-b+\sqrt{R}}{x^2+a x-b-\sqrt{R}}+\frac{1}{2} \log \frac{x^2+a x+1 a\left(a-\sqrt{\left.a^2+8 b\right)+\sqrt{ } R}\right.}{x^2+a x+\frac{1}{4} a\left(a-\sqrt{\left.a^2+8 b\right)-\sqrt{ } R}\right.} .
\end{aligned}
\]

Si l'on fait par exemple \(a=0, b=\frac{1}{2}\), on obtiendra

On peut continuer de cette manière et trouver un plus grand nombre d'intégrales. Ainsi par exemple l'intégrale
\[
\int \frac{\left(x+\frac{\sqrt{5}+1}{14}\right) d x}{\sqrt{\left(x^2+\frac{\sqrt{5}-1}{2}\right)^2+(\sqrt{5}-1)^2 x}}
\]
peut s'exprimer par des logarithmes.

Nous avons ici cherché les intégrales de la forme \(\int \frac{\varrho}{\sqrt{R}}\) qui peuvent s'exprimer par une fonction logarithmique de la forme \(\log \frac{p+q \sqrt{R}}{p-q \sqrt{R}}\). On pourait rendre le problème encore plus général, et chercher en général toutes les intégrales de la forme ci-dessus qui pouraient s'exprimer d'une ma-
%144
nière quelconque par des logarithmes; mais on ne trouverait pas d'intégrales nouvelles. On a en effet ce théorème remarquable:
"Lorsqu'une intégrale de la forme \(\int \frac{\varrho d x}{\sqrt{ } R}\), où \(\rho\) et \(R\) sont des "fonctions entières de \(x\), est exprimable par des logarithmes, on peut ,toujours l'exprimer de la manière suivante:
\[
\int \frac{\varrho d x}{\sqrt{R}}=A \log \frac{p+q \sqrt{R}}{p-q \sqrt{R}},
\]
"où \(A\) est constant, et \(p\) et \(q\) des fonctions entières de \(x\)." Je démontrerai ce théorème dans me antre occasion.
%145
XII.

MÉNOIRE SUR UNE PROPRIÉTÉ GÉNÉRALE D'UNE CLASSE TRÈSÉTENIUE DE FONCTIONS TRANSCENDANTES.

Présenté à l'Académie des sciences à Paris le 30 Octobre 1826. Mémoires présentés par divers savants t. VII, Paris 1841.
Les fonctions transcendantes considérées jusqu’à présent par les géomètres sont en très-petit nombre. Presque toute la théorie des fonctions transcendantes se réduit à celle des fonctions logarithmiques, exponentielles et circulaires, fonctions qui, dans le fond, ne forment qu'une seule espèce. Ce n'est que dans les derniers temps qu'on a aussi commencé à considérer quelques autres fonctions. Parmi celles-ci, les transcendantes elliptiques, dont II. Legendre a developpé tant de propriétés remarquables et élégantes, tiennent le premier rang. L'autenr a considéré, dans le mémoire qu’il a l'homneur de présenter à l'Acadénie, une classe très-étendue de fonctions, savoir: toutes celles dont les dérivées peuvent être exprimées au moyen d'équations algébriques, dont tous les coefficients sont des fonctions rationnelles d'une même variable, et il a trouvé pour ces fonctions des propriétés analogues à celles des fonctions logarithniques et elliptiques.

Une fonction dont la dérivée est rationnelle a, comme on le sait, la propriété qu'on peut exprimer la somme d'un nombre quelconque de semblables fonctions par une fonction algébrique et logarithmique, quelles que soient d'ailleurs les variables de ces fonctions. De même une fonction elliptique quelconque, c'est-à-dire une fonction dont la dérivée ne contient d'autres irrationnalités qu'un radical du second degré, sous lequel la variable ne passe pas le quatrième degré, aura encore la propriété qu'on peut exprimer une
%146
somme quelconque de semblables fonctions par une fonction algébrique et logarithmique, pourvu qu'on établisse entre les variables de ces fonctions une certaine relation algébrique. Cette analogie entre les propriétés de ces fonctions a conduit l'auteur à chercher s'il ne serait pas possible de trouver des propriétés analogues de fonctions plus générales, et il est parvenu aı théorème suivant:
"Si l'on a plusieurs fonctions dont les dérivées peuvent être racines "d'une même équation algébrique, dont tous les coefficients sont des fonctions "rationnelles d'une même variable, on peut toujours exprimer la somme d'un ",nombre quelconque de semblables fonctions par une fonction algébrique et "logarithmique, pourvu qu'on établisse entre les variables des fonctions en "question un certain nombre de relations algébriques."

Le nombre de ces relations ne dépend nullement du nombre des fonctions, mais seulement de la nature des fonctions particulières qu'on considère. Ainsi, par exemple, pour une fonction elliptique ce nombre est 1; pour une fonction dont la dérivée ne contient d'autres irrationnalités qu'un radical du second degré, sous lequel la variable ne passe pas le cinquième ou sixième degré, le nombre des relations nécessaires est 2, et ainsi de suite.

Le même théorème subsiste encore lorsqu'on suppose les fonctions multipliées par des nombres rationnels quelconques positifs on négatifs.
On en déduit encore le théorème suivant:
"On peut toujours exprimer la somme d'un nombre donné de fonctions, "qui sont multipliées chacune par un nombre rationnel, et dont les variables "2sont arbitraires, par une somme semblable en nombre déterminé de fonctions, "dont les variables sont des fonctions algébriques des variables des fonctions "données."

A la fin du mémoire on domne l'application de la théorie à une classe particulière de fonctions, savoir, à celles qui sont exprimées comme intégrales de formules différentielles, qui ne contiennent d'autres irrationmalités qu'un radical quelconque.
1.
Soit
(1)
\[
0=p_0+p_1 y+p_2 y^2+\cdots+p_{n-1} y^{n-1}+y^n=x y
\]
une équation algébrique quelconque, dont tous les coefficients sont des fonc-
%147
tions rationnelles et entières d'une même quantité variable \(x\). Cette équation, supposée irréductible, donne pour la fonction \(y\) un nombre \(n\) de formes différentes; nous les désignerons par \(y^{\prime}, y^{\prime \prime} \ldots y^{(n)}\), en conservant la lettre y pour indiquer l'une quelconque d'entre elles.
Soit de même
\[
\theta y=q_0+q_1 y+q_2 y^2+\cdots+q_{n-1} y^{n-1}
\]
une fonction rationnelle entière de \(y\) et \(x\), en sorte que les coefficients \(q_0\), \(q_1, q_2 \ldots q_{n-1}\), soient des fonctions entières de \(x\). Un certain nombre des coefficients des diverses puissances de \(x\) dans ces fonctions seront supposés indéterminés; nous les désignerons par \(a, a^{\prime}, a^{\prime \prime}\), etc.

Cela posé, si l'on met dans la fonction \(\theta y\), au lieu de \(y\), successivement \(y^{\prime}, y^{\prime \prime} \ldots y^{(n)}\), et si l'on désigne par \(r\) le produit de toutes les fonctions ainsi formées, c'est-à-dire si l'on fait
\[
v=\theta y^{\prime} \cdot \theta y^{\prime \prime} \ldots \theta \theta y^{(n)}
\]
la quantité \(r\) sera, comme on sait par la théorie des équations algébriques, une fonction rationnelle et entière de \(x\) et des quantités \(a, a^{\prime}, a^{\prime \prime}\), etc.
Supposons que l'on ait
\[
r=F_0 x \cdot F x
\]
\(F_0 x\) et \(F x\) étant deux fonctions entières de \(x\), dont la première, \(F_0 x\), est indépendante des quantités \(a, a^{\prime}, a^{\prime \prime}\), etc.; et soit
\[
F x=0 .
\]

Cette équation, dont les coefficients sont des fonctions ratiomnelles des quantités \(a, a^{\prime}, a^{\prime \prime}\), etc., donnera \(x\) en fonction de ces quantités, et on aura, pour cette fonction, autant de formes que l'équation \(F x=0\) a de racines. Désignons ces racines par \(x_1, x_2 \ldots x_\mu\), et par \(x\), l'une quelconque d'entre elles.

L'équation \(F x=0\), que nous venons de former, entraîne nécessairement la suivante \(r=0\), et celle-ci en amène une autre de la forme
\[
\theta y=0
\]

En mettant dans cette dernière, au lieu de \(x\), successivement \(x_1, x_2 \ldots x_\mu\),
%148
et désignant les valeurs correspoudantes de \(y\) par \(y_1, y_2 \ldots y_\mu\), on aura les "I équations suivantes:
\[
\theta y_1=0, \theta y_2=0 \ldots \theta y_\mu=0
\]
2.

Cela posé, je dis que si l'on désigne par \(f(x, y)\) une fonction quelconque rationnelle de \(x\) et \(y\), et si l'on fait
\[
d v=f\left(x_1, y_1\right) d x_1+f\left(x_2, y_2\right) d x_2+\cdots+f\left(x_\mu, y_\mu\right) d \dot{x}_\mu
\]
la différentielle \(d v\) sera une fonction rationnelle des quantités \(a, a^{\prime}, a^{\prime \prime}\), etc. En effet, en combinant les équations \(\theta y=0\) et \(x y=0\), on en peut tirer la valeur de \(y\), exprimée en fonction rationnelle de \(x\) et des quantités \(a\), etc.; en désignant cette fonction par e, on aura done
\[
y=\varrho \quad \text { et } f(x, y)=f(x, \varrho) \text {. }
\]

Mais en différentiant l'équation \(F x=0\), on aura
\[
F^{\prime} x \cdot d x+\delta F x=0
\]
en désignant, pour abréger, par \(F^{\prime} x\) la dérivée de \(F x\) par rapport à \(x\) seul, et par \(\$ F x\) la différentielle de la même fonction par rapport aux quantités \(a, a^{\prime}, a^{\prime \prime}\), etc. De là on tire
\[
d x=-\frac{\delta F x}{F^{\prime \prime} \cdot x}
\]
et par conséquent
\[
f(x, y) d x=-\frac{f(x, \varrho)}{F^{\prime \prime} x} \delta F x=\varphi_2 x
\]
où il est clair que \(\uparrow_2 x\) est une fonction rationnelle de \(x, a, a^{\prime}, a^{\prime \prime}\), etc. Au moyen de cette expression de la différentielle \(f^{\prime}(x, y) d x\), la valeur de \(d v\) deviendra
\[
d v=\varphi_2 x_1+\varphi_2 x_2+\cdots+\varphi_2 x_\mu
\]

Or, le second membre de cette équation est une fonction rationnelle des
%149
quantités \(a, a^{\prime}, a^{\prime \prime} \ldots x_1, x_2 \ldots x_\mu\), et en outre symétrique par rapport \(x_1, x_2 \ldots x_\mu\); done \(d v\) pent s'exprimer par une fonction rationnelle de \(a\), \(a^{\prime}, a^{\prime \prime} \ldots\) et des coefficients de l'équation \(F x=0 ;\) mais ces coefficients sont eux-mêmes des fonctions rationnelles de \(a, a^{\prime}\), etc.; done \(d v\) le sera de même, comme on vient de le dire.

Si maintenant \(d v\) est une fonction différentielle rationnelle des quantités \(a, a^{\prime} a^{\prime \prime}\)... son intégrale ou la quantité \(v\) sera une fonction algébrique et logarithmique de \(a, a^{\prime}, a^{\prime \prime} \ldots\)... Léquation (8) domnera done, en intégrant entre certaines limites des quantités \(a, a^{\prime}, a^{\prime \prime} \ldots\)
\[
\int f\left(x_1, y_1\right) d x_1+\int f\left(x_2, y_2\right) d x_2+\cdots+\int f\left(x_\mu, y_\mu\right) d x_\mu=v
\]
ou bien, en faisant
\[
\begin{gathered}
\int f\left(x_1, y_1\right) d x_1=\psi_1 x_1 ; \int f\left(x_2, y_2\right) d x_2=\psi_2 x_2 \ldots \int f\left(x_\mu, y_\mu\right) d x_\mu=\psi_\mu x_\mu \\
\psi_1 x_1+\psi_2 x_2+\psi_3 x_3+\cdots+\psi_\mu x_\mu=v
\end{gathered}
\]

Voilà la propriété générale des fonctions \(\psi_1 x_1, \psi_2 x_2\), etc., que nous avons énoncée au commencement de ce mémoire.
3.
Les formes des fonctions \(\psi_1 x_1, \psi_2 x_2\), etc., dépendent, en vertu des équations (13), de celles des fonctions \(y_1, y_2 \ldots y_\mu\). Ces dernières ne peuvent être choisies arbitrairement parmi celles qui satisfont à l'équation \(\chi y=0\); elles doivent en outre satisfaire aux équations (7); mais comme on a plusieuirs variables indépendantes, \(a, a^{\prime}, a^{\prime \prime}\). . . il est clair qu'on peut établir entre les formes des fonctions \(y_1, y_2 \ldots y_\mu\), un nombre de relations égal a celui de ces variables. On pent donc choisir arbitrairement les formes d'un certain nombre de fonctions \(y_1, y_2 \ldots y_\mu\); mais alors celles des autres fonctions dépendront, en vertu des équations (7), de celles-ci et de la grandeur des quantités \(a, a^{\prime}, \ldots\) Il se peut donc que la quantité constante d'intégration contenue dans la fonction \(v\) change de valeur pour des valeurs différentes des quantités \(a, a^{\prime}, a^{\prime \prime} \ldots\); mais par la nature de cette quantité, elle doit rester la même pour des valeurs de \(a, a^{\prime}, a^{\prime \prime} \ldots\) contenues entre certaines limites.
Lues fonctions \(x_1, x_2 \ldots x_\mu\), sont déterminées par l'équation \(F \cdot x=0\);
%150
cette équation dépend de la forme de la fonction \(\theta y\); mais comme on pent varier celle-ci d'une infinité de manières, il s'ensuit que l'équation (14) est susceptible d'une infinité de formes différentes pour la même espèce de fonctions. I.es fonctions \(x_1, x_2 \ldots x_\mu\), ont encore cela de très-remaiquable que les mêmès valeurs répondent à une infinité de fonctions différentes. En effet la forme de la fonction \(f(x, y)\), de laquelle ces quantités sont entièrement indépendantes, est assujettie à la seule condition d'être une fonction rationnelle de \(x\) et \(y\).
4.
Nous avons montré dans ce qui précède comment on peut toujours former la différentielle rationnelle \(d v\); mais comme la méthode indiquée sera en général très-longue, et pour des fonctions un peu composées, presque impraticable, je vais en domer une antre, par laquelle on obtiendra immédiatement l'expression de la fonction \(v\) dans tous les cas possibles.
On a par l'équation (3)
\[
r=\theta y^{\prime} \cdot \theta y^{\prime \prime} \ldots \theta y^{(n)}
\]
donc, en différentiant par rapport aux quantités \(a, a^{\prime}, a^{\prime \prime}\), etc., on obtiendra
\[
\delta i^{\prime}=\frac{r}{\theta y^{\prime}} \delta \theta \theta y^{\prime}+\frac{r}{\theta y^{\prime \prime}} \delta \theta y^{\prime \prime}+\cdots+\frac{r}{\theta y^{(n)}} \delta \theta y^{(n)}
\]
or, on a \(\theta y=0\), donc le second membre de l'équation précédente se réduira à \(\frac{r}{\theta y} \delta \theta y\), et l'on aura par conséquent
\[
\delta r=\frac{r}{\theta y} \delta \theta y
\]

Maintenant on a
\[
r=F_0 x \cdot F x
\]
où \(F_0^{\prime} x\) est indépendante de \(a, a^{\prime}, a^{\prime \prime}\), etc.; donc, en différentiant, on obtiendra
\[
\delta r=F_0 x \cdot \delta F x
\]
%151
et, par conséquent, en substituant et divisant par \(F_0 x\), on trouvera
\[
\delta F x=\frac{r \cdot \delta \theta y}{F_0 x \cdot \theta y} .
\]

Par la, la valeur de
\[
d x=-\frac{\delta F^{\prime} x}{F^{\prime} x}
\]
deviendra
\[
d x=-\frac{1}{F_0 x \cdot F^{\prime \prime} x} \stackrel{r}{\theta y} \delta \theta y
\]
et en multipliant par \(f(x, y)\)
\[
f(x, y) d x=-\frac{1}{F_0 x \cdot F^{\prime} x} f(x, y) \frac{r}{\theta y} \delta \theta y .
\]

En remarquant maintenant que \(\frac{r}{\theta y^{(k)}}\) s'évanouit, car autrement on allrait \(y^{(k)}=y\), il est clair que l'expression de \(f(x, y) d x\) peut s'écrire comme il suit:
\[
\begin{gathered}
f(x, y) d x= \\
-\frac{1}{F_0 x \cdot F^{\prime} x}\left\{f\left(x, y^{\prime}\right) \frac{r}{\theta y^{\prime}} \delta \theta y^{\prime}+f\left(x, y^{\prime \prime}\right) \frac{r}{\theta y^{\prime \prime}} \delta \theta y^{\prime \prime}+\cdots+f\left(x, y^{(n)}\right) \frac{r}{\theta y^{(n)}} \delta \theta y^{(n)}\right\} .
\end{gathered}
\]

Pour abréger, nous désignerons dans la suite par \(\Sigma F_1 y\) toute fonction de la forme
\[
F_1 y^{\prime}+F_1 y^{\prime \prime}+F_1 y^{\prime \prime \prime}+\cdots+F_1 y^{(n)}
\]
et par là la valeur précédente de \(f(x, y) d x\) deviendra
\[
f(x, y) d x=-\frac{1}{F_0 x \cdot F^{\prime} x} \Sigma f(x, y) \frac{r}{\theta y} \delta \theta y .
\]

Cela posé, soit \(\chi^{\prime} y\) la dérivée de \(\chi y\) prise par rapport à \(y\) seul, le produit \(f(x, y) \chi^{\prime} y\) sera une fouction rationnelle de \(x\) et \(y\). On pent donc: faire
\[
f(x, y) \chi^{\prime} y=\frac{P_1 y}{P_y}
\]
où \(P\) et \(P_1\) sont deux fonctions entières de \(x\) et \(y\). Mais si l'on désigue par \(T\) le produit \(P y^{\prime} . P y^{\prime \prime} \ldots P y^{(n)}\), on aura
%152
\[
\frac{P_1 y}{P_y}=\frac{1}{T} P_1 y \frac{T}{P_y}
\]
or 'T pent tonjours s'exprimer par me fonction entière de \(x\) et \(y\), et \(T\) par une fonction entiere de. \(x\), done on aura
\[
\frac{P_{1, y}}{P_y}=\frac{T_1}{T}
\]
oì \(T_1\) cost nue fonction cutiere de \(x\) et \(! /\) mais toute fonction entiere de \(x\) et !/ pent se metre sous la forme
\[
t_0+t_{1} ! y+t_{n} !^3+\cdots+t_{n-1 !} y^{n-1}=f_1(x, y),
\]
oì \(I_n, I_1 \ldots t_{n-1}\), sont des fonctions entières de \(x\) senl. On peut donc stipurer
\[
f(x, y) \chi^{\prime} y=\frac{i_1(x, y)}{f_y x},
\]
fyc étant une fonction entiero de \(x\) sans \(y\).
be lit on tire
\[
f(x, y)=\frac{f_1(x, y)}{f_y x \cdot x^{\prime} y} .
\]

Lin substituant maintenant cette valeur de \(f(x, y)\) dans lexpression de \(f(x, y) d x\) trouvée plus haut, il viendra

Dans le second membre do cette équation la quantité \(f_1(x, y) \frac{r}{\theta y}\) est une fonction entiere par rapport it \(x\) et \(y\); on pent donc supposer
\[
f_1(x, y) \frac{\dot{\theta}}{\theta y} d y=R^{(1)} y+R \cdot x \cdot y^{n-1},
\]
oì \(R^{(1)} y\) est une fonction entière de \(x\) et \(! /\) dans laquelle les puissances de y ne montent qu'an (n-2) degré; lix étant une fonction entièro de x sans \(y\). On aura done
%153
Or, on a
\[
\begin{aligned}
& x^{\prime} y^{\prime}=\left(y^{\prime}-y^{\prime \prime}\right)\left(y^{\prime}-y^{\prime \prime \prime}\right) \cdots\left(y^{\prime}-y^{(m)}\right), \\
& x^{\prime} y^{\prime \prime}=\left(y^{\prime \prime}-y^{\prime}\right)\left(y^{\prime \prime}-y^{\prime \prime \prime}\right) \cdots\left(y^{\prime \prime}-y^{(m)}\right), \text { etc.; }
\end{aligned}
\]
donc, d'après des fornules connues,
\[
\Sigma \frac{R^{(1)} y}{x^{\prime} y}=0 ; \quad \Sigma \frac{y^{n-1}}{x^{\prime} y}=1
\]

Par conséquent
\[
\Sigma \frac{f_1(x, y)}{x^{\prime} y} \frac{r}{\theta y} \% \theta y=R x .
\]

La fonction \(\sum \frac{f_1(x, y)}{x^{\prime} y} \frac{r}{\theta y} \delta \theta y\) peut donc s'exprimer par une fonction entièce de \(x\) seul sans \(y\). Les quantitess \(a, a^{\prime}, a^{\prime \prime}\) etc. d'ailleurs y entrent rationnellement.
Par là l'équation (18) donnera
\[
\frac{f_1(x, y)}{f_2 x \cdot y^{\prime} y} d x=-\frac{R x}{f_2 x \cdot F_0 x \cdot F^{\prime \prime} x} .
\]

En mettant dans cette équation au lieu de \(x\) successivement \(x_1, x_2 \ldots x_\mu\), on obtiendra \(\mu\) équations qui, ajoutées ensemble, donneront la suivante:
\[
\begin{aligned}
d v= & \frac{f_1\left(x_1, y_1\right) d x_1}{f_2 x_1 \cdot \chi^{\prime} y_1}+\frac{f_1\left(x_2, y_2\right) d x_2}{f_2 x_2 \cdot \chi^{\prime} y_2}+\cdots+\frac{f_1\left(x_\mu, y_\mu\right) d x_\mu}{f_2 x_\mu \cdot \chi^{\prime} y_\mu}= \\
& \quad-\frac{R x_1}{f_2 x_1 \cdot F_0 x_1 \cdot F^{\prime \prime} x_1}-\frac{R x_2}{f_2 x_2 \cdot F_0 x_2 \cdot F^{\prime \prime} x_2}-\cdots-\frac{R x_\mu}{f_z x_\mu \cdot F_0 x_\mu \cdot F^{\prime} x_\mu}
\end{aligned}
\]

Si donc on désigne par \(\Sigma F_1 x\) une somme de la forme
\[
F_1 x_1+F_1 x_2+F_1 x_3+\cdots+F_1 x_\mu
\]
l'expression de dv pourra s'écrire comme il suit:
\[
d v=-\Sigma \frac{R x}{f_8 x \cdot F_0 x \cdot F^{\prime} x} .
\]

Cela posé, soient
\[
\left\{\begin{array}{l}
F_0 x=\left(x-\beta_1\right)^{\mu_1}\left(x-\beta_2\right)^{\mu_2} \cdots\left(x-\beta_\alpha\right)^{\mu_\alpha} \\
f_2 x=\left(x-\beta_1\right)^{m_1}\left(x-\beta_2\right)^{m_2} \cdots\left(x-\beta_\alpha\right)^{m_\alpha} A \\
R x=\left(x-\beta_1\right)^{k_1}\left(x-\beta_2\right)^{k_3} \cdots\left(x-\beta_\alpha\right)^{k_\alpha} R_1 x
\end{array}\right.
\]
%154
\(\beta_1, \beta_2 \ldots \beta_e\), étant des quantités indépendantes de \(a, a^{\prime}, a^{\prime \prime}\) etc.; \(\mu_1, \mu_2 \ldots m_1, m_2 \ldots k_1, k_z\), etc., étant des nombres entiers, zéro y compris; et \(R_1 x\) étant une fonction entière de \(x\).

En substituant ces valeurs de \(F_0 x, f_2 x, R x\) dans l'expression de \(d v\), elle deviendra
\[
d v=-\Sigma \frac{R_1 x}{A F^{\prime} x \cdot\left(x-\beta_1\right)^{\mu_1+m_1-k_1}\left(x-\beta_2\right)^{\mu_2+m_2-k_2} \ldots\left(x-\beta_\alpha\right)^{\mu_\alpha+m_\alpha-k_\alpha}},
\]
ou bien en faisant, pour abréger,
\[
\mu_1+m_1-k_1=\nu_1, \mu_2+m_2-k_2=\nu_2, \ldots \mu_\alpha+m_\alpha-k_\alpha=\nu_\alpha
\]
\[
\begin{gathered}
A\left(x-\beta_1\right)^{\nu_1}\left(x-\beta_2\right)^{\nu_2} \cdots\left(x-\beta_\alpha\right)^{\nu_\alpha}=\theta_1 x: \\
d v=-\Sigma \frac{R_1 x}{\theta_1 x \cdot F^{\prime} x} .
\end{gathered}
\]

Maintenant on peut toujours supposer
\[
\frac{R_1 x}{\theta_1 x}=R_2 x+\frac{R_3 x}{\theta_1 x},
\]
où \(R_2 x\) et \(R_3 x\) sont deux fonctions entières de \(x\), le degré de la dernière étant plus petit que celui de la fonction \(\theta_1 x\); en substituant, il viendra done
\[
d v=-\Sigma \frac{R_2 x}{F^{\prime} x}-\Sigma \frac{R_3 x}{\theta_1 x \cdot F^{\prime} x}
\]

La fonction \(-\Sigma \frac{R_2 x}{F^{\prime} x}\) peut se trouver de la manière suivante.
Puisque \(x_1, x_2 \ldots x_\mu\) sont les racines de l'équation \(F x=0\), on aura, en désignant par \(\alpha\) une quantité indéterminée quelconque,
\[
\frac{1}{F \alpha}=\frac{1}{\alpha-x_1} \frac{1}{F^{\prime} x_1}+\frac{1}{\alpha-x_2} \frac{1}{F^{\prime} x_2}+\cdots+\frac{1}{\alpha-x_\mu} \frac{1}{F^{\prime} x_\mu},
\]
c'est-à-dire
\[
\frac{1}{F \alpha}=\sum \frac{1}{\alpha-x} \frac{1}{F^{\prime} x}
\]
d'où l'on tire, en développant \(\frac{1}{a-x}\) suivant les puissances descendantes de \(\alpha\),
%155
\[
\frac{1}{F^{\prime} \alpha}=\frac{1}{\alpha} \Sigma \frac{1}{F^{\prime} x}+\frac{1}{\alpha^2} \Sigma \frac{x}{F^{\prime} x}+\cdots+\frac{1}{\alpha^{m+1}} \Sigma \frac{x^m}{F^{\prime} x}+\cdots
\]
d'où il suit que \(\sum \frac{x^m}{F^{\prime \prime} x}\) est égal au coefficient de \(\frac{1}{\boldsymbol{\alpha}^{m+1}}\) dans le développement de la fonction \(\frac{1}{F \alpha}\), ou, ce qui revient au même, à celui de \(\frac{1}{\alpha}\) dans le développement de \(\frac{\boldsymbol{\alpha}^m}{\boldsymbol{F} \boldsymbol{\alpha}}\). En désignant donc par \(\Pi F_1 x\) le coefficient de \(\frac{1}{x}\) dans le développement d'une fonction quelconque \(F_1 x\), suivant les puissances descendantes de \(x\), on aura
\[
\Sigma \frac{x^m}{F^{\prime} x}=\Pi \frac{x^m}{F x} .
\]

De là il suit que
\[
\Sigma \frac{F_1 x}{F^{\prime} x}=\Pi \frac{F_1 x}{F_x}
\]
en désignant par \(F_1 x\) une fonction quelconque entière de \(x\). On aura donc, en mettant \(R_z x\),
\[
\Sigma \frac{R_2 x}{F^{\prime} x}=\Pi \frac{R_2 x}{F x}
\]
mais ayant
\[
\frac{R_1 x}{\theta_1 x \cdot F x}=\frac{R_3 x}{\theta_1 x \cdot F x}+\frac{R_2 x}{F x}
\]
on aura aussi
\[
\Pi \frac{R_1 x}{\theta_1 x \cdot F x}=\Pi \frac{R_3 x}{\theta_1 x \cdot F x}+\Pi \frac{R_2 x}{F x} .
\]

Or, le degré de \(R_3 x\) étant moindre que celui de \(\theta_1 x\), il est clair qu'on aura
\[
\Pi \frac{R_3 x}{\theta_1 x \cdot F x}=0
\]
done
\[
\Sigma \frac{R_2 x}{F^{\prime \prime} x}=\Pi \frac{R_1 x}{\theta_1 x \cdot F^{\prime} x}
\]
%156
Le second terme du second membre de l'équation (27), savoir la quantité \(\sum \frac{R_3 x}{\theta_1 x \cdot F^{\prime} x}\), se trouve comme il suit:
Soit
\[
\begin{aligned}
\frac{R_3 x}{\theta_1 x}=\frac{A_1^{(1)}}{x-\beta_1} & +\frac{A_1^{(2)}}{\left(x-\beta_1\right)^2}+\cdots+\frac{A_1^{\left(\nu_1\right)}}{\left(x-\beta_1\right)^{\nu_1}} \\
& +\frac{A_2^{(1)}}{x-\beta_2}+\frac{A_2^{(2)}}{\left(x-\beta_2\right)^2}+\cdots+\frac{A_2^{\left(\nu_2\right)}}{\left(x-\beta_2\right)^{\nu_2}}+\text { etc. }
\end{aligned}
\]
ou bien, pour abréger,
\[
\frac{R_3 x}{\theta_1 x}=\Sigma^{\prime}\left\{\frac{A_1}{x-\beta}+\frac{A_2}{(x-\beta)^2}+\cdots+\frac{A_\nu}{(x-\beta)^\nu}\right\},
\]
on aura
\[
A_1=\frac{d^{\nu-1} p}{\Gamma \nu \cdot d \beta^{\nu-1}}, A_2=\frac{d^{\nu-2} p}{\Gamma(\nu-1) d \beta^{\nu-2}}, \cdots A_\nu=p
\]
où
\[
p=\frac{(x-\beta)^\nu R_3 x}{\theta_1 x}
\]
pour \(x=\beta\); c'est-ì-dire
\[
p=\frac{\Gamma(\nu+1) R_3 \beta}{\theta_1(v) \beta}
\]
en désignant par \(\theta_1^{(v)} x\) la \(\nu^e\) dérivée de la fonction \(\theta_1 x\) par rapport à \(x\), et par \(\boldsymbol{\Gamma}(\nu+1)\) le produit 1.2.3.. \(\nu-1) \cdot \nu\).
En substituant ces valeurs des quantités \(A_1, A_2 \ldots A_\nu\), il viendra
\[
\frac{R_3 x^{\prime}}{\theta_1 x}=\Sigma^{\prime}\left\{\begin{array}{c}
\frac{d^{\nu-1} p}{(x-\beta) d \beta^{\nu-1}}+(\nu-1) \frac{d^{\nu-2} p}{(x-\beta)^2 d \beta^{\nu-8}} \\
+(\nu-1)(\nu-2) \frac{d^{\nu-3} p}{(x-\beta)^3 d \beta^{\nu-3}}+\text { etc. }
\end{array}\right\} \frac{1}{\Gamma \nu} .
\]

Maintenant on a, en désignant \(\frac{1}{x-\beta}\) par \(q\),
\[
\frac{1}{(x-\beta)^2}=\frac{d q}{d \beta}, \quad \frac{1}{(x-\beta)^3}=\frac{1}{2} \frac{d^2 q}{d \beta^2}, \cdots \frac{1}{(x-\beta)^\nu}=\frac{1}{\Gamma \nu} \frac{d^{\nu-1} q}{d \beta^{\nu-1}}
\]
donc l'expression de \(\frac{R_3 x}{\theta_1 x}\) peut s'écrire comme il suit:
%157
\[
\frac{R_3 x}{\theta_1 x^{\prime}}=\Sigma^{\prime} \frac{1}{I^{\prime} \nu}\left\{\begin{array}{c}
\frac{d^{\nu-1} p}{d \beta^{\nu-1}} q+\frac{\nu-1}{1} \frac{d^{\nu-2} p}{d \beta^{\nu-2}} \frac{d q}{d \beta} \\
+\frac{(\nu-1)(\nu-2)}{1.2} \frac{d^{\nu-3} p}{d \beta^{\nu-3}} \frac{d^2 q}{d \beta^2}+\cdots+p \frac{d^{\nu-1} q}{d \beta^{\nu-1}}
\end{array}\right\}
\]

Or la quantité entre les accolades est égale à \(\frac{d^{\nu-1}(p q)}{d \beta^{\nu-1}}\), donc
\[
\frac{R_3 x}{\theta_1 x}=\Sigma^{\prime} \frac{1}{T_v} \frac{d^{v-1}(p q)}{d \beta^{v-1}}
\]
d'où l'on tirera, en substituant les valeurs de \(p\) et \(q\), et remarquant que \(\Gamma(\nu+1)=\nu^{\prime} \nu\)
\[
\frac{R_3 x}{\theta_1 x}=\Sigma^{\prime} \nu \frac{d^{\nu-1}}{d \beta^{\nu-1}}\left\{\frac{R_3 \beta}{\theta_1^{(\nu)} \beta \cdot(x-\beta)}\right\}
\]

En substituant cette expression au lieu de \(\frac{R_3 x}{\theta_1 x}\) dans la fonction \(\frac{R_3 x}{\theta_1 x \cdot F^{\prime \prime} x}\), il viendra
\[
\Sigma \frac{R_3 x}{\theta_1 x \cdot F^{\prime} x}=\Sigma \frac{1}{F^{\prime} x} \Sigma^{\prime} \nu \frac{d^{\nu-1}}{d \beta^{\nu-1}}\left\{\frac{R_3 \beta}{\theta_1^{(\nu)} \beta \cdot(x-\beta)}\right\}
\]
ou bien
\[
\Sigma \frac{R_3 x}{\theta_1 x \cdot F^{\prime \prime} x}=\Sigma^{\prime} \nu \frac{d^{\nu-1}}{d_{\beta^2}{ }^{\gamma-1}}\left\{\frac{R_3 \beta}{\theta_1^{(\nu)} \beta} \Sigma \frac{1}{(x-\beta)} F^{\prime \prime} x\right\}
\]

Or, comme nous avons vu plus haut (28),
\[
\Sigma \frac{1}{(x-\beta) F^{\prime \prime} x}=-\frac{1}{F^{\prime} \beta}
\]
done
\[
\sum \frac{R_3 x}{\theta_1 x \cdot F^{\prime \prime} x}=-\Sigma^{\prime} \nu^{\prime} \frac{d^{\nu-1}}{d \beta^{\nu-1}}\left\{\frac{R_3 \beta}{\theta_1^{(\nu)} \beta \cdot F^{\prime} \beta}\right\}
\]
mais l'équation
\[
\frac{R_1 x}{\theta_1 x}=R_2 x+\frac{R_3 x}{\theta_1 x}
\]
donne, si l'on multiplie les deux membres par \((x-\beta)^\nu\), et qu'on fasse ensuite \(x=\beta\),
%158
\[
\frac{R_1 \beta}{\theta_1^{(\nu)} \beta}=\frac{R_3 \beta}{\theta_1^{(\nu)} \beta}
\]
donc, en substituant,
\[
\Sigma \frac{R_3 x}{\theta_1 x \cdot F^{\prime} x}=-\Sigma^{\prime} \nu \frac{d^{\nu-1}}{d \beta^{\nu-1}}\left\{\frac{R_1 \beta}{\theta_1^{(\nu)} \beta \cdot F \beta}\right\} .
\]

Ayant ainsi trouvé les valeurs de \(\Sigma \frac{R_2 x}{F^{\prime} x}\) et \(\Sigma \frac{R_3 x}{\theta_1 x \cdot F^{\prime} x}\), l'équation donnera, porr la différentielle \(d v\), l'expression suivante,
\[
d v=-\Pi \frac{R_1 x}{\theta_1 x \cdot F x}+\Sigma^{\prime} v^{\prime} \frac{d^{\nu-1}}{d \beta^{\nu-1}}\left\{\frac{R_1 \beta}{\theta_1^{(\nu)} \beta \cdot F^{\prime} \beta}\right\}
\]
on bien
\[
\begin{gathered}
d v=-\Pi \frac{R_1 x}{\theta_1 x \cdot F x}+\Sigma^{\prime} v \frac{d^{\nu-1}}{d x^{\nu-1}}\left\{\frac{R_1 x}{\theta_1^{(v)} x \cdot F x}\right\} \\
\left(x=\beta_1, \beta_2 \ldots \beta_\alpha\right) .
\end{gathered}
\]

Maintenant on a (19)
\[
\begin{aligned}
& R x=\Sigma \frac{f_1(x, y)}{\chi^{\prime} y} \frac{r}{\theta y} \delta \theta y=F_0 x \cdot F x \cdot \Sigma \frac{f_1(x, y)}{\chi^{\prime} y} \frac{\delta \theta y}{\theta y} \\
& R_1 x=R x \cdot\left(x-\beta_1\right)^{-k_1}\left(x-\beta_z\right)^{-k_3} \cdots\left(x-\beta_\alpha\right)^{-k_\alpha}
\end{aligned}
\]
donc en faisant, pour abréger,
\[
\begin{gathered}
F_0 x \cdot\left(x-\beta_1\right)^{-k_1}\left(x-\beta_2\right)^{-k_2} \cdots\left(x-\beta_\alpha\right)^{-k_\alpha} \\
=\left(x-\beta_1\right)^{\mu_1-k_1}\left(x-\beta_2\right)^{\mu_2-k_2} \cdots\left(x-\beta_\alpha\right)^{\mu_\alpha-k_\alpha}=F_2 x: \\
R_1 x=F_2 x \cdot F x \cdot \Sigma \frac{f_1(x, y)}{\chi^{\prime} y} \frac{\delta \theta y}{\theta y}
\end{gathered}
\]
et en substituant cette valeur de \(R_1 x\) dans l'expression précédente de \(d v\), on obtiendra
\[
d v=-\Pi \frac{F_2 x}{\theta_1 x} \Sigma \frac{f_1(x, y)}{\chi^{\prime} y} \frac{\delta \theta y}{\theta y}+\Sigma^{\prime} \nu \frac{d^{\nu-1}}{d x^{\nu-1}}\left\{\frac{F_2 x}{\theta_1^{(\nu)} x} \Sigma \frac{f_1(x, y)}{\chi^{\prime} y} \frac{\delta \theta y}{\theta y}\right\}
\]

Sous cette forme la valeur de \(d v\) est immédiatement intégrable, car \(F_2 x, \theta_1 x, f_1(x, y)\) et \(\chi^{\prime} y\) sont toutes indépendantes des quantités \(a, a^{\prime}, a^{\prime \prime} \ldots\), auxquelles la différentiation se rapporte. On aura donc, en intégrant, pour \(v\) l'expression suivante:
%159
(37)
\[
\begin{gathered}
v=C-\Pi \frac{F_2 x}{\theta_1 x} \Sigma \frac{f_1(x, y)}{\chi^{\prime} y} \log \theta y+\Sigma^{\prime} \nu \frac{d^{\nu-1}}{d x^{\nu-1}}\left\{\frac{F_2 x}{\theta_1^{(\nu)} x} \Sigma \frac{f_1(x, y)}{\chi^{\prime} y} \log \theta y\right\} \\
\left(x=\beta_1, \beta_2 \ldots \beta_\alpha\right)
\end{gathered}
\]
ou bien en faisant, pour abréger,
\[
\begin{gathered}
\Sigma \frac{f_1(x, y)}{f_2 x \cdot \chi^{\prime} y} \log \theta y=\varphi x \\
\frac{\hat{F}_2 x}{\theta_1^{(\nu)} x} \Sigma \frac{f_1(x, y)}{\chi^{\prime} y} \log \theta y=\varphi_1 x
\end{gathered}
\]
et remarquant que d'après (23), (24), (25) et (35),
\[
\begin{gathered}
F_2 x=\frac{\theta_1 x}{f_2 x}: \\
v=C-\Pi \varphi x+\Sigma^{\prime} \nu \frac{d^{\nu-1} \varphi_1 x}{d x^{\nu-1}}
\end{gathered}
\]
voilà l'expression de la fonction \(v\) dans tous les cas possibles. Elle contient, comme on le voit, en général, des fonctions logarithmiques; mais dans des cas particuliers elle peut aussi devenir seulement algébrique et même constante.

En substituant cette valeur au lieu de \(v\) dans la formule (14), il viendra
\[
\psi_1 x_1+\psi_2 x_2+\cdots+\psi_\mu x_\mu=C-\Pi \varphi x+\Sigma^{\prime} \nu \frac{d^{\nu-1} \varphi_1 x^x}{d x^{\nu-1}}
\]
ou bien pour abréger:
\[
\Sigma \psi x=C-\Pi \varphi x+\Sigma \nu \frac{d^{\nu-1} \varphi_1 x}{d x^{\nu-1}}
\]
lorsqu'on fait
\[
\psi_1 x_1+\psi_2 x_2+\cdots+\psi_\mu x_\mu=\Sigma \psi x \text { et } \Sigma^{\prime}=\Sigma
\]
5.

Nous avons supposé dans ce qui précède que la fonction \(r\) aurait pour facteur la fonction
\[
F_0 x=\left(x-\beta_1\right)^{\mu_1}\left(x-\beta_2\right)^{\mu_2} \ldots\left(x-\beta_\alpha\right)^{\mu_\alpha} .
\]

Sinon tous les exposants \(\mu_1, \mu_2 \ldots \mu_\alpha\) sont égaux à zéro, il en résultera
%160
nécessairement certaines relations entre les coefficients des fonctions \(q_0, q_1, q_2\) .. \(q_{n-1}\), relations qui peuvent toujours s'exprimer par des équations linéaires entre ces coefficients; car si \(r=0\) pour \(x=\beta\), il faut aussi qu'on ait une équation de la forme \(\theta y=0\) pour la même valeur de \(x\); mais cette équation est linéaire. En général donc la fonction \(r\) n'aura pas de facteur comme \(F_0 x\), c'est-à-dire indépendant des quantités \(a, a^{\prime}, a^{\prime \prime} \ldots\) Ce cas mérite d'être remarqué:
Ayant (19)
\[
R x=\Sigma \frac{f_1(x, y)}{x^{\prime} y} \frac{r}{\theta y} \delta \theta y
\]
on aura en général, si \(F_0 x=1, k_1=k_2=k_3=\cdots=k_\alpha=0\) (on peut faire la même supposition dans tous les cas); on aura done en vertu de (35) et \((25)\)
\[
F_2^{\prime} x=1, \theta_1 x=F_2 x \cdot f_2 x=f_2 x
\]
la valeur (38) de \(\varphi_1 x\) deviendra donc (en remarquant que \(\nu_1=m_1, v_2=m_2\), etc., et désignant \(\nu\) par \(m\) )
\[
\varphi_1 x=\frac{1}{f_2^{(m)} x} \Sigma \frac{f_1(x, y)}{\chi^{\prime} y} \log \theta y
\]
et par conséquent la formule (41) (en désignant par \(B\) la valeur de \(y\) pour \(x=\boldsymbol{\beta})\)
\[
\Sigma \int \frac{f_1(x, y) d x}{f_2 x \cdot \chi^{\prime} y}=\left\{\begin{array}{l}
C-I I \Sigma \frac{f_1(x, y)}{f_2 x \cdot \chi^{\prime} y} \log \theta y \\
+\Sigma m \frac{d^{m-1}}{d \beta^{m-1}}\left(\frac{1}{f_2^{(m)} \beta} \sum \frac{f_1(\beta, B)}{\chi^{\prime} B} \log \theta B\right)
\end{array}\right.
\]

Pour le cas particulier où \(f_2 x=(x-\beta)^m\), on aura \(f_2^{(m)} \beta=1.2 \ldots m\), donc en substituant
\[
\Sigma \int \frac{f_1(x, y) d x}{(x-\beta)^m \chi^{\prime} y}=\left\{\begin{array}{l}
C-\Pi \Sigma \frac{f_1(x, y)}{(x-\beta)^m \chi^{\prime} y} \log \theta y \\
+\frac{1}{1.2 \ldots(m-1)} \frac{d^{m-1}}{d \beta^{m-1}}\left(\Sigma \frac{f_1(\beta, B)}{\chi^{\prime} B} \log \theta B\right)
\end{array}\right.
\]

Si \(m=1\), il vient
\[
\Sigma \int \frac{f_1(x, y) d x}{(x-\beta) \chi^{\prime} y}=C-\Sigma \Pi \frac{f_1(x, y)}{(x-\beta) \chi^{\prime} y} \log \theta y+\Sigma \frac{f_1(\beta, B)}{\chi^{\prime} B} \log \theta B
\]
et si \(m=0\),
%161
\[
\Sigma \int \frac{f_1(x, y) d x}{\chi^{\prime} y}=C-\Sigma \Pi \frac{f_1(x, y)}{\chi^{\prime} y} \log \theta y
\]

Daus la formule (43), le second membre est en général une fonction des quantités \(a, a^{\prime}, a^{\prime \prime}\), etc. Si on le suppose égal à une constante, il en résultera donc en général certaines relations entre ces quantités; mais il y a anssi certains cas pour lesquels le second membre se réduit à une constante, quelles que soient d'ailleurs les valeurs des quantités \(a, a^{\prime} a^{\prime \prime}\), etc. Cherchons ces cas:

D'abord il est évident que la fonction \(f_2 x\) doit être constante, car dans le cas contraire le second membre contiendrait nécessairement les quantités \(a, a^{\prime}, a^{\prime \prime} \ldots\), vu les valeurs arbitraires de ces quantités.
En faisant donc \(f_2 x=1\), il viendra
\[
\Sigma \int \frac{f_1(x, y)}{\chi^{\prime} y} d x=C-\Sigma \Pi \frac{f_1(x, y)}{\chi^{\prime} y} \log \theta y
\]

Or, en observant que ces quantités \(a, a^{\prime}, a^{\prime \prime}, \ldots\) sont toutes arbitraires, il est clair que la fonction \(\sum \frac{f_1(x, y)}{x^{\prime} y} \log \theta y\); développée suivant les puissances descendantes de \(x\), aura la forme suivante:
\[
R \log x+A_0 x^{\mu_0}+A_1 x^{\mu_0-1}+\cdots+A_{\mu_0}+\frac{A_{\mu_0+1}}{x}+\frac{A_{\mu_0+2}}{x^2}+\cdots,
\]
\(l i\) étant une fonction de \(x\) indépendante de \(a, a^{\prime}, a^{\prime \prime}\), etc., \(\mu_0\) un nombre entier, et \(A_0, A_1, \ldots A_{\mu_0}, A_{\mu_0+1}\), etc., des fonctions de \(a, a^{\prime}, a^{\prime \prime}\), etc.; done pour que la fonction dont il s'agit soit constante, il faut que \(\|_0\) soit moindre que - 1; et par conséquent la plus grande valeur de ce nombre est -2.

Cela posé, en désignant par le symbole \(h R\) le plus hant exposant de \(x\) dans le développement d'une fonction quelconque \(R\) de cette quantité, suivant les puissances descendantes, il est clair que \(\boldsymbol{\mu}_0\) sera égal au nombre entier le plus grand contenu dans les nombres:
\[
h \frac{f_1\left(x, y^{\prime}\right)}{x^{\prime} y^{\prime}}, \quad h \frac{f_1\left(x, y^{\prime \prime}\right)}{x^{\prime} y^{\prime \prime}}, \ldots h \frac{f_1\left(x, y^{(n)}\right)}{\chi^{\prime} y^{(n)}}
\]
il faut donc que tous ces nombres soient inférieurs à l'unité prise négativement.

Or, si \(\frac{R}{R_1}\) est une fonction de \(x\), on aura, comme il est aisé de le voir,
%162
\[
h \frac{R}{R_1}=h R-h h_1
\]
par conséquent
\[
\begin{aligned}
h f_1\left(x, y^{\prime}\right)<h \chi^{\prime} y^{\prime}-1, h f_1\left(x, y^{\prime \prime}\right) & <h \chi^{\prime} y^{\prime \prime}-1 \\
& \ldots h f_1\left(x, y^{(n)}\right)<h \chi^{\prime} y^{(n)}-1 .
\end{aligned}
\]

De ces inégalités on déduira facilement dans chaque cas particulier la forme la plus générale de lä fonction \(f_1(x, y)\).
Comme on a
\[
\begin{aligned}
& x^{\prime} y^{\prime}=\left(y^{\prime}-y^{\prime \prime}\right)\left(y^{\prime}-y^{\prime \prime \prime}\right) \cdots\left(y^{\prime}-y^{(n)}\right) \\
& \chi^{\prime} y^{\prime \prime}=\left(y^{\prime \prime}-y^{\prime}\right)\left(y^{\prime \prime}-y^{\prime \prime \prime}\right) \cdots\left(y^{\prime \prime}-y^{(n)}\right), \text { etc. },
\end{aligned}
\]
il s'ensuit que
\[
\begin{aligned}
& h \chi^{\prime} y^{\prime}=h\left(y^{\prime}-y^{\prime \prime}\right)+h\left(y^{\prime}-y^{\prime \prime \prime}\right)+\cdots+h\left(y^{\prime}-y^{(n)}\right) \\
& h \chi^{\prime} y^{\prime \prime}=h\left(y^{\prime \prime}-y^{\prime}\right)+h\left(y^{\prime \prime}-y^{\prime \prime \prime}\right)+\cdots+h\left(y^{\prime \prime}-y^{(n)}\right), \text { ete. }
\end{aligned}
\]

Supposons, ce qui est permis, que l'on ait
\[
h y^{\prime} \geqq h y^{\prime \prime}, h y^{\prime \prime} \geqq h y^{\prime \prime \prime}, \quad h y^{\prime \prime \prime} \geq h y^{\prime \prime \prime \prime}, \ldots h y^{(n-1)} \geq h y^{(n)},
\]
de sorte que les quantités \(h y^{\prime}, h y^{\prime \prime}, h y^{\prime \prime \prime}, \ldots\) suivent l'ordre de leurs grandeurs en commençant par la plus grande. Alors on aura, en général, excepté quelques cas particuliers que je me dispense de considérer:
Si ces équations ont lieu, on se convaincra sans peine, en supposant
\[
f_1(x, y)=t_0+t_1 y+t_2 y^2+\cdots+t_{n-1} y^{n-1}
\]
que les inégalités (47) entraînent nécessairement les suivantes:
\[
\begin{aligned}
h\left(t_m y^{\prime m}\right)<h \chi^{\prime} y^{\prime}-1, \quad h\left(t_m y^{\prime \prime m}\right)<h \chi^{\prime} y^{\prime \prime}-1, & \\
& h\left(t_m y^{\prime \prime \prime m}\right)<h \chi^{\prime} y^{\prime \prime \prime}-1, \ldots
\end{aligned}
\]
\(m\) étant l'un quelconque des nombres \(0,1,2, \ldots n-1\).
%163
D'où l'on tire, en remarquant que
\[
h\left(t_m y^m\right)=h t_m+h y^m=l_t t_m+m h y,
\]
les inégalités
\[
\begin{aligned}
& h t_m<h \chi^{\prime} y^{\prime}-m h y^{\prime}-1, h t_m<h \chi^{\prime} y^{\prime \prime}-m h y^{\prime \prime}-1 \\
& \ldots h t_m<h \chi^{\prime} y^{(n)}-m h y^{(n)}-1 . \\
&
\end{aligned}
\]

Or, au moyen des équations (48) et (50), on aura
\[
\begin{aligned}
& h \chi^{\prime} y^{\prime}-m h y^{\prime}-1=(n-m-1) h y^{\prime}-1, \\
& h \chi^{\prime} y^{\prime \prime}-m h y^{\prime \prime}-1=(n-m-2) h y^{\prime \prime}+h y^{\prime}-1, \\
& h \chi^{\prime} y^{\prime \prime \prime}-m h y^{\prime \prime \prime}-1=(n-m-3) h y^{\prime \prime \prime}+h y^{\prime}+h y^{\prime \prime}-1,
\end{aligned}
\]
etc.,
\[
\begin{aligned}
& h \chi^{\prime} y^{(n-m-1)}-m h y^{(n-m-1)}-1=h y^{(n-m-1)}+h y^{\prime}+h y^{\prime \prime}+\cdots+h y^{(n-m-2)}-1, \\
& h \chi^{\prime} y^{(n-m)}-m h y^{(n-m)}-1=h y^{\prime}+h y^{\prime \prime}+\cdots+h y^{(n-m-1)}-1, \\
& h \chi^{\prime} y^{(n-m+1)}-m h y^{(n-m+1)}-1=-h y^{(n-m+1)}+h y^{\prime}+h y^{\prime \prime}+\cdots+h y^{(n-m)}-1, \\
& \quad \text { etc., } \\
& h \chi^{\prime} y^{(n)}-m h y^{(n)}-1=-m h y^{(n)}+h y^{\prime}+h y^{\prime \prime}+\cdots+h y^{(n-1)}-1 .
\end{aligned}
\]
etc.,
\[
h \chi^{\prime} y^{(n)}-m h y^{(n)}-1=-m h y^{(n)}+h y^{\prime}+h y^{\prime \prime}+\cdots+h y^{(n-1)}-1
\]

En remarquant done que les quantités \(h y^{\prime}, h y^{\prime \prime}, \ldots\) suivent l'ordre de leurs grandeurs, il est clair que le plus petit des nombres
\[
h \chi^{\prime} y^{\prime}-m h y^{\prime}-1, h \chi^{\prime} y^{\prime \prime}-m h y^{\prime \prime}-1, \text { etc., } h \chi^{\prime} y^{(n)}-m h y^{(n)}-1
\]
est égal à
\[
h y^{\prime}+h y^{\prime \prime}+h y^{\prime \prime \prime}+\cdots+h y^{(n-m-1)}-1
\]

Done la plus grande valeur de \(h t_m\) est égale au nombre entier immédiatement inférieur à cette quantité, et on aura
\[
h t_m=h y^{\prime}+h y^{\prime \prime}+\cdots+h y^{(n-m-1)}-2+\varepsilon_{n-m-1},
\]
où \(\varepsilon_{n-m-1}\) est le nombre positif moindre que l'unité qui rend possible cette équation.

Cela posé, soit \(h y^{\prime}=\frac{m^{\prime}}{\mu^{\prime}}, m^{\prime}\) et \(\mu^{\prime}\) étant deux nombres entiers et la fraction \(\frac{m^{\prime}}{\mu^{\prime}}\) réduite à sa plus simple expression, alors il faudra que l'on ait
\[
h y^{\prime}=h y^{\prime \prime}=h y^{\prime \prime \prime}=\cdots=h y^{(m)}=\frac{m^{\prime}}{\mu^{\prime}} .
\]
%164
Car si une équation de la forme \(\chi y=0\) est satisfaite par une fonction de la forme
\[
y=A x^{\frac{m^{\prime}}{\mu^{\prime}}}+\text { etc. }
\]
cette même équation est aussi satisfaite par les \(\mu^{\prime}\) valeurs de \(y\) qu'on obtiendra en mettant au lieu de \(x^{\frac{1}{\mu^{\prime}}}\),
\[
\alpha_1 x^{\frac{1}{\mu^{\prime}}}, \alpha_2 x^{\frac{1}{\mu^{\prime}}}, \ldots \alpha_{\mu^{\prime}-1} x^{\frac{1}{\mu^{\prime}}},
\]
\(1, \alpha_1, \alpha_2, \ldots \alpha_{\mu^{\prime}-1}\) étant les \(\iota^{\prime}\) racines de l'équation \(a^{\mu^{\prime}}-1=0\).
Parmi les quantités \(h y^{\prime}, h y^{\prime \prime}, \ldots h y^{(n)}\), il y en a done " \({ }^{\prime}\) qui sont égales entre elles. De même le nombre total des exposants qui sont égaux à une fraction réduite doit être un multiple du dénominateur.
On peut done supposer
\[
\left\{\begin{array}{c}
h y^{\prime}=h y^{\prime \prime}=\cdots=h y^{\left(k^{\prime}\right)}=\frac{m^{\prime}}{\mu^{\prime}}, \\
h y^{\left(k^{\prime}+1\right)}=h y^{\left(k^{\prime}+2\right)}=\cdots=h y^{\left(k^{\prime \prime}\right)}=\frac{m^{\prime \prime}}{\mu^{\prime \prime}}, \\
h y^{\left(k^{\prime \prime}+1\right)}=h y^{\left(k^{\prime \prime}+2\right)}=\cdots=h y^{\left(k^{\prime \prime \prime}\right)}=\frac{m^{\prime \prime \prime}}{\mu^{\prime \prime \prime}}, \\
\text { etc., } \\
h y^{\left(k^{(\varepsilon-1)}+1\right)}=h y^{(k(\varepsilon-1)+2)}=\cdots=h y^{(n)}=\frac{m^{(\varepsilon)}}{\mu^{(\varepsilon)}},
\end{array}\right.
\]
etc.,
où
\[
h y^{\left(k^{(\varepsilon-1)}+1\right)}=h y^{(k(\varepsilon-1)+2)}=\cdots=h y^{(n)}=\frac{m^{(\varepsilon)}}{\mu^{(\varepsilon)}}
\]
(55) \(\left\{\begin{array}{l}k^{\prime}=n^{\prime} \mu^{\prime} ; k^{\prime \prime}=n^{\prime} u^{\prime}+n^{\prime \prime} \mu^{\prime \prime} ; k^{\prime \prime \prime}=n^{\prime} u^{\prime}+n^{\prime \prime} u^{\prime \prime}+n^{\prime \prime \prime} \mu^{\prime \prime \prime} ; \text { etc. } \\ n=n^{\prime} u^{\prime}+n^{\prime \prime} u^{\prime \prime}+n^{\prime \prime \prime} \mu^{\prime \prime \prime}+\cdots+n^{(\varepsilon)} u^{(\varepsilon)}\end{array}\right.\)
les fractions \(\frac{m^{\prime}}{\mu^{\prime}}, \frac{m^{\prime \prime}}{\mu^{\prime \prime}}, \ldots \frac{m^{(\varepsilon)}}{\mu^{(\varepsilon)}}\) sont réduites à leur plus simple expression, et \(n^{\prime}, n^{\prime \prime}, n^{\prime \prime \prime}, \ldots n^{(*)}\) sont des nombres entiers.

Supposons maintenant dans l'expression de \(h t_m\), que \(m=n-k^{(\alpha)}-\beta-1\), \(\beta\) étant un nombre moindre que \(k^{(\alpha+1)}-k^{(\alpha)}\), c'est-à-dire moindre que \(n^{(\kappa+1)} \boldsymbol{\iota}^{(\alpha+1)}\), il viendra alors
%165
\[
h t_{n-k^{(\alpha)}-\beta-1}=\left\{\begin{array}{l}
h y^{\prime}+h y^{\prime \prime}+\cdots+h y^{\left(k^{\prime}\right)} \\
+h y^{\left(k^{\prime}+1\right)}+h y^{\left(k^{\prime}+2\right)}+\cdots+h y^{\left(k^{\prime}\right)} \\
+\mathrm{etc} . \\
+h y^{\left(k^{(\alpha-1)}+1\right)}+h y^{\left(k^{(\alpha-1)}+2\right)}+\cdots+h y^{\left(k^{(\alpha)}\right)} \\
+h y^{\left(k^{(\alpha)}+1\right)}+h y^{\left(k^{(\alpha)}+2\right)}+\cdots+h y^{\left(k^{(\alpha)}+\beta\right)} \\
+\varepsilon_{\left(k^{(\alpha)}+\beta\right)}-2
\end{array}\right.
\]
or, les équations (54) et (55) donnent
\[
\begin{gathered}
h y^{\prime}+h y^{\prime \prime}+\cdots+h y^{\left(k^{\prime}\right)}=k^{\prime} \frac{m^{\prime}}{\mu^{\prime}}=n^{\prime} m^{\prime} \\
h y^{\left(k^{\prime}+1\right)}+h y^{\left(k^{\prime}+2\right)}+\cdots+h y^{\left(k^{\prime \prime}\right)}=\left(k^{\prime \prime}-k^{\prime}\right) \frac{m^{\prime \prime}}{\mu^{\prime \prime}}=n^{\prime \prime} m^{\prime \prime}
\end{gathered}
\]
etc.,
\[
h y^{\left(k^{(\alpha)}+1\right)}+\cdots+h y^{\left(k^{(\alpha)}+\beta\right)}=\beta \frac{m^{(\alpha+1)}}{\mu^{(\alpha+1)}},
\]
done, en substituant
\[
h t_{n \rightarrow k^{(\alpha)}-\beta-1}=\left\{\begin{array}{c}
n^{\prime} m^{\prime}+n^{\prime \prime} m^{\prime \prime}+n^{\prime \prime \prime} m^{\prime \prime \prime}+\cdots+n^{(\alpha)} m^{(\alpha)} \\
+\beta \frac{m^{(\alpha+1)}}{\mu^{(\alpha+1)}}+\varepsilon_{k^{(\alpha)}+\beta}-2 .
\end{array}\right.
\]

Quant ì la valeur de \(\varepsilon_{k^{(r)}+\beta}\), il est clair qu'en faisant
\[
\mu^{(\alpha+1)} \cdot \varepsilon_{k^{(\alpha)}+\beta}=A_\beta^{(\alpha+1)},
\]
cette quantité \(A_\beta^{(\alpha+1)}\) sera le plus petit nombre entier positif, qui rend le . nombre \(\beta m^{(\alpha+1)}+A_{\beta^3}^{(\alpha+1)}\) divisible par \(\|^{(\alpha+1)}\); on aura done
\[
l_{n-k^{(\alpha)}-\beta-1}=\left\{\begin{array}{l}
-2+n^{\prime} m^{\prime}+n^{\prime \prime} m^{\prime \prime}+n^{\prime \prime \prime} m^{\prime \prime \prime}+\cdots+n^{(\alpha)} m^{(\alpha)} \\
+\frac{\beta m^{(\alpha+1)}+A_\beta^{(\alpha+1)}}{\mu^{(\alpha+1)}} .
\end{array}\right.
\]

En faisant dans cette équation \(\alpha=0\), il viendra
\[
h t_{n-\beta-1}=-2+\frac{\beta m^{\prime}+A_\beta^{\prime}}{\mu^{\prime}}
\]
donc si \(\frac{\beta m^{\prime}+A_\beta^{\prime}}{\mu^{\prime}}<2, h t_{n-\beta-1}\) est négatif, et par conséquent il faut faire \(t_{n-\beta-1}=0\); car, pour toute fonction entière \(t\), let est nécessairement positif, zéro y compris. Or, en faisant \(\beta=0\), on a toujours \(\frac{\beta m^{\prime}+A_\beta^{\prime}}{\mu^{\prime}}<2\); donc:
%166
\(t_{n-1}\) est toujours égal à zéro, c'est-à-dire que la fonction \(f_1(x, y)\) doit être de la forme
\[
f_1(x, y)=t_0+t_1 y+t_2 y^2+\cdots+t_{n-\beta^{\prime}-1} y^{n-\beta^{\prime-1}},
\]
où \(\beta^{\prime}\), étant plus grand que zéro, est déterminé par l'équation
\[
\frac{\beta^{\prime} m^{\prime}+A_{\beta^{\prime}}^{\prime}}{\mu^{\prime}}=2,
\]
d'où il suit que \(\beta^{\prime}\) est égal au plus grand nombre entier contenu dans la fraction \(\frac{\mu^{\prime}}{m^{\prime}}+1\).

Ine fonction telle que \(f_1(x, y)\) existe donc toujours ì moins que \(\beta^{\prime}\) ne surpasse \(n-1\). Pour que cela puisse avoir lieu, il faut que
\[
\frac{\mu^{\prime}}{m^{\prime}}+1=n+\varepsilon
\]
où \& est une quantité positive, zéro \(\mathrm{y}\) compris; de là il suit
\[
\frac{m^{\prime}}{\mu^{\prime}}=\frac{1}{n-1+\varepsilon} \text {. }
\]

Or, la plus grande valeur de \(\mu^{\prime}\) est \(n\), donc cette équation donne
\[
\frac{m^{\prime}}{\mu^{\prime}}=\frac{1}{n-1} \text { ou } \frac{m^{\prime}}{\mu^{\prime}}=\frac{1}{n} \text {. }
\]

Or, je dis que dans ces deux cas l'intégrale \(\int f(x, y) d x\) peut s'exprimer au moyen de fonctions algébriques et logarithmiques. En effet, pour que \(\frac{m^{\prime}}{\mu^{\prime}}\), qui est le plus grand des exposants \(h y^{\prime}, h y^{\prime \prime}, \ldots h y^{(n)}\), ait une des deux valeurs \(\frac{1}{n-1}, \frac{1}{n}\), il faut que l'équation \(x y=0\), qui donne la fonction \(y\), ne contienne la variable \(x\) que sous une forme linéaire. On aura done
\[
\chi y=P+x Q
\]
où \(P\) et \(Q\) sont des fonctions entières de \(y\); de là il suit
\[
x=-\frac{P}{Q}, \quad d x=\frac{P d Q-Q d P}{Q^2},
\]
et
\[
f(x, y) d x=f\left(-\frac{P}{Q}, y\right) \frac{P d Q-Q d P}{Q^2}=R d y
\]
%167
où il est clair que \(R\) est une fonction rationnelle de \(y\); par conséquent l'intégrale \(\int l i d y\), et par suite \(\int f(x, y) d x\), pent être exprimée al moyen de fonctions logarithmiques et algébriques.

Excepté ce cas done, la fonction \(f_1(x, y)\) existe toujours; en la substituant dans l'équation (46), elle deviendra
\[
\Sigma \int \frac{\left(t_0+t_1 y+\cdots+t_{n-\beta^{\prime}-1} y^{\left(n-\beta^{\prime}-1\right)}\right) d_x t}{\chi^{\prime} y}=C .
\]

Un cas particulier de cette équation est le suivant:
\[
\Sigma \int \frac{x^k y^n d x}{\chi^{\prime} y}=C
\]
où \(k\) et \(m\) sont deux nombres entiers et positifs, tels que
\[
\begin{gathered}
m<n-\frac{\mu^{\prime}}{m^{\prime}}-1 ; \\
k<-1+n^{\prime} m^{\prime}+n^{\prime \prime} m^{\prime \prime}+\cdots+n^{(\alpha)} m^{(\alpha)}+\frac{\beta m^{(\alpha+1)}}{\mu^{(\alpha+1)}} \\
m=n-k^{(\alpha)}-\beta-1 ; \beta<\mu^{(\alpha+1)} n^{(\alpha+1)}
\end{gathered}
\]
et il est clair que cette formule peut remplacer la formule (59) dans toute sa généralité.

Puisque le degré de la fonction entière \(t_m\) est égal à \(h t_m\), cette même fonction contiendra un nombre de constantes arbitraires égal a \(h t_m+1\). La fonction \(f_1(x, y)\) en contiendra donc un nombre exprimé par
\[
h t_0+h t_1+\cdots+h t_{n-\beta-1}+n-\beta^{\prime}
\]
ou bien, comme il est aisé de le voir,
\[
h t_0+h t_1+\cdots+h t_{n-\beta-1}+\cdots+h t_{n-2}+n-1
\]

En désignant ce nombre par \(\gamma\), on trouvera aisément, en vertu de l'équation qui donne la valeur générale de \(l l t_m\),
%168
or, en remarquant que \(m^{\prime}\) et \(\mu^{\prime}\) sont premiers entre eux, on sait par la théorie des nombres que la suite \(A_0{ }^{\prime}, A_1{ }^{\prime}, A_2{ }^{\prime}, A_3{ }^{\prime} \ldots A_{n^{\prime} \boldsymbol{\mu}^{\prime}-1}\), contiendra \(n^{\prime}\) fois la suite des nombres naturels \(0,1,2,3, \ldots, \mu^{\prime}-1\), donc
\[
\begin{gathered}
A_0{ }^{\prime}+A_1{ }^{\prime}+A_2{ }^{\prime}+\cdots+A_{n^{\prime} \mu^{\prime}-1}=n^{\prime}\left(0+1+2+\cdots+\mu^{\prime}-1\right) \\
=n^{\prime} \frac{\mu^{\prime}\left(\mu^{\prime}-1\right)}{2}
\end{gathered}
\]
de même
\[
\begin{gathered}
A_0^{\prime \prime}+A_1^{\prime \prime}+A_2^{\prime \prime}+\cdots+A^{\prime \prime}{ }_{n^{\prime \prime} \mu^{-1}}=n^{\prime \prime}\left(0+1+2+\cdots+\mu^{\prime \prime}-1\right) \\
=n^{\prime \prime} \frac{\mu^{\prime \prime}\left(\mu^{\prime \prime}-1\right)}{2}
\end{gathered}
\]
etc.
En substituant ces valeurs et réduisant, la valeur de \(\gamma\) deviendra
\[
y=\left\{\begin{array}{l}
-n+1+\frac{1}{2} m^{\prime} n^{\prime}\left(n^{\prime} \mu^{\prime}-1\right)+\frac{1}{2} n^{\prime}\left(\mu^{\prime}-1\right)+\frac{1}{2} m^{\prime \prime} n^{\prime \prime}\left(n^{\prime \prime} \mu^{\prime \prime}-1\right) \\
+\cdots+\frac{1}{2} n^{\prime \prime}\left(\mu^{\prime \prime}-1\right) \\
+n^{\prime} m^{\prime} n^{\prime \prime} \mu^{\prime \prime}+\left(n^{\prime} m^{\prime}+n^{\prime \prime} m^{\prime \prime}\right) n^{\prime \prime \prime} \mu^{\prime \prime \prime}+\left(n^{\prime} m^{\prime}+n^{\prime \prime} m^{\prime \prime}+n^{\prime \prime \prime} m^{\prime \prime \prime}\right) n^{\prime \prime \prime \prime} \mu^{\prime \prime \prime \prime \prime} \\
+\cdots+\left(n^{\prime} m^{\prime}+n^{\prime \prime} m^{\prime \prime}+\cdots+n^{(\varepsilon-1)} m^{(\varepsilon-1)}\right) n^{(\varepsilon)} \mu^{(\varepsilon)}
\end{array}\right.
\]
ou bien en remarquant que
(62)
\[
n=n^{\prime} \boldsymbol{u}^{\prime}+n^{\prime \prime} \boldsymbol{u}^{\prime \prime}+\cdots+n^{(\varepsilon)} \boldsymbol{u}^{(\varepsilon)}
\]
\[
\gamma=\left\{\begin{array}{l}
n^{\prime} u^{\prime}\left(\frac{m^{\prime} n^{\prime}-1}{2}\right)+n^{\prime \prime} u^{\prime \prime}\left(m^{\prime} n^{\prime}+\frac{m^{\prime \prime} n^{\prime \prime}-1}{2}\right)+n^{\prime \prime \prime} u^{\prime \prime \prime}\left(m^{\prime} n^{\prime}+m^{\prime \prime} n^{\prime \prime}+\frac{m^{\prime \prime \prime} n^{\prime \prime \prime}-1}{2}\right) \\
+\cdots+n^{(\varepsilon)} u^{(\varepsilon)}\left(m^{\prime} n^{\prime}+m^{\prime \prime} n^{\prime \prime}+\cdots+m^{(\varepsilon-1)} n^{(\varepsilon-1)}+\frac{m^{(\varepsilon)} n^{(\varepsilon)}-1}{2}\right) \\
-\frac{u^{\prime}\left(m^{\prime}+1\right)}{2}-\frac{n^{\prime \prime}\left(m^{\prime \prime}+1\right)}{2}-\frac{n^{\prime \prime \prime}\left(m^{\prime \prime \prime}+1\right)}{2}-\cdots-\frac{n^{(\varepsilon)}\left(m^{(\varepsilon)}+1\right)}{2}+1
\end{array}\right.
\]

Comme cas particuliers on doit remarquer les deux suivants:
1. Lorsque
\[
h y^{\prime}=h y^{\prime \prime}=\cdots=h y^{(n)}=\frac{m^{\prime}}{\mu^{\prime}} .
\]

Dans ce cas \(\varepsilon=1\), et par conséquent
\[
\eta=n_{\prime}^{\prime} n^{\prime} \frac{n^{\prime} m^{\prime}-1}{2}-n^{\prime} \frac{m^{\prime}+1}{2}+1 .
\]

Si en outre \(\mu^{\prime}=n\), on airra \(n^{\prime}=1\), et
\[
\because=(n-1) \frac{m^{\prime}-1}{2} \text {. }
\]
%169
2. Lorsque toutes les quantités \(h y^{\prime}, h y^{\prime \prime}, \ldots h y^{(n)}\) sont des nombres entiers. Alors on aura
\[
\mu^{\prime}=\mu^{\prime \prime}=\mu^{\prime \prime \prime}=\cdots=\mu^{(\varepsilon)}=1
\]
et si l'on fait de plus
\[
n^{\prime}=n^{\prime \prime}=\cdots=n^{(\varepsilon)}=1
\]
on aura \(\varepsilon=n\), et par conséquent en substituant,
\[
\begin{aligned}
\gamma=(n-1) m^{\prime}+(n-2) m^{\prime \prime} & +(n-3) m^{\prime \prime \prime}+\cdots \\
& +2 m^{(n-2)}+m^{(n-1)}-n+1
\end{aligned}
\]
\[
\begin{aligned}
\hat{\gamma}^{\prime}=(n-1) h y^{\prime}+(n-2) h y^{\prime \prime} & +(n-3) h y^{\prime \prime \prime}+\cdots \\
& +2 h y^{(n-2)}+h y^{(n-1)}-n+1 .
\end{aligned}
\]

Dans le cas où tous les nombres \(h y^{\prime}, h y^{\prime \prime}, \ldots h y^{(n-1)}\) sont égaux entre eux, la valeur de \(\gamma\) deviendra
\[
\gamma=\frac{n(n-1)}{2} h y^{\prime}-n+1=(n-1)\left(\frac{n h y^{\prime}}{2}-1\right)
\]

La formule (59) a généralement lieu pour des valeurs quelconques des quantités \(a, a^{\prime}, a^{\prime \prime}, \ldots\) toutes les fois que la fonction \(r\) n'a pas un facteur de la forme \(F_0 x\); mais dans ce cas elle a encore lieu, sinon \(F_0 x\) et \(\frac{x^{\prime} y}{f_1(x, y)}\) s'évanouissent pour une même valeur de \(x\). Alors la formule dont il s'agit cesse d'avoir lieu, et on aura au lieu d'elle la formule (40), qui deviendra, en faisant \(f_2 x=1\),
\[
\Sigma \int \frac{f_1(x, y) d x}{\chi^{\prime} y}=\left\{\begin{array}{l}
C-\Pi \Sigma \frac{f_1(x, y)}{\chi^{\prime} y} \log \theta y \\
+\Sigma \nu \frac{d^{\nu-1}}{d_\beta \beta^{\nu-1}}\left(\frac{\theta_1 \beta}{\theta_1^{(\nu)} \beta} \Sigma \frac{f_1(\beta, B)}{\chi^{\prime} B} \log \theta B\right),
\end{array}\right.
\]
c'est-à-dire, en remarquant que
\[
I \geq \frac{f_1(x, y)}{\chi^{\prime} y} \log \theta y=0
\]
\[
\Sigma \int \frac{f_1(x, y) d x}{x^{\prime} y}=C+\Sigma \nu \frac{d^{\nu-1}}{d \beta^{\nu-1}}\left(\frac{\theta_1 \beta}{\theta_1^{(\nu) \beta}} \Sigma \frac{f_1(\beta, B)}{x^{\prime} B} \log \theta B\right) .
\]

Maintenant on a (19)
\[
R x=\Sigma \frac{f_1(x, y)}{\chi^{\prime} y} \frac{r}{\theta y} \delta \theta y
\]
%170
d'où il suit que si \(\frac{f_1(x, y)}{\chi^{\prime} y}\) conserve une valeur finie pour \(x=\beta_1\), la fonction entière \(R x\) aura \(\left(x-\beta_1\right)^{\mu_1}\) pour facteur, donc
\[
k_1=\mu_1 \quad \text { et } \quad \nu_1=\mu_1-k_1=0 .
\]

Par là on voit que, dans le second membre de l'équation précédente, tous les termes relatifs à des valeurs de \(\beta\), qui ne rendent point infinie la valeur de \(\frac{f_1(\beta, B)}{\chi^{\prime} B}\), s'évanouiront; par conséquent ledit nombre se réduit à une constante, si \(F_0 x\) n'a pas de facteur commun avec \(\frac{\chi^{\prime} y}{f_1(x, y)}\).
6.
Reprenons maintenant la formule générale (14), et considérons les fonctions \(x_1, x_2, x_3, \ldots x_\mu\). Ces quantités sont données, par l'équation \(F x=0\), en fonctions des quantités indépendantes \(a, a^{\prime}, a^{\prime \prime}\), etc.; soient
\[
x_1=f_1\left(a, a^{\prime}, a^{\prime \prime}, \ldots\right) ; x_2=f_2\left(a, a^{\prime}, a^{\prime \prime}, \ldots\right) ; \ldots x_\mu=f_\mu\left(a, a^{\prime}, a^{\prime \prime}, \ldots\right) .
\]

Si maintenant on désigne par \(\alpha\) le nombre des quantités \(a, a^{\prime}, a^{\prime \prime}, \ldots\) on peut en général tirer de ces équations les valeurs de \(a, a^{\prime}, a^{\prime \prime}, \ldots\) en fonctions d'un nombre \(\alpha\) des quantités \(x_1, x_2 \ldots x_\mu\); par exemple, en fonctions de \(x_1, x_2, \ldots x_\alpha\). En substituant les valeurs de \(a, a^{\prime}, a^{\prime \prime}, \ldots\) ainsi déterminées, dans les expressions de \(x_{\alpha+1}, x_{\alpha+2}, \ldots x_\mu\), ces dernières quantités deviendront des fonctions de \(x_1, x_2, \ldots x_\alpha\); et alors celles-ci seront indéterminées. La formule (14) deviendra donc
\[
v=\left\{\begin{aligned}
\psi_1 x_1+\psi_2 x_2 & +\cdots+\psi_\alpha x_\alpha \\
& +\psi_{\alpha+1} x_{\alpha+1}+\psi_{\alpha+2} x_{\alpha+2}+\cdots+\psi_\mu x_\mu,
\end{aligned}\right.
\]
où \(x_1, x_2, \ldots x_\alpha\) sont des quantités quelconques, \(x_{\alpha+1}, x_{\alpha+2}, \ldots x_\mu\) des fonctions algébriques de \(x_1, x_2, \ldots x_\alpha\), et \(v\) une fonction algébrique et logarithmique des mêmes quantités.

Les quantités \(a, a^{\prime}, a^{\prime \prime}, \ldots\) et \(x_{\alpha+1}, x_{\alpha+2}, \ldots x_\mu\) se trouvent de la manière suivante. Les équations (7) domnent les suivantes:
\[
\theta y_1=0, \theta y_2=0, \ldots \theta y_\alpha=0
\]
qui toutes sont linéaires par rapport aux quantités \(a, a^{\prime}, a^{\prime \prime}, \ldots\) Elles donneront done ces quantités en fonctions rationnelles de \(x_1, y_1 ; x_2, y_2 ; x_3, y_3\);
%171
\(\ldots x_\alpha, y_\alpha\). Maintenant si l'on substitue ces fonctions au lieu de \(a, a^{\prime}, a^{\prime \prime}, \ldots\) dans l'équation \(F x=0\), la fonction \(F x\) deviendra divisible par le produit \(\left(x-x_1\right)\left(x-x_2\right) \cdots\left(x-x_\alpha\right)\); car on a
\[
F x=B\left(x-x_1\right)\left(x-x_2\right) \cdots\left(x-x_\alpha\right)\left(x-x_{\alpha+1}\right) \cdots\left(x-x_\mu\right) .
\]

En désignant donc le quotient \(\frac{F x}{\left(x-x_1\right)\left(x-x_2\right) \cdots\left(x-x_\alpha\right)}\) par \(F^{(1)} x\), l'équation
\[
F^{(1)} x=0
\]
sera du degré \(\mu-\alpha\), et aura pour racines les quantités \(x_{\alpha+1}, \ldots x_\mu\). Quant aux coefficients de cette équation, il est aisé de voir qu'ils seront des fonctions rationnelles des quantités
\[
x_1, y_1 ; x_2, y_2 ; \ldots x_\alpha, y_\alpha \text {. }
\]

De cette manière donc les, \(\boldsymbol{\mu}-\boldsymbol{\alpha}\) quantités \(x_{\alpha+1}, \ldots x_\mu\) sont déterminées en fonctions de \(x_1, x_2, \ldots x_\alpha\) par une même équation du \((\mu-\alpha)^e\) degré.

Les équations (71) sont en général en nombre suffisant pour déterminer les \(\alpha\) quantités \(a, a^{\prime}, a^{\prime \prime}, \ldots\), mais il \(\mathrm{y}\) a un cas où plusicurs d'entre elles deviendront identiques. C'est ce qui arrive lorsqu'on a à la fois
\[
x_1=x_2=\cdots=x_k ; y_1=y_2=\cdots=y_k
\]
car alors
\[
\theta y_1=\theta y_2=\cdots=\theta y_k \text {. }
\]

Or dans ce cas on aura, d'après les principes du calcul différentiel, au lieu des \(k\) équations identiques,
\[
\theta y_1=0, \quad \theta y_2=0, \ldots, \theta y_k=0
\]
les suivantes
\[
\theta_{y_1}=0, \quad \frac{d \theta y_1}{d x_1}=0, \quad \frac{d^2 \theta y_1}{d x_1^2}=0, \cdots \frac{d^k \theta y_1}{d x_1^k}=0
\]
qui, jointes aux équations
\[
\theta y_{k+1}=0, \ldots \theta y_\alpha=0
\]
détermineront les valeurs de \(a, a^{\prime}, \ldots a^{(\alpha-1)}\).
La formule (70) montre qu'on peut exprimer une somme quelconque de la forme
\[
\psi_1 x_1+\psi_2 x_2+\cdots+\psi_\alpha x_u
\]
%172
par une fonction connue \(v\) et une somme semblable d'antres fonctions; en effet elle donnera
\[
\psi_1 x_1+\psi_z x_2+\cdots+\psi_u x_\alpha=v-\left(\psi_{\mu+1} x_{\mu+1}+\cdots+\psi_\mu x_\mu\right) .
\]
7.

Dans cette formule le nombre des fonctions \(\psi_{\alpha+1} x_{\alpha+1}, \psi_{\alpha+2} x_{\alpha+2}, \ldots \psi_\mu x_\mu\) est très-remarquable. Plus il est petit, plus la formule est simple. Nous allons, dans ce qui suit, chercher la moindre valeur dont ce nombre, qui est exprimé par,\(\mu-\alpha\), est susceptible.

Si la fonction \(F_0 x\) se réduit à l'unité, tous les coefficients dans les fonctions \(q_0, q_1, q_2, \ldots q_{n-1}\) seront arbitraires; dans ce cas done on aura (en remarquant que, d'après la forme des équations (71), un des coefficients dans les fonctions \(q_0, q_1, \ldots\) pent être pris à volonté sans nuire à la généralité),
\[
\alpha=h q_0+h q_1+h q_2+\cdots+h q_{n-1}+n-1
\]

Si \(F_0^{\prime} x\) n'est pas égal à l'unité, il faut en geénéral uu nombre \(h F_0 x\) de conditions différentes pour que l'équation
\[
F_0 x \cdot F x=r
\]
soit satisfaite; mais la forme particulière de la fonction y pourrait rendre moindre ce nombre de conditions nécessaires. Supposons donc qu’il soit égal à
\[
h F_0 x-A
\]
le nombre des quantités indéterminées \(a, a^{\prime}, a^{\prime \prime}, \ldots\) deviendra
\[
\alpha=h q_0+h q_1+h q_2+\cdots+h q_{n-1}+n-1-h F_0 x+A
\]
maintenant on a
done
\[
h r=h F_0 x+h F x=h F_0 x+\mu
\]
\[
\mu=h r-h F_0 x
\]
et par conséquent
\[
, \prime-\alpha=h r-\left(h q_0+h q_1+h q_2+\cdots+h q_{n-1}\right)-n+1-A .
\]
%173
Mais comme on a (3)
il est clair que
\[
r=\theta y^{\prime} \cdot \theta y^{\prime \prime} \ldots \theta y^{(n)}
\]
\[
h r=h \theta y^{\prime}+h \theta y^{\prime \prime}+\cdots+h \theta y^{(n)}
\]
done:
\[
\begin{aligned}
\mu-\alpha=h \theta y^{\prime}+h \theta y^{\prime \prime}+\cdots+h \theta y^{(n)} \\
\\
\quad-\left(h q_0+h q_1+\cdots+h q_{n-1}\right)-n+1-A .
\end{aligned}
\]

Ayant maintenant (2)
\[
\theta y=q_0+q_1 y+q_2 y^2+\cdots+q_{n-1} y^{n-1},
\]
on aura nécessairement, pour toutes les valeurs de \(m\),
\[
\boldsymbol{h} \theta y>h\left(q_m, y^m\right)
\]
où le signe > n'exclut pas l'égalité.
Donc en faisant
et remarquant que
\[
y=y^{\prime}, y^{\prime \prime}, y^{\prime \prime \prime}, \ldots y^{(n)}
\]
on aura aussi
\[
h\left(q_m y^m\right)=h q_m+m h . y
\]
(81) \(h \boldsymbol{\theta} y^{\prime}>h q_m+m h y^{\prime} ; h \boldsymbol{\theta} y^{\prime \prime}>h q_m+m h y^{\prime \prime}, \ldots h \boldsymbol{\theta} y^{(n)}>h q_m+m h y^{(n)}\).

Cela posé, désignons par \(n^{\prime}, m^{\prime}, u^{\prime}, k^{\prime} ; n^{\prime \prime}, m^{\prime \prime}, u^{\prime \prime}, k^{\prime \prime}\); etc. les mêmes choses que plus haut dans le numéro (5), et supposons que \(h\left(q_{0_1}, y^{\prime o_1}\right)\) soit la plus grande des \(n^{\prime} u^{\prime}\) quantités
\[
\eta_l\left(q_{n-1} y^{\prime n-1}\right) ; h\left(q_{n-2} y^{\prime n-2}\right) ; \ldots h\left(q_{n-k^{\prime}} y^{\prime n-k^{\prime}}\right),
\]
en sorte que
\[
h q_{o_{,}}+\varrho_1 h y^{\prime}>h q_{n-\beta-1}+(n-\beta-1) h y^{\prime} .
\]

En désignant, pour abréger, \(h q_m\) par \(f m\), et mettant \(\frac{m^{\prime}}{\mu^{\prime}}\) au lieu de \(h y^{\prime}\), il est clair que cette formule donne
\[
\begin{aligned}
& f \varrho_1-f(n-\beta-1)=\left(n-\beta-1-\varrho_1\right) \frac{m^{\prime}}{\mu^{\prime}}+\varepsilon_\beta^{\prime}+A_\beta^{\prime}
\end{aligned}
\]
(depuis \(\beta=0\), jusqu'à \(\beta=k^{\prime}-1\) ),
où \(A_\beta^{\prime}\) est un nombre positif moindre que l'unité, et \(\varepsilon_\beta^{\prime}\) un nombre entier positif, zéro y compris.
soient de même
%174
\[
\begin{aligned}
& f \varrho_2-f(n-\beta-1)=\left(n-\beta-1-\varrho_2\right) \frac{m^{\prime \prime}}{\mu^{\prime \prime}}+\varepsilon_\beta^{\prime \prime}+A_\beta^{\prime \prime} \\
& \text { (depuis } \beta=k^{\prime} \text {, jusqu'd } \beta=k^{\prime \prime}-1 \text { ), } \\
& f \varrho_3-f(n-\beta-1)=\left(n-\beta-1-\varrho_3\right) \frac{m^{\prime \prime \prime}}{\mu^{\prime \prime \prime}}+\varepsilon_\beta^{\prime \prime \prime}+A_\beta^{\prime \prime \prime} \\
& \text { (depuis } \beta=k^{\prime \prime} \text {, jusqu'à } \beta=k^{\prime \prime \prime}-1 \text { ), } \\
& \text { etc., } \\
& f \varrho_m-f(n-\beta-1)=\left(n-\beta-1-\varrho_m\right) \frac{m^{(m)}}{\mu^{(m)}}+\varepsilon_\beta^{(m)}+A_\beta^{(m)} \\
& \text { (depuis } \beta=k^{(m-1)} \text {, jusqu'à } \beta=k^{(m)}-1 \text { ), } \\
& f \boldsymbol{\vartheta}_{\varepsilon}-f(n-\beta-1)=\left(n-\beta-1-\varrho_{\varepsilon}\right) \frac{m^{(\varepsilon)}}{\boldsymbol{\mu}^{(\varepsilon)}}+\varepsilon_\beta^{(\varepsilon)}+A_\beta^{(\varepsilon)} \\
& \text { - (depuis } \beta=k^{(\varepsilon-1)} \text {, jusqu'à } \beta=n-1 \text { ). } \\
&
\end{aligned}
\]
etc.,
\[
\begin{aligned}
f \hat{\vartheta}_{\varepsilon}-f(n-\beta-1)= & \left(n-\beta-1-\varrho_{\varepsilon}\right) \frac{m^{(\varepsilon)}}{\mu^{(\varepsilon)}}+\varepsilon_\beta^{(\varepsilon)}+A_\beta^{(\varepsilon)} \\
& -\left(\text { depuis } \beta=k^{(\varepsilon-1)}, \text { jusqu'à} \beta=n-1\right) .
\end{aligned}
\]
\(A_\beta{ }^{\prime \prime}, A_\beta{ }^{\prime \prime \prime}, \ldots A_\beta^{\left({ }^{(\varepsilon)}\right.}\) étant des nombres positifs et moindres que l'unité, et \(\varepsilon_\beta{ }^{\prime \prime}, \varepsilon_\beta{ }^{\prime \prime \prime}\), etc. des nombres entiers positifs, en y comprenant zéro.

Considérons l'une quelconque de ces équations, par exemple la \((m-1)^{\text {e }}\); en domnant à \(\beta\) les \(k^{(m)}-k^{(m-1)}\) valeurs,
\[
\beta=k^{(m-1)}, k^{(m-1)}+1, k^{(m-1)}+2, \ldots k^{(m)}-1,
\]
on obtiendra un nombre \(k^{(m)}-k^{(m-1)}\) d'équations semblables; et en les ajoutant il viendra
\[
\begin{aligned}
& \left(k^{(m)}-k^{(m-1)}\right)\left(f \varrho_m+\varrho_m \frac{m^{(m)}}{\mu^{(m)}}\right)= \\
& \text { Or } \quad \begin{array}{c}
\frac{1}{2}\left(2 n-k^{(m)}-k^{(m-1)}-1\right)\left(k^{(m)}-k^{(m-1)}\right) \frac{m^{(m)}}{\mu^{(m)}} \\
+A_0^{(m)}+A_1^{(m)}+\cdots+A_{k^{(m)}-k^{(m-1)}-1}^{(m)} \\
+\varepsilon_0^{(m)}+\varepsilon_1^{(m)}+\cdots+\varepsilon_{k^{(m)}-k^{(m-1)}-1}^{(m-1)}+\cdots \\
+f\left(n-1-k^{(m-1)}\right)+f\left(n-2-k^{(m-1)}\right)+\cdots \\
+f\left(n-k^{(m)}\right) .
\end{array} \\
& \quad k^{(m)}-k^{(m-1)}=n^{(m)} \mu^{(m)},
\end{aligned}
\]

Or
\[
k^{(m)}-k^{(m-1)}=n^{(m)} \boldsymbol{\mu}^{(m)}
\]
done en substituant,
%175
Or, en remarquant que \(A_\beta^{(m)}\) est le nombre, moindre que l'unité, qui, ajouté à \(\left(n-\beta-1-\varrho_n\right) \frac{m^{(m)}}{\mu^{(m)}}\), rend cette quantité égale à un nombre entier, on voit sans peine que la suite
\[
A_0^{(m)}+A_1^{(m)}+\cdots+A_{n^{(m)} \mu^{(m)}-1}^{(n)},
\]
qui est composée de \(n^{(m)} \boldsymbol{\mu}^{(m)}\) termes, contiendra \(n^{(m)}\) fois la suite des nombres
done
\[
\frac{0}{\mu^{(m)}}, \frac{1}{\mu^{(m)}}, \frac{2}{\mu^{(m)}}, \ldots \frac{\mu^{(m)}-1}{\mu^{(m)}}
\]
\[
\begin{aligned}
A_0^{(m)}+A_1^{(m)}+\cdots+A_{n^{(m)} \mu^{(m)}-1}^{(n)} & =\frac{\boldsymbol{u}^{(n)}\left(0+1+\cdots+\mu^{(m)}-1\right)}{\mu^{(m)}} \\
& =\frac{n^{(m)} \mu^{(m)}\left(\mu^{(m)}-1\right)}{2 \mu^{(m)}}=\frac{1}{2} n^{(m)}\left(\mu^{(m)}-1\right) .
\end{aligned}
\]

En substituant cette valeur, et faisant pour abréger,
il viendra
\[
\varepsilon_0^{(m)}+\varepsilon_1^{(m)}+\cdots+\varepsilon^{(m)}{ }_{n^{(m)} \mu^{(m)}-1}=C_m,
\]
\[
n^{(m)} \boldsymbol{\mu}^{(m)}\left(f \varrho_m+\varrho_m \frac{m^{(m)}}{\mu^{(m)}}\right)=\left\{\begin{array}{l}
\frac{1}{2}\left(2 n-k^{(m)}-k^{(m-1)}-1\right) n^{(m)} m^{(m)} \\
+\frac{1}{2} n^{(m)}\left(\boldsymbol{\mu}^{(m)}-1\right)+C_m \\
+f\left(n-k^{(m-1)}-1\right)+\cdots+f\left(n-k^{(m)}\right) .
\end{array}\right.
\]

Maintenant on a, en désignant \(h \theta y^{(m)}\) par \(\varphi m\),
\[
\text { (87) } \quad \varphi\left(k^{(m-1)}+1\right)=\varphi\left(k^{(m-1)}+2\right)=\varphi\left(k^{(m-1)}+3\right)=\cdots=\varphi\left(k^{(m)}\right) \text {; }
\]
en remarquant que \(h y^{(m)}\) conserve la même valeur pour toutes les valeurs de \(m\), de \(k^{(m-1)}+1\) à \(k^{(m)}\). Les inégalités (81) domneront donc
\[
\begin{aligned}
\varphi\left(k^{(m-1)}+1\right) & +\varphi\left(k^{(m-1)}+2\right)+\varphi\left(k^{(m-1)}+3\right)+\cdots+\varphi\left(k^{(m)}\right) \\
& >\left(f \varrho_m+\varrho_m \frac{m^{(m)}}{\mu^{(m)}}\right)\left(k^{(m)}-k^{(m-1)}\right)>n^{(m)} \mu^{(m)}\left(f \varrho_m+\varrho_m \frac{m^{(m)}}{\mu^{(m)}}\right)
\end{aligned}
\]
donc on aura, en vertu de l'équation précédente,
\[
\begin{aligned}
\varphi\left(k^{(m-1)}+1\right)+\left(\varphi\left(k^{(m-1)}+2\right)+\varphi\left(k^{(m-1)}+3\right)+\cdots+\varphi\left(k^{(m)}\right)\right. \\
>>\left\{\begin{array}{l}
\frac{1}{2} n^{(m)} m^{(m)}\left(2 n-k^{(m)}-k^{(m-1)}-1\right)+\frac{1}{2} n^{(m)}\left(\mu^{(m)}-1\right)+C_m \\
+f\left(n-k^{(m-1)}-1\right)+f\left(n-k^{(m-1)}-2\right)+\cdots+f\left(n-k^{(m)}\right) .
\end{array}\right.
\end{aligned}
\]

En faisant dans cette formule successivement \(m=1,2,3, \ldots\) et puis ajoutant les équations qu'on obtiendra, il viendra
%176
\[
\begin{aligned}
\varphi(1)+\varphi(2)+\varphi(3)+\cdots+\varphi(n) \\
\quad>\left\{\begin{array}{l}
f(n-1)+f(n-2)+f(n-3)+\cdots+f(1)+f(0) \\
+\frac{1}{2} n^{\prime} m^{\prime}\left(2 n-k^{\prime}-1\right)+\frac{1}{2} n^{\prime}\left(\mu^{\prime}-1\right)+C_1 \\
+\frac{1}{2} n^{\prime \prime} m^{\prime \prime}\left(2 n-k^{\prime \prime}-k^{\prime}-1\right)+\frac{1}{2} n^{\prime \prime}\left(\mu^{\prime \prime}-1\right)+C_{\varepsilon} \\
+\frac{1}{2} n^{\prime \prime \prime} m^{\prime \prime \prime}\left(2 n-k^{\prime \prime \prime}-k^{\prime \prime}-1\right)+\frac{1}{2} n^{\prime \prime \prime}\left(\mu^{\prime \prime \prime}-1\right)+C_3 \\
+\cdots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \\
+\frac{1}{2} n^{(\varepsilon)} m^{(\varepsilon)}\left(2 n-k^{(\varepsilon)}-k^{(\varepsilon-1)}-1\right)+\frac{1}{2} n^{(\varepsilon)}\left(\mu^{(\varepsilon)}-1\right)+C_{\varepsilon} .
\end{array}\right.
\end{aligned}
\]

En substituant les valeurs des quantités \(k^{\prime}, k^{\prime \prime}, k^{\prime \prime \prime}, \ldots\) savoir,
\[
k^{\prime}=n_i^{\prime} u^{\prime} ; k^{\prime \prime}=n_{\prime}^{\prime} u^{\prime}+n^{\prime \prime} u^{\prime \prime} ; k^{\prime \prime \prime}=n^{\prime} u^{\prime}+n^{\prime \prime} u^{\prime \prime}+n^{\prime \prime \prime} u^{\prime \prime \prime} \text {, etc., }
\]
et pour \(n\) sa valeur (55)
on obtiendra
\[
n=n^{\prime} \boldsymbol{u}^{\prime}+n^{\prime \prime} \boldsymbol{u}^{\prime \prime}+\cdots+n^{(\varepsilon)} \boldsymbol{u}^{(\varepsilon)},
\]
\[
\begin{aligned}
h \theta y^{\prime}+h \theta y^{\prime \prime}+h \theta y^{\prime \prime \prime}+ & \cdots+h \theta y^{(n)}-\left(h q_0+h q_1+h q_2+\cdots+h q_{n-1}\right) \\
>\gamma^{\prime} & +C_1+C_2+\cdots+C_{\varepsilon},
\end{aligned}
\]
où l'on a fait pour abréger
\((88)\)
\[
\gamma^{\prime}=\left\{\begin{array}{l}
n^{\prime} m^{\prime}\left(\frac{n^{\prime} \mu^{\prime}-1}{2}+n^{\prime \prime} \mu^{\prime \prime}+n^{\prime \prime \prime} \mu^{\prime \prime \prime}+\cdots+n^{(\varepsilon)} \mu^{(\varepsilon)}\right)+n^{\prime} \frac{\mu^{\prime}-1}{2} \\
+n^{\prime \prime} m^{\prime \prime}\left(\frac{n^{\prime \prime} \mu^{\prime \prime}-1}{2}+n^{\prime \prime \prime} \mu^{\prime \prime \prime}+n^{\prime \prime \prime \prime} \mu^{\prime \prime \prime \prime}+\cdots+n^{(\varepsilon)} \mu^{(\varepsilon)}\right)+n^{\prime \prime} \frac{\mu^{\prime \prime}-1}{2} \\
+\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \\
+n^{(\varepsilon-1)} m^{(\varepsilon-1)}\left(\frac{n^{(\varepsilon-1)} \mu^{(\varepsilon-1)}-1}{2}+n^{(\varepsilon)} \mu^{(\varepsilon)}\right)+n^{(\varepsilon-1)}\left(\frac{\mu^{(\varepsilon-1)}-1}{2}\right) \\
+n^{(\varepsilon)} m^{(\varepsilon)} \frac{n^{(\varepsilon)} \mu^{(\varepsilon)}-1}{2}+n^{(\varepsilon)} \frac{\mu^{(\varepsilon)}-1}{2} .
\end{array}\right.
\]

De cette formule combinée avec l'équation (80) on déduira
\[
\mu-a>\gamma^{\prime}-n+1-A+C_1+C_2+\cdots+C_{\varepsilon} .
\]

Or, je remarque que le nombre \(\gamma^{\prime}-n+1\) est précisément égal à celui que uous avons désigné précédemment par \(\gamma\), équation (62), donc
\[
\mu-\alpha > \gamma-A+ C_1+C_2+\cdots+C_{\varepsilon} \text {. }
\]

Cette formule nous montre que \(\mu-\alpha\) ne peut être moindre que \(\gamma-A\), or je dis qu'il peut être précisément égal à ce nombre.
En effet c'est ce qui arrive lorsqu'on a
%177
(91) \(\left\{\begin{array}{c}\varphi k^{(m)}=f \varrho_m+\varrho_m \frac{m^{(m)}}{\mu^{(m)}}, \\ \text { et } \quad C_1+C_2+C_3+\cdots+C_{\varepsilon}=0\end{array}\right.\)
or on peut démontrer de la manière suivante que ces équations pourront avoir lieu.

En se rappelant la valeur de \(C_m\), il est clair que l'équation (91) entraîne la suivante:
\[
\left.\varepsilon_\beta^{(m)}=0 \text { (depuis } \beta=k^{(m-1)} \text {, jusqu'à } \beta=k^{(m)}-1\right)
\]
donc è vertu des équations (83) et (84)
\[
f(n-\beta-1)=f \varrho_m-\left(n-\beta-1-\varrho_m\right) \frac{m^{(m)}}{\mu^{(m)}}-A_\beta^{(m)},
\]
\[
\text { (depuis } \beta=k^{(m-1)} \text {, jusqu'à } \beta=k^{(m)}-1 \text { ). }
\]

Il s'agit maintenant de trouver la valeur de \(f \varrho_m\).
Or. l'équation (91) donne
\[
f \varrho_m+\varrho_m \frac{m^{(m)}}{\mu^{(m)}}>f \varrho_a+\varrho_\alpha \frac{m^{(m)}}{\mu^{(m)}} .
\]
pour toutes les valeurs de \(m\) et de \(\alpha\).
De là on tire, en désignant pour abréger
\[
\begin{gathered}
\frac{m^{(\alpha)}}{\mu^{(\alpha)}} \text { par } \sigma_\alpha, \\
f \varrho_m-f \varrho_c>\left(\varrho_\alpha-\varrho_m\right) \sigma_m .
\end{gathered}
\]
\[
\begin{gathered}
\frac{m^{(\alpha)}}{\mu^{(\alpha)}} \operatorname{par} \sigma_\alpha \\
f \varrho_m-f \varrho_u>\left(\varrho_\alpha-\varrho_m\right) \sigma_m
\end{gathered}
\]

En faisant \(m=\alpha-1\), et changeant ensuite \(\alpha\) en \(m\), de même que \(\alpha\) en \(m-1\), on obtiendra les deux formules
\[
\left\{\begin{array}{l}
f \varrho_m-f \varrho_{m-1}<\left(\varrho_{m-1}-\varrho_m\right) \sigma_{m-1}, \\
f \varrho_m-f \varrho_{m-1}>\left(\varrho_{m-1}-\varrho_m\right) \sigma_m .
\end{array}\right.
\]

Par là on voit que la différence entre la plus grande et la plus petite valeur de \(f \varrho_m-f \varrho_{m-1}\) ne peut surpasser \(\left(\varrho_{m-1}-\varrho_m\right)\left(\sigma_{m-1}-\sigma_m\right)\). Par conséquent on doit avoir
\[
f \varrho_m-f \varrho_{m-1}=\left(\varrho_{m-1}-\varrho_m\right) \sigma_m+\theta_{m-1}\left(\varrho_{m-1}-\varrho_m\right)\left(\sigma_{m-1}-\sigma_m\right),
\]
où \(\theta_{m-1}\) est une quantité positive qui ne peut surpasser l'unité.
Cette équation peut s'écrire comme il suit:
\[
f \varrho_m-f \varrho_{m-1}=\left(\varrho_{m-1}-\varrho_m\right)\left[\theta_{m-1} \sigma_{m-1}+\left(1-\boldsymbol{\theta}_{m-1}\right) \sigma_m\right] .
\]
%178
De là on tire sans peine
\[
f \varrho_m=\left\{\begin{array}{l}
f \varrho_1+\left(\varrho_1-\omega_2\right)\left[\theta_1 \sigma_1+\left(1-\theta_1\right) \sigma_2\right] \\
+\left(\varrho_2-\varrho_3\right)\left[\theta_2 \sigma_2+\left(1-\theta_2\right) \sigma_3\right]+\cdots \\
\cdots+\left(\varrho_{m-1}-\varrho_m\right)\left[\theta_{m-1} \sigma_{m-1}+\left(1-\theta_{m-1}\right) \sigma_m\right]
\end{array}\right.
\]

Si \(f_{\varrho_m}\) a cette valeur, il n'est pas difficile de voir que la condition
\[
f \boldsymbol{\varphi}_m-f \boldsymbol{\varrho}_\alpha>\left(\boldsymbol{\omega}_\alpha-\boldsymbol{\varphi}_m\right) \sigma_m
\]
est satisfaite pour toute valeur de \(\alpha\) et \(m\), quelle que soit la valenr de \(f \varrho_1\) et celles des quantités \(\boldsymbol{\theta}_1, \boldsymbol{\theta}_2, \cdots \boldsymbol{\theta}_{m-1}\), pourvu qu'elles ne surpassent pas l'unité.

Connaissant ainsi la valeur de \(f \varrho_m\), on aura celle de \(f(n-\beta-1)\) par l'équation (92).

Après avoir de cette manière déterminé les valeurs de toutes les quantités \(f(0), f(1), f(2), \ldots f(n-1)\), voyons à présent si elles satisfont en effet ì l'équation (91)
\[
\varphi k^{(m)}=f \varrho_m+\varrho_m \frac{m^{(m)}}{\mu^{(m)}}=f \varrho_m+\varrho_m \sigma_m .
\]

Pour que cette équation ait lieu, il est nécessaire et il suffit que l'équation
\[
f \varrho_m+\varrho_{m s} \sigma_m>f \alpha+\alpha \sigma_m
\]
soit satisfaite pour toutes les valeurs de \(\alpha\) et \(m\). Il faut done que
\[
P_m^{(\delta)}=f \varrho_m-f \alpha_\delta+\left(\varrho_m-\alpha_\delta\right) \sigma_m>0 .
\]

Soit \(\alpha_\delta=n-\beta-1\), où \(\beta\) a une valeur quelconque comprise entre \(k^{(\delta-1)}\) et \(k^{(8)}-1\) inclusivement, l'équation (92) domnera
\[
f \alpha_\delta=f \omega_\delta-\left(\alpha_\delta-\rho_\delta\right) \sigma_\delta-A_\beta^{(\delta)}
\]
et par conséquent
\[
P_m^{(\delta)}=f \varrho_m-f \varrho_\delta+\left(\varrho_m-\alpha_\delta\right) \sigma_m+\left(\alpha_\delta-\varrho_\delta\right) \sigma_\delta+A_\beta^{(\delta)} .
\]

En mettant \(m+1\) au lieu de \(m\), il viendra
\[
P_{m+1}^{(\delta)}-P_m^{(\delta)}=f \varrho_{m+1}-f \varrho_m+\varrho_{m+1} \sigma_{m+1}-\varrho_m \sigma_m+\alpha_\delta\left(\sigma_m-\sigma_{m+1}\right) .
\]

On a par l'équation (97)
\[
f \varrho_{m+1}-f \varrho_m=\left(\varrho_m-\varrho_{m+1}\right)\left[\theta_m \sigma_m+\left(1-0_m\right) \sigma_{m+1}\right] ;
\]
done, en substituant et réduisant,
\[
P_{m+1}^{(\delta)}-P_m^{(\delta)}=\left(\alpha_\delta-\left[\varrho_m\left(1-\theta_m\right)+\varrho_{m+1} \theta_m\right]\right)\left(\sigma_m-\sigma_{m+1}\right)
\]
%179
or, en remarquant que \(\alpha_\delta\) est compris entre \(n-1-k^{(\delta-1)}\) et \(n-k^{(\delta)}\), que \(n-k^{(m+1)}\), il est clair que le second membre de cette équation sera toujours positif si \(m>\delta+1\), et toujours négatif si \(m \overline{<} \delta-2\).

De là il suit: \(1^0\) que \(P_{m+1+\delta}>0\) si \(P_{\delta+1}>0 ; 2^0\) que \(P_{\delta-1-m}>0\) si \(P_{\delta-1}>0\). Donc pour que \(P_m^{(\delta)}\) soit positif pour toutes les valeurs de \(m\), il suffit qu'il le soit pour \(m=\delta+1, \delta, \delta-1\).
Or, en faisant dans l'équation (102) \(m=\delta, m=\delta-1\), il viendra
\[
\begin{aligned}
& P_{\delta+1}^{(\delta)}-P_\delta^{(\delta)}=\left(\alpha_\delta-\left[\varrho_\delta\left(1-\theta_\delta\right)+\varrho_{\delta+1} \theta_\delta\right]\right)\left(\sigma_\delta-\sigma_{\delta+1}\right), \\
& P_\delta^{(\delta)}-P_{\delta-1}^{(\delta)}=\left(\alpha_\delta-\left[\rho_{\delta-1}\left(1-\theta_{\delta-1}\right)+\omega_\delta \theta_{\delta-1}\right]\right)\left(\sigma_{\delta-1}-\sigma_\delta\right) .
\end{aligned}
\]

Mais l'équation (101) donne pour \(m=\delta\),
\[
P_\delta^{(\delta)}=A_\beta^{(\delta)}
\]
donc \(P_\delta^{(\delta)}\) est toujours positif, et en substituant cette valeur, les deux équations précédentes donneront, en mettant \(\delta+1\) au lieu de \(\delta\) dans la dernière,
\[
\begin{aligned}
P_{\delta+1}^{(\delta)} & =\left[\alpha_\delta-\omega_\delta+\theta_\delta\left(\omega_\delta-\omega_{\delta+1}\right)\right]\left(\sigma_\delta-\sigma_{\delta+1}\right)+A_\beta^{(\delta)} \\
P_\delta^{(\delta+1)} & =\left[\varrho_\delta-\alpha_{\delta+1}-\theta_\delta\left(\varrho_\delta-\omega_{\delta+1}\right)\right]\left(\sigma_\delta-\sigma_{\delta+1}\right)+A_\beta^{(\delta+1)}
\end{aligned}
\]

De ces équations on tire (en remarquant qu'on doit avoir pour \(P_{\delta+1}^{(\delta)}\) et \(P_\delta^{(\delta+1)}\) des valeurs positives),
\[
\left\{\begin{array}{l}
\theta_\delta>\frac{\varrho_\delta-\alpha_\delta}{\varrho_\delta-\varrho_{\delta+1}}-\frac{A_\beta^{(\delta)}}{\left(\varrho_\delta-\varrho_{\delta+1}\right)\left(\sigma_\delta-\sigma_{\delta+1}\right)}=B_\delta \\
\theta_\delta<\frac{\rho_\delta-\alpha_{\delta+1}}{\varrho_\delta-\varrho_{\delta+1}}+\frac{A_\beta(\delta+1)}{\left(\varrho_\delta-\varrho_{\delta+1}\right)\left(\sigma_\delta-\sigma_{\delta+1}\right)}=C_\delta
\end{array}\right.
\]

Maintenant \(\theta_\delta\) est compris entre 0 et 1 ; par conséquent il faut que \(B_\delta\) ne surpasse pas l'unité, et que \(C_\delta\) soit positif. Or c'est ce qui a toujours lieu. En effet on trouve
\[
1-B_\delta=\frac{\alpha_\delta-\varrho_{\delta+1}}{\varrho_\delta-\varrho_{\delta+1}}+\frac{A_\beta^{(\delta)}}{\left(\varrho_\delta-\varrho_{\delta+1}\right)\left(\sigma_\delta-\sigma_{\delta+1}\right)}
\]
done \(1-B_\delta\) est toujours positif en remarquant que \(\alpha_\delta>\varphi_{\delta+1}\); par conséquent \(B_\delta\) ne peut surpasser l'unité. De même \(\varrho_\delta>\alpha_{\delta+1}\); done \(C_\delta\) est tolljours positif.
La condition
\[
P_m^{(8)}>0
\]
%180
est donc satisfaite pour toute valeur de \(\delta\) et \(m\); d'où résulte l'équation
\[
\varphi k^{(\delta)}=f \rho_\delta+\rho \delta m^{(\delta)} \text {. }
\]

On aura donc, comme on vient de le dire, (104)
\[
\mu-\alpha=\gamma-A
\]
qui est la moindre valeur que peut avoir \(\mu-\alpha\).
Si l'on suppose que tous les coefficients dans les fonctions \(q_0, q_1, \ldots q_{n-1}\), soient des quantités indéterminées, alors \(F_0 x=1\), et par suite \(A=0\); donc: dans ce cas
\[
\mu-\alpha=\gamma
\]

C'est ce qui a lieu généralement, car c'est seulement pour des fonctions d'une forme particulière que le nombre \(A\) a une valeur plus grande que zéro.

Dans ce qui précède nous avons supposé que tous les coefficients dans \(q_0, q_1, \ldots q_{n-1}\), étaient indéterminés, excepté ceux qui sont déterminés par la condition que \(r\) ait pour diviseur la fonction \(F_0 x\). Dans ce cas on a toujours, comme nous l'avons supposé plus haut (87),
\[
\varphi\left(k^{(m-1)}+1\right)=\varphi\left(k^{(m-1)}+2\right)=\cdots=\varphi\left(k^{(m)}\right)=f \varrho_m+\varrho_m \sigma_m
\]
et par suite
\[
h r=\left\{\begin{aligned}
n^{\prime} \mu^{\prime}\left(f \varrho_1+\varrho_1 \sigma_1\right)+n^{\prime \prime} \mu^{\prime \prime}\left(f \varrho_2+\varrho_2 \sigma_2\right) & +\cdots \\
& +n^{(\varepsilon)} u^{(\varepsilon)}\left(f \varrho_{\varepsilon}+\varrho_{\varepsilon} \sigma_{\varepsilon}\right) .
\end{aligned}\right.
\]

C'est la valeur de \(h r\) en général. Supposons maintenant que les quantités \(a, a^{\prime}, a^{\prime \prime}, \ldots\) ne soient pas toutes indéterminées, mais qu'un certain nombre d'elles soient déterminées par la condition que la valeur de \(h r\) soit de \(A^{\prime}\) unités moindre que la valeur précédente. En général, un nombre \(A^{\prime}\) des quantités \(a, a^{\prime}, a^{\prime \prime}, \ldots\) sera déterminé par cette condition, et alors, \(1-\alpha\) ne change pas de valeur; mais il est possible que, pour les fonctions d'une forme particulière, la condition dont il s'agit n'entraîne qu'un nombre moindre d'équations différentes entre \(a, a^{\prime}, a^{\prime \prime}, \ldots\) Soit donc ce nombre \(A^{\prime}-B\), la valeur de \(\boldsymbol{\mu}-\alpha\) deviendra
c'est-à-dire
\[
\begin{gathered}
\left(\iota-A^{\prime}\right)-\left[\alpha-\left(A^{\prime}-B\right)\right]-A \\
u-\alpha=\gamma-A-B
\end{gathered}
\]
\[
u-\alpha=\gamma-\Lambda-B
\]
%181
8.
Pour donner un exemple de l'application de la théorie précédente, supposons que \(n=13\), en sorte que \(y\) soit déterminé par l'équation
et
\[
0=\left\{\begin{array}{c}
p_0+p_1 y+p_2 y^2+p_3 y^3+p_4 y^4+p_5 y^5+p_6 y^6+p_7 y^7 \\
+p_8 y^8+p_9 y^9+p_{10} y^{10}+p_{11} y^{11}+p_{12} y^{12}+y^{13}
\end{array}\right.
\]
\[
\theta y=q_0+q_1 y+q_2 y^2+\cdots+q_{12} y^{12} .
\]

Supposons que les degrés des fonctions entières
\[
p_0, p_1, p_2, p_3, p_4, p_5, p_6, p_7, p_8, p_9, p_{10}, p_{11}, p_{12}
\]
soient respectivement
\[
2,3,2,3,4,5,3,4,2,3,4,1,1,
\]

I'abord, il faut chercher les valeurs de \(h y^{\prime}, h y^{\prime \prime}, \ldots h y^{(13)}\). Or, pour cela, il suffit de faire dans l'équation proposée,
\[
y=A x^m
\]
et de déterminer ensuite \(A\) et \(m\) de manière que l'équation soit satisfaite pour \(x=\infty\).
On obtiendra l'équation
\[
0=\left\{\begin{aligned}
A^{13} x^{13 m}+B_{12} A^{12} x^{12 m+1} & +B_{11} A^{11} x^{11 m+1}+B_{10} A^{10} x^{10 m+4} \\
& +\cdots+B_2 A^2 x^{2 m+2}+B_1 A x^{m+3}+B_0 x^2 .
\end{aligned}\right.
\]

Pour y satisfaire il faut qu'un certain nombre des exposants soient égaux et en même temps plus grands que les autres, et que la somme des termes correspondants soit égale à zéro.
Or on trouve qu'en faisant
\(1^0 13 m=10 m+4\), d'où \(m=\frac{4}{3}\), les deux exposants \(13 m, 10 m+4\), \(2^0 \quad 10 m+4=5 m+5\), d'où \(m=\frac{1}{5}\), seront les plus grands; \(3^0 \quad 5 m+5=m+3\), d'où \(m=-\frac{1}{2}\), \(10 m+4,5 m+5\) \(5 m+5, \quad m+3\) \(m^3+3,2\) \(4^0 \quad m+3=2\), d'où \(m=-1\), On a donc
\[
y=\stackrel{4}{A x^3}, A^{13}+B_{10} A^{10}=0,
\]
%182
donc
\[
\begin{gathered}
A=-\sqrt[3]{B_{10}} \text { et } h y^{\prime}=h y^{\prime \prime}=h y^{\prime \prime \prime}=\frac{m^{\prime}}{\mu^{\prime}}=\frac{4}{3}, n^{\prime}=1 ; \\
y=A x^{\frac{1}{5}}, B_{10} A^{10}+B_5 A^5=0,
\end{gathered}
\]
done
\[
\begin{gathered}
A=-\sqrt[5]{\frac{B_5}{B_{10}}} \text { et } h y^{(3)}=h y^{(5)}=h y^{(6)}=h y^{(7)}=h y^{(8)}=\frac{m^{\prime \prime}}{\mu^{\prime \prime}}=\frac{1}{5}, n^{\prime \prime}=1 ; \\
y=A x^{-\frac{1}{2}}, B_5 A^5+B_1 A=0,
\end{gathered}
\]
done
\[
\begin{gathered}
A=\sqrt[4]{-\frac{B_1}{B_5}} \text { et } h y^{(9)}=h y^{(10)}=h y^{(11)}=h y^{(12)}=\frac{m^{\prime \prime \prime}}{\mu^{\prime \prime \prime}}=\frac{-1}{2}, n^{\prime \prime \prime}=2 ; \\
y=A x^{-1}, B_1 A+B_0=0,
\end{gathered}
\]
done
\[
A=-\frac{B_0}{B_1} \text { et } h y^{(13)}=\frac{m^{\prime \prime \prime \prime}}{\mu^{\prime \prime \prime \prime}}=-1, n^{\prime \prime \prime \prime}=1 .
\]

Ayant ainsi trouvé les valeurs des nombres \(m^{\prime}, u^{\prime}, n^{\prime}, m^{\prime \prime}, \mu^{\prime \prime}, n^{\prime \prime}\), \(m^{\prime \prime \prime}, \prime^{\prime \prime \prime}, n^{\prime \prime \prime}, m^{\prime \prime \prime \prime}, u^{\prime \prime \prime \prime}, n^{\prime \prime \prime \prime}\), on aura
\[
\begin{gathered}
k^{\prime}=n^{\prime} \mu^{\prime}=3, k^{\prime \prime}=n^{\prime} \mu^{\prime}+n^{\prime \prime} \mu^{\prime \prime}=8, k^{\prime \prime \prime}=n^{\prime} \mu^{\prime}+n^{\prime \prime} u^{\prime \prime}+n^{\prime \prime \prime} u^{\prime \prime \prime}=12, \\
k^{\prime \prime \prime \prime}=n^{\prime} \mu^{\prime}+n^{\prime \prime} \mu^{\prime \prime}+n^{\prime \prime \prime} \mu^{\prime \prime \prime}+n^{\prime \prime \prime \prime} \mu^{\prime \prime \prime \prime}=13=n .
\end{gathered}
\]

Maintenant le nombre \(\varrho_1\) doit être compris entre \(n-1\) et \(n-k^{\prime}, \varrho_2\) entre \(n-k^{\prime}-1\) et \(n-k^{\prime \prime}\), etc.; done on trouvera pour ces quantités, les valeurs suivantes:
\[
\varrho_1=12,11,10, \varrho_2=9,8,7,6,5, \quad \varrho_3=4,3,2,1, \quad \varrho_4=0 .
\]

Comnaissant \(\varrho_1, \varrho_2, \varrho_3, \varrho_4\), on aura \(A_\beta^{\prime}, A_\beta^{\prime \prime}, A_\beta^{\prime \prime \prime}, A_\beta^{\prime \prime \prime \prime}\) par l'équation (92); ensuite \(\theta_1, \theta_2, \theta_3, \theta_4\) par les équations (103); \(f \varrho_2, f \varrho_3, f \varrho_4\) par l'équation (98); et enfin \(f(0), f(1), f(2), \ldots f(12)\) par l'équation (92).

La valeur de \(\gamma\), qui est toujours la même, deviendra par l'équation (88) et la relation \(y^{\prime}=\gamma^{\prime}-n+1\),
\[
y=\left\{\begin{array}{l}
1 \cdot 4 \cdot\left(\frac{3-1}{2}+5+4+1\right)+1 \cdot \frac{3-1}{2} \\
+1 \cdot 1 \cdot\left(\frac{5-1}{2}+4+1\right)+1 \cdot \frac{5-1}{2} \\
+2 \cdot(-1) \cdot\left(\frac{4-1}{2}+1\right)+2 \cdot \frac{2-1}{2} \\
+1 \cdot(-1) \cdot\left(\frac{1-1}{2}\right)+1 \cdot \frac{1-1}{2}-13+1
\end{array}\right.
\]
%183
c'est-à-dire, en réduisant,
\[
\gamma=38 .
\]

Pour pouvoir déterminer numériquement les valeurs de \(\alpha\) et de " , supposons, par exemple,
\[
\varrho_1=11, \quad \varrho_2 \doteq 6, \varrho_3=4, \quad \varrho_4=0 .
\]

Alors l'équation (92) donnera les suivantes:
\[
\begin{aligned}
& f(12)=f(11)-\frac{4}{3}-A_0{ }^{\prime}, \text { donc } A_0{ }^{\prime}=\frac{2}{3}, f(12)=f(11)-2 \\
& f(10)=f(11)+\frac{4}{3}-A_2{ }^{\prime}, \text { donc } A_2{ }^{\prime}=\frac{1}{3}, f(10)=f(11)+1 \\
& f(9)=f(6)-\frac{3}{5}-A_3{ }^{\prime \prime}, \text { donc } A_3{ }^{\prime \prime}=\frac{2}{5}, f(9)=f(6)-1 \\
& f(8)=f(6)-\frac{2}{5}-A_4{ }^{\prime \prime}, \text { donc } A_4{ }^{\prime \prime}=\frac{3}{5}, f(8)=f(6)-1 \\
& f(7)=f(6)-\frac{1}{5}-A_5{ }^{\prime \prime}, \text { donc } A_5{ }^{\prime \prime}=\frac{4}{5}, f(7)=f(6)-1 \\
& f(5)=f(6)+\frac{1}{5}-A_7^{\prime \prime}, \text { donc } A_7^{\prime \prime}=\frac{1}{5}, f(5)=f(6) \\
& f(3)=f(4)-\frac{1}{2}-A_9{ }^{\prime \prime \prime}, \text { donc } A_9{ }^{\prime \prime \prime}=\frac{1}{2}, f(3)=f(4)-1 \\
& f(2)=f(4)-1-A_{10}{ }^{\prime \prime \prime}, \text { donc } A_{10}{ }^{\prime \prime \prime}=0, f(2)=f(4)-1 \\
& f(1)=f(4)-\frac{3}{2}-A_{11}{ }^{\prime \prime \prime}, \text { donc } A_{11}{ }^{\prime \prime \prime}=\frac{1}{2}, f(1)=f(4)-2 .
\end{aligned}
\]

Pour trouver maintenant \(f(0), f(4), f(6), f(11)\), il faut chercher les limites de \(\theta_1, \theta_2, \theta_3, \theta_4\).
Or les équations (103), qui déterminent ces limites, donnent
\[
\begin{aligned}
& \theta_1>\frac{11-\alpha_1}{5}-\frac{3 A_\beta{ }^{\prime}}{17} \text {, d'où } \theta_1>-\frac{1}{5}-\frac{2}{17}, 0, \frac{1}{5}-\frac{1}{17} \text {; } \\
& \theta_1<\frac{11-\alpha_2}{5}+\frac{3 A_\beta^{\prime \prime}}{17} \text {, d'où } \theta_1<\frac{2}{5}+\frac{6}{5.17}, \frac{3}{5}+\frac{9}{5.17} \text {, } \\
& \frac{4}{5}+\frac{12}{5.17}, 1, \frac{6}{5}+\frac{3}{5.17} . \\
&
\end{aligned}
\]

Il suit de là que
\[
\theta_1>\frac{12}{85}, \quad \theta_1<\frac{8}{17} .
\]

On trouve de la même manière
\[
\theta_2>\frac{\check{5}}{14}, \theta_2<1, \theta_3>\frac{1}{2}, \theta_3<1 .
\]

Maintenant l'équation (97) donne
\[
\begin{aligned}
& f \varrho_m-f \varrho_{m-1}>\left(\varrho_{m-1}-\varrho_m\right)\left[\theta^{\prime \prime}{ }_{m-1} \sigma_{m-1}+\left(1-\theta^{\prime \prime}{ }_{m-1}\right) \sigma_m\right], \\
& f \varrho_m-f \varrho_{m-1}<\left(\varrho_{m-1}-\varrho_m\right)\left[\theta_{m-1}^{\prime} \sigma_{m-1}+\left(1-\theta_{m-1}^{\prime}\right) \sigma_m\right],
\end{aligned}
\]
%184
oì \(\theta^{\prime \prime}{ }_{m-1}\) est la plus petite et \(\theta_{m-1}^{\prime}\) la plus grande valeur de \(\theta_{m-1}\); donc on trouvera, en faisant,
\[
\begin{gathered}
m=2,3,4 \\
f(6)-f(11)>5 \cdot\left[\frac{1}{8} \cdot \frac{4}{3}+\left(1-\frac{12}{85}\right) \cdot \frac{1}{5}\right]\left(=1+\frac{6}{8}\right) \\
f(6)-f(11)<5 \cdot\left[\frac{8}{17} \cdot \frac{4}{3}+\left(1-\frac{8}{17}\right) \cdot \frac{1}{5}\right]\left(=3+\frac{2}{3}\right) \\
f(4)-f(6)>2 \cdot\left[\frac{5}{14} \cdot \frac{1}{5}-\left(1-\frac{5}{14}\right) \cdot \frac{1}{2}\right]\left(=-\frac{1}{2}\right) \\
f(4)-f(6)<2 \cdot\left[1 \cdot \frac{1}{5}-(1-1) \cdot \frac{1}{2}\right]\left(=\frac{2}{5}\right) \\
f(0)-f(4)>4 \cdot\left[\frac{1}{2} \cdot\left(-\frac{1}{2}\right)+\left(1-\frac{1}{2}\right) \cdot(-1)\right](=-3) \\
f(0)-f(4)<4 \cdot\left[1 \cdot\left(-\frac{1}{2}\right)+(1-1) \cdot(-1)\right](=-2)
\end{gathered}
\]
done on aura pour \(f(6)-f(11), f(4)-f(6), f(0)-f(4)\), les valeurs suivantes:
\[
f(\mathbf{6})-f(11)=2,3, f(4)-f(6)=0, f(0)-f(4)=-3,-2 ;
\]
d'où
\[
\begin{aligned}
f(6) & =f(11)+2, f(11)+3, f(4)=f(11)+2, f(11)+3 \\
f(0) & =f(11)-1, f(11), f(11)+1 ; \\
f(12) & =f(11)-2 ; f(10)=f(11)+1 ; f(9)=f(11)+1, f(11)+2 \\
f(8) & =f(11)+1, f(11)+2 ; f(7)=f(11)+1, f(11)+2 \\
f(5) & =f(11)+2, f(11)+3 ; f(3)=f(11)+1, f(11)+2 \\
f(2) & =f(11)+1, f(11)+2 ; f(1)=f(11), f(11)+1 .
\end{aligned}
\]

En exprimant done toutes ces quantités par \(f(12)\), on voit que les fonctions \(q_{12}, q_{11}, q_{10}, \ldots q_0\), sont respectivement des degrés suivants
(12) (11)
(10)
(9)
(8)
(7)
\[
\theta, \theta+2, \theta+3,[\theta+3, \theta+4],[\theta+3, \theta+4],[\theta+3, \theta+4],
\]
(6)
\[
[\boldsymbol{\theta}+4, \boldsymbol{\theta}+5],[\boldsymbol{\theta}+4, \boldsymbol{\theta}+5],[\boldsymbol{\theta}+4, \boldsymbol{\theta}+5],[\boldsymbol{\theta}+3, \boldsymbol{\theta}+4],
\]
\((0)\)
\[
[\boldsymbol{\theta}+3, \boldsymbol{\theta}+4],[\boldsymbol{\theta}+2, \boldsymbol{\theta}+3],\left[\begin{array}{l}
\boldsymbol{\theta}+1, \boldsymbol{\theta}+2 \\
\boldsymbol{\theta}+2, \boldsymbol{\theta}+3
\end{array}\right]
\]
où \(\theta\) est le degré de la fonction \(q_{12}\).
De là suit que
\[
\begin{array}{r}
a=f(0)+f(1)+\cdots+f(12)+12=13 \theta+47,13 \theta+48 \\
13 \theta+57,13 \theta+58,
\end{array}
\]
%185
et
\[
\begin{aligned}
& \qquad=n^{\prime} \mu^{\prime}\left(f \varrho_1+\varrho_1 \frac{m^{\prime}}{\mu^{\prime}}\right)+n^{\prime \prime} \mu^{\prime \prime}\left(f \varrho_2+\varrho_2 \frac{m^{\prime \prime}}{\mu^{\prime \prime}}\right) \\
& \quad+n^{\prime \prime \prime} \mu^{\prime \prime \prime}\left(f \varrho_3+\varrho_3 \frac{m^{\prime \prime \prime}}{\mu^{\prime \prime \prime}}\right)+n^{\prime \prime \prime \prime} \mu^{\prime \prime \prime \prime}\left(f \varrho_4+\varrho_4 \frac{m^{\prime \prime \prime \prime}}{\mu^{\prime \prime \prime \prime}}\right) \\
& =3\left(f(11)+11 \cdot \frac{4}{5}\right)+5 .\left(f(6)+6 \cdot \frac{1}{5}\right)+4\left(f(4)-4 \cdot \frac{1}{2}\right)+1 .(f(0)-0) ;
\end{aligned}
\]
c'est-ì-dire,
\[
\mu=13 \theta+85,13 \theta+86,13 \theta+95,13 \theta+96 .
\]

La valeur de \(\boldsymbol{\mu}-\alpha\) deviendra donc
\[
\mu-\alpha=38
\]
comme nous avons trouvé plus haut pour la valeur de \(\gamma\).
9.
Par les équations (92) et (98) établies précédemment, on aura les valeurs de toutes les quantités \(f(0), f(1), f(2) \ldots f(n-1)\), exprimées de la manière suivante:
\[
f m=f \varrho_1+M_m
\]
où \(M_m\) est indépendant de \(f \varrho_1\). Cette dernière quantité est entièrement arbitraire. Le nombre des coefficients dans \(q_0, q_1, q_2 \ldots q_{n-1}\), sera donc égal à
\[
n f \varphi_1+M_0+M_1+M_2+\cdots+M_{n-1}
\]
mais \(\alpha\), ou le nombre des quantités indéterminées \(a, a^{\prime}, a^{\prime \prime} \ldots\), est égal au nombre des coefficients déjà mentionnés diminué d'un certain nombre. On aura donc
\[
\alpha=n f \varrho_1+M
\]
où \(M\) est indépendant de \(f \varrho_1\).
De là il suit qu'on peut prendre \(\alpha\) aussi grand qu'on voudra, le nombre : \(-\alpha\) restant toujours le même.

L'équation (74) nous met donc en état d'exprimer une somme d'un nombre queleonque de fonctions données, de la forme \(\psi x\), par une somme d'un nombre déterminé de fonctions. Ie dernier nombre peut toujours être supposé égal à \%, qui, en général, sera sa plus petite valeur.

De la formule (74) on peut en dérluire une autre qui est plus générale encore, et dont elle est un cas particulier.
%186
En effet, soient
(111)
\[
\begin{gathered}
\psi_1 x_1+\psi_2 x_2+\cdots+\psi_\alpha x_\alpha=v-\left(\psi_{\alpha+1} x_{\alpha+1}+\psi_{\alpha+2} x_{\alpha+2}+\cdots+\psi_\mu x_\mu\right) \\
\psi_1^{\prime} x_1^{\prime}+\psi_2^{\prime} x_2^{\prime}+\cdots+\psi_{\alpha^{\prime}}^{\prime} x_{\alpha^{\prime}}^{\prime}= \\
v^{\prime}-\left(\psi_{\alpha^{\prime}+1}^{\prime} x_{\alpha^{\prime}+1}^{\prime}+\psi_{\mu^{\prime}+2}^{\prime} x_{\alpha^{\prime}+2}^{\prime}+\cdots+\psi_{\mu^{\prime}}^{\prime} x_{\mu^{\prime}}^{\prime}\right)
\end{gathered}
\]
où \(\psi_1^{\prime}, \psi_2^{\prime}, \ldots\) sont des fonctions semblables à \(\psi_1, \psi_2, \ldots\)
Supposons, ce qui est permis, que
\[
x_{\alpha^{\prime}}^{\prime}=x_\mu, x_{\alpha^{\prime}-1}^{\prime}=x_{\mu-1}, x_{\alpha^{\prime}-2}^{\prime}=x_{\mu-2}, \ldots x_{\alpha^{\prime}-\mu+\alpha+1}^{\prime}=x_{\alpha+1}
\]
et
\[
\psi_{\alpha^{\prime}}^{\prime} x_{\alpha^{\prime}}^{\prime}=\psi_\mu x_\mu, \psi_{u^{\prime}-1}^{\prime} x_{\mu^{\prime}-1}^{\prime}=\psi_{\mu-1} x_{\mu-1}, \ldots \psi_{\alpha^{\prime}-\mu+\alpha+1}^{\prime} x_{\alpha^{\prime}-\mu+\alpha+1}^{\prime}=\psi_{\alpha+1} x_{a+1}
\]
les équations précédentes donneront
\[
\begin{aligned}
\psi_1 x_1+\psi_2 x_2+\cdots+\psi_c x_\alpha-\psi_1^{\prime} x_1^{\prime}-\psi_2^{\prime} x_2^{\prime}-\cdots-\psi_{\alpha^{\prime}-\mu+\alpha}^{\prime} x_{\alpha^{\prime}-\mu+\alpha}^{\prime} & \\
& =v-v^{\prime}+\psi_{\alpha^{\prime}+1}^{\prime} x_{\alpha^{\prime}+1}^{\prime}+\cdots+\psi_{\mu^{\prime}}^{\prime} x_{\mu^{\prime}}^{\prime}
\end{aligned}
\]
donc en mettant \(V\) au lieu de \(v-v^{\prime}, \alpha^{\prime}\) au lieu de \(\alpha^{\prime}-\mu+\alpha\),
\[
\begin{aligned}
& \psi_1^{\prime \prime}, \psi_2^{\prime \prime}, \ldots \psi_k^{\prime \prime} \text { au lieu de } \psi_{\alpha^{\prime}+1}^{\prime}, \psi_{\alpha^{\prime}+2}^{\prime}, \ldots \psi_{\mu^{\prime}}^{\prime} \\
& x_1^{\prime \prime}, x_2^{\prime \prime}, \ldots x_k^{\prime \prime} \text { au lieu de } x_{\alpha^{\prime}+1}^{\prime}, x_{\alpha^{\prime}+2}^{\prime}, \ldots x_{\mu^{\prime}}^{\prime},
\end{aligned}
\]
et enfin \(k\) au lieu de,\(\prime^{\prime}-\alpha^{\prime}\), il viendra
\[
\begin{aligned}
\psi_1 x_1+\psi_2 x_2+\cdots & +\psi_\alpha x_\alpha-\psi_1^{\prime} x_1^{\prime}-\psi_2^{\prime} x_2^{\prime}-\cdots-\psi_{\alpha^{\prime}}^{\prime} x_{\alpha^{\prime}}^{\prime} \\
& =V+\psi_1^{\prime \prime} x_1^{\prime \prime}+\psi_2^{\prime \prime} x_2^{\prime \prime}+\psi_3^{\prime \prime} x_3^{\prime \prime}+\cdots+\psi_k^{\prime \prime} x_k^{\prime \prime}
\end{aligned}
\]

Le nombre \(k\), qui est égal à \(\iota^{\prime}-\alpha^{\prime}\), est indépendant de \(\alpha\) et \(\alpha^{\prime}\), qui sont des nombres quelconques.
Si l'on suppose
\[
x_1^{\prime \prime}=c_1, x_2^{\prime \prime}=c_2, \ldots x_k^{\prime \prime}=c_k
\]
\(c_1, c_2, \ldots c_k\) étant des constantes, alors la formule (112) deviendra
\[
\text { (114) } \psi_1 x_1+\psi_2 x_2+\cdots+\psi_\alpha x_\alpha-\psi_1^{\prime} x_1^{\prime}-\psi_2^{\prime} x_2^{\prime}-\cdots-\psi_{\alpha^{\prime}}^{\prime} x_{\alpha^{\prime}}^{\prime}=C+V \text {, }
\]
où un nombre \(k\) des quantités \(x_1, x_2, \ldots x_\alpha, x_1^{\prime}, x_2^{\prime}, \ldots x_{u^{\prime}}^{\prime}\) sont fonctions des autres, en vertu des équations (113). Il est clair qu'on peut prendre \(c_1, c_2, \ldots c_k\) de manière que \(C\) deviendra égal à zéro.
Supposons maintenant qu'on ait dans la formule précédente
%187
\[
\left\{\begin{array}{l}
x_1=x_2=x_3=\cdots=x_{\varepsilon_1}=z_1 \\
x_{\varepsilon_1+1}=x_{\varepsilon_1+2}=x_{\varepsilon_1+3}=\cdots=x_{\varepsilon_1+\varepsilon_2}=z_2 \\
x_{\varepsilon_1+\varepsilon_2+1}=x_{\varepsilon_1+\varepsilon_2+2}=\cdots=x_{\varepsilon_1+\varepsilon_2+\varepsilon_3}=z_3 \\
\cdots \cdots \cdots \\
x_{\alpha-\varepsilon_m+1}=x_{\alpha-\varepsilon_m+2}=\cdots \cdots x_\alpha=z_m \\
\psi_1=\psi_2=\cdots=\psi_{\varepsilon_1}=\pi_1 \\
\psi_{\varepsilon_1+1}=\psi_{\varepsilon_1+2}=\cdots=\psi_{\varepsilon_1+\varepsilon_2}=\pi_2, \\
\psi_{\varepsilon_1+\varepsilon_2+1}=\psi_{\varepsilon_1+\varepsilon_2+2}=\cdots=\psi_{\varepsilon_1+\varepsilon_2+\varepsilon_3}=\pi_3 \\
\cdots \cdots \cdots \cdots \\
\psi_{\alpha-\varepsilon_m+1}=\psi_{\alpha-\varepsilon_m+2}=\cdots \cdots \psi_\alpha=\pi_m
\end{array}\right.
\]
en sorte que
\[
\alpha=\varepsilon_1+\varepsilon_2+\cdots+\varepsilon_m .
\]

Supposons les mêmes choses relativement aux quantités \(x_1^{\prime}, x_2^{\prime}, \ldots \psi_1^{\prime}\), \(\psi_2^{\prime}, \ldots \alpha^{\prime}\), en accentuant les lettres \(\varepsilon_1, \varepsilon_2, \ldots \varepsilon_m, z_1, z_2, \ldots z_m, \pi_1, \pi_2\), \(\ldots \pi_m\) et \(m\). Alors la formule (114) deviendra:
\[
\text { (116) } V=\left\{\begin{aligned}
\varepsilon_1 \pi_1 z_1+\varepsilon_2 \pi_2 z_2+\varepsilon_3 \pi_3 z_3+\cdots+\varepsilon_m \pi_m z_m-\varepsilon_1^{\prime} \pi_1{ }^{\prime} z_1^{\prime} & -\varepsilon_2^{\prime} \pi_2{ }^{\prime} z_2{ }^{\prime}-\cdots-\varepsilon_{m^{\prime}}^{\prime} \pi_{m^{\prime}}^{\prime} z_{m^{\prime}}^{\prime},
\end{aligned}\right.
\]
où un nombre \(k\) des fonctions \(\pi_1 z_1, \pi_2 z_2, \ldots \pi_1{ }^{\prime} z_1{ }^{\prime}, \ldots\) dépendent des formes et des valeurs des autres.

En divisant les deux membres de cette équation par un nombre quelconque \(A\) et désignant les nombres rationnels
\[
\frac{\varepsilon_1}{A}, \frac{\varepsilon_2}{A}, \ldots \frac{\varepsilon_m}{A},-\frac{\varepsilon_1^{\prime}}{A},-\frac{\varepsilon_2^{\prime}}{A}, \ldots-\frac{\varepsilon_{m^{\prime}}^{\prime}}{A},
\]
par \(h_1, h_2, h_3, \ldots h_\alpha\), et mettant \(\psi\) an lieu de \(\pi, x\) au lieu de \(z\), et \(v\) au lieu de \(\frac{V}{A}\), il viendra:
\[
h_1 \psi_1 x_1+h_2 \psi_2 x_2+\cdots+h_\alpha \psi_\alpha x_\alpha=v
\]
où il est clair que \(h_1, h_2, \ldots h_\alpha\) peuvent être des nombres rationnels quelconques, positifs on négatifs.

En remarquant que \(k\) des quantités \(x_1, x_2, \ldots x_\alpha\) sont déterminées en fonctions des autres, on peut écrire cette formule comme il suit:
\[
\begin{gathered}
h_1 \psi_1 x_1+h_2 \psi_2 x_2+\cdots+h_m \psi_m x_m \\
=v+k_1 \psi_1^{\prime} x_1^{\prime}+k_2 \psi_2^{\prime} x_2^{\prime}+\cdots+k_k \psi_k^{\prime} x_k{ }^{\prime}, \\
h_1, h_2, \ldots h_m, k_1, k_2, \ldots k_k
\end{gathered}
\]
%188
étant des nombres rationnels quelconques;
\[
x_1, x_2, \ldots x_m
\]
étant des quantités indéterminées en nombre arbitraire;
\[
x_1{ }^{\prime}, x_2{ }^{\prime}, \ldots x_k{ }^{\prime}
\]
étant des fonctions de ces quantités, qui peuvent se trouver algébriquement, et \(k\) étant un nombre indépendant de \(m\).
Si l'on prend, par exemple,
\[
k_1=k_2=\cdots=k_k=1 \text {, }
\]
on aura la formule
\[
\begin{aligned}
h_1 \psi_1 x_1+h_2 \psi_2 x_2+\cdots & +h_m \psi_m x_m \\
& =v+\psi_1{ }^{\prime} x_1{ }^{\prime}+\psi_2{ }^{\prime} x_2{ }^{\prime}+\cdots+\psi_k{ }^{\prime} x_k{ }^{\prime} .
\end{aligned}
\]
10.
\(\Lambda\) près avoir ainsi, dans ce qui précède, considéré les fonctions en général, je vais maintenant appliquer la théorie à une classe de fonctions qui méritent une attention particulière. Ce sont les fonctions de la forme
\[
\int f(x, y) d x
\]
où \(y\) est donné par l'équation
\[
x y=y^n+p_0=0
\]
\(p_0\) étant une fonction entière de \(x\).
Quelle que soit la fonction entière \(p_0\), on peut toujours supposer
\[
-p_0=r_1^{\mu_1} r_2^{\mu_2} r_3^{\mu_3} \ldots r_{\varepsilon}^{\mu_{\varepsilon}},
\]
où \(\mu_1, \mu_2, \ldots \mu_{\varepsilon}\) sont des nombres entiers et positifs, et \(r_1, r_2, \ldots r_{\varepsilon}\) des fonctions entières qui n'ont point de facteurs égaux.

En substituant cette expression de \(-p_0\) dans l'équation (121), on en tirera la valeur de \(y\), savoir:
\[
y=r_1^{\frac{\mu_1}{n}} r_2^{\frac{\mu_2}{n}} r_3^{\mu_3} \ldots r_{\varepsilon}^{\frac{\mu_{\varepsilon}}{n}}
\]

Si l'on désigne cette valeur de y par \(R\), et par \(1, \omega, \omega^2, \ldots \omega^{n-1}\) les \(n\) racines de l'équation \(\omega^n-1=0\), les \(n\) valeurs de \(!\) seront
\[
R, \omega R, \omega^2 R, \omega^3 R, \ldots \omega^{n-1} R \text {; }
\]
%189
on aura, par conséquent,
\[
\begin{aligned}
& r=\theta y^{\prime} \cdot \theta y^{\prime \prime} \ldots \theta y^{(n)}=\left(q_0+q_1 R+q_2 R^2+\cdots+q_{n-1} R^{n-1}\right) \\
& \times\left(q_0+\cdots q_1 R+\omega^2 q_2 R^2+\cdots+\omega^{n-1} q_{n-1} R^{n-1}\right) \\
& \times\left(q_0+\omega^2 q_1 R+\omega^4 q_2 R^2+\cdots+\omega^{2 n-2} q_{n-1} R^{n-1}\right) \\
& \times\left(q_0+\omega^3 q_1 R+\omega^6 q_2 R^2+\cdots+\omega^{3 n-3} q_{n-1} R^{n-1}\right) \\
& \ldots \ldots \ldots \ldots \ldots \ldots \\
& \times\left(q_0+\omega^{n-1} q_1 R+\omega^{2 n-2} q_2 R^2+\cdots+\omega^{(n-1)^2} q_{n-1} R^{n-1}\right) ; \\
&
\end{aligned}
\]
attendı que
\[
\left\{\begin{array}{l}
\theta y^{\prime}=q_0+q_1 R+q_2 R^2+\cdots+q_{n-1} R^{n-1} \\
\theta y^{\prime \prime}=q_0+\omega q_1 R+\omega^2 q_2 R^2+\cdots+\omega^{n-1} q_{n-1} R^{n-1} \\
\theta y^{\prime \prime \prime}=q_0+\omega^2 q_1 R+\omega^4 q_2 R^2+\cdots+\omega^{2 n-2} q_{n-1} R^{n-1} \\
\text { etc., etc. }
\end{array}\right.
\]

Cela posé, soit
\[
f(x, y)=\frac{f_1(x, y)}{f_2 x \cdot \chi^{\prime} y}
\]
et supposons
\[
f_1(x, y)=n f_3 x \cdot y^{n-m-1}
\]
où \(f_2 x\) et \(f_3 x\) sont denx fonctions entières de \(x\); alors on aura, en vertu de l'équation \(x y=y^n+p_0\), qui donne \(\chi^{\prime} y=n y^{n-1}\),
\[
f(x, y)=\frac{f_3 x}{f_2 x \cdot y^m}
\]
d'où
\[
\psi \cdot x=\int \frac{f_3 x \cdot d x}{y^m f_2 x} .
\]

L'une queleonque des valeurs de \(y\) est de la forme \(\omega^{\circ} R\), done
\[
\psi x=\omega^{-e m} \int \frac{f_3 x \cdot d x}{R^m f_2 x} .
\]

En indiquant done par \(\psi \cdot x\) la fonction \(\int \frac{f_3 x \cdot d x}{R^m f_2 x}\), toutes les fonctions \(\psi_1 x, \psi_2 x \ldots \psi_\mu x\) seront de la forme \(a^{-e m} \psi x\). Soient donc
\[
\psi_1 x=\omega^{-e_1 m} \psi \cdot x, \psi_2 x=\omega^{-e_2 m} \psi^{\prime} x, \ldots \psi_\mu^{\prime} x=\omega^{-e} \mu^m \psi^{\prime} x,
\]
où
\[
\psi x=\int \frac{f_3 x \cdot d x}{R^m f_2 \cdot x}
\]

Maintenant les équations (38) domnent pour \(\psi x\) et \(\varphi_1 x\) les expressions suivantes:
%190
c'est-à-dire
\[
\begin{gathered}
\varphi x=\Sigma \frac{f_3 x}{f_2 x \cdot y^m} \log \theta y, \varphi_1 x=\frac{F_2 x}{\theta_1(v) x} \Sigma \frac{f_3 x}{y^m} \log \theta y, \\
\varphi x=\frac{f_3 x}{f_2 \cdot x} \Sigma \frac{\log \theta y}{y^m}, \quad \varphi_1 x=\frac{F_2 x \cdot f_3 x}{\theta_1{ }^{(v)} x} \Sigma \frac{\log \theta y}{y^m}
\end{gathered}
\]
où il est clair que
\[
\Sigma \frac{\log \theta y}{y^m}=\frac{\log \theta R}{R^m}+\omega^{-m} \frac{\log \theta(\omega R)}{R^m}+\cdots+\omega^{-(n-1) m} \frac{\log \theta\left(\omega^{n-1} R\right)}{R^m},
\]
ou bien
\[
\Sigma \frac{\log \theta y}{y^m}=\frac{1}{R^m}\left\{\begin{array}{l}
\log \theta R+\omega^{-m} \log \theta(\omega R)+\omega^{-2 m} \log \theta\left(\omega^2 R\right) \\
+\cdots+\omega^{-(n-1) m} \log \theta\left(\omega^{n-1} R\right) .
\end{array}\right\}
\]

En faisant donc, pour abréger,
\[
\varphi_2 x=\frac{f_3 x}{R^m}\left\{\begin{array}{l}
\log \theta R+\omega^{-m} \log \theta(\omega R)+\omega^{-2 m} \log \theta\left(\omega^2 R\right) \\
+\cdots+\omega^{-(n-1) m} \log \theta\left(\omega^{n-1} R\right)
\end{array}\right\}
\]
on aura
\[
\varphi x=\frac{\varphi_2 x}{f_2 x}, \quad \varphi_1 x=\frac{F_2 x}{\theta_1{ }^{(v)} x} \varphi_2 x .
\]

La formule (41) deviendra done
\[
\begin{aligned}
& \omega^{-e_1^m} \psi x_1+\omega^{-e_2 m} \psi x_2+\cdots+\omega^{-\mu^m m} \psi x_\mu \\
& \quad=C-\Pi \frac{\varphi_2 x}{f_2 x}+\Sigma \nu \frac{d^{\nu-1}}{d \beta^{\nu-1}}\left(\frac{F_2 \beta \cdot f_2 \beta}{\theta_1{ }^{(v)} \beta}\right) .
\end{aligned}
\]

Lés équations
\[
\theta y_1=0, \theta y_2=0, \ldots \theta y_\mu=0
\]
qui ont lieu entre les quantités \(a, a^{\prime}, a^{\prime \prime}, \ldots x_1, x_2, \ldots x_\mu, y_1, y_2, \ldots y^\mu\), peuvent, dans les cas que nous considérons, s'écrire comme il suit:
\[
\begin{array}{r}
\theta\left(x_1, \omega^{e_1} R_1\right)=0, \theta\left(x_2, \omega^{e_2} R_2\right)=0, \theta\left(x_3, \omega^{e_3} R_3\right)=0, \\
\ldots \theta\left(x_\mu, \omega^e \mu R_\mu\right)=0,
\end{array}
\]
où
\[
\boldsymbol{\theta}(x, y)=q_0+q_1 y+q_2 y^2+\cdots+q_{n-1} y^{n-1},
\]
et \(R_1, R_2, R_3, \ldots R_\mu\) désignent les valeurs de \(R\) pour \(x=x_1, x_2, x_3, \ldots x_\mu\).
Cela posé, supposons d'abord que tous les coefficients dans \(q_0, q_1, \ldots q_{n-1}\) soient des quantités indéterminées, en sorte que le nombre des quantités \(a, a^{\prime}, a^{\prime \prime}, \ldots\) serait
\[
\alpha=h \eta_0+h q_1+h \eta_2+\cdots+h \eta_{n-1}+n-1,
\]
et cherchons la plus petite valeur de \(\boldsymbol{\mu}-\boldsymbol{\alpha}\).
%191
Comme toutes les fonctions \(y^{\prime}, y^{\prime \prime}, y^{\prime \prime \prime}, \ldots y^{(n)}\) sont du même degré, on aura
\[
h y^{\prime}=h y^{\prime \prime}=h y^{\prime \prime \prime}=\cdots=h y^{(n)}=\frac{m^{\prime}}{\mu^{\prime}}
\]
par conséquent
\[
\varepsilon=1, n=n^{\prime} \mu^{\prime}=k^{\prime} .
\]

L'équation (92) donne donc
\[
f m=f \varrho_1+\left(\varrho_1-m\right) \frac{m^{\prime}}{\mu^{\prime}}-A_m{ }^{\prime},
\]
où \(m\) est un nombre entier quelconque depuis zéro jusqu’à \(n-1\), et \(A_m{ }^{\prime}\) une quantité positive moindre que l'unité.
On a de même par (106)
donc
\[
\mu=h r=n^{\prime} \mu^{\prime}\left(f \varrho_1+\varrho_1 \frac{m^{\prime}}{\mu^{\prime}}\right)
\]
\[
\mu=n f \varrho_1+n^{\prime} m^{\prime} \varphi_1
\]
et par l'équation (62) la valeur de \(\gamma\), qui sera celle de \(\mu-\alpha\), savoir:
\[
\mu-\alpha=\gamma=n^{\prime} \iota^{\prime} \frac{n^{\prime} m^{\prime}-1}{2}-n^{\prime} \frac{m^{\prime}+1}{2}+1,
\]
ou bien en remarquant que \(n=n^{\prime} \mu^{\prime}, n^{\prime} m^{\prime}=n h R\) :
\[
\mu-\alpha=\gamma=\frac{n-1}{2} n . h R-\frac{n+n^{\prime}}{2}+1
\]

C'est là la moindre valeur de,\(\ldots-\alpha\) lorsque toutes les quantités \(a, a^{\prime}\), \(a^{\prime \prime}, \ldots\) sont indéterminées; mais dans le cas qui nous occupe, on peut rendre ce nombre beaucoup plus petit en déterminant convenablement quelquesunes des quantités \(a, a^{\prime}, a^{\prime \prime}, \ldots\).

Désignons, pour abréger, par \(E A\) le plus grand nombre entier contenu dans un nombre quelconque \(A\), et par \(\varepsilon A\) le reste, on aura:
\[
A=E A+\varepsilon A
\]
où il est clair que \(\varepsilon A\) est positif et plus petit que l'unité.
Cela posé, soient
\[
\theta_m=E^{\frac{\mu_n}{n}}+E^{\frac{2 \mu_m}{n}}+E^{\frac{3 \mu_m}{n}}+\cdots+E^{\frac{(n-1) \mu_m}{n}}
\]
et
\[
\mho_{n, n}=\theta_m-E\left(\frac{x \mu_n}{u}-\frac{\alpha_{n n}}{n}\right)
\]
%192
où \(m\) est l'un quelconque des nombres \(1,2,3, \ldots \varepsilon, \pi\) un des nombres \(0,1,2, \ldots n-1\), et \(\alpha_1, \alpha_2, \ldots \alpha_{\varepsilon}\) des nombres entiers positifs.
Supposons
\[
q_\pi=v_\pi r_1^{\delta_{1, \pi}} r_2^{\delta_{2, \pi}} \ldots r_{\varepsilon}^{\delta_{\varepsilon, \pi}}
\]
\(v_x\) étant une fonction entière de \(x\).
De là on tire
or
\[
\eta_x \boldsymbol{R}^x=v_{, r_1} r_1^{\frac{\pi \mu_1}{n}+\delta_{1, x}} r_2^{\frac{\pi \mu_2}{n}+\delta_{2, x}} \ldots r_{\varepsilon}^{\frac{\pi \mu_{\varepsilon}}{n}+\delta_{\varepsilon, x}}
\]
\[
\frac{\pi \mu_n}{n}+J_{m, \lambda}=\frac{\pi \mu_m}{n}+\theta_m-E\left(\frac{\pi \mu_m}{n}-\frac{\alpha_n}{n}\right)
\]
mais en vertu de l'équation (140),
\[
E\left(\frac{\pi \mu_m}{n}-\frac{\alpha_m}{n}\right)=\frac{\pi \mu_m}{n}-\frac{\alpha_m}{n}-\varepsilon\left(\frac{x \mu_m-\alpha_m}{n}\right)
\]
donc en substituant:
\[
\frac{\pi \mu_m}{n}+\delta_{m, \pi}=\theta_m+\frac{\alpha_m}{n}+\varepsilon \frac{\pi \mu_m-\omega_m}{n}
\]
en faisant donc, pour abréger,
\[
\varepsilon \frac{\pi \mu_m-\alpha_m}{\varkappa}=k_{m, \pi},
\]
on alla
\[
\eta_x R^n=v_\pi r_1^{\theta_1+\frac{\alpha_1}{n}} r_2^{\theta_2+\frac{\alpha_2}{n}} \ldots r_{\varepsilon}^{\theta_{\varepsilon}+\frac{\alpha_{\varepsilon}}{n}} \times r_1^{k_{1, \pi}} r_2^{k_{2, \pi}} \ldots r_{\varepsilon}^{k_{\varepsilon, \pi}},
\]
ou bien en faisant
\[
\begin{aligned}
& r_1^{k_{1, x}} r_1^{k_{2, \pi}}, r_3^{k_{3, x}} \ldots r_{\varepsilon}^{k_{\varepsilon, \pi}}=\boldsymbol{R}^{(x)}: \\
& \eta_x R^x=v_x r_1^{\theta_1+\frac{\alpha_1}{n}} r_2^{\theta_2+\frac{\alpha_3}{n}} \ldots r_{\varepsilon}^{\theta_{\varepsilon}+\frac{\alpha_{\varepsilon}}{n}} R^{(\pi)} . \\
& r_1^{k_{1, x}} r_1^{k_{2, \pi}}, r_3^{k_{3, x}} \ldots r_{\varepsilon}^{k_{\varepsilon, \pi}}=\boldsymbol{R}^{(x)}: \\
&
\end{aligned}
\]

Par la il est évident qu'on aura
et en général (126)
%193
Soit, pour abréger,
\[
\text { (151) } v_0 R^{(0)}+\omega^e v_1 R^{(1)}+\omega^{2 e} v_2 R^{(2)}+\cdots+\omega^{(n-1) e} v_{n-1} R^{(n-1)}=\theta^{\prime}(x, e),
\]
il est clair que
\[
\begin{aligned}
& \quad r=\theta y^{\prime} \cdot \theta y^{\prime \prime} \ldots \theta y^{(n)} \\
& =\theta^{\prime}(x, 0) \theta^{\prime}(x, 1) \theta^{\prime}(x, 2) \ldots \theta^{\prime}(x, n-1) r_1^{n \theta_1+\alpha_1} r_2^{n \theta_2+\alpha_2} \ldots r_{\varepsilon}^{n \theta_{\varepsilon}+\alpha} \varepsilon
\end{aligned}
\]
donc en supposant que tous les coefficients dans \(v_0, v_1, \ldots v_{n-1}\) soient des quantités indéterminées, on aura
\[
\begin{aligned}
F_0 x & =r_1^{n \theta_1+\alpha_1} r_2^{n \theta_2+\alpha_2} \ldots r_{\varepsilon}^{n \theta_{\varepsilon}+\alpha_{\varepsilon}}, \\
F x & =\theta^{\prime}(x, 0) \theta^{\prime}(x, 1) \theta^{\prime}(x, 2) \ldots \theta^{\prime}(x, n-1) .
\end{aligned}
\]

Maintenant l'équation (19) donne, en substituant les valeurs de \(f_1(x, y)\) \(=n f_3 x \cdot y^{n-m-1}\) et de \(\chi^{\prime} y=n y^{n-1}\),
\[
R x=\Sigma \frac{f_3 u}{y^m} \frac{r \cdot \delta \theta y}{\theta y}
\]
or, par l'équation (150),
\[
\frac{\delta \boldsymbol{\theta} y^{(e)}}{\boldsymbol{\theta} y^{(e)}}=\frac{\delta \boldsymbol{\theta}^{\prime}(x, e)}{\boldsymbol{\theta}^{\prime}(x, e)},
\]
donc, en substituant et mettant au lieu de \(r\) sa valeur,
\[
\begin{gathered}
r=F_0 x \cdot F x: \\
R x=F_0 x \Sigma \frac{f_3 x}{y^m} \frac{F x \cdot \delta \theta^{\prime}(x, e)}{\theta^{\prime}(x, e)}
\end{gathered}
\]
où
\[
y=y^{(e)}
\]
or, on a par (123)
\[
y^m=r_1^{\frac{m \mu_1}{n}} r_2^{\frac{m \mu_2}{n}} \ldots r^{\frac{m \mu_{\varepsilon}}{n}}
\]
done
\[
y^m=r_1^{E \frac{m \mu_1}{n}} r_2^{E \frac{m \mu_2}{n}} \ldots r_{\varepsilon}^{E \frac{m \mu_{\varepsilon}}{n}} \times r_1^{\varepsilon \frac{m \mu_1}{n}} r_2^{\varepsilon \frac{m \mu_2}{n}} \ldots r_{\varepsilon}^{\varepsilon \frac{m \mu_{\varepsilon}}{n}}
\]
en faisant done pour abréger
\[
s_m=r_1^{{ }^{\frac{m \mu_1}{n}}} r_2^{\varepsilon^{\frac{m \mu_2}{n}}} \ldots r_{\varepsilon}^{{ }^{\frac{m \mu_{\varepsilon}}{n}}}
\]
%194
et posant ensuite
\[
f_3 x=f x \cdot r_1^{E \frac{m \mu_1}{n}} r_2^{E \frac{m \mu_3}{n}} \ldots r_{\varepsilon}^{E \frac{m \mu_{\varepsilon}}{n}}
\]
on aura
\[
\frac{f_3 x}{y^m} \doteq \frac{f x}{s_m}
\]
done
\[
\frac{f_3 x}{\left(y^{(e)}\right)^m}=\omega^{-e m} \frac{f x}{s_m}
\]
et par conséquent la valeur de \(R x\) deviendra
\[
\begin{gathered}
R x=\frac{f_x \cdot F_0 x}{s_m} \Sigma \omega^{-e m} \frac{F x}{\theta^{\prime}(x, e)} \delta^{\prime} \theta^{\prime}(x, e) \\
=\frac{F_0 x \cdot f x}{s_m}\left\{\begin{array}{r}
\frac{F x}{\theta^{\prime}(x, 0)} \delta \theta^{\prime}(x, 0)+\omega^{-m} \frac{F^{\prime} x}{\theta^{\prime}(x, 1)} \delta \theta^{\prime}(x, 1)+\omega^{-2 m} \frac{F x}{\theta^{\prime}(x, 2)} \delta \theta^{\prime}(x, 2) \\
+\cdots+\omega^{-(n-1) m} \frac{F x}{\theta^{\prime}(x, n-1)} \delta \theta^{\prime}(x, n-1)
\end{array}\right\} .
\end{gathered}
\]

Maintenant il est clair que
\[
\frac{F \cdot x}{\theta^{\prime}(x, 0)} \mathcal{J}^{\prime} \theta^{\prime}(x, 0)
\]
qui est égal à (153)
\[
\theta^{\prime}(x, 1) \theta^{\prime}(x, 2) \ldots \theta^{\prime}(x, n-1) \delta \theta^{\prime}(x, 0)
\]
et par conséquent une fonction entière de \(x\) et de \(R^{(0)}, R^{(1)}, \ldots R^{(n-1)}\), peut être mise sous la forme
\[
M_0+M_1 s_1+M_2 s_2+\cdots+M_m s_m+\cdots+M_{n-1} s_{n-1},
\]
où \(M_0, M_1, \ldots M_{n-1}\) sont des fonctions entières de \(x\).
De là il suit que la fonction \(R x\), qui doit être entière, sera égale à
\[
n F_0 x \cdot f x \cdot M_m \text {. }
\]

La fonction \(F_0 x\) est donc un facteur de \(R x\), et par conséquent
\[
R x=F_0 x \cdot R_1 x \text {. }
\]

Par là il est clair, en vertu des équations (23), (25) et (35), qu'on alira
\[
F_2 x=1, \theta_1 x=f_2 x .
\]

Cela posé, la valeur \((132)\) de \(\varphi_2 x\) deviendra, en mettant \(\frac{f x}{s_m}\) au Tieu
%195
de \(\frac{f_3 x}{R^m}\), substituant les valeurs de \(\theta(R), \theta(\omega R)\), etc., données par l'équation \((150)\), en remarquant que
\[
1+\omega^{-m}+\omega^{-2 m}+\cdots+\omega^{-(n-1) m}=0:
\]
\[
\varphi_2 x=\frac{f x}{s_m}\left\{\begin{array}{r}
\log \theta^{\prime}(x, 0)+\omega^{-m} \log \theta^{\prime}(x, 1)+\omega^{-2 m} \log \theta^{\prime}(x, 2) \\
+\cdots+\omega^{-(n-1) m} \log \theta^{\prime}(x, n-1)
\end{array}\right\}
\]
et les valeurs (133) de \(\varphi x\) et \(\varphi_1 x\) :
\[
\varphi x=\frac{\varphi_2 x}{f_2 x}, \varphi_1 x=\frac{\varphi_2 x}{f_2(\nu) x},
\]
et par suite la formule (134) donnera
\[
\begin{aligned}
\omega^{-e_1 m} \psi x_1+\omega^{-e_2 m} \psi x_2+\cdots & +\omega^{-e} \mu^m \psi x_\mu \\
& =C-\Pi \frac{\varphi_2 x}{t_2 x}+\Sigma v \frac{d^{\nu-1}}{d \beta^{\nu-1}}\left\{\frac{\varphi_2 \beta}{f_2(\nu) \beta}\right\}
\end{aligned}
\]
on a
\[
f_2 x=\left(x-\beta_1\right)^{\nu_1}\left(x-\beta_2\right)^{\nu_2} \ldots\left(x-\beta_k\right)^{\nu_k} .
\]

Il nous reste à trouver la valeur de "l et le nombre des quantités indéterminées; or, on a par l'équation (153)
\[
h F_0 x=\left(n \theta_1+\alpha_1\right) h r_1+\left(n \theta_2+\alpha_2\right) h r_2+\cdots+\left(n \theta_{\varepsilon}+\alpha_{\varepsilon}\right) h r_{\varepsilon}
\]
mais
\[
h r=n f \varrho_1+n^{\prime} m^{\prime} \varrho_1
\]
done
\[
\mu=n f \varrho_1+n^{\prime} m^{\prime} \varrho_1-\left[\left(n \theta_1+\alpha_1\right) h r_1+\left(n \theta_2+\alpha_2\right) h r_2+\cdots+\left(n \theta_{\varepsilon}+\alpha_{\varepsilon}\right) h r_{\varepsilon}\right]
\]
or
\[
\begin{aligned}
& n^{\prime} m^{\prime}=n . h R=n\left(\frac{\mu_1}{n} h r_1+\frac{\mu_2}{n} h r_2+\cdots+\frac{\mu_{\varepsilon}}{n} h r_{\varepsilon}\right) \\
& =\mu_1 h r_1+\mu_2 h r_2+\cdots+\mu_{\varepsilon} h r_{\varepsilon},
\end{aligned}
\]
donc en substituant,
\[
\mu=\left\{\begin{array}{l}
n f \varrho_1+\left(\mu_1 \varrho_1-n \theta_1-\alpha_1\right) h r_1 \\
+\left(\mu_2 \varrho_1-n \theta_2-\alpha_2\right) h r_2+\cdots+\left(\mu_{\varepsilon} \varrho_1-n \theta_{\varepsilon}-\alpha_{\varepsilon}\right) h r_{\varepsilon} .
\end{array}\right.
\]

Maintenant l'équation (143) donne
\[
h q_\pi=f \pi=\delta_{1, \pi} \cdot h r_1+\delta_{2, \pi} \cdot h r_2+\cdots+\delta_{\varepsilon, \pi} \cdot h r_{\varepsilon}+h v_\pi
\]
donc, en écrivant \(\varrho\) au lieu de \(\varrho_1\),
\[
\mu=n h v_\rho+\left(n \delta_{1, \rho}-n \theta_1+\varrho \mu_1-\alpha_1\right) h r_1+\left(n \delta_{2, \pi}-n \theta_2+\varrho \mu_2-\alpha_2\right) h r_2+\cdots ;
\]
%196
mais en vertu de (144) on aura
\[
n \delta_{m, \varrho}-n \theta_m+\varrho_1 \prime_m-\alpha_m=n \cdot \varepsilon \frac{\varrho \mu_m-\alpha_m}{n}
\]
done
\[
\text { (166) } \mu=n h v_\rho+n \cdot \varepsilon \frac{\varrho \mu_1-\alpha_1}{n} h r_1+n . \varepsilon \frac{\varrho \mu_2-\alpha_2}{n} h r_2+\cdots+n \cdot \varepsilon \frac{\varrho \mu_{\varepsilon}-\alpha_{\varepsilon}}{n} h r_{\varepsilon} .
\]

Cherchons maintenant la valeur de \(\alpha\) ou le nombre des indéterminées. On a
\[
\alpha=h v_0+h v_1+h v_2+\cdots+h v_{n-1}+n-1,
\]
donc en vertu de (165)
\[
\alpha=\left\{\begin{array}{c}
h q_0+h q_1+h q_2+\cdots+h q_{n-1}+n-1 \\
-\left(\delta_{1,0}+\delta_{1,1}+\delta_{1,2}+\cdots+\delta_{1, n-1}\right) h r_1 \\
-\left(\delta_{2,0}+\delta_{2,1}+\delta_{2,2}+\cdots+\delta_{2, n-1}\right) h r_2 \\
\cdots \cdots \\
-\left(\delta_{\varepsilon, 0}+\delta_{\varepsilon, 1}+\delta_{\varepsilon, 2}+\cdots \cdots\right.
\end{array}\right.
\]

On a d'après \((136)\) et \((85)\)
\[
\begin{aligned}
& \quad h q_0+h q_1+\cdots+h \eta_{n-1} \\
& =n . h \eta_\rho+[\varrho+(\varrho-1)+\cdots+(\varrho-n+1)] \frac{m^{\prime}}{\mu^{\prime}}-\left(A_0^{\prime}+A_1^{\prime}+\cdots+A_{n-1}^{\prime}\right) \\
& =n\left(h v_o+\delta_{1, o} h l r_1+\delta_{2, \varphi} h r_2+\cdots+\delta_{\varepsilon, \varphi} h r_{\varepsilon}\right)+\left(n \varrho-\frac{n(n-1)}{2}\right) \frac{m^{\prime}}{\mu^{\prime}}-\frac{n^{\prime}\left(\mu^{\prime}-1\right)}{2},
\end{aligned}
\]
et d'après (142)
\[
\begin{aligned}
& \delta_{m, 0}+\delta_{m, 1}+\cdots+\delta_{m, n-1}=n \theta_m \\
& -\left(E \frac{-\alpha_m}{n}+E \frac{\mu_m-\alpha_m}{n}+E \frac{2 \mu_m-\alpha_m}{n}+\cdots+E^{(n-1) \mu_m-\alpha_m}\right) . \\
&
\end{aligned}
\]

En désignant le second membre par
\[
n \boldsymbol{\theta}_m-P_m
\]
on aura
\[
P_m=\left\{\begin{array}{l}
\frac{-\alpha_m}{n}+\frac{\mu_m-\alpha_m}{n}+\frac{2 \mu_m-\alpha_m}{n}+\cdots+\frac{(n-1) \mu_m-\alpha_m}{n} \\
-\left(\varepsilon \frac{-\alpha_m}{n}+\varepsilon \frac{\mu_m-\alpha_m}{n}+\cdots+\varepsilon \frac{(n-1) \mu_m-\alpha_n}{n}\right)
\end{array}\right.
\]
or, la suite
\[
\varepsilon \frac{-\alpha_m}{n}+\varepsilon \frac{\mu_m-\alpha_m}{n}+\cdots+\varepsilon \frac{(n-1) \mu_m-\alpha_m}{n}
\]
%197
- contiendra \(k_m\) fois la suivante
si l'on suppose
\[
\frac{0}{n_m}+\frac{1}{n_m}+\frac{2}{n_m}+\cdots+\frac{n_m-1}{n_m},
\]
\[
\frac{\mu_m}{n}=\frac{\mu_m^{\prime}}{n_m} \text { et } n=k_m n_m
\]
et
\[
\alpha_m=\varepsilon_m k_m
\]
\(\varepsilon_m\) étant nu nombre entier.
La somme dont il s'agit sera donc
\[
k_m \frac{n_m-1}{2}
\]
et par conséquent
\[
P_m=-\alpha_m+\frac{n-1}{2} \mu_m-\frac{n_m-1}{2} k_m .
\]

En faisant \(\alpha_m=0\), on aura d'après (141) \(P_m=\theta_m\), donc
\[
\theta_m=\frac{n-1}{2} \mu_m-\frac{n_m-1}{2} k_m
\]
de là il suit:
\[
\delta_{m, 0}+\delta_{m, 1}+\cdots+\delta_{m, n-1}=\alpha_m+(n-1) \theta_m
\]
la valeur de \(\alpha\) deviendra donc
\[
\alpha=\left\{\begin{array}{c}
n h v_{\varrho}+\left[n \delta_{1, \varrho}-\alpha_1-(n-1) \theta_1\right] h r_1 \\
+\left[n \delta_{2, \varrho}-\alpha_2-(n-1) \theta_2\right] h r_2+\cdots \\
+n-1-\frac{n^{\prime}\left(\mu^{\prime}-1\right)}{2}+\left(n \varrho-\frac{n(n-1)}{2}\right) \frac{m^{\prime}}{\mu^{\prime}}
\end{array}\right.
\]
or
\[
n \delta_{m, \varrho}-\alpha_m-n \theta_m=n . \varepsilon \frac{\varrho \mu_m-\alpha_m}{n}-\varrho_i, n_i^{\prime} \boldsymbol{\prime}^{\prime}=n
\]
et
\[
\frac{m^{\prime}}{\mu^{\prime}}=h R=\frac{1}{n}\left(\mu_1 h r_1+\mu_2 h r_2+\cdots+\mu_{\varepsilon} h r_{\varepsilon}\right)
\]
donc en substituant
\[
\alpha=\left\{\begin{aligned}
n h v_o & +\left(n . \varepsilon \frac{\rho \mu_1-\alpha_1}{n}+\theta_1-\frac{n-1}{2} \mu_1\right) h r_1 \\
& +\left(n . \varepsilon \frac{\rho \mu_2-\alpha_2}{n}+\theta_2-\frac{n-1}{2} \mu_2\right) h r_2+\cdots \\
& +\left(n . \varepsilon \frac{\rho \mu_{\varepsilon}-\alpha_{\varepsilon}}{n}+\theta_{\varepsilon}-\frac{n-1}{2} \mu_{\varepsilon}\right) h r_{\varepsilon}-1+\frac{n+n^{\prime}}{2}
\end{aligned}\right.
\]
%198
mais nous avons vu que
done
\[
\theta_m=\frac{n-1}{2} \mu_m-\frac{n_m-1}{2} k_m=\frac{n-1}{2} \mu_m-\frac{n-k_m}{2},
\]
\[
\alpha=\left\{\begin{aligned}
n h v_\rho & +\left(n . \varepsilon \frac{\varrho \mu_1-\alpha_1}{n}-\frac{n-k_1}{2}\right) h r_1 \\
& +\left(n . \varepsilon \frac{\varrho \mu_2-\alpha_2}{n}-\frac{n-k_2}{2}\right) h r_2+\cdots \\
& +\left(n . \varepsilon \frac{\varrho \mu_{\varepsilon}-\alpha_{\varepsilon}}{n}-\frac{n-k_{\varepsilon}}{2}\right) h r_{\varepsilon}-1+\frac{n+n^{\prime}}{2} .
\end{aligned}\right.
\]
savoir:
\[
\begin{aligned}
\mu-\alpha=\frac{n-k_1}{2} h r_1+\frac{n-k_2}{2} h r_2 & +\frac{n-k_3}{2} h r_3+\cdots \\
& +\frac{n-k_{\varepsilon}}{2} h r_{\varepsilon}+1-\frac{n^{\prime}+n}{2}=\theta ;
\end{aligned}
\]
\(\mu-\alpha\) est donc, comme on le voit, indépendant de \(\varrho\) et \(\alpha_1, \alpha_2, \alpha_3, \ldots \alpha_{\varepsilon}\). En vertu des équations \((145)\) et (147), il est clair qu'on aura aussi
\[
\begin{aligned}
& \mu \equiv n \cdot h v_\rho+n \cdot h R^{(\rho)}, \\
& \alpha=n \cdot h v_\rho+n \cdot h R^{(\rho)}-\theta .
\end{aligned}
\]

Les quantités \(h v_0, h v_1, \ldots h v_{n-1}\) peuvent s'exprimer en \(h v_{\varrho}\) au moyen des équations (136) et (165).
On a
et
\[
\begin{gathered}
f m=\delta_{1, m} h r_1+\delta_{2, m} h r_2+\cdots+\delta_{\varepsilon, m} h r_{\varepsilon}+h v_m \\
f_{\varrho}=\delta_{1, \varrho} h r_1+\delta_{2, \varrho} h r_2+\cdots+\delta_{\varepsilon, \varrho} h r_{\varepsilon}+h v_{\varrho} \\
f m=f \varrho+(\varrho-m) \frac{m^{\prime}}{\mu^{\prime}}-A_m^{\prime}
\end{gathered}
\]
donc en éliminant \(f m\) et \(f \varrho\),
\[
h v_m=\left\{\begin{array}{c}
h v_{\varrho}+(\varrho-m) \frac{m^{\prime}}{\mu^{\prime}}+\left(\delta_{1, \varrho}-\delta_{1, m}\right) h r_1+\left(\delta_{2, \varrho}-\delta_{2, m}\right) h r_2+\cdots \\
+\left(\delta_{\varepsilon, \varrho}-\delta_{\varepsilon, m}\right) h r_{\varepsilon}-A_m^{\prime} .
\end{array}\right.
\]

Or,
et par (142)
\[
\frac{m^{\prime}}{\mu^{\prime}}=\frac{1}{n}\left(\mu_1 h r_1+\mu_2 h r_2+\cdots+\mu_{\varepsilon} h r_{\varepsilon}\right)
\]
%199
\[
\begin{aligned}
& \delta_{k, \varrho}-\delta_{k, m}=\theta_k-E\left(\frac{\varrho \mu_k}{n}-\frac{\alpha_k}{n}\right)-\left\{\theta_k-E\left(\frac{m \mu_k}{n}-\frac{\alpha_k}{n}\right)\right\} \\
& =(m-\varrho) \frac{\mu_k}{n}+\varepsilon \frac{\varrho \mu_k-\alpha_k}{n}-\varepsilon \frac{m \mu_k-\alpha_k}{n}=(m-\varrho) \frac{\mu_k}{n}+k_{k, \emptyset}-k_{k, m}
\end{aligned}
\]
donc en substituant et réduisant
\[
h v_m=\left\{\begin{aligned}
h v_{\varrho}+\left(k_{1, \rho}-k_{1, m}\right) h r_1+\left(k_{2, \varrho}-k_{2, m}\right) h r_2+\cdots & \\
& +\left(k_{\varepsilon, \rho}-k_{\varepsilon, m}\right) h r_{\varepsilon}-A_m{ }^{\prime}
\end{aligned}\right.
\]
c'est-ì-dire en remarquant que \(A_m^{\prime}\) est positif et plus petit que l'unité,
\[
h v_m=h v_{\varrho}+E\left\{\begin{array}{r}
\left(k_{1, \varrho}-k_{1, m}\right) h r_1+\left(k_{2, \varrho}-k_{2, m}\right) h r_2+\cdots \\
+\left(k_{\varepsilon, \varrho}-k_{\varepsilon, m}\right) h r_{\varepsilon}
\end{array}\right\}
\]
1'après l'équation (147), qui donne la valeur de \(R^{(\pi)}\), on peut aussi écrire
\[
h v_m=h v_\rho+E h \frac{R^{(\rho)}}{R^{(m)}} .
\]

Cela posé, soient
\[
\text { (177) }\left\{\begin{array}{l}
x_{\alpha+1}=z_1, x_{\alpha+2}=z_2, x_{\alpha+3}=z_3, \ldots x_{\mu-1}=z_{\theta-1}, x_\mu=z_\theta, \\
e_{\alpha+1}=\varepsilon_1, e_{\alpha+2}=\varepsilon_2, e_{\alpha+3}=\varepsilon_3, \ldots e_{\mu-1}=\varepsilon_{\theta-1}, e_\mu=\varepsilon_\theta,
\end{array}\right.
\]
et pour abréger
\[
\omega^{-e} \mu=\omega_\mu, \quad \omega^{-\varepsilon} \mu=\pi_\mu .
\]

La formule \((134)\) deviendra, en mettant \(s_m(x)\) au lieu de \(s_m\), et \(\frac{f x \cdot \varphi x}{s_m(x)}\) au lieu de \(\varphi_2 x\),
\[
\begin{gathered}
\omega_1^m \psi x_1+\omega_2^m \psi x_2+\cdots+\omega_\alpha^m \psi x_\alpha+\pi_1^m \psi z_1+\pi_z^m \psi z_2+\cdots+\pi_\theta^m \psi z_\theta \\
=C-\Pi \frac{f x \cdot r x}{s_m(x) \cdot f_2 x}+\Sigma \nu \frac{d^{\nu-1}}{d \beta^{\nu-1}}\left\{\frac{f \beta \cdot \varphi \beta}{s_m(\beta) \cdot f_z^{(\nu)} \beta}\right\}
\end{gathered}
\]

Dans cette formule on a
\[
\psi x=\int \frac{f x \cdot d x}{f_2 x \cdot s_m(x)}
\]
où \(f x\) est une fonction entière quelconque, et
\[
f_2 x=A\left(x-\beta_1\right)^{\nu_1}\left(x-\beta_2\right)^{\nu_2} \ldots
\]

Les quantités \(x_1, x_2, \ldots x_\alpha\), sont des variables indépendantes; \(\omega_1, \omega_2\), \(\ldots \omega_\alpha\), des racines quelconques de l'équation
\[
\omega^n-1=0
\]
%200
Les fonctions \(z_1, z_3, \ldots z_\theta\), sont les \(\theta\) racines de l'équation
\[
\frac{\boldsymbol{\theta}^{\prime}(z, 0) \boldsymbol{\theta}^{\prime}(z, 1) \boldsymbol{\theta}^{\prime}(z, 2) \ldots \boldsymbol{\theta}^{\prime}(z, n-1)}{\left(z-x_1\right)\left(z-x_2\right)\left(z-x_3\right) \cdots\left(z-x_\alpha\right)}=0 .
\]

Les quantités \(a, a^{\prime}, a^{\prime \prime}, \ldots\) sont déterminées par les \(\alpha\) équations
\[
\boldsymbol{\theta}^{\prime}\left(x_1, e_1\right)=0, \theta^{\prime}\left(x_2, e_2\right)=0, \theta^{\prime}\left(x_3, e_3\right)=0, \ldots \theta^{\prime}\left(x_\alpha, e_\alpha\right)=0 ;
\]
et les nombres \(\varepsilon_1, \varepsilon_2, \ldots \varepsilon_\theta\), par les \(\theta\) équations
\[
\boldsymbol{\theta}^{\prime}\left(z_1, \varepsilon_1\right)=0, \boldsymbol{\theta}^{\prime}\left(z_2, \varepsilon_2\right)=0, \boldsymbol{\theta}^{\prime}\left(z_3, \varepsilon_3\right)=0, \ldots \boldsymbol{\theta}^{\prime}\left(z_\theta, \varepsilon_\theta\right)=0 .
\]

La fonction \(\theta^{\prime}(x, e)\) est donnée par l'équation
\[
\theta^{\prime}(x, e)=v_0 R^{(0)}+\omega^e v_1 R^{(1)}+\omega^{2 e} v_{\Sigma} R^{(2)}+\cdots+\omega^{(n-1) e} v_{n-1} R^{(n-1)},
\]
et la fonction \(\varphi x\) par
\[
\begin{aligned}
\varphi(x)=\log \theta^{\prime}(x, 0)+()^{-m} \log \theta^{\prime}(x, 1)+\omega^{-2 m} \log \theta^{\prime}(x, 2)+\cdots \\
+\omega^{-(m-1) m} \log \theta^{\prime}(x, n-1) .
\end{aligned}
\]

Si les fonctions \(v_0, v_1, \ldots v_{n-1}\) sont déterminées d'après l'équation (175), les quantités \(\theta\), " et \(\alpha\) auront les valeurs que leur donnent les équations (172), (173), (174), et dans le même cas la valeur de \(\boldsymbol{\mu - \alpha}\) ou le nombre des fonctions dépendantes est le plus petit possible. Mais si les fonctions \(v_0, v_1, \ldots v_{n-1}\) ont des formes quelconques, alors on a toujours
\[
\boldsymbol{\theta}=\boldsymbol{\mu}-\boldsymbol{\alpha}, \boldsymbol{\mu}=\boldsymbol{h}\left[\boldsymbol{\theta}^{\prime}(x, 0) \cdot \boldsymbol{\theta}^{\prime}(x, 1) \cdot \boldsymbol{\theta}^{\prime}(x, 2) \ldots \boldsymbol{\theta}^{\prime}(x, n \div 1)\right]
\]
\(\alpha\) ou le nombre des indéterminées \(a, a^{\prime} a^{\prime \prime}, \ldots\) est arbitraire, mais sa valeur ne peut pas surpasser le nombre
\[
h v_0+h v_1+h v_2+\cdots+h v_{n-1}+n-1
\]
ou celui des coefficients dans \(v_0, v_1, \ldots v_{n-1}\) moins un.
Comme cas particuliers ou doit remarquer les suivants: \(1^0\) Lorsque \(f_2 x=(x-\beta)^\nu\).
Alors la formule (179) deviendra, en faisant pour abréger,
\[
\begin{aligned}
& \omega_1^m \psi x_1+\omega_2^m \psi x_2+\cdots+\omega_\alpha^m \psi x_\alpha=\Sigma \omega^m \psi x, \\
& \pi_1^m \psi z_1+\pi_2^m \psi z_2+\cdots+\pi_\theta^m \psi z_\theta=\Sigma x^m \psi z,
\end{aligned}
\]
et
\[
\begin{gathered}
\Sigma \omega^m \psi x+\Sigma x^m \psi z=C-\Pi \frac{f x \cdot \varphi^x}{s_m(x)(x-\beta)^\nu}+\frac{1}{\Gamma \nu} \frac{d^{\nu-1}}{d \beta^{\nu-1}}\left\{\frac{f \beta \cdot q^\beta}{s_m(\beta)}\right\} \\
\psi x=\int \frac{f x \cdot d x}{(x-\beta)^\nu s_m(x)^2}
\end{gathered}
\]
%201
\(2^0\) Lorsque \(f_{\mathrm{z}} x=x-\boldsymbol{\beta}\),
\[
\Sigma \omega^m \psi x+\Sigma \pi^m \psi z=C-I I \frac{f x \cdot q \cdot x}{s_m(x) \cdot(x-\beta)}+\frac{f \beta \cdot q \beta}{s_m(\beta)},
\]
où
\[
\psi x=\int \frac{f x \cdot d x}{(x-\beta) \cdot s_m(x)}
\]
\(3^0\) Lorsque \(f_2 x=1\).
Alors on aura la formule
\[
\Sigma \omega^m \psi x+\Sigma \pi^m \psi z=C-\Pi \frac{f \cdot x \cdot(\cdot x}{s_m(x)} .
\]
s'évanouira, et on aura
\[
\Sigma \omega^m \psi x+\Sigma \pi^m \psi z=C .
\]

D'après la valeur de \(\varphi x\), il est clair que le degré de la fonction \(\frac{f x \cdot r x}{s_m(x)}\) ou le nombre \(h \frac{f x \cdot \uparrow x}{s_m(x)}\) est toujours un nombre entier; or \(\varphi x\) est du degré zéro en général, et ne peut pas être d'un degré plus élevé, donc \(h \frac{f x \cdot f^x}{s_m(x)}\) ne peut pas surpasser le plus grand nombre entier contenu dans \(h \frac{f x}{s_m(x)}\), c'est-à-dire que, d'après la notation adoptée, on aura en général
\[
h \frac{f x \cdot q x}{s_m(x)} \leqq E h \frac{f x}{s_m(x)} \leqq E(h f x)+E\left[-h s_m(x)\right] \leqq h f x+E\left[-h s_m(x)\right]
\]

Si done
\[
h f x \leq-E\left[-h s_m(x)\right]-2
\]
le nombre \(h \frac{f x \cdot r x}{s_m(x)}\) sera toujours moindre que - 1, et par conséquent la formule (190) aura lieu.

La détermination de la fonction \(q x\), qui dépend de celle des quantités \(a, a^{\prime}, a^{\prime \prime}\), ete., est en général assez longue; mais il y a un cas dans lequel on peut déterminer cette fonction d'une manière assez simple; c'est celui où l'on suppose
\[
\theta^{\prime}(x, 0)=v_t R^{(t)}+R^{\left(t_1\right)}
\]

En effet, en faisant
\[
v_t=\theta x, \frac{R^{\left(t_1\right)}}{R^{(t)}}=-\theta_1 x,
\]
%202
les équations
\[
\theta^{\prime}\left(x_1, e_1\right)=0, \theta^{\prime}\left(x_2, e_2\right)=0, \ldots \theta^{\prime}\left(x_\alpha, e_\alpha\right)=0
\]
peuvent s'écrire comme il suit:
\[
\theta x_1=\omega_1^{t_1-t} \theta_1 x_1, \theta x_2=\omega_2^{t_1-t} \theta_1 x_2, \ldots \theta x_u=\omega_\alpha^{t_1-t} \theta_1 x_\alpha .
\]

En supposant maintenant que tous les coefficients dans \(\theta x\) soient des quantités indéterminées, la fonction \(\theta x\) sera du degré \(\alpha-1\); il s'agit donc de trouver une fonction entière de \(x\) du degré \(\alpha-1\), qui, pour les \(\alpha\) valeurs particulières de \(x: x_1, x_2, \ldots x_\alpha\), auront les \(\alpha\) valeurs correspondantes
\[
\omega_1^{t_1-t} \theta_1 x_1, \omega_2^{t_1-t} \theta_1 x_2, \ldots \omega_\alpha^{t_1-t} \theta_1 x_\alpha .
\]

Or, comme on sait, la fonction \(\theta x\) aura alors la valeur suivante:
\[
\boldsymbol{\theta} x=\left\{\begin{array}{cl}
\frac{\left(x-x_2\right)\left(x-x_3\right) \cdots\left(x-x_\alpha\right)}{\left(x_1-x_2\right)\left(x_1-x_3\right) \cdots\left(x_1-x_\alpha\right)} & \omega_1^{t_1-t} \theta_1 x_1 \\
+\frac{\left(x-x_1\right)\left(x-x_3\right) \cdots\left(x-x_\alpha\right)}{\left(x_2-x_1\right)\left(x_2-x_3\right) \cdots\left(x_2-x_\alpha\right)} & \omega_2^{t_1-t} \boldsymbol{\theta}_1 x_2+\cdots \\
+\frac{\left(x_1-x_1\right)\left(x-x_2\right) \cdots\left(x-x_{\alpha-1}\right)}{\left(x_\alpha-x_1\right)\left(x_\alpha-x_2\right) \cdots\left(x_\alpha-x_{\alpha-1}\right)} & \omega_\alpha^{t_1-t} \theta_1 x_\alpha .
\end{array}\right.
\]

En désignant cette fonction par \(\theta^{\prime} x\), la fonction la plus générale qui peut satisfaire aux équations (194) sera
\[
\theta x=\theta^{\prime} x+\left(x-x_1\right)\left(x-x_2\right) \cdots\left(x-x_\alpha\right) \theta^{\prime \prime} x,
\]
\(\theta^{\prime \prime} x\) étant une fonction entière quelconque.
Ayant ainsi déterminé \(\theta x\), on aura \(\theta^{\prime}(x, m)\) d'après l'équation
\[
\boldsymbol{\theta}(x, m)=\omega^{t m} \theta x \boldsymbol{R}^{(t)}+\left(\boldsymbol{1}^{m t_1} \boldsymbol{R}^{\left(t_1\right)},\right.
\]
et la fonction \(\varphi x\) par l'équation (185).
Dans ce qui précède nous avons exposé ce qui concerne les fonctions \(\int \frac{f_x \cdot d x}{f_z x \cdot s_m}\) en général, quelle que soit la forme de la fonction \(s_m\).
Considérons maintenant quelques cas particuliers:
A) soit d'abord \(n=1\).
Dans ce cas, le nombre des fonctions \(s_0, s_1, s_2, \ldots s_{n-1}\) se réduit à l'unité, c'est-à-dire qu'on aura la seule fonction \(s_0\), qui, d'après l'équation (156), se réduit à l'unité.
%203
On aura done
\[
s_0=1, \psi x=\int \frac{f_{i x} \cdot d x}{f_2 x} .
\]

L'équation (147) donne \(R^{(0)}=1\), et l'équation (184)
\[
\theta^{\prime}(x, 0)=v_0 R^{(0)}=v_0(x)
\]
on aura ensuite la fonction \(\varphi x\) par (185), savoir:
\[
\varphi x=\log v_0(x) \text {. }
\]

Les équations (182) qui détermineront
\[
x_1, x_2, \ldots x_\alpha
\]
seront
\[
v_0\left(x_1\right)=0, v_0\left(x_2\right)=0, \ldots v_0\left(x_\alpha\right)=0,
\]
et celle qui donne \(z_1, z_2, \ldots z_\theta\),
\[
\frac{v_0(z)}{\left(z-x_1\right)\left(z-x_2\right) \cdots\left(z-x_\alpha\right)}=0
\]

Cela posé, la formule générale (179) deviendra, en remarquant que \(m=0\)
\[
\begin{aligned}
\psi x_1+\psi x_2+\cdots & +\psi x_\alpha+\psi z_1+\psi z_2+\cdots+\psi z_\theta \\
& =C-\Pi \frac{f x}{f_2 \cdot x^2} \log v_0(x)+\Sigma \nu \frac{d^{v-1}}{d \beta v-1}\left(\frac{f \beta}{f_2(\nu) \beta} \log v_0(\beta)\right)
\end{aligned}
\]

Les équations (198) et (199) donnent
\[
v_0(x)=a\left(x-x_1\right)\left(x-x_2\right)\left(x-x_3\right) \ldots\left(x-x_\alpha\right) \cdot\left(x-z_1\right)\left(x-z_2\right) \ldots\left(x-z_\theta\right) .
\]

D'après l'équation (172) il est clair qu'on peut faire \(\theta=0\). Alors on aura, en faisant en même temps \(v=1\),
\[
\Sigma \psi x=\left\{\begin{array}{c}
C-\Pi \frac{f x}{f_2 x}\left[\log \alpha+\log \left(x-x_1\right)+\log \left(x-x_2\right)+\cdots+\log \left(x-x_\alpha\right)\right] \\
+\Sigma \frac{f \beta}{f_2 \beta}\left[\log \alpha+\log \left(\beta-x_1\right)+\log \left(\beta-x_2\right)+\cdots+\log \left(\beta-x_\alpha\right)\right]
\end{array}\right.
\]

En faisant \(\alpha=1\), il viendra
\[
\text { (201) } \int \frac{f x_1 \cdot d x_1}{f_2 x_1}=C-I \frac{f x}{f_2 x} \log \left(x-x_1\right)+\Sigma v \frac{d^{\nu-1}}{d \beta^{\nu-1}}\left(\frac{f \beta}{f_2(\nu) \beta} \log \left(\beta-x_1\right)\right) \text {, }
\]
formule qu’il est aisé de vérifier. Elle donne, comme on le voit, l'intégrale de toute différentielle rationnelle.
%204
B) soit en second lieu \(n=2, R=r_1^{\frac{1}{2}} r_2^{\frac{1}{2}}, \alpha_1=1, \alpha_2=0\). Dans ce cas on aura
\[
\begin{gathered}
s_0=1, s_1=\left(r_1 r_2\right)^{\frac{1}{2}}, P^{(0)}=r_1^{\frac{1}{2}}, R^{(1)}=r_2^{\frac{1}{2}}, \\
\theta^{\prime}(x, 0)=v_0 r_1^1+v_1 r_2^{\frac{1}{2}}, \theta^{\prime}(x, 1)=v_0 r_1^{\frac{1}{2}}-v_1 r_2^{\frac{1}{2}}, \quad \omega=-1 .
\end{gathered}
\]

La fonction \(\varphi x\) sera, en faisant \(m=1\),
donc:
\[
\varphi x=\log \theta^{\prime}(x, 0)-\log \theta^{\prime}(x, 1)=\log \frac{\theta^{\prime}(x, 0)}{\theta^{\prime}(x, 1)},
\]
\[
\varphi x=\log \frac{v_0 v_1{ }_1^{\frac{1}{2}}+v_1 r_2{ }_2^{\frac{1}{2}}}{v_0 r_1{ }_1^2-v_1{ }_1 r_2{ }^2} .
\]

Cela posé, en mettant \(v_0(x)\) et \(v_1(x)\) an lieu de \(v_0\) et \(v_1\), et faisant
\[
r_1=\varphi_0 x, r_2=\varphi_1 x
\]
la formule (179) deviendra, en faisant \(m=1\),
\[
\begin{aligned}
& +\Sigma v^{\prime} \frac{d l^{\nu-1}}{d \beta^{\nu-1}} \frac{f \beta}{f_2(\nu) \beta \cdot \sqrt{\tau_0 \beta \cdot \Phi_1 \beta}} \log \left(\frac{v_0(\beta) \sqrt{\Phi_0 \beta}+v_1(\beta) \sqrt{\Phi_1 \beta}}{v_0(\beta) \sqrt{\Phi_0 \beta-v_1(\beta) \sqrt{\Phi_1 \beta}}}\right), \\
& \psi x=\int \frac{f x \cdot d x}{f_2 x \sqrt{\varphi_0 x \cdot \Psi_1 x}} . \\
&
\end{aligned}
\]
où
\[
\psi x=\int \frac{f x \cdot d x}{f_2 x \sqrt{\Upsilon_0 x \cdot \Upsilon_1 x}}
\]

Les fonctions \(v_0(x)\) et \(v_1(x)\) sont déterminées par les équations:
\[
\begin{aligned}
& v_0\left(x_1\right) \sqrt{\varphi_0 x_1}+\omega_1 v_1\left(x_1\right) \sqrt{\varphi_1 x_1}=0, \\
& v_0\left(x_2\right) \sqrt{\varphi_0 x_2}+\omega_2 v_1\left(x_2\right) \sqrt{\varphi_1 x_2}=0, \text { ete. }
\end{aligned}
\]
et \(z_1, z_2, \ldots z_0\), par l'équation (181), qui deviendra
\[
\frac{\left[v_0(z)\right]^2 \Upsilon_0 z-\left[v_1(z)\right]^2 \varphi_1 z}{\left(z-x_1\right)\left(z-x_2\right) \cdots\left(z-x_\alpha\right)}=0
\]

Les quantités \(\omega_1, \omega_2, \ldots \omega_c\) sont toutes égales à +1 ou à -1 , et \(\pi_1, \pi_2, \ldots \pi_\theta\), qui sont aussi de la même forme, sont déterminées par
\[
\pi_1=-\frac{v_0\left(z_1\right) \sqrt{\varphi_1 z_1}}{v_1\left(z_1\right) \sqrt{{\Upsilon_1}_1}}, \pi_2=-\frac{v_0\left(z_2\right) \sqrt{\varphi_0 z_2}}{v_1\left(z_2\right) \sqrt{\Upsilon_1 z_2}}, \ldots
\]
%205
La plus petite valeur de \(\theta\) se trouve par l'équation (172), en remarquant que
\[
k_1=1, k_2=1
\]
on aura
\[
\boldsymbol{\theta}=\frac{1}{2} h r_1+\frac{1}{2} h r_2-\frac{n^{\prime}}{2}=\frac{1}{2}\left[h\left(r_1 r_2\right)-n^{\prime}\right]
\]
où \(n^{\prime}\) est le plus grand commun diviseur de 2 et \(h r_1+h r_2\); si donc
oul
\[
\begin{gathered}
h\left(\varphi_0 x \cdot \varphi_1 x\right)=2 m-1, \\
h\left(\varphi_0 x \cdot \varphi_1 x\right)=2 m,
\end{gathered}
\]
on aura pour \(\theta\) la même valeur, savoir:
\[
\theta=m-1
\]
quant aux valeurs de \(v_0\) et \(v_1\), on aura l'équation (176), savoir, si \(\varrho=1\),
\[
h v_0=h v_1+E h \frac{R^{(1)}}{R^{(0)}}=h w_1+E_{\frac{1}{2}}\left(h \varphi_1 x-h \varphi_0 x\right)
\]
done dans le cas où \(h\left(\varphi_0 x \cdot \varphi_1 x\right)=2 m-1\),
\[
h v_0=h v_1+\frac{1}{2}\left(h \varphi_1 x-h \varphi_0 x\right)-\frac{1}{2}
\]
et dans le cas où \(l_1\left(\varphi_0 x \cdot \varphi_1 x\right)=2 m\),
\[
h v_0=h v_1+\frac{1}{2}\left(h \varphi_1 x-h \varphi_0 x\right) .
\]

Pour les valeur's de \(\mu\) et \(\alpha\) on aura, d'après les équations (173) et (174),
\[
\begin{aligned}
& u=2 h v_1+h \varphi_1 x \\
& \alpha=2 h v_1+h \varphi_1 x-m+1
\end{aligned}
\]

Si \(m=1\), on a \(\theta=0\), donc alors:

Dalls ce cas:
\[
\Sigma \omega \psi x=v
\]
\[
\psi x=\int \frac{f x \cdot d x}{f_2 x \cdot \sqrt{R}},
\]
où \(R\) est du premier ou du second degré.
Cette intégrale peut donc s'exprimer par des fonctions algébriques et logarithmiques, comme on le voit, en faisant
\[
\begin{gathered}
\varphi_0 x=\varepsilon_0 x+\delta_0, \varphi_1 x=\varepsilon_1 x+\delta_1, f_2 x=(x-\beta)^{\prime} \\
v_1(x)=1, \quad v_0(x)=a
\end{gathered}
\]
%206
on allra
\[
a=-\frac{\omega_1 \sqrt{\varphi_1 x_1}}{\sqrt{\rho_0 x_1}}=v_0(x)
\]
donc en substituant et faisant \(\omega_1=1\),
\[
\int \frac{f x_1 \cdot d x_1}{\left(x_1-\beta\right)^\nu \sqrt{\left(\varepsilon_0 x_1+\delta_0\right)\left(\varepsilon_1 x_1+\delta_1\right)}}=C
\]
soit, par exemple, \(v=0, f \cdot x_1=1\), on aura, en mettant \(z\) au lieu de \(x_1\),
done:
\[
\int \frac{d z}{\sqrt{\left(\varepsilon_0 z+\delta_0\right)\left(\varepsilon_1 z+\delta_1\right)}}=C+\frac{1}{\sqrt{\varepsilon_0 \varepsilon_1}} \log \frac{\sqrt{\varepsilon_0} \sqrt{\varepsilon_1 z+\delta_1}+\sqrt{\varepsilon_1} \sqrt{\varepsilon_0 z+\delta_0}}{\sqrt{\varepsilon_0 \sqrt{\varepsilon_1 z+\delta_1}-\sqrt{\varepsilon_1} \sqrt{\varepsilon_0 z+\delta_0}}} .
\]

Si \(m=2\), on aura \(\theta=1\),
\[
h\left(\varphi_0 x \cdot \varphi_1 x\right)=3 \text { on } 4 \text {. }
\]

Dans ce cas on aura donc
\[
\Sigma \omega \psi x=v-\pi_1 \psi z_1=()_1 \psi x_1+\omega_2 \psi x_2+\cdots+\omega_\alpha \psi x_\alpha
\]
et la fonction \(\psi x\) sera une fonction elliptique.
On aura immédiatement la valeur de \(z_1\) par l'équation (203). En effet, en faisant
on aura
\[
\left(v_0 z\right)^2 \varphi_0 z-\left(v_1 z\right)^2 \varphi_1 z=A+\cdots+B z^{\alpha+1},
\]
donc:
\[
x_1 x_2 \ldots x_\alpha z_1=\frac{A}{B}(-1)^{\alpha+1}
\]
\[
z_1=\frac{A}{B} \frac{(-1)^{\alpha+1}}{x_1 x_2 \ldots x_\alpha}
\]
%207
il est clair que \(\frac{A}{B}\) est une fonction rationnelle de \(x_1, x_2, \ldots x_\alpha, \sqrt{\varphi_0 x_1}\),
\[
\sqrt{\varphi_0 x_2}, \ldots \sqrt{\varphi_0 x_\alpha}, \sqrt{\varphi_1 x_1}, \sqrt{\varphi_1 x_2}, \ldots \sqrt{\varphi_1 x_\alpha} \text {. }
\]

Soit, par exemple,
\[
\varsigma_0 x=1, \varphi_1 x=\alpha_0+\alpha_1 x+\alpha_2 x^2+\alpha_3 x^3, v_1 x=1, v_0 x=a_0+a_1 x,
\]
on trouvera les équations:
on trouve de même:
\[
A=a_0^2-\alpha_0, B=-\alpha_3,
\]
done
\[
z_1=\frac{1}{x_1 x_2} \frac{\left(a_0^2-\alpha_0\right)}{\alpha_3}=\frac{1}{\alpha_3 x_1 x_2}\left(\frac{x_2^2 \uparrow_1 x_1+x_1^2 \uparrow_1 x_2-2\left(\omega _ { 1 } \left(\omega_2 \cdot x_1 x_2 \sqrt{\uparrow_1 x_1 \cdot \uparrow_1 x_2}\right.\right.}{\left(x_1-x_2\right)^2}-\alpha_0\right) ;
\]
si l'on fait
\[
\omega_1=1, \omega_2= \pm 1
\]
l'équation (205) deviendra donc
\[
\begin{aligned}
& \psi x_1 \pm \psi x_2= \pm \psi z+C \\
& \quad-I I\left(\frac{f x}{f_2 x \cdot \sqrt{\varphi^x}} \log F x\right)+\Sigma v \frac{d^{v-1}}{d \beta^{\nu-1}}\left(\frac{f \beta}{f_2^{(\nu)} \beta \sqrt{\varphi \beta}} \log F \beta\right)
\end{aligned}
\]
où
\[
\begin{aligned}
& \psi x=\int \frac{f x \cdot d x}{f_2 x \cdot \sqrt{\alpha_0+\alpha_1 x+\alpha_2 x^2+\alpha_3 x^3}}, \varphi x=\alpha_0+\alpha_1 x+\alpha_2 x^2+\alpha_3 x^3, \\
& z=\frac{\left(x_2 \sqrt{\operatorname{qr} x_1} \pm x_1 \sqrt{1 x_2}\right)^2-\alpha_0\left(x_1-x_2\right)^2}{\alpha_3 x_1 x_2\left(x_1-x_2\right)^2}, \\
& F x=\frac{-\frac{x-x_2}{x_1-x_2} \sqrt{\rho x_1} \mp \frac{x-x_1}{x_2-x_1} \sqrt{\uparrow \cdot x_2}+\sqrt{\rho \cdot x}}{-\frac{x-x_2}{x_1-x_2} \sqrt{\rho x_1} \mp \frac{x-x_1}{x_2-x_1} \sqrt{\rho \cdot x_2}-\sqrt{\rho \cdot v}}, \\
&
\end{aligned}
\]
ou bien
\[
F x=\frac{\frac{\sqrt{\varphi x_1}}{\left(x_1-x\right)\left(x_1-x_2\right)} \pm \frac{\sqrt{\varphi x_2}}{\left(x_2-x\right)\left(x_2-x_1\right)}+\frac{\sqrt{\varphi x}}{\left(x-x_1\right)\left(x-x_2\right)}}{\frac{\sqrt{\varphi x_1}}{\left(x_1-x\right)\left(x_1-x_2\right)} \pm \frac{\sqrt{\varphi x}}{\left(x_2-x\right)\left(x_2-x_1\right)}-\frac{\sqrt{\varphi x}}{\left(x-x_1\right)\left(x-x_2\right)}} .
\]
%208
Poul \(f_2 x=x-\beta, f x=1\), on a
\[
\psi x_1 \pm \psi x_2= \pm \psi z+C+\frac{1}{\sqrt{q \beta}} \log F \beta, \text { où } \psi x=\int \frac{d x}{(x-\beta) \sqrt{\varphi x}} ;
\]
et pour \(f_2 x=1, f x=1\),
\[
\psi x_1 \pm \psi x_2= \pm \psi z+C, \text { où } \psi x=\int \frac{d x}{\sqrt{q \cdot x}} .
\]

Soit encore \(m=3\), on aura \(\theta=2\), et \(h\left(\varphi_0 x \cdot \varphi_1 x\right)=5\) ou 6 . Dans ce cas done on a
\[
\psi x=\int \frac{f_x x \cdot d x}{f_2 x \sqrt{R}},
\]
où \(R\) est un polynonie du cinquième ou sixième degré, et
\[
\omega_1 \psi x_1+\omega_2 \psi x_2+\cdots+\omega_a \psi x_u=v-\pi_1 \psi z_1-\pi_2 \psi z_3 .
\]

Ces fonctions \(z_1, z_2\) sont les deux racines d'une équation du second degré, dont les coefticients sont des fonctions rationnelles de \(x_1, x_2, x_3 \ldots\) et \(\boldsymbol{V} \boldsymbol{R}_1, \mathbb{V} \boldsymbol{R}_2, \boldsymbol{V} \boldsymbol{R}_3 \ldots\), en désignant par \(\boldsymbol{R}_1, R_2, R_3 \ldots\), les valeurs de \(\boldsymbol{R}\) correspondant à \(x_1, x_2, x_3 \ldots\)
Comme cas particuliers je citerai seulement les suivants:
\(1^0\) Lorsque \(f x=A_0+A_1 x, f_2 x=1\). Alors on aura
et
\[
\psi x=\int \frac{\left(A_0+A_1 x\right) d x}{\sqrt{\alpha_0+\alpha_1 x+\cdots+\alpha_5 x^5+\alpha_6 x^6}}
\]
\[
\pm \psi x_1 \pm \psi x_2 \pm \psi x_3 \pm \cdots \pm \psi x_\alpha= \pm \psi z_1 \pm \psi z_2+C .
\]
\(2^0\) Lorsque \(\varphi_0 x=1, \varphi_1 x=\alpha_0+\alpha_1 x+\alpha_2 x^2+\alpha_3 x^3+\alpha_4 x^4+\alpha_5 x^5=\varphi x\), \(v_0 x=a_0+a_1 x+a_2 x^2, v_1 x=1\).
Alors on trouvera facilement
\[
v_0 x=\mp \frac{\left(x-x_2\right)\left(x-x_3\right)}{\left(x_1-x_2\right)\left(x_1-x_3\right)} \sqrt{\varphi x_1} \mp \frac{\left(x-x_1\right)\left(x-x_3\right)}{\left(x_2-x_1\right)\left(x_2-x_3\right)} \sqrt{\varphi x_2} \mp \frac{\left(x-x_1\right)\left(x-x_2\right)}{\left(x_3-x_1\right)\left(x_3-x_2\right)} \sqrt{\varphi x_3}
\]
et
\[
\pm \psi x_1 \pm \psi x_2 \pm \psi x_3= \pm \psi z_1 \pm \psi z_2+C
\]
\(-I I \frac{f x}{f_2 x \sqrt{\rho x}} \log \frac{F_0^{\prime} x}{F_1^{\prime} x}+\Sigma \nu \frac{d^{\nu-1}}{d \beta^{\nu-1}}\left\{\frac{f \beta}{f_2^{(\nu) \beta \sqrt{\varphi \beta}}} \log \frac{F_0 \beta}{F_1^{\prime} \beta}\right\}\)
où
\[
\psi x=\int \frac{f x \cdot d x}{f_2 x \cdot \sqrt{f x}}
\]
%209
et
\[
\frac{F_0 x}{F_1 x}=\frac{\frac{ \pm \sqrt{\varphi x_1}}{\left(x_1-x\right)\left(x_1-x_2\right)\left(x_1-x_3\right)}+\frac{ \pm \sqrt{\varphi x_2}}{\left(x_2-x\right)\left(x_2-x_1\right)\left(x_2-x_3\right)}+\frac{ \pm \sqrt{q x_3}}{\left(x_3-x\right)\left(x_3-x_1\right)\left(x_3-x_2\right)}+\frac{\sqrt{\varphi x}}{\left(x-x_1\right)\left(x-x_2\right)\left(x-x_3\right)}}{\frac{ \pm \sqrt{\varphi x_1}}{\left(x_1-x\right)\left(x_1-x_2\right)\left(x_1-x_3\right)}+\frac{ \pm \sqrt{\varphi x_2}}{\left(x_2-x\right)\left(x_2-x_1\right)\left(x_2-x_3\right)}+\frac{ \pm \sqrt{\varphi x_3}}{\left(x_3-x\right)\left(x_3-x_1\right)\left(x_3-x_2\right)}-\frac{\sqrt{\varphi x}}{\left(x-x_1\right)\left(x-x_2\right)\left(x-x_3\right)}}
\]
\(z_1\) et \(z_2\) sont les racines de l'équation
\[
\frac{\left(v_0 z\right)^2-\varphi z}{\left(z-x_1\right)\left(z-x_2\right)\left(z-x_3\right)}=0 .
\]

En faisant dans la formule générale (202) \(v_1=1\), on aura
\[
v_0 x=\left\{\begin{array}{c}
-\omega_1 \frac{\left(x-x_2\right) \cdots\left(x-x_\alpha\right)}{\left(x_1-x_2\right) \cdots\left(x_1-x_\alpha\right)} \sqrt{\frac{\varphi_1 x_1}{\rho_0 x_1}-\omega_2 \frac{\left(x-x_1\right)\left(x-x_3\right) \cdots\left(x-x_\alpha\right)}{\left(x_2-x_1\right)\left(x_2-x_3\right) \cdots\left(x_2-x_\alpha\right)} \sqrt{\frac{\Phi_1 x_2}{f_0 x_2}}} \\
-\cdots-\omega_\alpha \frac{\left(x-x_1\right) \cdots\left(x-x_{\alpha-1}\right)}{\left(x_\alpha-x_1\right) \cdots\left(x_\alpha-x_{\alpha-1}\right)} \sqrt{\frac{\varphi_1 x_\alpha}{\varphi_0 x_\alpha}}
\end{array}\right.
\]
et d'après cela
où
\(z_1, z_2, \ldots z_0\) sont les racines de l'équation
\[
\frac{v_0{ }^2 \cdot \varphi_0 z-\varphi_1 z}{\left(z-x_1\right)\left(z-x_2\right) \cdots\left(z-x_\omega\right)}=0 .
\]

En faisant dans la même formule générale \(f_2 x=1\), on aura
\[
\Sigma \omega \psi x+\Sigma \pi \psi z=C-\Pi\left(\frac{f_i}{\sqrt{\varphi_0 x \cdot \varphi_1 x}} \log \frac{v_0 x \sqrt{\varphi_0 x}+v_1 x \sqrt{\varphi_1 x}}{v_0 x \sqrt{\varphi_0 x}-v_1 x \sqrt{\varphi_1 x}}\right),
\]
%210
où
\[
\psi x=\int \frac{f x \cdot d x}{\sqrt{q_0 x \cdot f_1 x}} .
\]

Si \(f x\) est du \((m-2)^e\) degré, on aura
\[
\Sigma \omega \psi x+\Sigma \pi \psi z=C
\]

Si l'on fait \(f_{\mathrm{z}} x=x-\beta, f x=1\), on aura
où
\[
\psi x=\int \frac{d x}{(x-\beta) \sqrt{\rho_0 x \cdot \varsigma_1 x}} .
\]
C) Soit en troisième lieu \(n=3, R=r_1^{\frac{1}{3} r_z^2}, \alpha_1=0, \alpha_2=0\).

Alors on aura
\[
\begin{aligned}
& s_0=1, s_1=r_1^{\frac{1}{3}} r_2^2, s_2=r_1^{{ }^3} r_2^{\frac{1}{3}}, \boldsymbol{R}^{(0)}=s_0, \boldsymbol{R}^{(1)}=s_1, \boldsymbol{R}^{(2)}=s_2, \\
& \theta^{\prime}(x, 0)=v_0+v_1 r_1^1 r_2^{\frac{2}{3}}+v_2 r_1^3 r_2^{\frac{1}{3}}, \\
& \theta^{\prime}(x, 1)=v_0+\omega v_1 r_1^{\frac{1}{3}} r_2^{\frac{2}{3}}+\omega^2 v_2 r_1^{\frac{2}{3} r_2^{\frac{1}{3}},} \\
& \theta^{\prime}(x, 2)=v_0+\omega^2 v_1 r_1^{\frac{1}{3}} r_2^{\frac{2}{3}}+\omega v_2 r_1^3 r_z^{\frac{1}{3}}, \\
& \varphi x=\log \theta^{\prime}(x, 0)+\omega^m \log \theta^{\prime}(x, 1)+\omega^{2 m} \log \theta^{\prime}(x, 2), \\
& \boldsymbol{\theta}^{\prime}(x, 0) \boldsymbol{\theta}^{\prime}(x, 1) \boldsymbol{\theta}^{\prime}(x, 2)=v_0^3+v_1^3 r_1 r_2^2+v_2^3 r_1^2 r_2-3 v_0 v_1 v_2 r_1 r_2 . \\
&
\end{aligned}
\]

En faisant donc \(m=1, r_1=\varphi_0 x, r_2=\varphi_1 x, v_0=v_0(x), v_1=v_1(x)\), \(v_2=v_2(x)\), la formule \((179)\) deviendra
où
%211
\[
\begin{aligned}
& F_0 x=v_0(x)+v_1(x)\left(\varphi_0 x\right)^{\frac{1}{3}}\left(\varphi_1 x\right)^{\frac{8}{3}}+v_2(x)\left(\varphi_0 x\right)^{\frac{2}{3}}\left(\varphi_1 x\right)^{\frac{1}{3}} \\
& F_1 \dot{x}=v_0(x)+\omega v_1(x)\left(\varphi_0 x\right)^{\frac{1}{3}}\left(\varphi_1 x\right)^{\frac{8}{3}}+\omega^2 v_2(x)\left(\varphi_0 x\right)^{\frac{8}{3}}\left(\varphi_1 x\right)^{\frac{1}{3}} \\
& F_2 x=v_0(x)+\omega^2 v_1(x)\left(\varphi_0 x\right)^{\frac{1}{3}}\left(\varphi_1 x\right)^{\frac{2}{3}}+\omega v_2(x)\left(\varphi_0 x\right)^{\frac{8}{3}}\left(\varphi_1 x\right)^{\frac{1}{3}}
\end{aligned}
\]

Pour les mêmes valeurs de \(x_1, x_2, x_3, \ldots z_1, z_2, \ldots F_0 x, F_1 x, F_2 x\), on aura aussi
\[
\begin{aligned}
& \Sigma \omega \psi x+\Sigma \pi \psi z= \\
& C-\Pi \frac{f x}{f_2 x \cdot\left(\varphi_0 x\right)^{\frac{2}{3}}\left(\Upsilon_1 x\right)^{\frac{1}{3}}}\left[\log \left(F_0 x\right)+\omega^2 \log \left(F_1 x\right)+\omega \log \left(F_2 x\right)\right] \\
& +\Sigma v^{\prime} \frac{d^{\nu-1}}{d \beta^{\nu-1}}\left\{\frac{f \beta}{\left\{f_2^{(\nu) \beta \cdot\left(\varphi_0 \beta\right)^{\frac{8}{3}}\left(\varphi_1 \beta\right)^{\frac{1}{3}}}\right.}\left[\log \left(F_0 \beta\right)+\omega^2 \log \left(F_1 \beta\right)+\omega \log \left(F_2 \beta\right)\right]\right\} . \\
&
\end{aligned}
\]

Les fonctions \(z_1, z_2, \ldots z_\theta\), sont les racines de l'équation
\[
\frac{\left[v_0(z)\right]^3+\left[v_1(z)\right]^3 \varphi_0 z\left(\varphi_1 z\right)^2+\left[v_2(z)\right]^3\left(\varphi_0 z\right)^2\left(\varphi_1 z\right)-3 v_0(z) \cdot v_1(z) \cdot v_2(z) \cdot \varphi_0 z \cdot \varphi_1 z}{\left(z-x_1\right)\left(z-x_2\right)\left(z-x_3\right) \cdots\left(z-x_{\alpha-1}\right)\left(z-x_\alpha\right)}=0
\]

D'après l'équation (172), la plus petite valeur sera
\[
\theta=h r_1+h r_2+1-\frac{3+n^{\prime}}{2}
\]
en remarquant que \(k_1=1, k_2=1, n^{\prime}\) est le plus grand commun diviseur de 3 et \(h r_1+2 h r_2\).
Soit d'abord \(h r_1+2 h r_2=3 m\), on aura \(n^{\prime}=3\) et \(\theta=h\left(\varphi_0 x \cdot \varphi_1 x\right)-2\).
Si \(h r_1+2 h r_8=3 m-1\) ou \(3 m-2\), on aura \(n^{\prime}=1\), et par suite \(\theta=h\left(\varphi_0 x \cdot \varphi_1 x\right)-1\).
Ainsi, par exemple, on aura pour
\[
\begin{aligned}
h\left(\varphi_0 x \cdot \varphi_1 x\right) & =1,2,3,4,5,6 \ldots \\
\theta & =0,1,2,3,4,5 \ldots \text { lorsque } h \varphi_0 x+2 h \varphi_1 x=3 m \pm 1 \\
\text { et } \theta & =0,1,2,3,4 \ldots \text { lorsque } h \varphi_0 x+2 h \varphi_1 x=3 m .
\end{aligned}
\]
%212
XIII.

RECHERCHE DE LA QUANTITÉ QUI SATISFAIT A LA FOIS A DEUX ÉQUATIONS ALGÉBRIQUES DONNÉES.

Annales de Mathímatiques pures et appliquées rédigées par M. J. D. Gergonne, t. XVII, Paris 1827.

Lorsqu'une quantité satisfait, à la fois, à deux équations algébriques données, ces deux équations ont un facteur commun du premier degré. En supposant quelles n'ont pas d'autre facteur commun que celui-la, on peut toujours, comme l'on sait, exprimer rationnellement l'inconnue en fonction des coefficiens des deux équations. On y parvient d'ordinaire à l'aide de l'élimination; mais je vais faire voir, dans ce qui va suivre, que, dans tous les cas, on peut calculer immédiatement la valeur de l'inconnue, ou, plus généralement encore, la valeur d'une fonction rationnelle quelconque de cette ineonnue.
Soient
\[
\begin{aligned}
& \varphi y=p_0+p_1 y+p_2 y^2+\cdots+p_{m-1} y^{m-1}+y^m=0, \\
& \psi y=q_0+q_1 y+q_2 y^2+\cdots+q_{n-1} y^{n-1}+y^n=0,
\end{aligned}
\]
les deux équations proposées, la première du \(m^{\text {ieme }}\) et l'autre du \(n^{\text {ìme }}\) degré. Désignons les \(n\) racines de (2) par \(y, y_1, y_2, \ldots y_{n-1}\); en les substituant tour a tour dans (1), on aura les \(n\) fonctions
\[
\varphi y, \varphi y_1, \varphi y_2, \ldots \varphi y_{n-1} \text {. }
\]
%213
Soient
\[
\left\{\begin{array}{c}
R=\varphi y_1 \cdot \varphi y_2 \cdot \varphi y_3 \ldots \varphi y_{n-2} \cdot \varphi y_{n-1} \\
R_1=\varphi y \cdot \varphi y_2 \cdot \varphi y_3 \ldots \varphi y_{n-2} \cdot \varphi y_{n-1} \\
R_2=\varphi y \cdot \varphi y_1 \cdot \varphi y_3 \ldots \varphi y_{n-2} \cdot \varphi y_{n-1} \\
\cdots \cdots \cdots \cdots \\
R_{n-2}=\varphi y \cdot \varphi y_1 \cdot \varphi y_2 \ldots \varphi y_{n-3} \cdot \varphi y_{n-1} \\
R_{n-1}=\varphi y \cdot \varphi y_1 \cdot \varphi y_2 \ldots \varphi \varphi y_{n-3} \cdot \varphi y_{n-2} .
\end{array}\right.
\]

Cela posé, soit \(f y\) la fonction rationnelle de \(y\) dont on veut déterminer la valeur, et désignons par \(\theta y\) une autre fonction rationnelle quelconque de \(\%\). On aura l'équation identique
(5)
\[
f y \cdot \theta y \cdot R=f y \cdot \theta y \cdot R .
\]

Maintenant, ayant \(\varphi y=0\), on aura
\[
R_1=0, R_2=0, R_3=0, \ldots R_{n-1}=0,
\]
et, par suite, .
\[
t R+t_1 R_1+t_2 R_2+t_3 R_3+\cdots+t_{n-2} R_{n-2}+t_{n-1} R_{n-1}=t R
\]
où \(t, t_1, t_2, \ldots t_{n-2}, t_{n-1}\) sont des quantités quelconques.
En faisant done d'abord
\[
t=\theta y, t_1=\theta y_1, t_2=\theta y_2, \ldots t_{n-1}=\theta y_{n-1},
\]
et ensuite
\[
t=f y \cdot \theta y, t_1=f y_1 \cdot \theta y_1, t_2=f y_2 \cdot \theta y_2, \ldots t_{n-1}=f y_{n-1} \cdot \theta y_{n-1},
\]
on obtiendra les deux équations
(6)
\[
\left\{\begin{array}{r}
\theta y \cdot R=\theta y \cdot R+\theta y_1 \cdot R_1+\theta y_2 \cdot R_2+\cdots+\theta y_{n-1} \cdot R_{n-1} \\
f y \cdot \theta y \cdot R=f y \cdot \theta y \cdot R+f y_1 \cdot \theta y_1 \cdot R_1+f y_2 \cdot \theta y_2 \cdot R_2+\cdots \\
+f y_{n-1} \cdot \theta y_{n-1} \cdot R_{n-1}
\end{array}\right.
\]
par là, l'équation (5) deviendra
\[
\begin{aligned}
& f y\left(\theta y \cdot R+\theta y_1 \cdot R_1+\theta y_2 \cdot R_2+\cdots+\theta y_{n-1} \cdot R_{n-1}\right) \\
& \quad=\theta y \cdot f y \cdot R+\theta y_1 \cdot f y_1 \cdot R_1+\theta y_2 \cdot f y_2 \cdot R_2+\cdots+\theta y_{n-1} \cdot f y_{n-1} \cdot R_{n-1} ;
\end{aligned}
\]
équation qui, en posant, pour abréger,
\[
\left\{\begin{array}{r}
\theta y \cdot R+\theta y_1 \cdot R_1+\theta y_2 \cdot R_3+\cdots+\theta y_{n-1} \cdot R_{n-1}=\Sigma \theta y \cdot R \\
f y \cdot \theta y \cdot R+f y_1 \cdot \theta y_1 \cdot R_1+f y_{\mathrm{s}} \cdot \theta y_2 \cdot R_2+\cdots \\
+f y_{n-1} \cdot \theta y_{n-1} \cdot R_{n-1}=\Sigma f y \cdot \theta y \cdot R,
\end{array}\right.
\]
%214
deviendra
et de la
\[
f y \Sigma \theta y \cdot R=\Sigma f y \cdot \theta y \cdot R
\]
\[
f y=\frac{\Sigma f y \cdot \theta y \cdot R}{\Sigma \theta y \cdot R}
\]

Maintenant il est clair que le numérateur et le dénominateur de cette valeur de \(f y\) sont des fonctions rationnelles et symétriques des racines \(y\), \(y_1, y_2, y_3, \ldots y_{n-1}\); on pent donc en vertu des formules comnues, les exprimer ratiomellement par les coefficiens des équations (1) et (2). Il en est donc de même de la fonction \(f y\).

La fonction rationmelle \(\theta y\) étant arbitraire, on peut en disposer pour simplitier l'expression de \(f y\). Pour cela, soit
\[
f y=\frac{F y}{x . y},
\]
où \(F y\) et \(\chi y\) sont deux fonctions entières; on aura, en substituant,
\[
\frac{F^{\prime} y}{\chi y}=\frac{\Sigma \frac{F y \cdot \theta y . R}{\chi(y)}}{\Sigma \theta y \cdot R}
\]
si donc on suppose \(\theta y=\chi ! y\), on aura
\[
\frac{F y}{\chi y}=\frac{\Sigma F y \cdot R}{\Sigma_{\chi y \cdot R}}
\]
et alors le numérateur et le dénominateur de cette fonction seront des fonctions entières des coefficiens des équations proposées.
Si \(x y=1\), on aura, pour une fonction entière quelconque \(F y\),
\[
F y=\frac{\Sigma F y \cdot R}{\Sigma R}
\]
ou bien
\[
F y=\frac{F y \cdot R+F y_1 \cdot R_1+F y_2 \cdot R_2+\cdots+F y_{n-1} \cdot R_{n-1}}{R+R_1+R_2+\cdots+R_{n-1}}
\]

Mais on pent encore simplifier beaucoup l'expression de \(F y\) de la manière suivante:
Désignons par \(\psi^{\prime} y\) la dérivée de \(\psi y\), par rapport à \(y\), et faisons
\[
\theta y=\frac{1}{\psi^{\prime} y}
\]
l'équation (8) domnera
%215
\[
F y=\frac{\Sigma \frac{F^{\prime} y}{\psi^{\prime} y}}{\Sigma \frac{R}{\psi^{\prime} y}} .
\]

Cela posé, on peut d'abord exprimer \(R\) par une fonction entière de \(y\). En effet, si l'on fait
\[
\left(z-y_1\right)\left(z-y_2\right) \cdots\left(z-y_{n-1}\right)=z^{n-1}+v_{n-2} z^{n-2}+v_{n-3} z^{n-3}+\cdots+v_0=0,
\]
on peut transformer \(R\), qui est une fonction entière et symétrique de \(y_1, y_2\), \(y_3, \ldots y_{n-1}\), en fonction entière des coefficiens \(v_0, v_1, v_2, \ldots v_{n-2}\).
Maintenant, on a
\[
\begin{aligned}
&\left.v_0+v_1 z+v_2 z^2+\cdots+v_{n-2} z^{n-2}+z^{n-1}\right)(z-y) \\
&=q_0+q_1 z+q_2 z^2+\cdots+q_{n-1} z^{n-1}+z^n=z^n+\left(v_{n-2}-y\right) z^{n-1} \\
&+\left(v_{n-3}-y v_{n-2}\right) z^{n-2}+\left(v_{n-4}-y v_{n-3}\right) z^{n-3}+\cdots
\end{aligned}
\]
done
\[
\begin{aligned}
& v_{n-2}=q_{n-1}+y, \\
& v_{n-3}=q_{n-2}+y \cdot v_{n-2}, \\
& v_{n-4}=q_{n-3}+y \cdot v_{n-3}, \\
& \ldots \ldots \ldots
\end{aligned}
\]
d'où il suit que \(v_0, v_1, v_2, \ldots v_{n-2}\) sont des fonctions entières de \(y\); la fonction \(R\) l'est donc aussi; elle est donc de la forme
\[
R=\varrho_0+\varrho_1 y+\varrho_2 y^2+\varrho_3 y^3+\cdots+\varrho_\mu y^\mu,
\]
où il est évident que \(\varphi_0, \varrho_1, \varrho_2, \ldots \varrho_\mu\) seront des fonctions entières des coefficiens des équations (1) et (2).

La fonction \(R\) sera d'un degré supérieur à \(n-1\); mais il est clair qu'on peut, en vertu de l'équation (2), en éliminer toutes les puissances de y supérieures à la \((n-1)^{i \text { ièe }}\), et de cette manière mettre \(R\) sous la forme
\[
R=\varrho_0+\varrho_1 y+\varrho_2 y^2+\varrho_3 y^3+\cdots+\varrho_{n-1} y^{n-1},
\]
où \(\varrho_0, \varrho_1, \varrho_2, \ldots \varrho_{n-1}\) sont tonjours des fonctions entières de \(p_0, p_1, p_2\), \(\cdots p_{m-1}, q_0, q_1, q_2, \ldots q_{n-1}\).

En multipliant \(R\) par la fonction entière \(F_y\) on aura la fonction \(F y . R\), qui est de même une fonction entière de \(y\). On peut donc la mettre sous la même forme que \(R\), c'est-à-dire qu'on peut poser
\[
F y \cdot R=t_0+t_1 y+t_2 y^2+t_3 y^3+\cdots+t_{n-1} y^{n-1},
\]
%216
\(t_0, t_1, t_2, \ldots t_{n-1}\) étant encore des fonctions entières de \(p_0, p_1, p_2 \cdots p_{m-1}\), \(q_0, q_1, q_2, \ldots q_{n-1}\).
Dès que \(R\) sera déterminé par l'équation (12), il est clair qu'on aura
\[
\begin{aligned}
& R_{n-1}=\varrho_0+\varrho_1 y_{n-1}+\varrho_2 y_{n-1}^2+\varrho_3 y_{n-1}^3+\cdots+\varrho_{n-1} y_{n-1}^{n-1} \text {. } \\
&
\end{aligned}
\]

On aura de même
\[
\begin{gathered}
F y_1 \cdot R_1=t_0+t_1 y_1+t_2 y_1^2+t_3 y_1^3+\cdots+t_{n-1} y_1^{n-1} \\
F y_2 \cdot R_2=t_0+t_1 y_2+t_2 y_2^2+t_3 y_2^3+\cdots+t_{n-1} y_2^{n-1} \\
\cdots \cdots \cdots \cdot \cdots \cdot \cdots \cdot t_{n-1} y_{n-1}^{n-1}
\end{gathered}
\]

Maintenant je dis qu'on aura
\[
F y=\frac{t_{n-1}}{\varrho_{n-1}} .
\]

En effet, on a d'abord
\[
\Sigma \frac{R}{\psi^{\prime} y}=\frac{R}{\psi^{\prime} y}+\frac{R_1}{\psi^{\prime} y_1}+\frac{R_2}{\psi^{\prime} y_2}+\cdots+\frac{R_{n-1}}{\psi^{\prime} y_{n-1}}
\]
donc, en substituant les valeurs de \(R, R_1, R_2, \ldots R_{n-1}\),
\[
\begin{aligned}
\Sigma \frac{R}{\psi^{\prime} y}= & \omega_0\left(\frac{1}{\psi^{\prime} y}+\frac{1}{\psi^{\prime} y_1}+\frac{1}{\psi^{\prime} y_2}+\cdots+\frac{1}{\psi^{\prime} y_{n-1}}\right) \\
& +\varrho_1\left(\frac{y}{\psi^{\prime} y}+\frac{y_1}{\psi^{\prime} y_1}+\frac{y_2}{\psi^{\prime} y_2}+\cdots+\frac{y_{n-1}}{\psi^{\prime} y_{n-1}}\right) \\
& +\omega_2\left(\frac{y^2}{\psi^{\prime} y}+\frac{y_1^2}{\psi^{\prime} y_1}+\frac{y_2^2}{\psi^{\prime} y_2}+\cdots+\frac{y_{n-1}^2}{\psi^{\prime} y_{n-1}}\right) \\
& +\cdots \cdots \cdots \\
& \left.+\cdots \cdots+\cdots+\frac{y_{n-1}^{n-1}}{\psi^{\prime} y_{n-1}}\right)
\end{aligned}
\]

Or, \(y, y_1, y_2, \ldots y_{n-1}\), étant les racines de l'équation (2) on a
\[
\begin{aligned}
& \psi^{\prime} y=\left(y-y_1\right)\left(y-y_2\right)\left(y-y_3\right) \cdots\left(y-y_{n-1}\right), \\
& \psi^{\prime} y_1=\left(y_1-y\right)\left(y_1-y_2\right)\left(y_1-y_3\right) \cdots\left(y_1-y_{n-1}\right), \\
& \psi^{\prime} y_2=\left(y_2-y\right)\left(y_2-y_1\right)\left(y_2-y_3\right) \cdots\left(y_2-y_{n-1}\right), \\
& \ldots \ldots \ldots \ldots \ldots
\end{aligned}
\]
%217
\[
\psi^{\prime} y_{n-1}=\left(y_{n-1}-y\right)\left(y_{n-1}-y_1\right)\left(y_{n-1}-y_2\right) \cdots\left(y_{n-1}-y_{n-2}\right)
\]
donc, d'après une formule comnue, les coefticiens de \(\varrho_0, \varrho_1, \varrho_2, \ldots \varrho_{n-1}\), dans l'expression de \(\Sigma \frac{R}{\psi^{\prime} y}\), s'évanouiront tous, excepté celui de \(\varrho_{n-1}\), qui se réduira à l'unité; on aura done
\[
\Sigma \frac{R}{\psi^{\prime} y}=\varrho_{n-1} .
\]

On pronvera exactement de la même manière que
\[
\Sigma \frac{R \cdot F y}{\psi^{\prime} y}=t_{n-1}
\]
donc, en vertu de l'équation (11),
\[
F y=\frac{t_{n-1}}{\varrho_{n-1}},
\]
ou bien, en écrivant \(t\) et \(\varphi\), au lieu de \(t_{n-1}\) et \(\varrho_{n-1}\),
\[
F y=\frac{t}{\varrho} \text {. }
\]

Soit maintenant \(F^{\prime} y\) une autre fonction entière de \(y\); en supposant
\[
F^{\prime} y \cdot R=t^{\prime} y^{n-1}+t_{n-2}^{\prime} y^{n-2}+t_{n-3}^{\prime} y^{n-3}+\cdots+t_1^{\prime} y+t_0^{\prime}
\]
\(t^{\prime}, t_{n-2}^{\prime}, t_{n-3}^{\prime}, \ldots t_0^{\prime}\) étant des fonctions entières des quantités \(p_0, p_1, p_2\), \(\ldots p_{m-1}, q_0, q_1, q_2, \ldots q_{n-1}\), on aura
\[
F^{\prime \prime} y=\frac{t^{\prime}}{\varrho}
\]
d'où, en comparant (14) à (16),
\[
\frac{F y}{F^{\prime} y}=\frac{t}{t^{\prime}}
\]

Ainsi on aura la valeur d'une fonction rationnelle quelconque \(\frac{F_y}{F^{\prime} y}\) par le développement des deux fonctions
\[
F y . R \text { et } F^{\prime \prime} y . R \text {. }
\]

La formule (17) peut facilement être traduite en théorème.
Le cas le plus simple est celui où l'on cherche uniquement la valeur de \(y\). Alors on a
\[
y=\frac{t}{\varrho}
\]
vù
\[
R=\rho y^{n-1}+\varrho^{\prime} y^{n-2}+\cdots \text { et } R y=t y^{n-1}+t^{\prime} y^{n-8}+\cdots
\]
%218
On peut exprimer \(t\) en \(\varrho\) et \(\varrho^{\prime}\). . En effet en substituant la valeur de \(R\), il viendra
\[
R y=\varrho y^n+\varrho^{\prime} y^{n-1}+\cdots ;
\]
or, en vertu de l'équation (2), on a
\[
y^n=-q_{n-1} y^{n-1}-q_{n-2} y^{n-2}-\cdots
\]
donc, en substituant
\[
R y=\left(\varrho^{\prime}-\rho q_{n-1}\right) y^{n-1}+\cdots \cdot
\]

Dans le développement de \(R y\), le coefficieut de \(y^{n-1}\) est donc
donc:
\[
\begin{aligned}
& \varrho^{\prime}-\varrho q_{n-1}=t \\
& y=\frac{\varrho^{\prime}-\varrho q_{n-1}}{\varrho}
\end{aligned}
\]
ou bien
\[
y=-q_{n-1}+\frac{\varrho^{\prime}}{\varrho}
\]

De cette manière, on n'a besoin de comnaître que les coefficiens de \(y^{n-1}\) et \(y^{n-2}\) dans le développement de
\[
\boldsymbol{l}=\varphi y^{n-1}+\varrho^{\prime} y^{n-2}+\cdots=\varphi y_1 \cdot \varphi y_2 \cdot \varphi y_3 \ldots \varphi y_{n-1} .
\]

Paris, le 2 novembre 1826
%219
XIV.

RECHERCHES SUR LA SÉRIE \(1+\frac{m}{1} x+\frac{m(m-1)}{1.2} x^2+\frac{m(m-1)(m-2)}{1.2 .3} x^3+\cdots\)
Journal für die reine und angewandte Mathematik, herausgegeben von Crelle, Bd. I, Berlin 1826.
1.
Si l'on fait subir au raisonnement dont on se sert en général quand il s'agit des séries infinies, un examen plus exact, on trouvera qu'il est, à tout prendre, peu satisfaisant, et que par conséquent le nombre des théorèmes, concemant les séries infinies, qui peuvent être considérés comme rigoureusement fondés, est très limité. On applique ordinairement les opérations de l'analyse aux séries infinies de la même manière que si les séries étaient finies, ce qui ne me semble pas permis sans démonstration particulière. Si par exemple on doit multiplier deux séries infinies l'une par l'autre, on pose
\[
\begin{aligned}
& \left(u_0+u_1+u_2+u_3+\cdots\right)\left(v_0+v_1+v_2+v_3+\cdots\right)=u_0 v_0+\left(u_0 v_1+u_1 v_0\right) \\
& +\left(u_0 v_2+u_1 v_1+u_2 v_0\right)+\cdots+\left(u_0 v_n+u_1 v_{n-1}+u_2 v_{n-2}+\cdots+u_n v_0\right)+\cdots
\end{aligned}
\]

Cette équation est très juste lorsque les séries \(u_0+u_1+\cdots\) et \(v_0+v_1+\cdots\) sont finies. Mais si elles sont infinies, il est d'abord nécessaire qu'elles convergent, ear une série divergente n'a pas de somme; ensuite la série du second membre doit de même converger. C'est senlement avec cette restriction que l'expression ci-dessus èst juste; mais, si je ne me trompe, jusqu'à présent on n'y a pas eu égard. C'est ce qu'on se propose de faire dans ce mémoire. Il y a encore plusieurs opérations semblables à justifier p. ex.
%220
le procédé ordinaire pour diviser une quantité par une série infinie, celui de l'élévation d'une série infinie à une puissance, celui de la détermination de son logarithme, de son sinus, de son cosinus, etc.

Un autre procédé qu'on trouve fréquemment dans l'analyse, et qui assez souvent conduit à des contradictions, c'est qu'on se sert des séries divergentes pour l'évaluation des valeurs numériques des séries. Une série divergente ne peut jamais être égale à une quantité déterminée; c'est seulement une expression jouissant de certaines propriétés qui se rapportent aux opérations auxquelles la série est soumise.

Les séries divergentes peuvent quelquefois servir avec succès de symboles pour exprimer telle ou telle proposition d'une manière abrégée; mais oll ne saurait jamais les mettre à la place de quantités déterminées. Par un tel procédé on peut démontrer tout ce qu'on veut, l'impossible aussi bien que le possible.

Une des séries les plus remarquables daus l'analyse algébrique est celle-ci :
\[
\begin{aligned}
1+\frac{m}{1} x+\frac{m(m-1)}{1.2} x^2+ & \frac{m(m-1)(m-2)}{1.2 .3} x^3+\cdots \\
& +\frac{m(m-1)(m-2) \cdots[m-(n-1)]}{1.2 .3 \ldots n} x^n+\cdots
\end{aligned}
\]

Lorsque \(m\) est un nombre entier positif, on 'sait que la somme de cette série, qui dans ce cas est finie, peut s'exprimer par \((1+x)^m\). Lorsque \(m\) n'est pas un nombre entier, la série ira à l'infini, et elle sera convergente ou divergente, selon les différentes valeurs qu'on attribuerà à \(m\) et à \(x\). Dans ce cas on pose de même l'équation
\[
(1+x)^m=1+\frac{m}{1} x+\frac{m(m-1)}{1.2} x^2+\cdots
\]
mais alors l'égalité exprime seulement que les deux expressions
\[
(1+x)^m \text { et } 1+\frac{m}{1} x+\frac{m(m-1)}{1.2} x^2+\cdots
\]
ont certaines propriétés communes desquelles, pour certaines valeurs de \(m\) et de \(x\), dépend l'égalité numérique des expressions. On suppose que l'égalité numérique aura toujours lieu, lorsque la série est convergente; mais c'est ce qui jusqu'à présent n'est pas encore démontré. On n'a même pas examiné tous les cas où la série est convergente. Lors même
%221
qu'on suppose l'existence de l'équation ci-dessus, il reste encore à chercher la valeur de \((1+x)^m\), car cette expression a en général une infinité de valeurs différentes, tandis que la série \(1+m x+\cdots\) n'en a qu'une seule.

Le but de ce mémoire est d'essayer de remplir une lacune par la solution complète du problème suivant:
"Trouver la somme de la série
\[
1+\frac{m}{1} x+\frac{m(m-1)}{1.2} x^2+\frac{m(m-1)(m-2)}{1.2 .3} x^3+\cdots
\]
"pour toutes les valeurs réelles ou imaginaires de \(x\) et de \(m\) pour "lesquelles la série est convergente."
2.

Nous allons d'abord établir quelques théorèmes nécessaires sur les séries. L'excellent ouvrage de M. Cauchy "Cours d'analyse de l'école polytechnique", qui doit être lu par tout analyste qui aime la rigueur dans les recherches mathématiques, nous servira de guide.
Définition. Une série quelconque
\[
v_0+v_1+v_2+\cdots+v_m+\cdots
\]
sera dite convergente, si pour des valeurs toujours croissantes de \(m\), la somme \(v_0+v_1+\cdots+v_m\) s'approche indéfiniment d'une certaine limite. Cette limite s'appellera la somme de la série. Dans le cas contraire la série sera dite divergente, et elle n'a pas de somme. D'après cette définition, pour qu'une séric soit convergente, il est nécessaire et il suffit que pour des valeurs toujours croissantes de \(m\), la somme \(v_m+v_{m+1}+\cdots+v_{m+n}\) s'approche indéfiniment de zéro, quelle que soit la valeur de \(n\).

Done, dans une série convergente quelconque, le terme général \(v_m\) s'approchera indéfiniment de zéro*).

Théorème I. Si en désignant par \(\varrho_0, \varrho_1, \varrho_2 \ldots\) une série de quantités positives, le quotient \(\frac{\varrho_{m+1}}{\varrho_m}\), pour des valeurs toujours croissantes de \(m_{\text {, s'ap- }}\), proche indéfiniment d'une limite \(\alpha\) plus grande que 1, la série
*) Pour abréger, on représentera dans ce mémoire par (1) une quantité qui peut être plus petite que tonte quantité domnée.
%222
\[
\varepsilon_0 \varrho_0+\varepsilon_1 \varrho_1+\varepsilon_2 \varrho_2+\cdots+\varepsilon_m \varrho_m+\cdots
\]
où \(\varepsilon_m\) est une quantité qui pour des valeurs toujours croissantes de \(m\) ne s'approche pas indéfiniment de zéro, sera nécessairement divergente.

Théorème II. Si dans une série de quantités positives \(\varrho_0+\varrho_1+\varrho_2+\cdots\) \(+\varrho_m+\cdots\) le quotient \(\frac{\varrho_{m+1}}{\varrho_m}\), pour des valeurs toujours croissantes de \(m\), s'approche indéfiniment d'une limite. \(\alpha\) plus petite que 1 , la série
\[
\varepsilon_0 \varrho_0+\varepsilon_1 \varrho_1+\varepsilon_2 \varrho_2+\cdots+\varepsilon_m \varrho_m+\cdots,
\]
où \(\varepsilon_0, \varepsilon_1, \varepsilon_2\) etc. sont des quantités qui ne surpassent pas l'unité, sera nécessairement convergente.

En effet, d'après la supposition, on peut toujours prendre \(m\) assez grand pour que \(\varrho_{m+1}<\alpha \varrho_m, \varrho_{m+2}<\alpha \varrho_{m+1}, \ldots \varrho_{m+n}<\alpha \varrho_{m+n-1}\). Il suit de la que \(\varrho_{m+k}<\boldsymbol{\alpha}^k \varrho_m\) et par suite
\[
\varrho_m+\varrho_{m+1}+\cdots+\varrho_{m+n}<\varrho_m\left(1+\alpha+\alpha^2+\cdots+\alpha^n\right)<\frac{\varrho_m}{1-\alpha},
\]
donc, ì plus forte raison
\[
\varepsilon_m \varrho_m+\varepsilon_{m+1} \varrho_{m+1}+\cdots+\varepsilon_{m+n} \varrho_{m+n}<\frac{\varrho_m}{1-\alpha} .
\]

Or, puisque \(\varrho_{m+k}<\alpha^k \varrho_m\) et \(\alpha<1\), il est clair que \(\varrho_m\) et par conséquent la somme
\[
\varepsilon_m \varrho_m+\varepsilon_{m+1} \varrho_{m+1}+\cdots+\varepsilon_{m+n} \varrho_{m+n}
\]
aura zéro pour limite. La série ci-dessus est done convergente.
Théorème III. En désignant par \(t_0, t_1, t_2, \ldots t_m \ldots\) une série de quantités quelconques, si \(p_m=t_0^{-}+t_1+t_2+\cdots+t_m\) est toujours moindre qu'une quantité déterminée \(\delta\), on aura
\[
r=\varepsilon_0 t_0+\varepsilon_1 t_1+\varepsilon_2 t_2+\cdots+\varepsilon_m t_m<\delta \varepsilon_0
\]
où \(\varepsilon_0, \varepsilon_1, \varepsilon_2 \ldots\). . sont des quantités positives décroissantes.
En effet, on a
\[
t_0=p_0, t_1=p_1-p_0, \check{i}_2=p_2-p_1 \text { etc. }
\]
done
\[
r=\varepsilon_0 p_0+\varepsilon_1\left(p_1-p_0\right)+\varepsilon_2\left(p_2-p_1\right)+\cdots+\varepsilon_m\left(p_m-p_{m-1}\right)
\]
ou bien
\[
v=p_0\left(\varepsilon_0-\varepsilon_1\right)+p_1\left(\varepsilon_1-\varepsilon_2\right)+\cdots+p_{m-1}\left(\varepsilon_{m-1}-\varepsilon_m\right)+p_m \varepsilon_m .
\]
%223
Or les différences \(\varepsilon_0-\varepsilon_1, \varepsilon_1-\varepsilon_2, \ldots\) étant positives, la quantité \(r\) sera évidemment moindre que \(\delta \varepsilon_0\).

Définition. Une fonction \(f x\) sera dite fonction continue de \(x\) entre les limites \(x=a\) et \(x=b\), si pour une valeur quelconque de \(x\) comprise entre ces limites, la quantité \(f(x-\beta)\), pour des valeurs toujours décroissantes de \(\beta\), s'approche indéfiniment de la limite \(f x\).
Théorème IV. Si la série
\[
f \alpha=v_0+v_1 \alpha+v_2 \alpha^2+\cdots+v_n \alpha^m+\cdots
\]
est convergente pour une certaine valeur \(\delta\) de \(\alpha\), elle sera aussi convergente pour toute valeur moindre que \(\delta\), et, pour des valeurs toujours décroissantes de \(\beta\), la fonction \(f(\alpha-\beta)\) s'approchera indéfiniment de la limite \(f \alpha\), en supposant que \(\alpha\) soit égal ou inférieur à \(j\).
Soit
on aura.
\[
\begin{gathered}
v_0+v_1 \alpha+\cdots+v_{m-1} \alpha^{m-1}=\varphi \alpha \\
v_m \alpha^m+v_{m+1} \alpha^{m+1}+\cdots=\psi \alpha
\end{gathered}
\]
\[
\psi \alpha=\left(\frac{\alpha}{\delta}\right)^m v_m \delta^m+\left(\frac{\alpha}{\delta}\right)^{m+1} v_{m+1} \delta^{m+1}+\cdots ;
\]
donc, d'après le théorème III, \(\psi \alpha<\left(\frac{\alpha}{\delta}\right)^m p, p\) désignant la plus grande des quantités \(v_m \delta^m, v_m \delta^m+v_{m+1} \delta^{m+1}, v_m \delta^m+v_{m+1} \delta^{m+1}+v_{m+2} \delta^{m+2}\) etc. On pourra done pour toute valeur de \(\alpha\), égale ou inférieure à \(\delta\), prendre \(m\) assez grand pour qu'on ait
\[
\psi \alpha=\omega .
\]

Or \(f \alpha=\varphi \alpha+\psi \alpha\), done \(f \alpha-f(\alpha-\beta)=\varphi \alpha-\varphi(\alpha-\beta)+\omega\).
De plus, \(p \alpha\) étant une fonction entière de \(\alpha\), on peut prendre \(\beta\) assez petit pour que
\[
\varphi \alpha-\varphi(\alpha-\beta)=\omega
\]
donc on a de même
\[
f(\alpha-f(\alpha-\beta)=\omega
\]
ce qu’il fallait démontrer.
Théorème V. Soit
\[
v_0+v_1 \delta+v_2 \delta^2+\cdots
\]
une série convergente, dans laquelle \(v_0, v_1, v_2 \ldots\) sont des fonctions conti-
%224
nues d'une même quantité variable \(x\) entre les limites \(x=a\) et \(x=b\), la série
\[
f x=v_0+v_1 \alpha+v_2 \alpha^2+\cdots,
\]
où \(\alpha<\delta\), sera convergente et fonction continue de \(x\) entre les mêmes limites.
Il est déjà démontré que la série \(f x\) est convergente. On peut démontrer comme il suit, que la fonction \(f x\) est continue.
Soit
\[
\begin{gathered}
v_0+v_1 \alpha+\cdots+v_{m-1} \alpha^{m-1}=\varphi x \\
v_m \alpha^m+v_{m+1} \alpha^{m+1}+\cdots=\psi x
\end{gathered}
\]
(oll all'a
\[
f x=\varphi x+\psi x .
\]
()
\[
\psi x=\left(\begin{array}{l}
\alpha \\
\delta
\end{array}\right)^m v_m \delta^m+\left(\frac{\alpha}{\delta}\right)^{m+1} v_{m+1} \delta^{m+1}+\left(\frac{\alpha}{\delta}\right)^{m+2} v_{m+2} \delta^{m+2}+\cdots
\]
donc en désignant par \(\theta x\) la plus grande des quantités \(v_m \delta^m, v_m \delta^m+v_{m+1} \delta^{m+1}\), \(v_m \delta^m+v_{m+1} \delta^{m+1}+v_{m+2} \delta^{m+2}\) etc., on aura en vertu du théorème III:
\[
\psi x<\left(\frac{\alpha}{\delta}\right)^m \theta x
\]

Il s'ensuit qu'on peut prendre \(m\) assez grand pour qu'on ait \(\psi x=\omega\), et que par conséquent on ait aussi
\[
f x=\varphi x+\omega
\]
où \(\omega\) est moindre que toute quantité assignable.
On a de même
done
\[
\begin{aligned}
f(x-\beta) & =\varphi(x-\beta)+\omega \\
f x-f(x-\beta) & =\varphi x-\varphi(x-\beta)+\omega .
\end{aligned}
\]

Or d'après la forme de \(\varphi x\) il est clair qu'on peut prendre \(\beta\) assez petit pour qu'on ait
d'où l'on tire
\[
\begin{gathered}
\rho x-\varphi(x-\beta)=\omega \\
f x-f(x-\beta)=\omega .
\end{gathered}
\]

Donc la fonction \(f x\) est continue*).
*) Dans l'ouvrage cité de M. Ćuuchy on trouve (p. 131) le théorème suivant: "Lors"que les différens termes de la série, \(u_0+u_1+u_2+\cdots\) sont des fonctions d'une
%225
Théorème VI. Lorsqu'on désigne par \(\varrho_0, \varrho_1, \varrho_2\) etc. \(\varrho_0{ }^{\prime}, \varrho_1{ }^{\prime}, \varrho_2{ }^{\prime}\) etc. les valeurs numériques des membres respectif's des deux séries convergentes
si les séries
\[
\begin{gathered}
v_0+v_1+v_z+\cdots=p, \\
v_0^{\prime}+v_1^{\prime}+v_2^{\prime}+\cdots=p^{\prime},
\end{gathered}
\]
\[
\begin{gathered}
\omega_0+\omega_1+\omega_2+\cdots \\
\omega_0^{\prime}+\omega_1^{\prime}+\omega_2^{\prime}+\cdots
\end{gathered}
\]
sont de même convergentes, la série \(r_0+r_1+r_2+\cdots\), dont le terme général est,
\[
v_m=v_0 v_m^{\prime}+v_1 v_{m-1}^{\prime}+v_2 v_{m-2}^{\prime}+\cdots+v_m v_0^{\prime},
\]
sera de même convergente, et aura pour somme
\[
\left(v_0+v_1+v_z+\cdots\right)\left(v_0^{\prime}+v_1^{\prime}+v_2^{\prime}+\cdots\right) .
\]

Démonstration. En faisant,
\[
\begin{aligned}
& p_m=v_0+v_1+\cdots+v_m, \\
& p_m{ }^{\prime}=v_0{ }^{\prime}+v_1{ }^{\prime}+\cdots+v_m{ }^{\prime}
\end{aligned}
\]
on voit aisément que
(a)
\[
\begin{aligned}
r_0+r_1+r_2+\cdots+r_{2 m}=p_m p_m^{\prime} & +\left[p_0 v_{2 m}^{\prime}+p_1 v_{2 m-1}^{\prime}+\cdots+p_{m-1} v_{m+1}^{\prime}(=t)\right. \\
& \left.+p_0^{\prime} v_{2 m}+p_1^{\prime} v_{2 m-1}+\cdots+p_{m-1}^{\prime} v_{m+1}\left(=t^{\prime}\right)\right]
\end{aligned}
\]

Soit
\[
\begin{aligned}
& \varrho_0+\omega_1+\varrho_2+\cdots=u \\
& \omega_0^{\prime}+\omega_1^{\prime}+\omega_z^{\prime}+\cdots=u^{\prime}
\end{aligned}
\]
il est clair que, sans égard au signe, on aura,
\[
\begin{aligned}
t & <u\left(\varrho_{2 m}^{\prime}+\varrho_{2 m-1}^{\prime}+\cdots+\varrho_{m+1}^{\prime}\right) \\
t^{\prime} & <u^{\prime}\left(\varrho_{2 m}+\varrho_{2 m-1}+\cdots+\varrho_{m+1}\right) .
\end{aligned}
\]
"même variable \(x\), continues par rapport à cette variable dans le voisinage d'une "valeur particulière pour laquelle la série est convergente, la somme \(s\) de la série "est aussi, dans le voisinage de cette valeur particulière, fonction continue de \(x\)." Mais il me semble que ce théorème admet des exceptions. Par exemple la série
\[
\sin x-\frac{1}{3} \sin 2 x+\frac{1}{3} \sin 3 x-\cdots
\]
est discontinue pour toute valeur \((2 m+1) x\) de \(x, m\) étant un nombre entier. Il y a, comme on sait, beaucoup de séries de cette espèce.
%226
Or les séries \(\rho_0+\varrho_1+\varrho_2+\cdots\) et \(\varrho_0^{\prime}+\varrho_1^{\prime}+\varrho_2^{\prime}+\cdots\) étant convergentes, les quantités \(t\) et \(t^{\prime}\), pour des valeurs toujours croissantes de \(m\), s'approcheront indéfiniment de la limite zéro. Donc en faisant dans l'équation (a) \(m\) infini, on aura
\[
r_0+r_1+r_2+r_3+\cdots=\left(v_0+v_1+v_2+\cdots\right)\left(v_0{ }^{\prime}+v_1{ }^{\prime}+v_2{ }^{\prime}+\cdots\right) .
\]

Soient \(t_0, t_1, t_2, \ldots, t_0{ }^{\prime}, t_1{ }^{\prime}, t_2{ }^{\prime} \ldots\) deux séries de- quantités positives ou négatives, dont les termes généraux s'approchent indéfiniment de zéro, il suit du théorème II que les séries \(t_0+t_1 \alpha+t_2 \alpha^2+\cdots\) et \(t_0{ }^{\prime}+t_1{ }^{\prime} \alpha+t_2{ }^{\prime} \alpha^2\) +..., où \(\alpha\) désigne une quantité inférieure à l'unité, doivent être convergentes. Il en sera de même en attribuant à chaque terme sa valeur numérique, donc en vertu du théorème précédent:
(b) \(\left\{\begin{array}{r}\left.t_0+t_1 a+t_2 \alpha^2+\cdots\right)\left(t_0{ }^{\prime}+t_1{ }^{\prime} \alpha+t_2{ }^{\prime} \alpha^2+\cdots\right) \\ =t_0 t_0{ }^{\prime}+\left(t_1 t_0{ }^{\prime}+t_0 t_1{ }^{\prime}\right) \alpha+\left(t_2 t_0{ }^{\prime}+t_1 t_1{ }^{\prime}+t_0 t_2{ }^{\prime}\right) \alpha^2+\cdots \\ \quad+\left(t_m t_0{ }^{\prime}+t_{m-1} t_1{ }^{\prime}+t_{m-2} t_2{ }^{\prime}+\cdots+t_0 t_m{ }^{\prime}\right) \alpha^m+\cdots\end{array}\right.\)

Maintenant si l'on suppose que les trois séries,
\[
\begin{gathered}
t_0+t_1+t_2+\cdots \\
t_0{ }^{\prime}+t_1{ }^{\prime}+t_2{ }^{\prime}+\cdots \\
t_0 t_0{ }^{\prime}+\left(t_1 t_0{ }^{\prime}+t_0 t_1{ }^{\prime}\right)+\left(t_2 t_0{ }^{\prime}+t_1 t_1{ }^{\prime}+t_0 t_2{ }^{\prime}\right)+\cdots
\end{gathered}
\]
soient convergentes, on trouvera, en vertu du théorème \(I V\), en faisant dans l'équation (b) a converger ver's l'unité:
\[
\begin{aligned}
\left(t_0+t_1+t_2+\cdots\right)\left(t_0{ }^{\prime}+t_1{ }^{\prime}+t_2{ }^{\prime}+\cdots\right) & \\
& =t_0 t_0{ }^{\prime}+\left(t_1 t_0{ }^{\prime}+t_0 t_1{ }^{\prime}\right)+\left(t_2 t_0{ }^{\prime}+t_1 t_1{ }^{\prime}+t_0 t_2{ }^{\prime}\right)+\cdots
\end{aligned}
\]
3.

Examinous maintenant la série proposée,
\[
1+\frac{m}{1} x+\frac{m(m-1)}{1.2} x^2+\cdots
\]

En la désignant par \(\varphi m\), et faisant pour abréger, \(1=m_0, \frac{m}{1}=m_1\), \(\frac{m(m-1)}{1.2}=m_2\), et en général \(\frac{m(m-1) \ldots(m-\mu+1)}{1.2 \ldots \mu}=m_\mu\), on aura
%227
(1)
\[
\varphi m=m_0+m_1 x+m_2 x^2+\cdots+m_\mu x^{\prime \prime}+\cdots
\]

Il s'agit d'abord de trouver les valeurs de \(m\) et de \(x\) pour lesquelles la série est convergente.
Les quantités \(m\) et \(x\) étant généralement imaginaires, soit*)
\[
x=a+b i, m=k+k^{\prime} i,
\]
où \(a, b, k, k^{\prime}\) sont des quantités réelles. En substituant ces valeurs dans l'équation (1), elle prendra la forme
\[
\varphi m=p+q i,
\]
où \(p\) et \(q\) sont des séries dont les termes ont des valeurs réelles. On peut trouver ces séries de la manière suivante: Soit
\[
\left(a^2+b^2\right)^{\frac{1}{2}}=\alpha, \frac{a}{\alpha}=\cos \varphi, \frac{b}{\alpha}=\sin \varphi,
\]
l'on aura
\[
x=\alpha(\cos \varphi+i \sin \varphi),
\]
où \(\alpha\) et q sont des quantités réelles, \(\alpha\) étant en outre positif. Si l'on fáait de plus
\[
\frac{m-\mu+1}{\mu}=\delta_\mu\left(\cos \gamma_\mu+i \sin \gamma_\mu\right)=\frac{k+k^{\prime} i-\mu+1}{\mu},
\]
on trouvera
\[
\delta_\mu=\left[\left(\frac{k-\mu+1}{\mu}\right)^2+\left(\frac{k^{\prime}}{\mu}\right)^2\right]^{\frac{1}{2}} ; \cos \gamma_\mu=\frac{k-\mu+1}{\mu \delta_\mu} ; \sin \gamma_\mu^{\prime}=\frac{k^{\prime}}{\mu \delta_\mu} .
\]

Si dans l'expression
\[
\frac{m-\mu+1}{\mu}=\delta_\mu\left(\cos \gamma_\mu+i \sin \gamma_\mu\right)
\]
on fait successivement " \("\) égal à \(1,2,3, \ldots\), , on obtiendra " équations qui multipliées terme à terme donneront
\[
\begin{aligned}
& m_\mu=\frac{m(m-1)(m-2) \cdots(m-\mu+1)}{1.2 .3 \cdots \mu} \\
& =\delta_1 \delta_2 \delta_3 \ldots \delta_\mu\left[\cos \left(\gamma_1+\gamma_2+\cdots+\gamma_\mu\right)+i \sin \left(\gamma_1+\gamma_2+\cdots+\gamma_\mu\right)\right] .
\end{aligned}
\]

On tire de là, en multipliant par
*) Pour abréger les formules nous cerivons partout dans ce mémoire \(i\) au lieu de \(\sqrt{-1}\).
Note des éd.
%228
\[
\begin{gathered}
x^\mu=\alpha^\mu(\cos \varphi+i \sin \varphi)^\mu=\mu^\mu(\cos \mu \varphi+i \sin \mu \varphi): \\
m_\mu x^\mu=\alpha^\mu \delta_1 \delta_2 \delta_3 \ldots \delta_\mu\left[\cos \left(\mu \varphi+\gamma_1+\gamma_2+\cdots+\gamma_\mu\right)\right. \\
\left.+i \sin \left(\mu \varphi+\gamma_1+\gamma_2+\cdots+\gamma_\mu\right)\right]
\end{gathered}
\]
ou bien en faisant pour abréger
\[
\begin{gathered}
\delta_1 \delta_2 \delta_3 \ldots \delta_\mu=\lambda_\mu, " \mu \varphi+\gamma_1+\gamma_{\prime}+\cdots+\gamma_\mu=\theta_\mu: \\
m_\mu x^\mu=\lambda_\mu \alpha^\mu\left(\cos \theta_\mu+i \sin \theta_\mu\right) .
\end{gathered}
\]

L'expression (1) se change par là en celle-ci,
\[
\begin{array}{r}
\varphi m=1+\lambda_1 \alpha\left(\cos \theta_1+i \sin \theta_1\right)+\lambda_2 \alpha^2\left(\cos \theta_2+i \sin \theta_2\right) \\
+\cdots+\lambda_\mu \alpha^\mu\left(\cos \theta_\mu+i \sin \theta_\mu\right)+\cdots,
\end{array}
\]
on en celle-ci,
\[
\begin{aligned}
\varphi m= & 1+\lambda_1 \alpha \cos \theta_1+\lambda_2 \alpha^2 \cos \theta_2+\cdots+\lambda_\mu \alpha^\mu \cos \theta_\mu+\cdots \\
& +i\left(\lambda_1 \alpha \sin \theta_1+\lambda_2 \alpha^2 \sin \theta_2+\cdots+\lambda_\mu \alpha^\mu \sin \theta_\mu+\cdots\right) .
\end{aligned}
\]

On a done
(2) \(\left\{\begin{array}{l}l=1+\lambda_1 \alpha \cos \theta_1+\lambda_2 \alpha^2 \cos \theta_2+\cdots+\lambda_\mu \alpha^\mu \cos \theta_\mu+\cdots \\ q=\lambda_1 \alpha \sin \theta_1+\lambda_2 \alpha^2 \sin \theta_2+\cdots+\lambda_\mu \alpha^\mu \sin \theta_\mu+\cdots\end{array}\right.\)

Or je dis que ces séries seront divergentes ou convergentes, selon que \(\alpha\) est supérieur on inférieur à l'unité.
De l'expression de \(\lambda_\mu\) on tire \(\lambda_{\mu+1}=\delta_{\mu+1} \lambda_\mu\), done
et
\[
\lambda_{\mu+1} \alpha^{\mu+1}=\alpha \delta_{\mu+1} \lambda_\mu \alpha^\mu
\]
\[
\frac{\lambda_{\mu+1} \alpha^{\mu+1}}{\lambda_\mu \alpha^\mu}=\alpha \delta_{\mu+1}
\]
mais on a
\[
\delta_{\mu+1}=\left[\left(\frac{k-\mu}{\mu+1}\right)^2+\left(\frac{k^{\prime}}{\mu+1}\right)^2\right]^{\frac{1}{2}}
\]
done pour des valeurs toujours croissantes de \(\mu, \delta_\mu\) s'approchera de la limite 1, et par suite \(\frac{\lambda_{\mu+1} \alpha^{\mu+1}}{\lambda_\mu \alpha^\mu}\) de la limite \(\alpha\). Donc en vertu des théorèmes I et II du paragraphe précédent les séries \(p\) et \(q\) seront divergentes on convergentes, suivant que \(\alpha\) est supérieur ou inférieur à l'unité. Il en est donc de même de la série proposée \(\varphi m\).
Le cas où \(\alpha=1\), sera traité plus bas.
Comme la série \(\varphi \mathrm{m}\) est convergente pour tonte valeur de \(\boldsymbol{\alpha}\) inférieure
%229
à l'unité, la somme en sera une certaine fonction de \(m\) et de \(x\). On peut, comme il suit, établir une propriété de cette fonction à l'aide de laquelle on pent la trouver: On a
\[
\begin{aligned}
& \varphi m=m_0+m_1 x+m_2 x^2+\cdots+m_\mu x^\mu+\cdots, \\
& \varphi n=n_0+n_1 x+n_2 x^2+\cdots+n_\mu x^\mu+\cdots,
\end{aligned}
\]
où \(n_\mu\) désigne la valeur de \(m_\mu\) pour \(n=n\). On en conclut d'après le théorème VI:
\[
\begin{aligned}
\varphi m . \varphi n=t_0 t_0{ }^{\prime}+\left(t_0 t_1{ }^{\prime}\right. & \left.+t_1 t_0{ }^{\prime}\right)+\left(t_0 t_2{ }^2+t_1 t_1{ }^{\prime}+t_2 t_0{ }^{\prime}\right)+\cdots \\
& +\left(t_0 t_\mu{ }^{\prime}+t_1 t^{\prime}{ }_{\mu-1}+t_2 t^{\prime}{ }_{\mu-2}+\cdots+t_\mu t_0{ }^{\prime}\right)+\cdots
\end{aligned}
\]
où \(t_\mu=m_\mu x^\mu, t_\mu{ }^{\prime}=n_\mu x^\mu\), en supposant que la série du second membre soit convergente. En substituant les valeurs de \(t_\mu\) et \(t_\mu{ }^{\prime}\), on aura
\[
\begin{aligned}
\varphi m \cdot \varphi n=m_0 n_0+ & \left(m_0 n_1+m_1 n_0\right) x+\left(m_0 n_2+m_1 n_1+m_2 n_0\right) x^2+\cdots \\
& +\left(m_0 n_\mu+m_1 n_{\mu-1}+m_2 n_{\mu-2}+\cdots+m_\mu n_0\right) x^\mu+\cdots
\end{aligned}
\]

Or, d'après une propriété connue de la fonction \(m_\mu\), on a
\[
(m+n)_\mu=m_0 n_\mu+m_1 n_{\mu-1}+m_2 n_{\mu-2}+\cdots+m_\mu n_0,
\]
\((m+n)_\mu\) désignant la valeur de \(m_\mu\) lorsqu'on y substitue \(m+n\) pour \(m\). On aura done par substitution
\[
\varphi m . \varphi n=(m+n)_0+(m+n)_1 x+(m+n)_2 x^2+\cdots+(m+n)_\mu x^\mu+\cdots
\]

Or d'après ce qui précède, le second membre de cette équation est une série convergente et précisément la même chose que \(\varphi(m+n)\); donc
\[
\varphi m \cdot \varphi n=\varphi(m+n) \text {. }
\]

Cette équation exprime une propriété fondamentale de la fonction \(\varphi \mathrm{m}\). De cette propriété nous déduirons une expression de la fonction sous forme finie à l'aide des fonctions exponentielles, logarithmiques et circulaires.

Comme on l'a vu plus haut, la fonction \(\varphi m\) est de la forme \(p+q i\), \(p\) et \(q\) étant toujours réels et fonctions des quantités \(k, k^{\prime}, \alpha\) et \(\varphi\), et \(m=k+k^{\prime} i, x=\alpha(\cos \varphi+i \sin \varphi)\). Soit
\[
p+q i=r(\cos s+i \sin s)
\]
on trouver:a
\[
\left(p^2+q^2\right)^{\frac{1}{2}}=r, \frac{p}{r}=\cos s, \frac{q}{r}=\sin s,
\]
%230
\(r\) étant toujours positif et \(s\) une quantité réelle. Soit
\[
r=f\left(k, k^{\prime}\right), s=\psi\left(k, k^{\prime}\right)
\]
on allra
\[
p+q i=\varphi\left(k+k^{\prime} i\right)=f\left(k, k^{\prime}\right)\left[\cos \psi\left(k, k^{\prime}\right)+i \sin \psi^{\prime}\left(k, k^{\prime}\right)\right] .
\]

On en tire, en mettant successivement \(l, l^{\prime}\) et \(k+l, k^{\prime}+l^{\prime}\) à la place de \(k\) et \(k^{\prime}\),
\[
\begin{aligned}
& \varphi\left(l+l^{\prime} i\right)=f\left(l, l^{\prime}\right)\left[\cos \psi\left(l, l^{\prime}\right)+i \sin \psi\left(l, l^{\prime}\right)\right] \\
& \varphi\left[k+l+\left(k^{\prime}+l^{\prime}\right) i\right] \\
& =f\left(k+l, k^{\prime}+l^{\prime}\right)\left[\cos \psi\left(k+l, k^{\prime}+l^{\prime}\right)+i \sin \psi\left(k+l, k^{\prime}+l^{\prime}\right)\right] .
\end{aligned}
\]

Or. en vertu de l'équation \(\varphi m \cdot \varphi n=\varphi(m+n)\), on a
\[
\varphi\left[k+l+\left(k^{\prime}+l^{\prime}\right) i\right]=\varphi\left(k+k^{\prime} i\right) \varphi\left(l+l^{\prime} i\right)
\]
en farisant \(m=k+k^{\prime} i, n=l+l^{\prime} i\). Donc en substituant, on obtient
\[
\begin{aligned}
& f\left(k+l, k^{\prime}+l^{\prime}\right)\left[\cos \psi\left(k+l, k^{\prime}+l^{\prime}\right)+i \sin \psi\left(k+l, k^{\prime}+l^{\prime}\right)\right] \\
& \quad=f\left(k, l^{\prime}\right) f\left(l, l^{\prime}\right)\left[\cos \left(\psi\left(k, k^{\prime}\right)+\psi\left(l, l^{\prime}\right)\right)+i \sin \left(\psi\left(k, k^{\prime}\right)+\psi\left(l, l^{\prime}\right)\right)\right] .
\end{aligned}
\]

Cette équation donne, lorsqu'on sépare les termes réels des termes imaginaires,
\[
\begin{aligned}
& f\left(k+l, k^{\prime}+l^{\prime}\right) \cos \psi\left(k+l, k^{\prime}+l^{\prime}\right)=\tilde{f}\left(k, k^{\prime}\right) f\left(l, l^{\prime}\right) \cos \left[\psi\left(k, k^{\prime}\right)+\psi\left(l, l^{\prime}\right)\right] \\
& f\left(k+l, k^{\prime}+l^{\prime}\right) \sin \psi\left(k+l, k^{\prime}+l^{\prime}\right)=f\left(k, k^{\prime}\right) f\left(l, l^{\prime}\right) \sin \left[\psi\left(k, k^{\prime}\right)+\psi\left(l, l^{\prime}\right)\right] .
\end{aligned}
\]

En faisant les carrés et ajoutant les équations membre à membre, on aura d'où
\[
\left[f\left(k+l, k^{\prime}+l^{\prime}\right)\right]^2=\left[f\left(k, k^{\prime}\right) f\left(l, l^{\prime}\right)\right]^2
\]
\[
f\left(k+l, k^{\prime}+l^{\prime}\right)=f\left(k, k^{\prime}\right) f\left(l, l^{\prime}\right) \text {. }
\]

En vertu de cette équation les précédentes se transforment en celles-ci:
\[
\begin{aligned}
& \cos \psi\left(k+l, k^{\prime}+l^{\prime}\right)=\cos \left[\psi\left(k, k^{\prime}\right)+\psi\left(l, l^{\prime}\right)\right] \\
& \sin \psi\left(k+l, k^{\prime}+l^{\prime}\right)=\sin \left[\psi\left(k, k^{\prime}\right)+\psi\left(l, l^{\prime}\right)\right]
\end{aligned}
\]
d'où l'on tire,
\[
\psi\left(k+l, k^{\prime}+l^{\prime}\right)=2 m \pi+\psi\left(k, k^{\prime}\right)+\psi\left(l, l^{\prime}\right)
\]
\(m\) étant un nombre entier positif ou négatif.
Maintenant il 's'agit de tirer les fonctions \(f\left(k, k^{\prime}\right)\) et \(\psi\left(k, k^{\prime}\right)\) des
%231
équations (4) et (5). D'abord je dis qu'elles sont des fonctions continues de \(k\) et \(k^{\prime}\) entre des limites quelconques de ces variables. Fn effet, d'après le théorème \(\mathrm{V}, p\) et \(q\) sont évidemment des fonctions continues. Or on a
\[
f\left(k, k^{\prime}\right)=\left(p^2+q^2\right)^{\frac{1}{2}}, \cos \psi\left(k, k^{\prime}\right)=\frac{p}{f\left(k, k^{\prime}\right)}, \sin \psi\left(k^{\prime}, k^{\prime}\right)=\frac{q}{f\left(k, k^{\prime}\right)}
\]
donc \(f\left(k, k^{\prime}\right)\), de même que cos \(\psi\left(k, k^{\prime}\right)\) et \(\sin \psi\left(k, k^{\prime}\right)\), est une fonction continue. On peut donc supposer que \(\psi\left(k, k^{\prime}\right)\) est aussi une fonction continue. Nous allous d'abord examiner l'équation (5). \(\psi\left(k, k^{\prime}\right)\) étant une fonction continue, il faut que \(m\) ait la même valeur pour toutes les valeurs de \(k, k^{\prime}\), \(l, l^{\prime}\). En faisant donc successivement \(l=0, k=0\), on obtient
\[
\begin{aligned}
& \psi\left(k, k^{\prime}+l^{\prime}\right)=2 m \boldsymbol{\lambda}+\psi\left(k, k^{\prime}\right)+\psi\left(0, l^{\prime}\right), \\
& \psi\left(l, k^{\prime}+l^{\prime}\right)=2 m \boldsymbol{x}+\psi\left(0, k^{\prime}\right)+\psi\left(l, l^{\prime}\right) .
\end{aligned}
\]

En éliminant entre ces équations et l'équation (5) les deux quantités \(\psi^{\prime}\left(k, k^{\prime}\right)\) et \(\psi\left(l, l^{\prime}\right)\), on trouvera
\[
\psi\left(k, k^{\prime}+l^{\prime}\right)+\psi\left(l, k^{\prime}+l^{\prime}\right)=2 m . x+\psi\left(0, k^{\prime}\right)+\psi\left(0, l^{\prime}\right)+\psi\left(k+l, k^{\prime}+l^{\prime}\right) .
\]

Soit pour abréger
\[
\left\{\begin{array}{l}
\psi\left(k, k^{\prime}+l^{\prime}\right)=\theta k, \\
2 m . x+\psi\left(0, k^{\prime}\right)+\psi\left(0, l^{\prime}\right)=a,
\end{array}\right.
\]
on illia
\[
\theta k+\theta l=a+\theta(k+l) .
\]

En faisant ici successivement \(l=k, 2 k, \ldots \rho k\), on aura
\[
\begin{aligned}
2 \theta k & =a+\theta(2 k), \\
\theta k+\theta(2 k) & =a+\theta(3 k), \\
\theta k+\theta(3 k) & =a+\theta(4 k), \\
\cdots \cdots \cdots & \cdots \cdots \\
\theta k+\theta(\varrho-1) k & =a+\theta(\varrho k) .
\end{aligned}
\]

En ajoutant ces équations, on trouve
\[
\rho \theta k=(\rho-1) a+\theta(\rho k) .
\]

On en tire, en faisant \(k=1\),
\[
\theta \omega=\varrho[\theta(1)-a]+a,
\]
%232
ou bien en faisant \(\theta(1)-a=c\),
\[
\boldsymbol{\theta} \rho=c \varrho+a \text {. }
\]

Voilà donc la valeur de la fonction \(\theta k\), lorsque \(k\) est un nombre entier. Mais la fonction \(\theta k\) aura la même forme pour toute valeur de \(k\), ce qu'on peut démontrer aisément comme il suit. Si l'on pose dans l'équation \(\left(7^{\prime}\right)\). \(k=\frac{\mu}{\varrho}, " \iota\) étant un nombre entier, on en tire \(\varrho \cdot \theta\left(\frac{\mu}{\varrho}\right)=(\varrho-1) a+\theta \mu\). Or en vertu de l'équation (8)
\[
\theta_i u=c_i u+a
\]
donc en substituant et divisant par \(\varrho\), on trouve
\[
\theta\left(\begin{array}{l}
\mu \\
\varrho
\end{array}\right)=c\left(\frac{\mu}{\varrho}\right)+a .
\]

L'équation (8) a donc lieu pour toute valeur positive et rationnelle de \(\varrho\). Soit \(l=-k\), l'équation (7) deviendra,
\[
\theta k+\theta(-k)=a+\theta(0) \text {. }
\]

II s'ensuit, en posant \(k=0\),
et par conséquent
\[
\begin{gathered}
\boldsymbol{\theta}(0)=a, \\
\boldsymbol{\theta}(-k)=2 a-\theta k .
\end{gathered}
\]

Or \(k\) étant rationnel et positif, on a \(\theta k=c k+a\), done L'équation
\[
\boldsymbol{\theta}(-k)=-c k+a \text {. }
\]
\[
\theta k=c k+a
\]
a donc lieu pour toute valeur rationnelle, de \(k\) et par conséquent, puisque \(\theta k\) est une fonction continue, pour toute valeur réelle de \(k\).

Or \(\theta k=\psi\left(k, k^{\prime}+l^{\prime}\right)\), et \(a=2 m \pi+\psi\left(0, k^{\prime}\right)+\psi\left(0, l^{\prime}\right)\); faisant done \(c=\boldsymbol{\theta}\left(k^{\prime}, l^{\prime}\right)\), on obtient
\[
\psi\left(k, k^{\prime}+l^{\prime}\right)=\theta\left(k^{\prime}, l^{\prime}\right) \cdot k+2 m \pi+\psi\left(0, k^{\prime}\right)+\psi\left(0, l^{\prime}\right) .
\]

On tire de là, en faisant \(k=0\),
\[
\psi\left(0, k^{\prime}+l^{\prime}\right)=2 m \pi+\psi\left(0, k^{\prime}\right)+\psi\left(0, l^{\prime}\right) .
\]

Cette équation étant de la même forme que l'équation (7), elle donnera de la même manière
%233
\[
\psi\left(0, k^{\prime}\right)=\beta^{\prime} k^{\prime}-2 m \pi
\]
\(\beta^{\prime}\) étant une quantité indépendante de \(l^{\prime}\).
En mettant \(l^{\prime}\) à la place de \(k^{\prime}\), on obtient \(\psi\left(0, l^{\prime}\right)=-2 m \pi+\beta^{\prime} l^{\prime}\). En substituant ces valeurs de \(\psi\left(0, k^{\prime}\right)\) et de \(\psi^{\prime}\left(0, l^{\prime}\right)\) dans l'équation (10) on en tirera
\[
\psi\left(k, k^{\prime}+l^{\prime}\right)=\boldsymbol{\theta}\left(k^{\prime}, l^{\prime}\right) \cdot k+\beta^{\prime}\left(k^{\prime}+l^{\prime}\right)-2 m \pi .
\]

On voit par là que \(\theta\left(k^{\prime}, l^{\prime}\right)\) est une fonction de \(l^{\prime}+l^{\prime}\). En la désignant par \(F\left(k^{\prime}+l^{\prime}\right)\), on aura
\[
\psi\left(k, k^{\prime}+l^{\prime}\right)=F\left(k^{\prime}+l^{\prime}\right) \cdot k+\beta^{\prime}\left(k^{\prime}+l^{\prime}\right)-2 m \pi
\]
et par conséquent, en faisant \(l^{\prime}=0\),
\[
\psi^{\prime}\left(k, k^{\prime}\right)=F k^{\prime} . k+\beta^{\prime} k^{\prime}-2 m . \pi
\]

En remarquant que
\[
\begin{gathered}
\psi\left(k, k^{\prime}+l^{\prime}\right)=2 m \pi+\psi\left(k, k^{\prime}\right)+\psi\left(0, l^{\prime}\right), \\
\psi\left(0, l^{\prime}\right)=\beta^{\prime} l^{\prime}-2 m \pi
\end{gathered}
\]
l'équation précédente domne
\[
\begin{aligned}
& F\left(k^{\prime}+l^{\prime}\right) \cdot k+\beta^{\prime}\left(k^{\prime}+l^{\prime}\right)-2 m \pi=2 m \pi+F k^{\prime} \cdot k+\beta^{\prime} k^{\prime}-2 m \pi+\beta^{\prime} l^{\prime}-2 m \pi, \\
& \text { c'est-à-dire: } \\
& F\left(k^{\prime}+l^{\prime}\right)=F k^{\prime} .
\end{aligned}
\]

Done faisant \(k^{\prime}=0\), on obtient \(F^{\prime} l^{\prime}=F(0)=\beta=F k^{\prime}\). Par suite la valeur de \(\psi\left(k, k^{\prime}\right)\) prend la forme,
\[
\psi\left(k, k^{\prime}\right)=\beta k+\beta^{\prime} k^{\prime}-2 m \pi
\]
\(\beta\) et \(\beta^{\prime}\) étant deux constantes. Cette valeur de \(\psi\left(k, k^{\prime}\right)\) satisfera à l'équation (5) dans toute sa généralité comme il est aisé de le voir.
Maintenant, examinons l'équation,
\[
f\left(k+l, k^{\prime}+l^{\prime}\right)=f\left(k, k^{\prime}\right) f\left(l, l^{\prime}\right)
\]

Puisque \(f\left(k, k^{\prime}\right)\) est toujours une quantité positive, on peut poser
\[
f\left(k, k^{\prime}\right)=e^{F\left(k, k^{\prime}\right)}
\]
\(F\left(k, k^{\prime}\right)\) désignant une fonction réelle continue de \(k\) et \(k^{\prime}\). En substituant et en prenant les logarithmes des deux membres, on trouvera
\[
F\left(k+l, k^{\prime}+l^{\prime}\right)=F\left(k, k^{\prime}\right)+F\left(l, l^{\prime}\right) \text {. }
\]
%234
Comme cette équation coïncide avec l'équation (5), en mettant \(F\) à la place de \(\psi\), et 0 à la place de \(m\), elle donnera en vertu de l'équation (11)
\[
F\left(k, k^{\prime}\right)=\delta k+\delta^{\prime} k^{\prime}
\]
\(\delta\) et \(\delta^{\prime}\), de même que \(\beta\) et \(\beta^{\prime}\), étant deux quantités indépendantes de \(k\) et de \(k^{\prime}\). La fonction \(f\left(k, k^{\prime}\right)\) prendra donc la forme,
\[
f\left(k, k^{\prime}\right)=e^{\delta k+\delta^{\prime} k^{\prime}} \text {. }
\]

Les fonctions \(\psi\left(k, k^{\prime}\right)\) et \(f\left(k, k^{\prime}\right)\) étant trouvées de cette manière, on aura, d'après l'équation \(\left(3^{\prime}\right)\),
\[
\varphi\left(k+k^{\prime} i\right)=e^{\delta k+\delta^{\prime} k^{\prime}}\left[\cos \left(\beta k+\beta^{\prime} k^{\prime}\right)+i \sin \left(\beta k+\beta^{\prime} k^{\prime}\right)\right]
\]
où il reste encore à trouver les quantités \(\delta, \delta^{\prime}, \beta, \beta^{\prime}\), qui ne peuvent être que des fonctions de \(\alpha\) et de \(\varphi\). On a
\[
\varphi\left(k+k^{\prime} i\right)=p+q i
\]
p et \(q\) étant domnés par les équations (2). En séparant les quantités réelles des imaginaires, on aura

Nous allons d'abord considérer le cas où \(m\) est réel, c'est-à-dire où \(k^{\prime}=0\). Alors les expressions (14) prement la forme,
\[
\left\{\begin{aligned}
& e^{\delta k} \cos \beta k=1+\frac{k}{1} \alpha \cos \varphi+ \frac{k(k-1)}{1.2} \alpha^2 \cos 2 \varphi \\
&+\frac{k(k-1)(k-2)}{1.2 .3} \alpha^3 \cos 3 \varphi+\cdots=f \alpha \\
& e^{\delta k} \sin \beta k=\frac{k}{1} \alpha \sin \varphi+\frac{k(k-1)}{1.2} \alpha^2 \sin 2 \varphi \\
&+\frac{k(k-1)(k-2)}{1.2 .3} \alpha^3 \sin 3 \varphi+\cdots=\theta \alpha
\end{aligned}\right.
\]

Pour trouver \(\delta\) et \(\beta\), posons \(k=1\), on aura
\[
e^\delta \cos \beta=1+\alpha \cos \varphi ; e^\delta \sin \beta=\alpha \sin \varphi \text {. }
\]

On en tire
\[
e^\delta=\left(1+2 \alpha \cos \varphi+u^2\right)^{\frac{1}{2}}
\]
%235
\[
\begin{gathered}
\cos \beta=\frac{1+\alpha \cos \varphi}{\left(1+2 \alpha \cos \varphi+\alpha^2\right)^{\frac{1}{2}}}, \sin \beta=\frac{\alpha \sin \uparrow}{\left(1+2 \alpha \cos \uparrow+\alpha^2\right)^{\frac{1}{2}}}, \\
\operatorname{tang} \beta=\frac{\alpha \sin \varphi}{1+\alpha \cos \uparrow} .
\end{gathered}
\]

Cette demière équation donne, en désignant par s la plus petite de toutes les valeurs de \(\beta\) qui \(\mathbf{y}\) satisfasse, et qui est toujours renfermée entre les limites \(-\frac{\pi}{2}\) et \(\frac{\pi}{2}\),
\[
\beta=s+\mu \pi
\]
" étaut un nombre entier positif ou négatif. Done les équations (15) se changent en celles-ci :
\[
\begin{aligned}
& f \alpha=e^{\delta k} \cos k(s+\mu \pi)=e^{\delta k} \cos k s \cos k \mu \pi-e^{\delta k} \sin k s \cdot \sin k \mu \pi \\
& \theta\left(\mu=e^{\delta k} \sin k(s+\mu \pi)=e^{\delta k} \sin k s \cos k \mu \pi+e^{\delta k} \cos k s \cdot \sin k \mu \pi\right.
\end{aligned}
\]

De ces équations on tire
\[
\begin{aligned}
& \cos k \| \pi=e^{-\delta k}(f \alpha \cdot \cos k s+\theta \alpha \cdot \sin k s), \\
& \sin k \| \pi=e^{-\delta k}(\theta \alpha \cdot \cos k s-f \alpha \cdot \sin k s) .
\end{aligned}
\]

Or, d'après le théorème IV, \(\theta \alpha\) et \(f \alpha\) sont des fonctions continues de \(\alpha\); par conséquent il faut que \(\cos k_{\imath} u \pi\) et \(\sin k_{\imath} \boldsymbol{\lambda} \pi\) conservent les mêmes valeurs pour toute valeur de \(\alpha\). Il suftit done pour les trouver, d'attribuer à \(\alpha\) une valeur quelconque. Soit \(\alpha=0\), on aura, en remarquant qu'alors \(e^\delta=1\), \(f \alpha=1, \theta \alpha=0, s=0\),
\[
\cos k_{\bullet} u \boldsymbol{\pi}=1, \sin k_{\bullet} u \boldsymbol{x}=0 .
\]

En substituant ces valeurs dans les expressions de \(f \alpha\) et \(\theta \alpha\), et en se rappelant que \(e^\gamma=\left(1+2 \alpha \cos \varphi+\alpha^2\right)^{\frac{1}{2}}\), on obtiendra
\[
f \alpha=\left(1+2 \alpha \cos \varphi+\alpha^2\right)^{\frac{k}{2}} \cos k s, \theta \alpha=\left(1+2 \alpha \cos \varphi+\alpha^2\right)^{\frac{k}{2}} \sin k s
\]

Donc enfin les expressions (15) deviendront:
\[
\left\{\begin{array}{c}
1+\frac{k}{1} \alpha \cos \varphi+\frac{k(k-1)}{1.2} \alpha^2 \cos 2 \varphi+\frac{k(k-1)(k-2)}{1.2 .3} \alpha^3 \cos 3 \varphi+\cdots \\
=\left(1+2 \alpha \cos \varphi+\alpha^2\right)^{\frac{k}{2}} \cos k s \\
\frac{k}{1} \alpha \sin \varphi+\frac{k(k-1)}{1.2} \alpha^2 \sin 2 \varphi+\frac{k(k-1)(k-2)}{1.2 .3} \alpha^3 \sin 3 \varphi+\cdots \\
=\left(1+2 \alpha \cos \varphi+\alpha^2\right)^2 \sin k s \\
30 *
\end{array}\right.
\]
%236
\(s\) étant renfermé entre les limites \(-\frac{\pi}{2}\) et \(+\frac{\pi}{2}\) et satisfaisant à l'équation
\[
\operatorname{tang} s=\frac{\alpha \sin \varphi}{1+\alpha \cos \varphi} \text {. }
\]

Les expressions (16) ont été établies pour la première fois par M. Cauclyy dans l'ouvrage cité plus haut.

On a supposé ici la quantité a moindre que l'unité. On verra plus bas que \(\alpha\) pent aussi être égal à l'unité, lorsqu'on donne à la quantité \(k\) une valeur convenable.

Dans ce qui précède nous avons trouvé les quantités \(\delta\) et \(\beta\). Maintenant nous allons montrer comment on peut trouver les deux autres quantités incomnues \(\delta^{\prime}\) et \(\beta^{\prime}\). Faisant à cet effet dans les équations (14) \(k=0\) et \(k^{\prime}=n\), on olotiendra
\[
\begin{aligned}
& e^{\delta \prime n} \cos \beta^{\prime} n=1+i_1 \mu \cos \theta_1+i_2 \alpha^2 \cos \theta_2+\cdots, \\
& e^{\delta \prime n} \sin \beta^{\prime} n=\quad \lambda_1 \mu \sin \theta_1+i_2 \alpha^2 \sin \theta_2+\cdots,
\end{aligned}
\]
où \(i_\mu=\delta_1 \delta_2 \delta_3 \ldots \delta_\mu, \theta_\mu=\mu \varphi+i_1+\gamma_2+\cdots+\gamma_\mu\), \(\delta_\mu\) et \(i_\mu\) étant déterminés par les équations
\[
\delta_\mu=\left[\left(\frac{\mu-1}{\mu}\right)^2+\left(\frac{n}{\mu}\right)^2\right]^{\frac{1}{2}}, \cos \gamma_\mu=-\frac{\mu-1}{\mu \delta_\mu}, \sin \gamma_\mu=\frac{n}{\mu \delta_\mu} .
\]

De ces équations on déduit les suivantes:
\[
\begin{aligned}
\frac{e^{\delta \prime n} \cos \beta^{\prime} n-1}{n} & =\frac{\lambda_1}{n} \alpha \cos \theta_1+\frac{\lambda_2}{n} \alpha^2 \cos \theta_2+\cdots, \\
\frac{e^{\delta^{\prime} n} \sin \beta^{\prime} n}{n} & =\frac{\lambda_1}{n} \alpha \sin \theta_1+\frac{\lambda_2}{n} \alpha^2 \sin \theta_2+\cdots
\end{aligned}
\]

Or en supposant \(n\) positif on a \(\lambda_1=\delta_1=n\), donc \(\frac{\lambda_\mu}{n}=\delta_2 \delta_3 \ldots \delta_\mu\), et par suite
\[
\begin{aligned}
\frac{e^{\delta^{\prime} n} \cos \beta^{\prime} n-1}{n} & =\alpha \cos \theta_1+\delta_2 \alpha^2 \cos \theta_2+\delta_2 \delta_3 \alpha^3 \cos \theta_3+\cdots \\
\frac{e^{\delta \prime n} \sin \beta^{\prime} u}{n} & =\kappa \sin \theta_1+\delta_2 \iota^2 \sin \theta_2+\delta_2 \delta_3 \alpha^3 \sin \theta_3+\cdots
\end{aligned}
\]

Ces séries sont convergentes pour toute valeur de \(n\), zéro y compris, ce qu'on voit aisément par le théorème II. En faisant donc converger \(n\) vers la limite zéro, et remarquant que, d'après le théorème \(V\), les séries sont des fonctions continues, on obtient
%237
\[
\begin{aligned}
& J^{\prime \prime}=\alpha \cos \theta_1{ }^{\prime}+\delta_2^{\prime} \alpha^2 \cos \theta_2{ }^{\prime}+\delta_2{ }^{\prime} \delta_3{ }^{\prime} \alpha^3 \cos \theta_3{ }^{\prime}+\cdots \\
& \beta^{\prime}=\alpha \sin \theta_1{ }^{\prime}+\delta_2^{\prime} \alpha^2 \sin \theta_2{ }^{\prime}+\delta_2{ }^{\prime} \delta_3{ }^{\prime} \alpha^3 \sin \theta_3{ }^{\prime}+\cdots
\end{aligned}
\]
puisque \(\delta^{\prime}\) et \(\beta^{\prime}\) sont les limites des quantités \(\frac{e^{\delta^{\prime} n} \cos \beta^{\prime} n-1}{n}\) et \(\frac{e^{\delta^{\prime} n} \sin \beta^{\prime} n}{n}\); \(\boldsymbol{\theta}_\mu^{\prime}\) est la limite de \(\boldsymbol{\theta}_\mu\) et \(\delta_\mu^{\prime}\) celle de \(\delta_\mu\). Or, d'après l'expression de \(\delta_\mu\), on a \(\delta_\mu^{\prime}=\frac{\mu-1}{\mu} ;\) donc \(\cos \gamma_\mu=-1 ; \sin \gamma_\mu=0\) (lorsque,\(">1\) ), done
\[
\begin{aligned}
& \cos \theta_\mu{ }^{\prime}=\cos \left(\mu \varphi+\gamma_1+\gamma_2+\cdots+\gamma_\mu\right)=+\sin \mu \varphi \cdot(-1)^{\prime \prime}, \\
& \sin \theta_\mu{ }^{\prime}=\sin \left(\mu \varphi+\gamma_1+\gamma_2+\cdots+\gamma_\mu\right)=-\cos \mu \varphi \cdot(-1)^{\prime \prime},
\end{aligned}
\]
oì il faut se rappeler qu'en vertu de l'équation
\[
n i=\delta_1\left(\cos \gamma_1+i \sin \gamma_1\right) \text {, }
\]
on a \(\cos \gamma_1=0, \sin \gamma_1=1\). Done les valeurs de \(\beta^{\prime}\) et \(\gamma^{\prime}\) seront celles-ci:
\[
\begin{aligned}
& \beta^{\prime}=\alpha \cos \varphi-\frac{1}{2} \alpha^2 \cos 2 \varphi+\frac{1}{3} \alpha^3 \cos 3 \varphi-\cdots \\
& \delta^{\prime}=-\alpha \sin \varphi-\frac{1}{2} \alpha^2 \sin 2 \varphi+\frac{1}{3} \alpha^3 \sin 3 \varphi-\cdots
\end{aligned}
\]

De cette manière on a trouvé les quantités \(\beta^{\prime}\) et \(\delta^{\prime}\) par des séries infinies. On peut aussi les exprimer sous forme finie. Car on tire de l'équation (15):
\[
\begin{aligned}
\frac{e^{\delta k} \cos \beta k-1}{k} & =\alpha \cos \varphi+\frac{k-1}{1.2} \alpha^2 \cos 2 \varphi+\frac{(k-1)(k-2)}{1.2 .3} \alpha^3 \cos 3 \varphi+\cdots \\
\frac{e^{\delta k} \sin \beta k}{k} & =\alpha \sin \varphi+\frac{k-1}{1.2} \alpha^2 \sin 2 \varphi+\frac{(k-1)(k-2)}{1.2 .3} \alpha^3 \sin 3 \varphi+\cdots
\end{aligned}
\]

On en déduit, en faisant converger \(k\) vers zéro,
\[
\left\{\begin{array}{l}
\delta=\kappa \cos \varphi-\frac{1}{2} \alpha^2 \cos 2 \varphi+\frac{1}{3} \alpha^3 \cos 3 \varphi-\cdots, \\
\beta=\kappa \sin \varphi-\frac{1}{2} \alpha^2 \sin 2 \varphi+\frac{1}{3} \alpha^3 \sin 3 \varphi-\cdots,
\end{array}\right.
\]
donc \(\beta^{\prime}=\delta^{\prime}, \delta^{\prime}=-\beta\). Donc les expressions (14) prennent la forme où
\[
\delta=\frac{1}{2} \log \left(1+2 \alpha \cos \varphi+\alpha^2\right), \beta=\operatorname{arc} \operatorname{tang} \frac{\alpha \sin \varphi}{1+\alpha \cos \varphi}
\]
%238
or la somme de la série proposée étant égale à \(p+q i\), on aura
\[
\begin{aligned}
1+\frac{m}{1} x+\frac{m(m-1)}{1.2} x^2+ & \cdots+\frac{m(m-1) \cdots(m-\mu+1)}{1.2 \cdots \mu} x^\mu+\cdots \\
& =e^{\delta k-\beta k^{\prime}}\left[\cos \left(\beta k+\delta k^{\prime}\right)+i \sin \left(\beta k+\delta k^{\prime}\right)\right]
\end{aligned}
\]

Maintenant on a
\[
m=k+k^{\prime} i, x=\alpha(\cos \varphi+i \sin \varphi)=a+b i
\]
donc
\[
\begin{gathered}
\alpha=\sqrt{a^2+b^2}, \alpha \cos \varphi=a, \alpha \sin \varphi=b, \\
\delta=\frac{1}{2} \log \left(1+2 a+a^2+b^2\right)=\frac{1}{2} \log \left[(1+a)^2+b^2\right], \beta=\operatorname{arctang} \frac{b}{1+a} .
\end{gathered}
\]

En substituant et en écrivant \(m\) pour \(k\) et \(n\) pour \(k\) ', l'expression ci-dessus prend la forme:
\[
\begin{aligned}
& 1+\frac{m+n i}{1}(a+b i)+\frac{(m+n i)(m-1+n i)}{1}(a+b i)^2 \\
& +\frac{(m+n i)(m-1+n i)(m-2+n i)}{1}(a+b i)^3+\cdots \\
& +\frac{(m+n i)(m-1+n i)(m-2+n i) \ldots(m-\mu+1+n i)}{1}(a+b i)^\mu+\cdots \\
& =\left[\cos \left(m \operatorname{arctang} \frac{b}{1+a}+\frac{1}{2} u \log \left[(1+a)^2+b^2\right]\right)+i \sin \left(m \operatorname{arctang} \frac{b}{1+a}+\frac{1}{2} n \log \left[(1+a)^2+b^2\right]\right)\right] \\
& \times\left[(1+a)^2+b^2\right]^{\frac{m}{2}} e^{-n \operatorname{arctang} \frac{b}{1+a} .}
\end{aligned}
\]

Cette expression a lieu comme nous l'avons vu, de même que l'expression (18), pour toute valeur de \(\alpha=\sqrt{a^2+b^2}\) inférieure à l'unité.
En faisant p. ex. \(b=0, n=0\), on a l'expression
\[
1+\frac{m}{1} a+\frac{m(m-1)}{1.2} a^2+\cdots=(1+a)^m
\]
de laquelle nous tirerons parti ci-après.
%239
4.

Dans ce qui précède on a trouvé la somme de la série proposée toutes les fois que \(a=\sqrt{a^2+b^2}\) est inférieur à l'unité. Il reste encore à examiner le cas où cette quantité est égale à 1 .

Nous avons vu par le théorème IV que lorsque \(\alpha\) s'approche indéfiniment de l'unité, la série
\[
v_0+v_1 \alpha+v_2 \alpha^2+\cdots
\]
s'approchera en même temps de la limite \(v_0+v_1+v_2+\cdots\), en smpposant que cette dernière série soit convergente. En faisant donc converger \(\alpha\) vers l'unité dans les équations (18), on aura
(21) \(\left\{\begin{array}{r}1+\lambda_1 \cos \theta_1+\lambda_2 \cos \theta_2+\cdots+\lambda_\mu \cos \theta_\mu+\cdots=e^{\delta_1 k-\beta_1 k^{\prime}} \cos \left(\beta_1 k+\delta_1 k^{\prime}\right), \\ \lambda_1 \sin \theta_1+\lambda_2 \sin \theta_2+\cdots+\lambda_\mu \sin \theta_\mu+\cdots=e^{\delta_1 k-\beta_1 k^{\prime}} \sin \left(\beta_1 k+\delta_1 k^{\prime}\right),\end{array}\right.\) où \(\delta_1\) et \(\beta_1\) sont les limites des quantités \(\delta\) et \(\beta\), en supposant que les séries, contenues dans ces équations, soient convergentes. \(\mathrm{O}_1\) il est clair que \(\frac{1}{2} \log (2+2 \cos \varphi)\) est la limite de \(\delta\), et que
\[
\operatorname{arctang} \frac{\sin \varphi}{1+\cos \varphi}=\operatorname{arctang} \frac{2 \cos \frac{1}{2} \varphi \sin \frac{1}{2} \varphi}{2\left(\cos \frac{1}{2} \varphi\right)^2}=\operatorname{arctang}\left(\operatorname{tang} \frac{1}{2} \varphi\right)
\]
est celle de \(\beta\); on a donc
\[
\delta_1=\frac{1}{2} \log (2+2 \cos \varphi), \quad \beta_1=\operatorname{arctang}\left(\operatorname{tang} \frac{1}{2} \varphi\right) .
\]

Nous n'avons donc qu'à examiner dans quels cas les séries sont convergentes. A cet effet il faut distinguer trois cas: lorsque \(k\) est égal à -1 , ou compris entre -1 et \(-\infty\); lorsque \(k\) est égal à zéro on compris entre 0 et \(+\infty\), et lorsque \(k\) est compris entre 0 et -1 .

Premier crs, lorsque \(k\) est égal à -1 ou compris entre -1 et \(-\infty\). On a
\[
\delta_\mu=\left[\left(\frac{k-\mu+1}{\mu}\right)^2+\left(\frac{k^{\prime}}{\mu}\right)^2\right]^{\frac{1}{2}}
\]

En faisant done \(k=-1-n\), on a
\[
\delta_\mu=\left[\left(\frac{n+\mu}{\mu}\right)^2+\left(\frac{k^{\prime}}{\mu}\right)^2\right]^{\frac{1}{2}}
\]
%240
d'où l'on voit que \(\delta_\mu\) est toujours égal on supérieur à l'unité. Or on a \(\lambda_\mu=\delta_1 \delta_2 \delta_3 \ldots \delta_\mu\), donc pour des valeurs toujours croissantes de \(\mu, \lambda_\mu\) ne convergera pas vers zéro, donc en vertu du théorème I les séries (21) sont divergentes.

Deuxième cas, lorsque \(k\) est positif. Supposons que \(c\) soit une quantité positive inférieure à \(k\), on aura
\[
(\prime \prime-k-1+c)^2=(\prime \prime-k-1)^2+2 c(\prime \prime-k-1)+c^2,
\]
rone
\[
(\prime \prime-k-1)^2+k^{\prime 2}=(1, k-1+c)^2+k^2-c^2-2 c(\prime \prime-k-1) .
\]

Si l'on fait
\[
\text { "1 }>k+1-\frac{1}{2} c+\frac{k^{\prime 2}}{2 c},
\]
il s'ensuit que \(k^{\prime 2}-c^2-2 c(\mu-k-1)\) est négatif; par conséquent
c'ext-à-rlire:
\[
(\prime \prime-k-1)^2+k^{\prime 2}<(, \prime-k-1+c)^2,
\]
\[
\jmath_n<\frac{\mu-k-1+c}{\mu}, \jmath_\mu<1-\frac{1+k-c}{\mu} .
\]

Si dans l'équation (20) on fait \(a=\frac{1}{\mu}, m=-n\), on aura
\[
\begin{aligned}
& \left(1+\frac{1}{\mu}\right)^{-n}=1-\frac{n}{\mu}+\frac{n(1+n)}{1.2} \frac{1}{\mu^2}-\cdots \\
& \quad=1-\frac{n}{\mu}+\frac{n(n+1)}{1.2} \frac{1}{\mu^2}\left(1-\frac{2+n}{3 \mu}\right)+\cdots
\end{aligned}
\]

Donc en faisant \(n=1+k-c\), on voit aisément que
\[
\left(1+\frac{1}{\mu}\right)^{-1-k+c}>1-\frac{1+k-c}{\mu}
\]
par conséquent
\[
\delta_\mu<\left(\frac{\mu}{1+\mu}\right)^{1+k-c}, \text { où }, \prime>k+1-\frac{1}{2} c+\frac{k^{\prime 2}}{2 c}(=0),
\]
done
\[
\delta_{\varrho+\mu}<\left(\frac{\varrho+\mu}{\varrho+\mu+1}\right)^{1+k-c} \text {, où }, \mu>0 .
\]

En posant successivement \(\mu=1,2,3 \ldots\), , et en faisant le produit des résultats, on obtiendra
%241
\[
\delta_{e+1} \delta_{\varrho+2} \ldots \delta_{e+\mu}<\left(\frac{\varrho+1}{\varrho+\mu+1}\right)^{1+k-c}
\]
or \(\lambda_{\mu+\varrho}=\delta_1 \delta_2 \delta_3 \ldots \delta_{\mu+\varrho}\), done
\[
\lambda_{\mu+\rho}<\delta_1 \delta_2 \ldots \delta_\rho\left(\frac{\varrho+1}{\varrho+\mu+1}\right)^{1+k-c}
\]
par conséquent lorsqu'on fait \(, u=0,1,2 \ldots \mu\),
\[
\begin{array}{r}
\lambda_{\varrho}+\lambda_{\varrho+1}+\cdots+\lambda_{\varrho+\mu}<\delta_1 \delta_2 \ldots \delta_{\varrho}(\varrho+1)^{1+k-c}\left(\frac{1}{(\varrho+1)^{1+k-c}}+\frac{1}{(\varrho+2)^{1+k-c}}\right. \\
\left.+\cdots+\frac{1}{(\varrho+\mu+1)^{1+k-c}}\right) .
\end{array}
\]

Si maintenant dans l'expression (20) on fait \(a=-\frac{1}{\varrho+\mu+1}, m=-k+c\), on aura
\[
\left(1-\frac{1}{\varrho+\mu+1}\right)^{c-k}=1+\frac{k-c}{\varrho+\mu+1}+\frac{(k-c)(k-c+1)}{1.2(\varrho+\mu+1)^2}+\cdots,
\]
donc en se rappelant que \(k>c\) :
\[
\left(\frac{\varrho+\mu}{\varrho+\mu+1}\right)^{c-k}>1+\frac{k-c}{\varrho+\mu+1} .
\]

Il s'ensuit, en divisant par \((k-c)(\rho+\mu+1)^{k-c}\),
\[
\frac{1}{(\varrho+\mu+1)^{1+k-c}}<\frac{1}{k-c}\left(\frac{1}{(\varrho+\mu)^{k-c}}-\frac{1}{(\varrho+\mu+1)^{k-c}}\right) .
\]

Cela domne, en faisant \(\mu=0,1,2 \ldots \mu\) et ajoutant,
\[
\begin{aligned}
\frac{1}{(\varrho+1)^{1+k-c}}+\frac{1}{(\varrho+2)^{1+k-c}}+ & \cdots+\frac{1}{(\varrho+\mu+1)^{1+k-c}} \\
& <\frac{1}{k-c}\left(\frac{1}{\varrho^{k-c}}-\frac{1}{(\varrho+\mu+1)^{k-c}}\right)<\frac{1}{k-c} \cdot \frac{1}{\varrho^{k-c}} .
\end{aligned}
\]

Il s'ensuit que
\[
\lambda_\rho+\lambda_{\rho+1}+\cdots+\lambda_{\rho+\mu}<\delta_1 \delta_2 \delta_3 \ldots \delta_\rho \frac{(\varrho+1)^{1+k-c}}{(k-c) \varrho^{k-c}},
\]
pour toute valeur de \(\mu\). Donc la série \(1+\lambda_0+\lambda_1+\lambda_2+\cdots\), dont tous les termes sont positifs, est convergente, et par conséquent, d'après le théorème II, les séries
\[
\begin{array}{r}
1+\lambda_1 \cos \theta_1+\lambda_2 \cos \theta_2+\cdots+\lambda_\mu \cos \theta_\mu+\cdots \\
\lambda_1 \sin \theta_1+\lambda_2 \sin \theta_2+\cdots+\lambda_\mu \sin \theta_\mu+\cdots
\end{array}
\]
seront de même convergentes.
%242
Troisième cas, lorsque \(k\) est égal à zéro ou compris entre zéro et -1 . Dans ce cas les séries ci-dessus seront convergentes pour toute valeur de \(k\), pourvu que \(q\) ne soit pas égal à \((2 n+1) \pi\). Cela peut se démontrer comme il suit: Soit
\[
\begin{gathered}
m=k+k^{\prime} i, x=\cos \varphi+i \sin \varphi \\
1+m_1 x+m_2 x^2+m_3 x^3+\cdots+m_n x^n=p_n .
\end{gathered}
\]

En multipliant par \(1+x\), on obtient
\[
1+\left(m_1+1\right) x+\left(m_2+m_1\right) x^2+\cdots+\left(m_n+m_{n-1}\right) x^n+m_n x^{n+1}=p_n(1+x) .
\]

Or on sait que
\[
m_1+1=(m+1)_1, m_2+m_1=(m+1)_2 \ldots, m_n+m_{n-1}=(m+1)_n,
\]
done en substituant:
\[
1+(m+1)_1 x+(m+1)_2 x^2+\cdots+(m+1)_n x^n=-m_n x^{n+1}+p_n(1+x) .
\]

Naintenant, si l'on fait \(n=\infty\), le premier membre de cette équation sera, d'après le cas précédent, une série convergente. En la désignant par \(s\), on allia
\[
s=p_n(1+x)-m_n[\cos (n+1) \varphi+i \sin (n+1) \varphi]
\]
où \(n\) est infini. - Or on peut démontrer comme dans le deuxième cas que \(m_n=0\) pour \(n=\infty\). On a done
\[
s=p(1+x) \text {, où } p=1+m_1 x+m_2 x^2+\cdots
\]

Cette équatión donne, si \(x+1\) n'est pas égal à zéro,
\[
p=\frac{s}{1+x} \text {. }
\]

La série \(p\) est donc alors convergente, et par conséquent les séries ci-dessus le sont également.

Si \(x+1=0\), on a \(1+\cos \varphi+i \sin \varphi=0\), donc \(\sin \varphi=0,1+\cos \varphi=0\), d'où \(\varphi=(2 n+1) \pi, n\) étant un nombre entier positif ou négatif. Done les séries en question sont convergentes pour toute valeur de \(k\) égale à zéro ou comprise entre 0 et -1 , si \(\varphi\) n'est pas égal à \((2 n+1) x\).

Lorsque \(\varphi=(2 n+1) \pi\), les séries sont nécessairement divergentes, cal si elles étaient convergentes, elles auraient pour somme les limites des fonctions
\[
e^{k \delta-k^{\prime} \beta}\left[\cos \left(k \beta+k^{\prime} \delta^{\prime}\right)+i \sin \left(k \beta+k^{\prime} \delta\right)\right]
\]
%243
en y faisant converger \(\alpha\) vers l'unité, et faisant \(\varphi=(2 n+1) \pi . \mathrm{Or}_{\mathrm{r}}\)
\[
\delta=\frac{1}{2} \log \left(1+2 \alpha \cos \varphi+\alpha^2\right), \beta=\operatorname{arctang} \frac{\alpha \sin \varphi}{1+\alpha \cos \uparrow},
\]
donc pour \(\varphi=(2 n+1) \pi\) on a
\[
\delta=\log (1-\alpha), \beta=0 .
\]

La fonction en question prendra done la forme
\[
(1-\alpha)^k\left[\cos \left(k^{\prime} \log (1-\alpha)\right)+i \sin \left(k^{\prime} \log (1-\alpha)\right)\right] .
\]

Or, \(k\) étant égal à zéro ou négatif, il est clair qu’en faisant converger \(\&\) vers l'unité, on n'obtiendra pas pour cette fonction une limite finie et déterminée. Donc les séries sont divergentes.

De ce qui précède il s'ensuit, que les séries (21) ont lieu pour toute valeur de \(\varphi\), lorsque \(k\) est positif, et pour toute-valeur de \(\varphi\) pour laquelle \(\cos \frac{q}{2}\) n'est pas zéro, lorsque \(k\) est égal à zéro on compris entre -1 et (), .quelle que soit d'ailleurs la valeur de \(k^{\prime}\). Dans tout autre cas les séries sont divergentes. Dans le cas que nous examinons, la série générale (19), lorsqu'on y fait \(b^2+a^2=1\), ou \(b=\sqrt{1-a^2}\), prend la forme:
\[
\left\{\begin{array}{r}
1+\frac{m+n i}{1}\left(a+\sqrt{a^2-1}\right)+\frac{(m+n i)(m-1+n i)}{1}\left(a+\sqrt{a^2-1}\right)^2 \\
+\frac{(m+n i)(m-1+n i)(m-2+n i)}{2}\left(a+\sqrt{a^2-1}\right)^3+\cdots \\
=(2+2 a)^{\frac{m}{2}} e^{-n \operatorname{arctang}} \sqrt{\frac{1-a}{1+a}}\left[\cos \left(m \text { arc. tang } \sqrt{\frac{1-a}{1+a}}+\frac{1}{2} n \log (2+2 a)\right)\right. \\
\left.+i \sin \left(m \text { arc. tang } \sqrt{\frac{1-a}{1+a}}+\frac{1}{2} n \log (2+2 a)\right)\right]
\end{array}\right.
\]

Voici un résumé des résultats précédents:
I. Lorsque la série,
\[
1+\frac{m+n i}{1}(a+b i)+\frac{(m+n i)(m-1+n i)}{1 \cdot 2}(a+b i)^2+\cdots
\]
est convergente, elle a pour somme
\[
\begin{aligned}
{\left[(1+a)^2+b^2\right]^{\frac{n}{2}} e^{-n \operatorname{arctang}} \frac{b}{1+a}\left[\cos \left(m \operatorname{arctang} \frac{b}{1+a}+\frac{n}{2} \log \left[(1+a)^2+b^2\right]\right)\right.} \\
\left.+i \sin \left(m \operatorname{arctang} \frac{b}{1+a}+\frac{n}{2} \log \left[(1+a)^2+b^2\right]\right)\right] . \\
\end{aligned}
\]
%244
II. La série est convergente pour toute valeur de \(m\) et \(n\), lorsque la quantité \(\sqrt{a^2+b^2}\) est inférieure à l'unité. Si \(\sqrt{a^2+b^2}\) est égal à l'unité, la série est convergente pour toute valeur de \(m\) comprise entre -1 et \(+\infty\), si l'on n'a pas en même temps \(a=-1\). Si \(a=-1, m\) doit être positif. Dans tout autre cas la série proposée est divergente:
Comme cas particuliers on doit considérer les suivants:
A. Lorsque \(n=0\). On a alors
(24) \(\left\{\begin{array}{l}1+\frac{m}{1}(a+b i)+\frac{m(m-1)}{1.2}(a+b i)^2+\cdots \\ =\left[(1+a)^2+b^2\right]^{\frac{m}{2}}\left[\cos \left(m \text { arc. tang } \frac{b}{1+a}\right)+i \sin \left(m \text { arc tang } \frac{b}{1+a}\right)\right] \ldots\end{array}\right.\)

Cette expression donne, en faisant \(a=\alpha \cos \varphi, b=\alpha \sin \varphi\) et en séparant les termes réels des imaginaires:
\[
\left\{\begin{aligned}
1+\frac{m}{1} \alpha \cos \varphi+\frac{m(m-1)}{1.2} \alpha^2 \cos 2 \varphi+\cdots & \\
& =\left(1+2 \alpha \cos \varphi+\alpha^2\right)^{\frac{m}{2}} \cos \left(m \text { arc. tang } \frac{\alpha \sin \varphi}{1+\alpha \cos \varphi}\right) \\
\frac{m}{1} \alpha \sin \varphi+\frac{m(m-1)}{1.2} \alpha^2 \sin 2 \varphi+\cdots & =\left(1+2 \alpha \cos \varphi+\alpha^2\right)^{\frac{m}{2}} \sin \left(m \operatorname{arctang} \frac{\alpha \sin \varphi}{1+\alpha \cos \varphi}\right)
\end{aligned}\right.
\]
B. Lorsque \(b=0\).

Dans ce cas l'expression générale prend la forme suivante:
\[
\left\{\begin{aligned}
1+\frac{n+n i}{1} & a+\frac{(m+n i)(m-1+n i)}{1 \cdot 2} a^2+\cdots \\
& =(1+a)^m[\cos (n \cdot \log (1+a))+i \sin (n \cdot \log (1+a))]
\end{aligned}\right.
\]
C. Lorsque \(n=0, b=0\).

Alors on a
\[
1+\frac{m}{1} a+\frac{m(m-1)}{1.2} a^2+\frac{m(m-1)(m-2)}{1.2 .3} a^3+\cdots=(1+a)^m
\]

Cette expression a lieu pour toute valeur de \(m\) lorsque la valeur numérique de \(a\) est inférieure à l'unité, de plus pour toute valeur de \(m\) comprise entre
%245
-1 et \(+\infty\), lorsque \(a=1\), et pour tonte valeur positive de \(m\), lorsque \(a=-1\). Pour toute autre valeur de \(a\) et de \(m\) le premier membre est une série divergente.
Faisant p. ex. \(a=1, a=-1\), on a
\[
\begin{aligned}
& 1+\frac{m}{1}+\frac{m(m-1)}{1.2}+\cdots=2^m, \\
& 1-\frac{m}{1}+\frac{m(m-1)}{1.2}-\cdots=0 .
\end{aligned}
\]

La première équation a lieu pour toute valeur de \(m\) comprise entre -1 et \(+\infty\), et la seconde pour toute valeur positive de \(m\).
1). Lorsque \(\sqrt{a^2+b^2}=1\).
Alors on a
\[
(28)\left\{\begin{array}{r}
1+\frac{m+n i}{1}\left(a+\sqrt{a^2-1}\right)+\frac{(m+n i)(m-1+n i)}{1 \cdot 2}\left(a+\sqrt{a^2-1}\right)^3+\cdots \\
=(2+2 a)^{\frac{m}{2}} e^{-n \text { arc. tang }} \sqrt{\frac{1-a}{1+a}}\left[\cos \left(m \text { arc. tang } \sqrt{\frac{1-a}{1+a}}+\frac{n}{2} \log (2+2 a)\right)\right. \\
\left.+i \sin \left(m \text { arc. tang } \sqrt{\frac{1-a}{1+a}}+\frac{n}{2} \log (2+2 a)\right)\right] .
\end{array}\right.
\]

Si l'on fait ici \(a=\cos \varphi\), on obtient
\[
\text { (29) }\left\{\begin{array}{r}
1+\frac{m+n i}{1}(\cos \varphi+i \sin \varphi)+\frac{(m+n i)(m-1+n i)}{1 \cdot 2}(\cos 2 \varphi+i \sin 2 \varphi)+\cdots \\
=(2+2 \cos \varphi)^{\frac{m}{2}} e^{-n\left(\frac{1}{2} \varphi-\rho \pi\right)}\left[\cos \left(m\left(\frac{1}{2} \varphi-\varrho \pi\right)+\frac{n}{2} \log (2+2 \cos \varphi)\right)\right. \\
\left.+i \sin \left(m\left(\frac{1}{2} \varphi-\varrho \pi\right)+\frac{n}{2} \log (2+2 \cos \varphi)\right)\right]
\end{array}\right.
\]
en remarquant qu'on a
\[
\text { arc. tang } \sqrt{\frac{1-a}{1+a}}=\operatorname{arc} \cdot \operatorname{tang} \sqrt{\frac{1-\cos \varphi}{1+\cos \varphi}}=\operatorname{arcs} \operatorname{tang}\left(\operatorname{tang} \frac{1}{2} \varphi\right)=\frac{1}{2} \varphi-\varphi \pi,
\]
si l'on suppose \(\frac{1}{2} \varphi\) compris entre \(\varrho \pi-\frac{\pi}{2}\) et \(\varrho \pi+\frac{\pi}{2}\).
%246
E. Lorsque \(\sqrt{a^2+b^2}=1, a=\cos \varphi, b=\sin \varphi, n=0\). Dans ce cas l'expression précédente domne
\[
\left\{\begin{array}{c}
1+\frac{m}{1}(\cos \varphi+i \sin \varphi)+\frac{m(m-1)}{1.2}(\cos 2 \varphi+i \sin 2 \varphi)+\cdots \\
=(2+2 \cos \varphi)^{\frac{m}{2}}\left[\cos m\left(\frac{1}{2} \varphi-\varrho \pi\right)+i \sin m\left(\frac{1}{2} \varphi-\varrho \pi\right)\right] \\
\text { depuis } \frac{1}{2} \varphi=\rho \pi-\frac{\pi}{2} \text { jusqu'a } \frac{1}{2} \varphi=\varrho \pi+\frac{\pi}{2},
\end{array}\right.
\]
ou, en séparant la partie réelle de l'imaginaire,
\((31)\left\{\begin{array}{c}1+\frac{m}{1} \cos \varphi+\frac{m(m-1)}{1.2} \cos 2 \varphi+\cdots=(2+2 \cos \varphi)^{\frac{m}{2}} \cdot \cos m\left(\frac{1}{2} \varphi-\varrho \pi\right) \\ \frac{m}{1} \sin \varphi+\frac{m(m-1)}{1.2} \sin 2 \varphi+\cdots=(2+2 \cos \varphi)^{\frac{m}{2}} \sin m\left(\frac{1}{2} \varphi-\varrho \pi\right) \\ \text { depuis }{ }_2^1 \varphi=\varrho \pi-\frac{\pi}{2} \text { jusqu's }{ }_2^1 \varphi=\varrho \pi+\frac{\pi}{2} .\end{array}\right.\)
F. Lorsque \(a=0, b=\operatorname{tang} \varphi\).
Dans ce cas on obtient, lorsque \(\varphi\) est compris entre \(+\frac{\pi}{4}\) et \(-\frac{\pi}{4}\),
(32) \(\left\{\begin{array}{l}1+\frac{m+n i}{1} i \operatorname{tang} \varphi+\frac{(m+n i)(m-1+u i)}{1 \cdot 2}(i \operatorname{tang} \varphi)^2+\cdots \\ =(\cos \varphi)^{-m} e^{-n \varphi}[\cos (m \varphi-n \log \cos \varphi)+i \sin (m \varphi-n \log \cos \varphi)] .\end{array}\right.\)
5.
Des expressions précédentes on peut, par des transformations convenables, en déduire plusieurs autres, parmi lesquelles il s'en trouve de très remarquables. Nous allons en développer quelques unes. Pour plus de détail on peut consulter l'ouvrage cité de M. Cauchy.
A.
Sommation des séries \(\alpha \cos \varphi-\frac{1}{2} \alpha^2 \cos 2 \varphi+\frac{1}{3} \alpha^3 \cos 3 \varphi-\cdots\),
\[
\alpha \sin \varphi-\frac{1}{2} \alpha^2 \sin 2 \varphi+\frac{1}{3} \alpha^8 \sin 3 \varphi-\cdots
\]

Lorsque \(\alpha\) est supérieur à l'unité, on voit aisément que ces séries sont divergentes. Si \(\alpha\) est inférieur à l'unité, nous avons vu plus haut qu'elles
%247
sont convergentes; leurs sommes sont les quantités \(\beta\) et \(\delta\) du \(\S 3\), c'est-à-dire, en mettant pour \(\beta\) et \(\delta\) leurs valeurs domées par les équations (18),
(33) \(\left\{\begin{array}{r}\frac{1}{2} \log \left(1+2 \alpha \cos \varphi+\alpha^2\right)=\alpha \cos \varphi-\frac{1}{2} \alpha^2 \cos 2 \varphi+\frac{1}{3} \alpha^3 \cos 3 \varphi-\cdots, \\ \text { arc. } \operatorname{tang} \frac{\alpha \sin \varphi}{1+\alpha \cos \varphi}=\alpha \sin \varphi-\frac{1}{2} \alpha^2 \sin 2 \varphi+\frac{1}{3} \alpha^3 \sin 3 \varphi-\cdots\end{array}\right.\)

Pour avoir les sommes de ces séries lorsque \(\alpha=+1\) ou -1 , il faut senlement faire converger \(\alpha\) vers cette limite. La première expression donne de cette manière
\[
\left\{\begin{array}{l}
\frac{1}{2} \log (2+2 \cos \varphi)=\cos \varphi-\frac{1}{2} \cos 2 \varphi+\frac{1}{3} \cos 3 \varphi-\cdots, \\
\frac{1}{2} \log (2-2 \cos \varphi)=-\cos \varphi-\frac{1}{2} \cos 2 \varphi-\frac{1}{3} \cos 3 \varphi-\cdots,
\end{array}\right.
\]
en supposant que les seconds membres de ces équations soient des séries convergentes, ce qui a lieu, d'après le théorème II, pour toute valeur de \(\varphi\), excepté pour \(\varphi=(2 \mu+1) \pi\) dans la première expression, et pour \(\varphi=2 u \pi\) dans la seconde, \(\boldsymbol{\iota}\) étant un nombre entier quelconque positif ou négatif.

La seconde formule donne, en supposant \(\varphi\) compris entre \(\pi\) et \(-\pi\), et en se rappelant qu'on a alors
\[
\text { arc. } \operatorname{tang} \frac{\sin \varphi}{1+\cos \varphi}=\operatorname{arc} \operatorname{tang}\left(\operatorname{tang} \frac{1}{2} \varphi\right)=\frac{1}{2} \varphi:
\]
(35) \(\frac{1}{2} \varphi=\sin \varphi-\frac{1}{2} \sin 2 \varphi+\frac{1}{3} \sin 3 \varphi-\cdots\) (depuis \(\varphi=+\pi\) jusqu'à \(\varphi=-\pi\) ).

Lorsque \(\varphi=\pi\) ou \(=-\pi\), la série se réduit à zéro, comme on le voit aisément. Il s'ensuit que la fonction:
\[
\sin \varphi-\frac{1}{2} \cdot \sin 2 \varphi+\frac{1}{3} \sin 3 \varphi-\cdots
\]
a la propriété remarquable d'être discontinue pour les valeurs \(\dot{\varphi}=\pi\) et \(\varphi=-\pi\). Èn effet, lorsque \(\varphi= \pm \pi\), la fonction se réduit à zéro; si au contraire \(\varphi= \pm(\pi-\alpha), \alpha\) étant positif et moindre que \(\pi\), la valeur de la fonction est
\[
\pm\left(\frac{\pi}{2}-\frac{\alpha}{2}\right)
\]

La formule (33) contient comme cas particulier la suivante:
\[
\text { arc. tang } \alpha=\alpha-\frac{1}{3} \alpha^3+\frac{1}{5} \alpha^5-\cdots
\]
ce qu'on trouve en faisant \(\varphi=\frac{\pi}{2}\). Cette formule sera applicable pour toute valeur de \(\alpha\), depuis -1 jusqu'à +1 , les limites y comprises.
%248
B.

Développement de cos mq et de sinmp suivant les puissances de tang \(\varphi\).
On peut déduire ces développemens de l'expression (32). - En effet, en faisant \(n=0\), et séparant les parties réelles des parties imaginaires, on obtient, après avoir multiplié par \((\cos \varphi)^m\),
\[
\left\{\begin{array}{c}
\cos m \varphi=(\cos \varphi)^m\left(1-\frac{m(m-1)}{1.2}(\operatorname{tang} \varphi)^2\right. \\
\left.\quad+\frac{m(m-1)(m-2)(m-3)}{1 \cdot 2 \cdot 3 \cdot 4}(\operatorname{tang} \varphi)^4-\cdots\right) \\
\sin m \varphi=(\cos \varphi)^m\left(m(\operatorname{tang} \varphi)-\frac{m(m-1)(m-2)}{1 \cdot 2 \cdot 3}(\operatorname{tang} \varphi)^3+\cdots\right)
\end{array}\right.
\]
depuis \(\varphi=\frac{\pi}{4}\) jusqu'à \(\varphi=-\frac{\pi}{4}\), et ces équations ont lieu pour toute valeur de \(m\) lorsque \(\operatorname{tang} \varphi\) est moindre que 1 . Si \(\operatorname{tang} \varphi= \pm 1\), elles ont lien pour tout \(m\) compris entre -1 et \(+\infty\). Elles sont alors:
\((38)\left\{\begin{array}{l}\cos \left(m \frac{\pi}{4}\right)=\left(\frac{1}{2}\right)^{\frac{m}{2}}\left(1-\frac{m(m-1)}{1 \cdot 2}+\frac{m(m-1)(m-2)(m-3)}{1 \cdot 2 \cdot 3 \cdot 4}-\cdots\right) \\ \sin \left(m \frac{\pi}{4}\right)=\left(\frac{1}{2}\right)^{\frac{m}{2}}\left(m-\frac{m(m-1)(m-2)}{1 \cdot 2 \cdot 3}+\cdots\right) .\end{array}\right.\)
C.
Développement de \((\cos x)^n\) et \((\sin x)^n\) en séries ordomées suivant les cosinus et les simus des arcs multiples.
Depuis quelque temps plusieurs analystes se sont occupés du développement de \((\cos x)^n\) et \((\sin x)^n\). Mais jusqu’à présent, si je ne me trompe, ces efforts n'ont pas entièrement réussi. On est bien parvenu à des expressions justes sous certaines restrictions, mais ces expressions n'ont pas été rigoureusement fondées. On peut les déduire assez simplement des expressions. démontrées ci-dessus. En effet, si l'on ajoute les deux équations (31), après avoir multiplié la première par \(\cos \alpha\) et la seconde par \(\sin \alpha\), on obtient
%249
\[
\begin{gathered}
\cos \alpha+\frac{m}{1} \cos (\alpha-\varphi)+\frac{m(m-1)}{1.2} \cos (\alpha-2 \varphi)+\cdots \\
=(2+2 \cos \varphi)^{\frac{m}{2}} \cos \left(\alpha-\frac{m \varphi}{2}+m \varrho \pi\right) \\
\left(\text { depuiş } \frac{1}{2} \varphi=\varrho \pi-\frac{\pi}{2} \text { jusqu'à } \frac{1}{2} \varphi=\varrho \pi+\frac{\pi}{2}\right) .
\end{gathered}
\]

Or puisque \(2+2 \cos \varphi=4\left(\cos \frac{1}{2} \varphi\right)^2\), on aura, en faisant \(\varphi=2 x\),
\[
\begin{gathered}
\cos \alpha+\frac{m}{1} \cos (\alpha-2 x)+\frac{m(m-1)}{1.2} \cos (\alpha-4 x)+\cdots=(2 \cos x)^m \cos (\alpha-m x+2 m \varrho \pi) \\
\text { depuis } x=2 \varrho \pi-\frac{\pi}{2} \text { jusqu'à } x=2 \varrho \pi+\frac{\pi}{2} \\
\cos \alpha+\frac{m}{1} \cos (\alpha-2 x)+\frac{m(m-1)}{1.2} \cos (\alpha-4 x)+\cdots=(-2 \cos x)^m \cos [\alpha-m x+m(2 \varrho+1) \pi]
\end{gathered}
\]
depuis \(x=2 \varrho \pi+\frac{\pi}{2}\) jusqu'à \(x=2 \varrho \pi+\frac{3 \pi}{2}\).
Si l'on fait ici 1) \(\alpha=m x\); 2) \(\alpha=m x+\frac{\pi}{2}\); 3) \(\alpha=m y, x=y-\frac{\pi}{2}\);
4) \(\alpha=m y-\frac{\pi}{2}, x=y-\frac{\pi}{2}\), on obtiendra
1) \((2 \cos x)^m \cos 2 m \omega \pi=\cos m x+\frac{m}{1} \cos (m-2) x+\frac{m(m-1)}{1.2} \cos (m-4) x+\cdots\),
2) \((2 \cos x)^m \sin 2 m \varphi \pi=\sin m x+\frac{m}{1} \sin (m-2) x+\frac{m(m-1)}{1.2} \sin (m-4) x+\cdots\),
depuis \(x=2 \varrho \pi-\frac{\pi}{2}\) jusqu'à \(x=2 \varrho \pi+\frac{\pi}{2}\);
3) \((2 \sin x)^m \cos m\left(2 \varrho+\frac{1}{2}\right) \pi=\cos m x-\frac{m}{1} \cos (m-2) x+\frac{m(m-1)}{1.2} \cos (m-4) x-\cdots\),
4) \((2 \sin x)^m \sin m\left(2 \varrho+\frac{1}{2}\right) \pi=\sin m x-\frac{m}{1} \sin (m-2) x+\frac{m(m-1)}{1.2} \sin (m-4) x-\cdots\), depuis \(x=2 \varrho \pi\) jusqu'à \(x=(2 \varrho+1) \pi\);
5) \((-2 \cos x)^m \cos m(2 \varrho+1) \pi=\cos m x+\frac{m}{1} \cos (m-2) x+\frac{m(m-1)}{1.2} \cos (m-4) x+\cdots\),
6) \((-2 \cos x)^m \sin m(2 \varrho+1) x=\sin m x+\frac{m}{1} \sin (m-2) x+\frac{m(m-1)}{1.2} \sin (m-4) x+\cdots\), depuis \(x=\left(2 \varphi+\frac{1}{2}\right) \pi\) jusqu’à \(x=\left(2 \varphi+\frac{3}{2}\right) \pi\);
7) \((-2 \sin x)^m \cos m\left(2 \varrho+\frac{3}{2}\right) \pi=\cos m x-\frac{m}{1} \cos (m-2) x+\frac{m(m-1)}{1.2} \cos (m-4) x-\ldots\),
8) \((-2 \sin x)^m \sin m\left(2 \varphi+\frac{3}{2}\right) \pi=\sin m x-\frac{m}{1} \sin (m-2) x+\frac{m(m-1)}{1.2} \sin (m-4) x-\cdots\), depuis \(x=(2 \varphi+1) \pi\) jusqu'à \(x=(2 \varphi+2) \pi\).
%250
Ces formules ont encore lieu pour les valeurs linites de \(x\), lorsque \(m\) est positif. Lorsque \(m\) est compris entre -1 et 0 ces valeurs sont exclues. Comme cas particuliers on peut considérer les deux suivants:
\[
\begin{gathered}
(2 \cos x)^m=\cos m x+\frac{m}{1} \cos (m-2) x+\frac{m(m-1)}{1.2} \cos (m-4) x+\cdots, \\
0=\sin m x+\frac{m}{1} \sin (m-2) x+\frac{m(m-1)}{1.2} \sin (m-4) x+\cdots \\
\left(\text { depuis } x=-\frac{\pi}{2} \text { jusqu'à } x=\frac{x}{2}\right) .
\end{gathered}
\]
%251
\(\mathrm{XV}\).

SUR QUELQUES INTÉGRALES DÉFINIES.

Journal für die reine und angewandte Mathematik, herausgegeben von Crelle, Bd. II, Berlin 1827.

Lorsque une intégrale définie contient une quantité constante indéterminée, on peut souvent en déduire, par différentiation, une équation différentielle par laquelle l’intégrale définie peut se déterminer en fonction de la quantité constante. Le plus souvent cette équation différentielle est linéaire; si elle est en même temps du premier ordre, elle peut, comme on sait, s'intégrer. Quoique cela n'ait pas lieu en général, lorsque l'équation est du second ordre ou d'un ordre plus élevé, on peut pourtant quelquefois déduire de ces équations plusieurs relations intéressantes entre les intégrales définies. Montrer cela sera l'objet de ce mémoire.

Soit \(\frac{d^2 y}{d a^2}+p \frac{d y}{d a}+q y=0\) une équation différentielle linéaire du second ordre entre \(y\) et \(a, p\) et \(q\) étant denx fonctions de \(a\). Supposons qu'on connaisse deux intégrales particulières de cette équation, savoir \(y=y_1\) et \(y=y_2\), on aura
\[
\frac{d^2 y_1}{d a^2}+p \frac{d y_1}{d a}+q y_1=0 ; \frac{d^2 y_2}{d a^2}+p \frac{d y_2}{d a}+q y_2=0
\]

De ces équations on tire, en éliminant \(q\),
\[
y_2 \frac{d^2 y_1}{d a^2}-y_1 \frac{d^2 y_2}{d a^2}=\frac{d\left(y_2 \frac{d y_1}{d u}-y_1 \frac{d y_2}{d u}\right)}{d u}=-p\left(y_2 \frac{d y_1}{d a}-y_1 \frac{d y_2}{d u}\right),
\]
%252
done en intégrant
\[
y_2 \frac{d y_1}{d a}-y_1 \frac{d y_2}{d a}=e^{-\int p d x}
\]
\(e\) étant la base des logarithmes Népériens.
Supposons que les deux fonctions \(y_1\) et \(y_2\) soient exprimées en intégrales définies, de sorte que \(y_1=\int v d x, y_2=\int u d x, v\) et \(u\) étant des fonctions de \(x\) et de \(a\), cette relation entre \(y_1\) et \(y_2\) donne en substituant,
\[
\int u d x \int \frac{d v}{d u} d x-\int v d x \int \frac{d u}{d a} d x=e^{-\int p d a} \text {. }
\]

Cette équation exprime, comme on le voit, une relation entre les quatre intégrales \(\int u d x, \int v d x, \int \frac{d u}{d u} d x, \int \frac{d v}{d u} d x\). Il s'agit maintenant de trouver des intégrales qui puissent satisfaire ì une équation différentielle du second ordre. Il y a plusieurs intégrales qui jouissent de cette propriété, et que nous allons considérer successivement.
I. Soit \(v=\frac{(x+a)^{\gamma+1}}{x^{1-\alpha}(1-x)^{1-\beta}}\) et \(y=\int_0^1 \frac{(x+a)^{\gamma+1} d x}{x^{1-\alpha}(1-x)^{1-\beta}}\),
\[
\frac{d y}{d a}=(\gamma+1) \int_0^1 \frac{(x+a)^\gamma d x}{x^{1-\alpha}(1-x)^{1-\beta}}, \frac{d^2 y}{d a^2}=\gamma(\gamma+1) \int_0^1 \frac{(x+a)^{\gamma-1} d x}{x^{1-\alpha}(1-x)^{1-\beta}},
\]
le signe \(\int_0^1\) dénotant que l'intégrale est prise depuis \(x=0\) jusqu'à \(x=1\). En différentiant la quantité \((x+a)^\gamma x^\alpha(1-x)^\beta=r\) par rapport ì \(x\), on obtient
\[
d r=d x \cdot x^{a-1}(1-x)^{\beta-1}(x+a)^{\gamma-1}[\gamma x(1-x)+\alpha(x+a)(1-x)-\beta(x+a) x] .
\]
\(\mathrm{Or}\)
\[
\begin{aligned}
& \gamma x(1-x)+\alpha(x+a)(1-x)-\beta(x+a) x \\
= & -\gamma\left(a^2+a\right)+[a(\beta+\gamma)+(a+1)(\alpha+\gamma)](x+a)-(\alpha+\beta+\gamma)(x+a)^2,
\end{aligned}
\]
donc en intégrant entre les limites \(x=0, x=1\), on obtient
\[
\begin{gathered}
0=-\gamma\left(a^2+a\right) \int_0^1 \frac{(a+a)^{\gamma-1} d x}{x^{1-\alpha}(1-x)^{1-\beta}} \\
+[(\beta+\gamma) a+(\alpha+\gamma)(\alpha+1)] \int_0^1 \frac{(x+a)^\gamma d x}{x^{1-\alpha}(1-x)^{1-\beta}}-(\alpha+\beta+\gamma) \int_0^1 \frac{(x+a)^{\gamma+1} d x}{x^{1-\alpha}(1-\gamma)^{1-\beta}} .
\end{gathered}
\]
%253
De cette équation on tire, en divisant par \(\frac{a^2+a}{\gamma+1}\) et substituant à la place des intégrales leurs valeurs en \(y\),
\[
\frac{d^2 y}{d a^2}-\left(\frac{\alpha+\gamma}{a}+\frac{\beta+\gamma}{1+a}\right) \frac{d y}{d a}+\frac{(\gamma+1)(\alpha+\beta+\gamma)}{a(a+1)} y=0 .
\]

Si l'on met à la place de \(\alpha, \beta, \gamma\) respectivement \(1-\beta, 1-\alpha\), \(\alpha+\beta+\gamma-1\), on aura la même équation, donc
\[
y_1=\int_0^1 \frac{(x+a)^{\gamma+1} d x}{x^{1-\alpha}(1-x)^{1-\beta}} \text { et } y_2=\int_0^1 \frac{(x+a)^{\alpha+\beta+\gamma} d x}{x \beta(1-x)^\alpha}
\]
sont deux intégrales particulières de cette équation.
\[
\text { Or } p=-\frac{\alpha+\gamma}{a}-\frac{\beta+\gamma}{1+a} \text {, et par conséquent } e^{-\int p d x}=C a^{\alpha+\gamma}(1+a)^{\beta+\gamma} \text {, }
\]
done l'équation (0) donne
\[
y_2 \frac{d y_1}{d a}-y_1 \frac{d y_2}{d a}=C a^{\alpha+\gamma}(1+a)^{\beta+\gamma}
\]

Pour déterminer la quantité constante \(C\), soit \(a=\infty\), on trouvera facilement
\[
C=-(\alpha+\beta-1) \int_0^1 d x \cdot x^{\alpha-1}(1-x)^{\beta-1} \cdot \int_0^1 d x \cdot x^{-\beta}(1-x)^{-\alpha}
\]
c'est-à-dire
\[
C=\pi[\cot (\alpha \pi)+\cot (\beta \pi)] .
\]

Par suite l'équation (4) donne
\[
\left\{\begin{array}{l}
(\alpha+\beta+\gamma) \int_0^1 \frac{d x(x+a)^{\gamma+1}}{x^{1-\alpha}(1-x)^{1-\beta}} \cdot \int_0^1 \frac{d x(x+a)^{\alpha+\beta+\gamma-1}}{x^\beta(1-x)^\alpha} \\
-(\gamma+1) \int_0^1 \frac{d x(x+a)^\gamma}{x^{1-\alpha}(1-x)^{1-\beta}} \cdot \int_0^1 \frac{d x(x+a)^{\alpha+\beta+\gamma}}{x^\beta(1-x)^\alpha} \\
=-\pi[\cot (\alpha \pi)+\cot (\beta \pi)] a^{\alpha+\gamma}(1+a)^{\beta+\gamma}
\end{array}\right.
\]

Le cas où \(\gamma=-\alpha-\beta\) mérite d'être remarqué. On a alor's, comme on le voit aisément,
\[
\int_0^1 \frac{d x}{x^{1-\alpha}(1-x)^{1-\beta}(x+a)^{\alpha+\beta}}=\frac{1}{a^\beta(1+a)^\alpha} \int_0^1 \frac{d x}{x^{1-\alpha}(1-x)^{1-\beta}}
\]

Or
\[
\int_0^1 \frac{d x}{x^{1-\alpha}(1-x)^{1-\beta}}=\frac{\Gamma \alpha \cdot \beta}{\Gamma(\alpha+\beta)}
\]
%254
Im étant égal à \(\int_0^{\infty} x^{m-1} e^{-x} d x\), donc
\[
\int_0^1 \frac{d x}{x^{1-\alpha}(1-x)^{1-\beta}(x+a)^{\alpha+\beta}}=\frac{\Gamma \alpha \cdot \Gamma \beta}{\Gamma(\alpha+\beta)} \frac{1}{a^\beta(1+a)^\alpha} .
\]

Soit p. ex. \(\beta=1-\alpha\), on aura
\[
\int_0^1 \frac{d x}{(1-x)^\alpha x^{1-\alpha}(x+a)}=\frac{\Gamma \alpha \cdot \Gamma(1-\alpha)}{\Gamma(1)} \frac{1}{a^{1-\alpha}(1+a)^\alpha},
\]
or \(I^{\prime}(1)=1, I^{\prime} \alpha \cdot I^{\prime}(1-\alpha)=\frac{\pi}{\sin \alpha / x}\), donc
\[
\int_0^1 \frac{d x}{(x+a) x^{1-\alpha}(1-x)^\alpha}=\frac{x}{\sin \alpha x} \frac{1}{a^{1-\alpha}(1+a)^\alpha} .
\]
II. Soit \(y=\int_0^{\infty} \frac{x^{-\alpha} d x}{(1+x)^\beta(x+a)^\gamma}\). En différentiant on obtient
\[
\begin{gathered}
\frac{d y}{d u}=-\gamma \int_0^{\infty} \frac{x^{-\alpha} d x}{(1+x)^\beta(x+a)^{\gamma+1}}, \\
d^2 y=\gamma(\gamma+1) \int_0^{\infty} \frac{x^{-\alpha} d x}{(1+x)^\beta(x+a)^{\gamma+2}} .
\end{gathered}
\]

Lorsqu'on différentie la fonction \(x^{1-\alpha}(1+x)^{1-\beta}(x+a)^{-\gamma-1}=r\), on obtient
\[
\begin{aligned}
d r=\frac{x^{-\alpha} d x}{(1+x)^\beta(x+a)^{\gamma+2}}[(1-\alpha) & (1+x)(x+a)+(1-\beta) x(x+a)-(\gamma+1) x(1+x)] \\
= & \frac{x^{-\alpha} d x}{(1+x)^\beta(x+a)^{\gamma+y}} q
\end{aligned}
\]
donc, puisque
\[
\begin{aligned}
& q=(\gamma+1)(1-a) a-[(\alpha+\gamma)(1-a)-(\gamma+\beta) a](x+a) \\
& +(1-\alpha-\beta-\gamma)(x+a)^2: \\
& d r=(\gamma+1) a(1-a) \frac{x^{-\alpha} d x}{(1+x)^\beta(x+a)^{\gamma+z}} \\
& -[(\alpha+\gamma)(1-a)-(\beta+\gamma) a]_{(1+x)^\beta(x+a)^{\gamma+1}}+(1-\alpha-\beta-\gamma) \frac{x^{-\alpha} d x}{(1+x)^\beta(x+a)^\gamma} . \\
&
\end{aligned}
\]

On tire de là en intégrant
(6)
\[
\frac{d^2 y}{d a^2}+\left(\frac{\alpha+\gamma}{a}-\frac{\beta+\gamma}{1-a}\right) \frac{d y}{d a}+\frac{\gamma(1-\alpha-\beta-\gamma)}{a(1-a)} y=0
\]

En mettant respectivement \(1-\beta, 1-\alpha, \gamma+\alpha+\beta-1\) ì la place de \(\alpha, \beta, \gamma\), il en résulte la même équation, donc
%255
\[
y_1=\int_0^{\infty} \frac{x^{-\alpha} d x}{(1+x)^\beta(x+\iota)^\gamma} \text { et } y_2=\int_0^{\infty} \frac{x^{\beta-1} d x}{(1+x)^{1-\alpha}(x+a)^{\alpha+\beta+\gamma-1}} \text {, }
\]
sont deux intégrales particulières de cette équation.
Or, puisque \(p=\frac{\alpha+\gamma}{a}-\frac{\beta+\gamma}{1-a}\) et par suite \(e^{-\int p d a}=\frac{C^{\prime}}{a^{\alpha+\gamma}(1-a)^{\beta+\gamma}}\), on a en vertu de l'équation (0)
\[
y_2 \frac{d y_1}{d a}-y_1 \frac{d y_2}{d a}=\frac{C^{\prime}}{a^{\alpha+\gamma}(1-a)^{\beta+\gamma}} .
\]

Fin faisant \(a=1\), on trouve \(C=0\), et par conséquent
\[
y_2 \frac{d y_1}{d a}-y_1 \frac{d y_2}{d a}=0
\]
c'est-à-dire \(y_1=C y_2, C\) étant une constante. Pour la trouver on fera \(a=1\); on aura
\[
\int_0^{\infty} \frac{x^{-\alpha} d x}{(1+x)^{\beta+\gamma}}=C \int_0^{\infty} \frac{x^{\beta-1} d x}{(1+x)^{\beta+\gamma}}
\]
\(\mathrm{Or}\)
\[
\begin{aligned}
\int_0^{\infty} \frac{x^{-u} d x}{(1+x)^{\beta+\gamma}}=\frac{\boldsymbol{\Gamma}(1-\alpha) \boldsymbol{\Gamma}(\alpha+\beta+\gamma-1)}{\boldsymbol{\Gamma}(\beta+\gamma)} \\
\int_0^{\infty} \frac{x^{\beta-1} d x}{(1+x)^{\beta+\gamma}}=\frac{\boldsymbol{\Gamma} \beta \cdot \boldsymbol{\Gamma} \gamma}{\boldsymbol{\Gamma}(\beta+\gamma)},
\end{aligned}
\]
done
\[
C=\frac{\boldsymbol{\Gamma}(1-\alpha) \boldsymbol{\Gamma}(\boldsymbol{\alpha}+\beta+\gamma-1)}{\boldsymbol{\Gamma} \beta \cdot \boldsymbol{\Gamma}_\gamma}
\]

Par conséquent l'équation \(y_1=C y_z\) donne
\[
\int_0^{\infty} \frac{x^{-\alpha} d x}{(1+x)^\beta(x+a)^\gamma}=\frac{\boldsymbol{\Gamma}(1-\alpha) \boldsymbol{\Gamma}(\boldsymbol{\alpha}+\beta+\gamma-1)}{\boldsymbol{\Gamma} \beta \cdot \boldsymbol{\Gamma} \gamma} \int_0^{\infty} \frac{x^{\beta-1} d x}{(1+x)^{1-\alpha}(x+a)^{\alpha+\beta+\gamma-1}} .
\]
- Si dans l'équation (6) on met \((1-a)\) à la place de \(a, \beta\) et \(\alpha\) à la place de \(\alpha\) et \(\beta\), elle ne change pas de forme.
Il s'ensuit que
\[
y_3=\int_0^{\infty} \frac{x^{-\beta} d x}{(1+x)^\alpha(x+1-a)^\gamma}
\]
est de même une intégrale particulière de la même équation. On a donc
\[
y_3 \frac{d y_1}{d u}-y_1 \frac{d y_3}{d a}=\frac{C^\gamma}{a^{\alpha+\gamma}(1-a)^\beta+\gamma} .
\]
%256
En mettant \(x a\) à la place de \(x\) dans l'expression de \(y_1\), on obtient
\[
y_1=a^{-\alpha-\gamma+1} \int_0^{\infty} \frac{x^{-u} d x}{(1+x)^\gamma(1+a x)^\beta} ; \frac{d y_1}{d a}=-\gamma a^{-\alpha-\gamma} \int_0^{\infty} \frac{x^{-\alpha} d x}{(1+x)^{\gamma+1}(1+u x)^\beta} \text {. }
\]

On trouve de même, en mettant \((1-a) x\) à la place de \(x\),
\[
\begin{aligned}
y_3 & =(1-a)^{-\beta-\gamma+1} \int_0^{\infty} \frac{x^{-\beta} d x}{(1+x)^\gamma[1+(1-a) x]^\alpha}, \\
\frac{d y_3}{d a} & =\gamma(1-a)^{-\beta-\gamma} \int_0^{\infty} \frac{x^{-\beta} d x}{(1+x)^{\gamma+1}[1+(1-a) x]^\alpha} .
\end{aligned}
\]

En substituant ces valeurs, multipliant par \(a^{\alpha+\gamma}(1-a)^{\beta+\gamma}\) et écrivant \(C\) aı lieu de \(-\frac{C^{\prime}}{\gamma}\), on trouve
\[
\left\{\begin{array}{l}
C=a \int_0^{\infty} \frac{x^{-\alpha} d x}{(1+x)^\gamma(1+a x)^\beta} \cdot \int_0^{\infty} \frac{x^{-\beta} d x}{(1+x)^{\gamma+1}[1+(1-a) x]^\alpha} \\
+(1-a) \int_0^{\infty} \frac{x^{-\beta} d x}{(1+x)^\gamma[1+(1-a) x]^\alpha} \cdot \int_0^{\infty} \frac{x^{-\alpha} d x}{(1+x)^{\gamma+1}(1+a x)^\beta} .
\end{array}\right.
\]

Pour trouver \(C\), soit \(a=0\), on aura
\[
C=\int_0^{\infty} \frac{x^{-\beta} d x}{(1+x)^{\gamma+\alpha}} \cdot \int_0^{\infty} \frac{x^{-\alpha} d x}{(1+x)^{\gamma+1}}=\frac{\Gamma(1-\alpha) \Gamma(1-\beta)}{\dot{\Gamma}(\gamma+1)} \boldsymbol{I}(\alpha+\beta+\gamma-1) .
\]

Si l'on fait p. ex. \(\beta=1-\alpha\), on aura en remarquant que
\[
\begin{gathered}
I^{\prime}(1-\alpha) I^{\prime} \alpha=\frac{\cdots}{\sin \alpha x}, I^{\prime}(\gamma+1)=\gamma \cdot \Gamma_\gamma: \\
\frac{\pi}{\gamma \cdot \sin \alpha \pi}=a \int_0^{\infty} \frac{x^{-\alpha} d x}{(1+x)^\gamma(1+a x)^{1-\alpha}} \cdot \int_0^{\infty} \frac{x^{\alpha-1} d x}{(1+x)^{\gamma+1}[1+(1-a) x]^\alpha} \\
+(1-a) \int_0^{\infty} \frac{x^{-\alpha} d x}{(1+x)^{\gamma+1}(1+a x)^{1-\alpha}} \cdot \int_0^{\infty} \frac{x^{\alpha-1} d x}{(1+x)^\gamma[1+(1-a) x]^\alpha}
\end{gathered}
\]

Lorsque \(\alpha=\gamma=\frac{1}{2}\) on a
\[
\begin{aligned}
2 \pi=a \int_0^{\infty} \frac{d x}{\sqrt{x(1+x)(1+a x)}} \cdot \int_0^{\infty} \frac{d x}{\sqrt{x(1+x)^3[1+(1-a) x]}} \\
+(1-a) \int_0^{\infty} \frac{d x}{\sqrt{x(1+x)[1+(1-a) x]}} \cdot \int_0^{\infty} \frac{d x}{\sqrt{x(1+x)^3(1+a x)}} .
\end{aligned}
\]
%257
Toutes ces intégrales peuvent s'exprimer par des fonctions elliptiques. En effet, soit \(x=(\operatorname{tang} \varphi)^2\), on aura après quelques transformations légères
\[
\begin{aligned}
\frac{\pi}{2}=a \int_0^{\frac{\pi}{2}} \frac{d \varphi}{\sqrt{1-(1-a) \sin ^2 \varphi}} \cdot \int_0^{\frac{\pi}{2}} \frac{d \varphi \cdot \cos ^2 \varphi}{\sqrt{1-a \cdot \sin ^2 \varphi}} \\
+(1-a) \int_0^{\frac{\pi}{2}} \frac{d \varphi}{\sqrt{1-a \sin ^2 \varphi}} \cdot \int_0^{\frac{\pi}{2}} \frac{d \varphi \cdot \cos ^2 \varphi}{\sqrt{1-(1-a) \sin ^2 \varphi}},
\end{aligned}
\]
c'est-à-dire, lorsqu'on fait \(a=c^2, b^2=1-c^2\),
\[
\frac{\pi}{2}=F^1(c) E^1(b)+F^1(b) E^1(c)-F^1(c) F^1(b),
\]
où, d'après la notation de M. Legendre,
\[
F^1(c)=\int_0^{\frac{\pi}{2}} \frac{d \varphi}{\sqrt{1-c^2 \sin ^2 \varphi}}, E^1(c)=\int_0^{\frac{\pi}{2}} d \varphi \cdot V 1-c^2 \sin ^2 \varphi .
\]

La formule ci-dessus se trouve dans les Exercices de Calcul intégral par M. Legendre, t. I, p. 61.

Dans la formule générale (7) les intégrales peuvent s'exprimer par d'autres dont les limites sont 0 et 1 . Soit à cet effet \(x=\frac{y}{1-y}\); on aura
\[
\text { (8) }\left\{\begin{array}{r}
\frac{\boldsymbol{\Gamma}(1-\alpha) \boldsymbol{\Gamma}(1-\beta) \boldsymbol{\Gamma}(\alpha+\beta+\gamma-1)}{\boldsymbol{\Gamma}(\gamma+1)}=a \int_0^1 \frac{d y(1-y)^{\alpha+\beta+\gamma-2}}{y^\alpha[1-(1-a) y]^\beta} \cdot \int_0^1 \frac{d y(1-y)^{\alpha+\beta+\gamma-1}}{y^\beta(1-a y)^\alpha} \\
+(1-a) \int_0^1 \frac{d y(1-y)^{\alpha+\beta+\gamma-1}}{y^\alpha[1-(1-a) y]^\beta} \cdot \int_0^1 \frac{d y(1-y)^{\alpha+\beta+\gamma-2}}{y^\beta(1-a y)^\alpha}
\end{array}\right.
\]

Nous avons vu plus haut que
\[
\int_0^1 \frac{d x}{x^{1-\alpha}(1-x)^{1-\beta}(x+a)^{\alpha+\beta}}=\frac{\Gamma \alpha \cdot I^{\prime} \beta}{\Gamma(\alpha+\beta)} \cdot \frac{1}{a^\beta(1+a)^\alpha} \cdot
\]

On pent trouver, comme il suit, une expression plus générale de laquelle celle-ci est un cas particulier. En différentiant l'intégrale
\[
y=\int_0^x \frac{d x \cdot x^{\alpha-1}(1-x)^{\beta-1}}{(x+a)^{\alpha+\beta}}
\]
par rapport à \(a\), on obtient
\[
\frac{d y}{d u}=-(\alpha+\beta) \int_0^x \frac{d x \cdot \cdot x^{u-1}(1-x)^{\beta-1}}{(x+a)^{\alpha+\beta+1}}
\]
%258
II s'ensuit que
\[
\frac{d y}{d a}+\left(\frac{\alpha}{1+a}+\frac{\beta}{a}\right) y=-\frac{x^\alpha(1-x)^\beta}{a(1+a)(x+a)^{\alpha+\beta}} .
\]

En multipliant cette éfuation par \(a^\beta(1+a)^\alpha\), le premier membre devient une différentielle complète, égale à \(d\left[y \cdot a^\beta(1+a)^{\prime \prime}\right]\), on aura donc en intégrant
\[
y \cdot a^\beta(1+a)^\alpha=C-x^\alpha(1-x)^\beta \int_0^a \frac{d a \cdot a^{\beta-1}(1+a)^{\alpha-1}}{(a+x)^{\alpha+\beta}} .
\]

Pour tronver \(C\), qui pent être une fonction de \(x\); nous ferons \(a=\infty\). On alla
\[
y \cdot a^\beta(1+a)^\alpha=\int_0^x d x \cdot x^{\alpha-1}(1-x)^{\beta-1}
\]
et par conséquent,
\[
C=\int_0^x d x \cdot x^{\alpha-1}(1-x)^{\beta-1}+x^\alpha(1-x)^\beta \int_0^{\infty} \frac{d a \cdot a^{\beta-1}(1+a)^{\alpha-1}}{(a+x)^{\alpha+\beta}} .
\]

Si l'on fait \(a=\frac{x-x y}{y-x}\), et par suite \(y=\frac{x+a x}{a+x}\), on trouvera
\[
\begin{aligned}
\int_0^{\infty} \frac{d a \cdot a^{\beta-1}(1+a)^{\alpha-1}}{(a+x)^{\alpha+\beta}}=-x^{-\alpha}(1-x)^{-\beta} \int_1^x d y \cdot y^{\alpha-1}(1-y)^{\beta-1} \\
=x^{-\alpha}(1-x)^{-\beta}\left(-\int_0^x d x \cdot x^{\alpha-1}(1-x)^{\beta-1}+\int_0^1 d x \cdot x^{\alpha-1}(1-x)^{\beta-1}\right) .
\end{aligned}
\]

En substituant cette valeur, on obtient
\[
C=\int_0^1 d x \cdot x^{\alpha-1}(1-x)^{\beta-1}=\frac{\Gamma \boldsymbol{\Gamma} \beta}{\Gamma(\alpha+\beta)}
\]
et par conséquent
\[
\frac{\boldsymbol{\Gamma} \alpha \cdot \boldsymbol{\Gamma} \beta}{\boldsymbol{\Gamma}(\alpha+\beta)}=a^\beta(1+a)^\alpha \int_0^x \frac{d x \cdot x^{\alpha-1}(1-x)^{\beta-1}}{(x+a)^{\alpha+\beta}}+x^\alpha(1-x)^\beta \int_0^a \frac{d a \cdot a^{\beta-1}(1+a)^{\alpha-1}}{(x+a)^{\alpha+\beta}} .
\]

Si p. ex. \(\alpha+\beta=1\), on aura
\[
\frac{x}{\sin \alpha x}=\frac{(1+a)^\alpha}{a^{\alpha-1}} \int_0^x \frac{d x \cdot x^{\alpha-1}(1-x)^{-\alpha}}{x+a}+\frac{x^\alpha}{(1-x)^{\alpha-1}} \int_0^a \frac{d a \cdot a^{-\alpha}(1+a)^{\alpha-1}}{x+a} .
\]

Si de plus \(\alpha=\frac{1}{2}\), on obtient
\[
\pi=\sqrt{a+a^2} \int_0^x \frac{d x}{(x+a) \sqrt{x-x^2}}+\sqrt{x-x^2} \int_0^a \frac{d a}{(a+x) \sqrt{a+a^2}},
\]
%259
ce qui est juste, car
\[
\begin{aligned}
\int_0^x \frac{d x}{(x+a) \sqrt{x-x^2}} & =\frac{2}{\sqrt{a+a^2}} \text { arc. tang } \sqrt{\frac{x+x a}{a-a x}} \\
\int_0^a \frac{d a}{(a+x) \sqrt{a+a^2}} & =\frac{2}{\sqrt{x-x^2}} \text { arc. tang } \sqrt{\frac{a-a x}{x+a a}}
\end{aligned}
\]
et arc. \(\operatorname{tang} z+\operatorname{arc} \operatorname{tang} \frac{1}{z}=\frac{\pi}{2}\).
III. Soit \(y=\int_0^1 e^{-\alpha x} x^{\alpha-1}(1-x)^{\beta-1} d x\), où \(\alpha>0, \beta>0\).
En différentiant par rapport à \(a\) on obtient
\[
\begin{aligned}
& \frac{d y}{d a}=-\int_0^1 e^{-a x} x^\alpha(1-x)^{\beta-1} d x \\
& \frac{d^2 y}{d a^2}=\int_0^1 e^{-a x} x^{\alpha+1}(1-x)^{\beta-1} d x .
\end{aligned}
\]

Lorsqu'on différentie la fonction \(r=e^{-a x} x^\alpha(1-x)^\beta\) par rapport à \(x\) on obtient
\[
\begin{array}{r}
d r=\alpha e^{-a x} x^{\alpha-1}(1-x)^{\beta-1} d x-(\alpha+\beta+a) e^{-a x} x^\alpha(1-x)^{\beta-1} d x \\
+a e^{-a x} x^{\alpha+1}(1-x)^{\beta-1} d x
\end{array}
\]
done en intégrant depuis \(x=0\) jusqu'à \(x=1\), et substituant pour les intégrales leurs valeurs en \(y, \frac{d y}{d a}\) et \(\frac{d^2 y}{d a^2}\) :
\[
\frac{d^2 y}{d a^2}+\left(\frac{\alpha+\beta}{a}+1\right) \frac{d y}{d a}+\frac{\alpha}{a} y=0
\]

Ou satisfait aussi à cette équation en faisant
\[
y=y_1=\int_1^{\infty} e^{-\alpha x} x^{\alpha-1}(x-1)^{\beta-1} d x
\]
\(a\) étant positif. Or on a \(p=\frac{\alpha+\beta}{a}+1\), donc \(e^{-\int p d a}=\frac{C}{e^a a^{\alpha+\beta}}\). Donc l'équation (0) donne
\[
y_1 \frac{d y}{d a}-y \frac{d y_1}{d a}=\frac{C}{e^a u^{\alpha+\beta}}
\]
%260
Si dans l'expression de \(y_1\) on met \(x+1\) à la place de \(x\), on trouve
\[
\begin{aligned}
& y_1=e^{-a} \int_0^{\infty} e^{-a x} x^{\beta-1}(1+x)^{\alpha-1} d x, \\
& \frac{d y_1}{d u}=-e^{-a} \int_0^{\infty} e^{-\alpha x} x^{\beta-1}(1+x)^\alpha d x,
\end{aligned}
\]
on bien, en mettant \(\frac{x}{a}\) ì la place de \(x\),
\[
\begin{aligned}
& y_1=e^{-a} a^{-\alpha-\beta+1} \int_0^{\infty} e^{-x} x^{\beta-1}(a+x)^{\alpha-1} d x, \\
& \frac{d y_1}{d u}=-e^{-\alpha} a^{-\alpha-\beta} \int_0^{\infty} e^{-x} x^{\beta-1}(a+x)^\alpha d x .
\end{aligned}
\]

En substituant ces valeurs de \(y_1, \frac{d y_1}{d a}\) de même que celles de \(y, \frac{d y}{d u}\), en multipliant par \(e^a a^{a+\beta}\), et faisant \(a=0\), on trouvera
c'est-ì-dire
\[
C=\int_0^{\infty} e^{-x} d x \cdot x^{\beta+\alpha-1} \cdot \int_0^1 d x \cdot x^{\alpha-1}(1-x)^{\beta-1},
\]
\[
C=I^{\prime}(\alpha+\beta) \frac{I^{\prime} \alpha \cdot \Gamma \beta}{I^{\prime}(\alpha+\beta)}=I^{\prime} \alpha \cdot I^{\prime} \beta .
\]

On aura done
\[
\begin{aligned}
I^{\prime} \alpha \cdot I^{\prime} \beta=\int_0^1 e^{-a x} d x \cdot x^{\alpha-1}(1-x)^{\beta-1} \cdot \int_0^{\infty} e^{-x} d x \cdot x^{\beta-1}(a+x)^\alpha \\
\quad-a \int_0^1 e^{-a x} d x \cdot x^\alpha(1-x)^{\beta-1} \cdot \int_0^{\infty} e^{-x} d x \cdot x^{\beta-1}(a+x)^{\alpha-1}
\end{aligned}
\]

Lorsque \(\beta=1-\alpha\), on a
\[
\begin{aligned}
\frac{\pi}{\sin \alpha x}=\int_0^1 \frac{d x}{x} e^{-a x}\left(\frac{x}{1-x}\right)^\alpha \cdot \int_0^{\infty} e^{-x} d x\left(1+\frac{a}{x}\right)^\alpha & \\
& -a \int_0^1 d x \cdot e^{-\alpha x}\left(\frac{x}{1-x}\right)^\alpha \cdot \int_0^{\infty} \frac{d x}{x+a} e^{-x}\left(1+\frac{a}{x}\right)^\alpha .
\end{aligned}
\]
IV. Soit
\[
y=\int_0^{\infty} e^{a x-x^2} x^{\alpha-1} d x, \text { où } \alpha>0 .
\]

En différentiant on aura
%261
\[
\frac{d y}{d a}=\int_0^{\infty} e^{a x-x^2} x^\alpha d x, \frac{d^2 y}{d a^2}=\int_0^{\infty} e^{a x-x^2} x^{\alpha+1} d x .
\]
\(\mathrm{Or}_1\)
\[
d\left(e^{a x-x^2} x^\alpha\right)=d x \cdot e^{a x-x^2} x^{\alpha-1}\left(\alpha+a x-2 \cdot x^2\right),
\]
done en intégrant depuis \(x=0\), jusqu'à \(x=\infty\), en substituant les valeurs des intégrales en \(y, \frac{d y}{d u}\) et \(\frac{d^2 y}{d a^2}\), et divisant par -2 , on aura
\[
\frac{d^2 y}{d a^2}-\frac{1}{2} a \frac{d y}{d a}-\frac{1}{2} a y=0 . '
\]

Cette équation conserve la même forme lorsqu'on remplace a par — a, donc
\[
y=y_1=\int_0^{\infty} e^{-c i x-x^2} x^{u-1} d x
\]
est de même une intégrale particulière de cette équation. Puisque \(p\) est égal à \(-\frac{1}{2} a\), on a \(e^{-\int p d a}=C e^{\frac{a^2}{4}}\), et par conséquent,
\[
y_1 \frac{d y}{d a}-y \frac{d y_1}{d a}=C e^{\frac{a^2}{4}}
\]

Si, pour trouver la quantité constante \(C\), on fait \(a=0\), on trouvera
\[
\begin{gathered}
y=\int_0^{\infty} e^{-x^x} x^{\alpha-1} d x=\frac{1}{2} \Gamma\left(\frac{\alpha}{2}\right), \\
\frac{d y}{d u}=\int_0^{\infty} e^{-x^2} x^{\prime \prime} d x=\frac{1}{2} \Gamma\left(\frac{\alpha+1}{2}\right), \\
y_1=\int_0^{\infty} e^{-x^2} x^{\alpha-1} d x=\frac{1}{2} \Gamma\left(\frac{\alpha}{2}\right), \\
\frac{d y_1}{d u}=-\int_0^{\infty} e^{-x^2} x^{\alpha u} d x=-\frac{1}{2} \Gamma\left(\frac{\alpha+1}{2}\right),
\end{gathered}
\]
donc en substituant:
\[
C=\frac{1}{2} \Gamma^{\prime}\left(\frac{\alpha+1}{2}\right) \Gamma\left(\frac{\alpha}{2}\right)
\]
et par suite
\[
\begin{aligned}
\frac{1}{2} r\left(\frac{\alpha+1}{2}\right) \Gamma\left(\frac{\alpha}{2}\right) e^{\frac{a^2}{4}}=\int_0^{\infty} e^{a x-x^2} d x \cdot x^{\alpha-1} \cdot \int_0^{\infty} e^{-a x-x^2} d x \cdot x^\alpha \\
+\int_0^{\infty} e^{n x-x^2} d x \cdot x^\alpha \cdot \int_0^{\infty} e^{-a x-x^2} d x \cdot x^{\alpha-1} .
\end{aligned}
\]
%262
Si l'on met \(a \sqrt{-1}\) à la place de \(a\), on obtient la formule suivante:
\[
\begin{aligned}
\frac{1}{4} \boldsymbol{\Gamma}\left(\frac{\alpha+1}{2}\right) \boldsymbol{r}\left(\frac{\alpha}{2}\right) e^{-\frac{a^2}{4}} & =\int_0^{\infty} d x \cdot e^{-x^2} \cos a x \cdot x^{\alpha-1} \cdot \int_0^{\infty} d x \cdot e^{-x^2} \cos a x \cdot x^\alpha \\
& +\int_0^{\infty} d x \cdot e^{-x^2} \sin a x x^{\alpha-1} \cdot \int_0^{\infty} d x \cdot e^{-x^2} \sin a x \cdot x^\alpha .
\end{aligned}
\]

Note. Les quantités constantes (exposants), qui se trouvent dans les intégrales de ce mémoire, doivent avoir des valeurs telles que les intégrales ne deviennent pas infinies. Ces valeurs sont faciles à trouver.
%263
XVI.

RECHERCHES SUR LES FONCTIONS ELLIPTIQUES.

Journal für dic reine und angewandte Mathematik, herausgegeben von Crclle, Bd. 2, 3. Berlin 1827, 1828.

Depuis longtemps les fonctions logarithmiques, et les fonctions exponentielles et circulaires, ont été les seules fonctions transcendantes, qui ont attiré l'attention des géomètres. Ce n'est que dans ces derniers temps, qu'on a commencé à en considérer quelques autres. Parmi celles-ci il faut distinguer les fonctions nommées elliptiques, tant pour leur belles propriétés analytiques, que pour leur application dans les diverses branches des mathématiques. La première idée de ces fonctions à été donnée par l'immortel Euler, en démontrant, que l'équation séparée
\[
\frac{d x}{\sqrt{\alpha+\beta x+\gamma x^2+\delta x^3+\varepsilon x^4}}+\frac{d y}{\sqrt{\alpha+\beta y+\gamma y^2+\delta y^3+\varepsilon y^4}}=0
\]
est intégrable algébriquement. Après Euler, Lagrange y a ajouté quelque chose, en donnant son élégante théorie de la transformation de l'intégrale \(\int \frac{R \cdot d x}{\sqrt{\cdot\left(1-p^2 x^2\right)\left(1-q^2 x^2\right)}}\), où \(R\) est une fonction rationnelle de \(x\). Mais le premier et, si je ne me trompe, le seul, qui ait approfondi la nature de ces fonctions, est M. Legendre, qui, d'abord dans un mémoire sur les fonctions 'elliptiques, et ensuite dans ses excellents Exercices de mathématiques, a développé nombre de propriétés élégantes de ces fonctions, et en a montré l'application. Depuis la publication de cet ouvrage, rien n'a été ajouté à la
%264
théorie de M. Legendie. Je crois qu'on ne verra pas ici sans plaisir rles recherches ultérieures sur ces fonctions.

En général on comprend sous la dénomination de fonctions elliptiques, toute fonction comprise dans l'intégrale
\[
\int \frac{R d x}{\sqrt{\alpha+\beta x+\gamma x^2+\delta x^3+\varepsilon x^4}}
\]
où \(l\) est une fonction rationnelle et \(\alpha, \beta, \gamma, \delta, \varepsilon\) sont des quantités constantes et réelles. M. Legendre a démontré que par des substitutions convenables on peut toujours ramener cette intégrale à la forme
\[
\int \frac{P d y}{\sqrt{a+b y^2+c y^4}},
\]
où \(P\) est une fonction rationnelle de \(y^2\). Par des réductions convenables, cette intégrale peut être ensuite ramenée à la forme
et celle-ci à
\[
\int \frac{A+B y^2}{C+D y^2} \frac{d y}{\sqrt{a+b y^2+c y^4}},
\]
\[
\int \frac{A+B \sin ^2 \theta}{C+I) \sin ^2 \theta} \frac{d \theta}{\sqrt{1-c^2 \sin ^2 \theta}},
\]
où \(c\) est réel et moindre que l'unité.
Il suit de là, que toute fonction elliptique peut être réduite à l'une des trois formes:
auxquelles M. Legendre donne les noms de fonctions elliptiques de la première, seconde et troisième espèce. Ce sont ces trois fonctions que M. Legendre a considérées, surtout la première, qui a les propriétés les plus remarquables et les plus simples.

Je me propose, dans ce mémoire, de considérer la fonction inverse, c'est-à-dire la fonction \(\varphi \alpha\), déterminée par les équations
\[
\begin{gathered}
\alpha=\int \frac{d \theta}{\sqrt{1-c^2 \sin ^2 \theta}}, \\
\sin \theta=\varphi \alpha=x .
\end{gathered}
\]

La dernière équation domne
\[
d \theta \sqrt{1-\sin ^2 \theta}=d(\varphi x)=d x,
\]
%265
done
\[
\alpha=\int_0 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}} .
\]
M. Legendie suppose \(c^2\) positif, mais j’ai remarqué que les formules deviennent plus simples, en supposant \(c^2\) négatif, égal à \(-e^2\). De même j'écris pour plus de symétrie \(1-c^2 x^2\) au lieu de \(1-x^2\), en sorte que la fonction \(\varphi \alpha=x\) sera domnée par l'équation
\[
\alpha=\int_0 \frac{d x}{\sqrt{\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)}},
\]
ou bien
\[
\varphi^{\prime} \alpha=\sqrt{\left(1-c^2 \varphi^2 \alpha\right)\left(1+e^2 \varphi^2 \alpha\right)} .
\]

Pour abréger, j'introduis deux autres fonctions de \(\alpha\), savoir
\[
f \alpha=\sqrt{1-c^2 \varphi^2 \alpha} ; \quad F \alpha=\sqrt{1+e^2 \varphi^2 \alpha} .
\]

Plusieurs propriétés de ces fonctions se déduisent immédiatement des propriétés comnues de la fonction elliptique de la première espèce, mais d'autres sont plus cachées. Par exemple on démontre que les équations \(\varphi \alpha=0\), \(f \alpha=0, F^{\prime} \alpha=0\) ont un nombre infini de racines, qu'on peut trouver toutes. Une des propriétés les plus remarquables est qu'on peut exprimer rationnellement \(\varphi(m \alpha), f(m \alpha), F(m \alpha)\) ( \(m\) étant un nombre entier) en \(\varphi \alpha, f \alpha, F \alpha\). Aussi rien n'est plus facile que de trouver \(\varphi(m \alpha), f(m \alpha), F(m \alpha)\), lorsqu'on connaît \(\varphi \alpha, f \alpha, F \alpha\); mais le problème inverse, savoir de déterminer \(\varphi \alpha\), \(f \alpha, F a\) en \(\varphi(m \alpha), f(m \alpha), F(m \alpha)\), est plus difficile, parcequ'il dépend d'une équation d'un degré élevé (savoir du degré \(m^2\) ).

La résolution de cette équation est l'objet principal de ce mémoire. D'abord on fera voir, comment on peut trouver toutes les racines, au moyen des fonctions \(\varphi, f, F\). On traitera ensuite de la résolution algébrique de l'équation en question, et on parviendra à ce résultat remarquable, que \(\varphi \frac{\alpha}{m}, f \frac{\alpha}{m}, F \frac{\alpha}{m}\) peuvent être exprimés en \(\varphi \alpha, f \alpha, F \alpha\), par une formule qui, par rapport à \(\alpha\), ne contient d'antres irratiomnalités que des radicaux. Cela donne une classe très générale d'équations qui sont résolubles algébriquement. Il est à remarquer que les expressions des racines contiennent des quantités constantes qui, en général, ne sont pas exprimables par des quantités algébriques. Ces quautités constantes dépendent d'une équation du degré \(m^2-1\). On fera voir comment, au moyen de fonctions algéloriques,
%266
on peut en ramener la résolution à celle d'une équation du degré \(m+1\). (O) donnera plusieurs expressions des fonctions \(\varphi(2 n+1) \alpha, f(2 n+1) \alpha\), \(F(2 n+1) \alpha\) en fonction de \(\varphi \alpha, f \alpha, F \alpha\). On en déduira ensuite les valeurs de \(\varphi \alpha, f \alpha, F_\alpha\) en fonction de \(\alpha\). On démontrera, que ces fonctions peuvent être décomposées en un nombre infini de facteurs, et même en une infinité de fiactions partielles.
\(\S \mathrm{I}\).
Propricites fondamentules des fonctions of \(\alpha, \mathrm{fa}, \mathrm{F} \alpha\).
1.
En supposant que
\[
\varphi \alpha=x,
\]
on aura en vertu de cee qui précède
\[
u=\int_0^{\infty} \frac{d x}{\sqrt{ }\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)} .
\]
l'ar là on voit que \(\alpha\), considéré comme fonction de \(x\), est positif depuis \(x=0\) juscu'à \(x=\frac{1}{e}\). En faisant done
\[
\frac{(1)}{2}=\int_0^1 \frac{d x}{\sqrt{\prime}\left(1-e^2 x^2\right)\left(1+e^2 \cdot x^2\right)},
\]
il est évident que q \(\alpha\) est positif et va en augmentant depuis \(\alpha=0\) jusqu'à \(\alpha=\frac{\omega}{2}\), et qu'on aura
\[
\varphi(0)=0, \varphi\left(\frac{(1)}{2}\right)=\frac{1}{c} .
\]

Comme \(a\) change de signe, lorsqu'on écrit \(-x\) à la place de \(x\), il en est de même de la fonction qu par rapport à \(\alpha\), et par conséquent on aura l'équation
\[
\varphi(-\alpha)=-\varphi \mu
\]

En mettant dans (1) \(x i\) an lieu de \(x\) (où \(i\), pour abréger, représente la (quantité imaginaire \(V-1\) ) et désignant la valeur de \(\alpha\) par \(\beta i\), il viendra
\[
x i=p(\beta i) \text { et } \beta=\int_0^x \frac{d x}{\sqrt{\left(1+c^2 x^2\right)\left(1-e^2 x^2\right)}} \text {. }
\]
%267
\(\beta\) est réel et positif depuis \(x=0\) jusqu'à \(x=\frac{1}{p}\), done en faisant
\[
\frac{\tilde{\omega}}{2}=\int_0^{\frac{1}{e}} \frac{d x}{\sqrt{\left(1-e^2 x^2\right)\left(1+c^2 x^2\right)}},
\]
\(x\) sera positif, depuis \(\beta=0\) jusqu'à \(\beta=\frac{\tilde{\omega}}{2}\), c'est-à-dire que la fonction \(\frac{1}{i} \varphi(\beta i)\). sera positive entre les mêmes limites. En faisant \(\beta=\alpha\) et \(y=\frac{q(\alpha i)}{i}\), on a
\[
\alpha=\int_0^y \frac{d y}{\sqrt{\left(1-e^2 y^2\right)\left(1+e^2 y^2\right)}},
\]
donc on voit, qu'en supposant \(c\) au lien de \(e\) et \(e\) an lien de \(c\),
\[
\frac{\tau(\alpha i)}{i} \text { se changera en } \varphi \alpha \text {. }
\]

Et comme
\[
\begin{aligned}
& f \alpha=\sqrt{1-e^2 \varphi^2 \alpha,} \\
& F \alpha=\sqrt{1+e^2 \varphi^2 \omega,}
\end{aligned}
\]
on voit que par le changement de \(c\) en \(e\) et \(e\), en \(c, f(\alpha i)\) et \(F(\alpha i)\) se changeront respectivement en \(F \boldsymbol{\alpha}\) et \(f \alpha\). Enfin les équations (3) et (7) font voir que par la même transformation \((\omega)\) et \(\widetilde{\omega}\) se changeront respectivement en \(\widetilde{\omega}\) et \((1)\).

D'après la formule \((7)\) on aura \(x=\frac{1}{\rho}\) pour \(\beta=\frac{\tilde{a}}{2}\), donc en vertu de l'équation \(x i=\varphi(\beta i)\), il viendra
\[
\varphi\left(\frac{\tilde{\omega} i}{2}\right)=i \cdot \frac{1}{e} \text {. }
\]
2.

En vertu de ce qui précède, on aura les valeurs de \(\varphi \boldsymbol{\alpha}\) pour toute valeur réelle de \(\alpha\), comprise entre \(-\frac{\omega}{2}\) et \(+\frac{\omega}{2}\), et pour toute valeur imaginaire de la forme \(\beta i\) de cette quantité, si \(\beta\) est une quantité contenue entre les limites \(-\frac{\tilde{v}}{2}\) et \(+\frac{\tilde{a}}{2}\). Il s'agit maintenant de trouver la valeur de cette fonction pour une valeur queleonque, réelle ou imaginaire, de la
%268
variable. Pour y parvenir, nous allons d'abord établir les propriétés fondamentales des fonctions \(\varphi, f\) et \(F\).
Ayant
\[
\begin{aligned}
& f^2 \alpha=1-c^2 \varphi^2 \alpha \\
& F^2 \alpha=1+e^2 \varphi^2 \alpha
\end{aligned}
\]
on aura, en différentiant
\[
\begin{aligned}
& f \alpha \cdot f^{\prime} \alpha=-c^2 \varphi \alpha \cdot \varphi^{\prime} \alpha \\
& F \alpha \cdot F^{\prime} \alpha=e^2 \varphi \alpha \cdot \varphi^{\prime} \alpha .
\end{aligned}
\]

Or d'après (2) on a
\[
\varphi^{\prime} \alpha=\sqrt{\left(1-r^2 \varphi^2 \alpha\right)\left(1+e^2 \varphi^2 \alpha\right)}=f \alpha \cdot F \alpha,
\]
donc, en substituant cette valeur de \(\varphi^{\prime} \alpha\) dans les deux équations précédentes, on trouvera que les fonctions \(\varphi \alpha, f \alpha, F^{\prime} \iota\) sont liées entre elles par les équations
\[
\left\{\begin{array}{l}
\varphi^{\prime} \alpha=f \alpha \cdot F \alpha, \\
f^{\prime} \alpha=-c^2 \varphi \alpha \cdot F \alpha, \\
F^{\prime} \alpha=e^2 \varphi \alpha \cdot f \alpha .
\end{array}\right.
\]

Cela posé, je dis qu'en désignant par \(\alpha\) et \(\beta\) deux indéterminées, on aura
\[
\left\{\begin{array}{l}
\varphi(\alpha+\beta)=\frac{\varphi \alpha \cdot f \beta \cdot F \beta+\varphi \beta \cdot f \alpha \cdot F \alpha}{1+e^2 c^2 \varphi^2 \alpha \cdot \varphi^2 \beta}, \\
f(\alpha+\beta)=\frac{f \alpha \cdot f \beta-c^2 \uparrow \alpha \cdot \varphi \beta \cdot F \alpha \cdot F \beta}{1+e^2 c^2 \varphi^2 \alpha \cdot \varphi^2 \beta}, \\
F(\alpha+\beta)=\frac{F \alpha \cdot F \beta+e^2 \varphi \alpha \cdot \varphi \beta \cdot f \alpha \cdot f \beta}{1+e^2 c^2 \varphi^2 \alpha \cdot \varphi^2 \beta} .
\end{array}\right.
\]

Ces formules peuvent être déduites sur le champ des propriétés connues des fonctions elliptiques (Legendre Exercices de Calcul intégral); mais on pent aussi les vérifier aisément de la manière suivante.

En désignant par \(r\) le second membre de la première des équations (10), on aura, en différentiant par rapport ì \(\alpha\),
\[
\begin{aligned}
& \frac{d r}{d c}=\frac{\varphi^{\prime} \alpha \cdot f \beta \cdot F \beta+\varphi \beta \cdot F \alpha \cdot f^{\prime} \alpha+\varphi \beta \cdot f \alpha \cdot F^{\prime} \alpha}{1+e^2 c^2 \varphi^2 \alpha \cdot \varphi^2 \beta} \\
& -\frac{(\tau \alpha \cdot f \beta \cdot F \beta+\varphi \beta \cdot f \alpha \cdot F \alpha) 2 e^2 c^2 \varphi \alpha \cdot \tau^2 \beta \cdot \tau^{\prime} \alpha}{\left(1+e^2 c^2 \varphi^2 \alpha \cdot \varphi^2 \beta\right)^2} . \\
&
\end{aligned}
\]

En substituant pour \(\varphi^{\prime} \alpha, f^{\prime} \alpha, F^{\prime} \alpha\) leurs valeurs données par les équations \((9)\), il viendra
%269
\[
\begin{aligned}
\frac{d v}{d \alpha} & =\frac{f \alpha \cdot F \alpha \cdot f \beta \cdot F \beta}{1+e^2 c^2 q^2 \alpha \cdot q^2 \beta}-\frac{2 e^2 c^2 q^2 \alpha \cdot q^2 \beta \cdot f \alpha \cdot f \beta \cdot F \alpha \cdot F \beta}{\left(1+e^2 c^2 q^z \alpha \cdot q^2 \beta\right)^2} \\
& +\frac{{ }^2 \alpha \cdot q \beta \cdot\left(1+e^2 c^2 q^2 \alpha \cdot q^2 \beta\right)\left(-c^2 F^2 \alpha+e^2 f^2 \alpha\right)-2 e^2 c^2 q \alpha \cdot \uparrow \beta \cdot q^2 \beta \cdot f^2 \alpha \cdot F^2 \alpha}{\left(1+e^2 c^2 q^2 \alpha \cdot q^2 \beta\right)^2}
\end{aligned}
\]
d'où, en substituant pour \(f^2 \alpha\) et \(F^2 \alpha\) leurs valeurs \(1-c^2 \varphi^2 \alpha, 1+e^2 \varphi^2 \alpha\), et en réduisant, on tire
\[
\frac{d r}{d \alpha}=\frac{\left(1-e^2 c^2 \uparrow^2 \alpha \cdot \uparrow^2 \beta\right)\left[\left(e^2-c^2\right) \varphi \alpha \cdot \varphi \beta+f \alpha \cdot f \beta \cdot F \alpha \cdot F \beta\right]-2 e^2 c^2 \uparrow \alpha \cdot \uparrow \beta\left(\uparrow^2 \alpha+\tau^2 \beta\right)}{\left(1+e^2 c^2 \varphi^2 \alpha \cdot \uparrow^2 \beta^2\right)^2} .
\]

Maintenant \(\alpha\) et \(\beta\) entrent symétriquement dans l'expression de \(r\); done on aura la valeur de \(\frac{d r}{d \beta}\), en permutant \(\alpha\) et \(\beta\) dans la valeur de \(\frac{d r}{d u} \cdot \quad O_0\). par la l'expression de \(\frac{d r}{d \alpha}\) ne change pas de valeur, done on aura
\[
\frac{d r}{d \alpha}=\frac{d r}{d \beta} .
\]

Cette équation aux différentielles partielles fait voir que \(r\) est fonction de \(\alpha+\beta\); done on aura
\[
r=\psi(\alpha+\beta)
\]

La forme de la fonction \(\psi\) se trouver en domnant à \(\beta\) une valeur particulière. En supposant par exemple \(\beta=0\), et en remarquant que \(\varphi(0)=0\), \(f(0)=1, F(0)=1\), les deux valeurs de \(r\) deviendront
done
\[
r=\varphi \alpha \text { et } r=\psi, \alpha
\]
d'où
\[
\psi \alpha=\varphi \alpha
\]
\[
r=\psi(\alpha+\beta)=\varphi(\alpha+\beta) .
\]

La première des formules (10) a donc effectivement lien.
On vérifiera de la même manière les deux autres formules.
3.
Des formules (10) on peut déduire une foule d'autres. Je vais rapporter quelques-unes des plus remarquables. Pour abréger je fais
\[
1+e^2 c^2 \varphi^2 \alpha \cdot \varphi^2 \beta=R \text {. }
\]

En changeant d'abord le signe de \(\beta\), on obtiendra
%270
\[
\left\{\begin{array}{l}
\varphi(\alpha+\beta)+\varphi(\alpha-\beta)=\frac{2 \varphi \alpha \cdot f \beta \cdot F \beta}{R}, \\
\varphi(\alpha+\beta)-\varphi(\alpha-\beta)=\frac{2 \varphi \beta \cdot f \alpha \cdot F \alpha}{R}, \\
f(\alpha+\beta)+f(\alpha-\beta)=\frac{2 f \alpha \cdot f \beta}{R}, \\
f(\alpha+\beta)-f(\alpha-\beta)=\frac{-2 c^2 \cdot q \alpha \cdot \uparrow \beta \cdot F \alpha \cdot F^{\prime} \beta}{R}, \\
F(\alpha+\beta)+F(\alpha-\beta)=\frac{2 F \alpha \cdot F \beta}{R}, \\
F(\alpha+\beta)-F(\alpha-\beta)=\frac{2 \rho^2 \cdot r \alpha \cdot \tau \beta \cdot f \alpha \cdot f \beta}{R} .
\end{array}\right.
\]

En formant le produit de \(\varphi(\alpha+\beta)\) et \(\varphi(\alpha-\beta)\), on tronvera
\[
\begin{aligned}
& \psi(\alpha+\beta) \cdot \psi(\alpha-\beta)=\frac{\tau \alpha \cdot f \beta \cdot F \beta+\varphi \beta \cdot f \alpha \cdot F \alpha \cdot \tau \alpha \cdot f \beta \cdot F \beta-\tau \beta \cdot f \cdot \alpha \cdot F \alpha}{R} \\
& ={ }^2 \alpha \cdot f^2 \beta \cdot F^2 \beta-q^2 \beta \cdot f^2 \alpha_0 \cdot F^2 \alpha, \\
&
\end{aligned}
\]
(ui, en substituant les valeurs de \(f^2 \beta, F^2 \beta, f^2 \alpha, F^2 \alpha\) en \(\varphi \beta\) et \(\varphi \alpha\),
\[
\begin{aligned}
& =\frac{\left(\tau^2 \alpha-\tau^2 \beta\right)\left(1+e^2 e^2 \boldsymbol{\gamma}^2 \alpha \cdot q^2 \beta\right)}{R^2} \\
&
\end{aligned}
\]
or \(R=1+e^2 c^2 \psi^2 \alpha \cdot \varphi^2 \beta\), done
\[
\varphi(\alpha+\beta) \cdot \varphi(\alpha-\beta)=\frac{\tau^2 \alpha-\tau^2 \beta}{k} .
\]

On trouvera de même
%271
4.

En faisant dans les formules \((10) \beta= \pm \frac{(1)}{2}, \beta= \pm \frac{\hat{0}}{2} i\), et en remarquant que \(f\left( \pm \frac{\omega}{2}\right)=0, F\left( \pm \frac{\tilde{\omega}}{2} i\right)=0\), on aura
\[
\begin{aligned}
& \left(\varphi\left(\alpha \pm \frac{(1)}{2}\right)= \pm \varphi \frac{(1)}{2} \cdot \frac{i \alpha}{F_\alpha^{\prime}} ; f\left(\alpha \pm \frac{(1)}{2}\right)=\mp \frac{F^{\prime \prime \prime)}}{\tau^{\prime \prime \prime}} \cdot \frac{\rho^{\prime \prime}}{F^{\prime} \alpha}\right. \\
& F^{\prime}\left(\alpha \pm \frac{(1)}{2}\right)=\frac{F^{\prime(1)}}{2} \\
& \varphi\left(\alpha \pm \frac{\tilde{\omega}}{2} i\right)= \pm \varphi\left(\frac{\tilde{\omega}}{2} i\right) \cdot \frac{F \alpha}{f \alpha} ; F\left(\alpha \pm \frac{\tilde{\omega}}{2} i\right)=\mp \frac{f\left(\frac{\tilde{\omega}}{2} i\right)}{\varphi\left(\frac{\tilde{\omega}}{2} i\right)} \cdot \frac{\varphi^2 \alpha}{f \alpha} \text {; } \\
& f\left(\alpha \pm \frac{i}{2} i\right)=\frac{f\left(\frac{i i}{2} i\right)}{f \alpha} \\
&
\end{aligned}
\]
on bien:

De là on tire sur le champ
\[
\begin{aligned}
& \varphi\left(\frac{(1)}{2}+\alpha\right)=\varphi\left(\frac{(1)}{2}-\alpha\right) ; f\left(\frac{(1)}{2}+\alpha\right)=-f\left(\frac{(1)}{2}-\alpha\right) ; \\
& F\left(\frac{\omega}{2}+\alpha\right)=F\left(\frac{11}{2}-\alpha\right) \text {; } \\
& \varphi\left(\frac{\hat{\omega}}{2} i+\alpha\right)=\varphi\left(\frac{\hat{\omega}}{2} i-\alpha\right) ; F\left(\frac{\hat{0}}{2} i+\alpha\right)=-F\left(\frac{\hat{\omega}}{2} i-\alpha\right) ; \\
& f\left(\frac{\hat{\theta}}{2} i+\alpha\right)=f\left(\frac{\hat{\omega}}{2} i-\mu\right) \text {. } \\
&
\end{aligned}
\]
%272
\[
\left\{\begin{array}{c}
\varphi\left(\alpha \pm \frac{(0)}{2}\right) \Psi\left(\alpha+\frac{\hat{\omega}}{2} i\right)= \pm \frac{i}{c e} ; F\left(\alpha \pm \frac{\omega}{2}\right) F \alpha=\frac{\sqrt{e^2+c^2}}{c} \\
f\left(\alpha \pm \frac{\hat{\omega}}{2} i\right) f \alpha=\frac{\sqrt{e^2+c^2}}{e}
\end{array}\right.
\]

En faisant \(\alpha=\frac{(\prime)}{2}\) et \(\frac{\hat{\omega}}{2} i\), on en déduit
\[
\psi\left(\begin{array}{l}
(\prime) \\
2
\end{array}+\frac{(i)}{2} i\right)=\frac{1}{0}, f\left(\begin{array}{l}
(\prime) \\
2
\end{array}+\frac{\hat{v}}{2} i\right)=\frac{1}{0}, F\left(\begin{array}{l}
(\prime \prime) \\
2
\end{array}+\frac{\hat{\omega}}{2} i\right)=\frac{1}{0} .
\]

En mettant ensuite dans les trois premières équations \((17) \alpha+\frac{(1)}{2}\) an lieu de \(\alpha\), et dans les trois dernières \(a+\frac{\hat{\omega}}{2} i\) au lieu de \(\alpha\), on obtiendra les suivantes
(19) \(\left\{\begin{array}{l}\varphi(\alpha+\omega)=-\varphi \alpha ; f(\alpha+\omega)=-f \alpha ; F(\alpha+\omega)=F \alpha ; \\ \varphi(\alpha+\bar{\omega} i)=-\varphi \alpha ; f(\alpha+\widetilde{\omega} i)=f \alpha ; F(\alpha+\widetilde{\omega} i)=-F \alpha ;\end{array}\right.\)
et en mettant \(a+(1)\) et \(u+\bar{w} i\) an lieu de \(a\) :
\((20) \quad\left\{\begin{array}{l}\varphi(2 \omega+\alpha)=\varphi \alpha ; \varphi(2 \widetilde{\omega} i+\alpha)=\varphi \alpha ; \varphi(\omega+\widetilde{\omega} i+\alpha)=\varphi \alpha ; \\ f(2 \omega+\alpha)=f \mu ; \quad f(\widetilde{\omega} i+\alpha)=f \alpha ; \\ F(\omega+\alpha)=F \alpha ; \quad F(2 \widetilde{\omega} i+\alpha)=F \alpha .\end{array}\right.\)
Ces équations font voir que les fonctions \(\varphi \alpha, f \alpha, F \propto\) sont des fonctions périodiques. On en déduira sans peine les suivantes, où \(m\) et \(n\) sont deux nombres entiers positifs ou négatifs:
(21) \(\left\{\begin{array}{l}\varphi[(m+n) \omega+(m-n) \widetilde{\omega} i+\alpha]=\varphi \alpha ; \\ \varphi[(m+n) \omega+(m-n+1) \widetilde{\omega} i+\alpha]=-\varphi \alpha ; \\ f(2 m \omega+n \widetilde{\omega} i+\alpha)=f \alpha ; f[(2 m+1) \omega+n \bar{\omega} i+\alpha]=-f \alpha . \\ F(m \omega+2 n \widetilde{\omega} i+\alpha)=F \alpha ; F[m \omega+(2 n+1) \widetilde{\omega} i+\alpha]=-F \alpha .\end{array}\right.\)

Ces formules peuvent aussi s'écrire comme il suit:
\[
\left\{\begin{array}{l}
\varphi(m(i)+n \tilde{\omega} i \pm \alpha)= \pm(-1)^{m+n} \varphi \alpha \\
f(m \omega)+n \widetilde{\omega} i \pm \alpha)=(-1)^m f \alpha \\
F(m(1)+n \tilde{\omega} i \pm \alpha)=(-1)^n F(\%
\end{array}\right.
\]

On peut remarquer comme cas particuliers:
%273
\(\left(22^{\prime}\right)\)
\[
\begin{cases}\varphi(m \omega \pm \alpha)= \pm(-1)^m \varphi \alpha ; & \varphi(n \widetilde{\omega} i \pm \alpha)= \pm(-1)^n \varphi \alpha \\ f(m \omega \pm \alpha)=(-1)^m f \alpha ; & f(n \bar{\omega} i \pm \alpha)=f \alpha \\ F(m \omega \pm \alpha)=F \alpha ; & F(n \bar{\omega} i \pm \alpha)=(-1)^n F \alpha .\end{cases}
\]
5.

Les formules qu'on vient d'établir font voir qu'on aura les valeurs des fonctions \(\varphi \alpha, f \alpha, F \alpha\) pour toutes les valeurs réelles ou imaginaires de la variable, si on les connaît pour les valeurs réelles de cette quantité, comprises entre \(\frac{(1)}{2}\) et \(-\frac{\omega}{2}\) et pour les valeurs imaginaires de la forme \(\beta i\), où \(\beta\) est compris entre \(\frac{\hat{\omega}}{2}\) et \(-\frac{\hat{\omega}}{2}\).

En effet, supposons qu'on demande la valeur des fonctions \(\varphi(\alpha+\beta i)\), \(f(\alpha+\beta i), F(\alpha+\beta i)\), où \(\alpha\) et \(\beta\) sont des quantités réelles quelconques. En mettant dans les formules (10) \(\beta i\) à la place de \(\beta\), il est clair qu'on aura les trois fonctions dont il s'agit, exprimées par les fonctions \(\varphi \alpha, f \alpha\), \(F \alpha, \varphi(\beta i), f(\beta i), F(\beta i)\). Il ne reste donc qu'à déterminer ces dernières. Or, quelles que soient les valeurs de \(\alpha\) et \(\beta\), on peut toujours trouver deux nombres entiers \(m\) et \(n\), tels que \(\alpha=m \omega \pm \alpha^{\prime}, \beta=n \widetilde{\varpi} \pm \beta^{\prime}\), où \(\alpha^{\prime}\) est une quantité comprise entre 0 et \(+\frac{\omega}{2}\), et \(\beta^{\prime}\) entre 0 et \(+\frac{\tilde{\sigma}}{2}\). Donc on aura, en vertu des équations \(\left(22^{\prime}\right)\), en substituant les valeurs précédentes de \(\alpha\) et \(\beta\),
\[
\begin{aligned}
\varphi \alpha & =\varphi\left(m \omega \pm \alpha^{\prime}\right)= \pm(-1)^m \varphi \alpha^{\prime}, \\
f \alpha & =f\left(m \omega \pm \alpha^{\prime}\right)=(-1)^m f \alpha^{\prime}, \\
F \alpha & =F\left(m \omega \pm \alpha^{\prime}\right)=F^{\prime} \alpha^{\prime}, \\
\varphi(\beta i) & =\varphi\left(n \bar{\omega} i \pm \beta^{\prime} i\right)= \pm(-1)^n \varphi\left(\beta^{\prime} i\right), \\
f(\beta i) & =f\left(n \bar{\omega} i \pm \beta^{\prime} i\right)=f\left(\beta^{\prime} i\right), \\
F(\beta i) & =F^{\prime}\left(n \bar{\omega} i \pm \beta^{\prime} i\right)=(-1)^n F\left(\beta^{\prime} i\right) .
\end{aligned}
\]

Donc les fonctions \(\psi \alpha, f \alpha, F \alpha, \psi(\beta i), f(\beta i), F(\beta i)\) seront exprimées comme on vient de le dire, et par suite aussi les fonctions \(\varphi(\alpha+\beta i), f(\alpha+\beta i)\), \(F(\alpha+\beta i)\).
Nous avous vu précédemment, que \(\uparrow \alpha\) est réel depuis \(\alpha=-\frac{\omega}{2}\) jusqu’à
%274
\(\alpha=+\frac{\prime \prime}{2}\), et que \(\frac{q(\alpha i)}{i}\) est réel dépuis \(\alpha=-\frac{\grave{\omega}}{2}\) jusqu’à \(\alpha=+\frac{\hat{\omega}}{2}\). Donc en vertu des équations (22) il est clair
1) que \(q \alpha\) et \(\frac{\uparrow(a i)}{i}\) sont réels pour toute valeur réelle de \(\alpha ; \varphi \alpha\) est compris entre \(-\frac{1}{c}\) et \(+\frac{1}{c}\), et \(\frac{r(\boldsymbol{\alpha} i)}{i}\) entre \(-\frac{1}{e}\) et \(+\frac{1}{e}\);
2) que \(q \alpha\) s'évanonit pour \(\alpha=m\left(\omega\right.\), et \(\frac{\tau(\alpha i)}{i}\) pour \(\alpha=m \widetilde{\omega}, m\) étant un nombre entier positif on négatif; mais \(\varphi \propto\) n'est pas nul pour aucune antre valeur réelle de \(\alpha\).

En remarquant, que \(f \alpha=\sqrt{1-c^2 \varphi^2 \alpha}, \quad l^{\prime} \alpha=\sqrt{1+e^2 \varphi^2 \alpha}\), il suit de ce que nous venons de dire
1) que les fonctions \(f \alpha, F \alpha, f(\alpha i), F(\alpha i)\) sont réelles pour toute valeur de \(\alpha\);
2) que \(f \alpha\) est compris entre les limites -1 et +1 et \(\boldsymbol{F} \alpha\) entre les limites +1 et \(+\sqrt{1+\frac{e^2}{e^2}}\), de sorte que \(F_\alpha\) est positif pour tonte valeur réelle de \(\boldsymbol{\alpha}\);
3) que \(f(\alpha i)\) est positif et compris entre les limites +1 et \(\sqrt{1+\frac{c^2}{e^z}}\) et \(F(\alpha i)\) entre les limites -1 et +1 pour toute valeur réelle de \(\alpha\);
4) que \(f \alpha\) s'évanouit pour \(\alpha=\left(m+\frac{1}{2}\right) \omega\) et \(F(\alpha i)\) pour \(\alpha=\left(m+\frac{1}{2}\right) \pi\); mais que ces fonctions ne s'annulent pour aucune autre valeur de \(\alpha\).
On remarquera ce qui suit, comme corollaires des formules (22):
1) Soit \(\alpha=0\). Dans ce cas, en remarquant que \(\varphi(0)=0, f(0)=1\), \(F(0)=1\), on aura
\[
\left\{\begin{array}{l}
\varphi(m \omega+n \widetilde{w} i)=0, \\
f(m(i)+n \widetilde{\omega} i)=(-1)^m, \\
F(m \omega+n \widetilde{w} i)=(-1)^n .
\end{array}\right.
\]
2) Soit \(\alpha=\frac{1}{2}\). En vertu des équations:

On allra
\[
\varphi\left(\frac{\omega}{2}\right)=\frac{1}{c}, f\left(\frac{\omega}{2}\right)=0, F\left(\frac{\omega}{2}\right)=\frac{\sqrt{e^2+c^2}}{c}=\frac{1}{c},
\]
\[
\left\{\begin{array}{l}
\varphi\left[\left(m+\frac{1}{2}\right) \omega+n \widetilde{\omega} i\right]=(-1)^{m+n} \frac{1}{c}, \\
f\left[\left(m+\frac{1}{2}\right) \omega+n \widetilde{\omega} i\right]=0, \\
F\left[\left(m+\frac{1}{2}\right) \omega+n \widetilde{\omega} i\right]=(-1)^n \frac{b}{c} .
\end{array}\right.
\]
%275
3) Soit \(u=\frac{\tilde{v}}{2} i\). En vertu des équations
\[
\varphi\left(\frac{\tilde{\omega}}{2} i\right)=\frac{i}{e}, f\left(\frac{\tilde{\omega}}{2} i\right)=\frac{b}{e}, \quad F\left(\frac{\tilde{\omega}}{2} i\right)=0
\]
on aura
\[
\left\{\begin{array}{l}
\varphi\left[m \omega+\left(n+\frac{1}{2}\right) \widetilde{\omega} i\right]=(-1)^{m+n} \frac{i}{e} \\
f\left[m \omega+\left(n+\frac{1}{2}\right) \widetilde{\omega} i\right]=(-1)^m \frac{b}{e} \\
F\left[m \omega+\left(n+\frac{1}{2}\right) \widetilde{\omega} i\right]=0
\end{array}\right.
\]
4) Soit \(\alpha=\frac{\omega}{2}+\frac{\tilde{\omega}}{2} i\). En vertu des équations ci-dessus on aura
\[
\left\{\begin{array}{l}
\varphi\left[\left(m+\frac{1}{2}\right) \omega+\left(n+\frac{1}{2}\right) \widetilde{\omega} i\right]=\frac{1}{0}, \\
f\left[\left(m+\frac{1}{2}\right) \omega+\left(n+\frac{1}{2}\right) \widetilde{\omega} i\right]=\frac{1}{0}, \\
F\left[\left(m+\frac{1}{2}\right) \omega+\left(n+\frac{1}{2}\right) \widetilde{\omega} i\right]=\frac{1}{0} .
\end{array}\right.
\]
6.

Les équations (23), (24), (25) font voir que la fonction \(\varphi \alpha\) s'évanouit toutes les fois que \(\alpha\) est de la forme \(\alpha=m \omega+n \widetilde{\omega} i\); que \(f \alpha\) s'évanouit toutes les fois que \(\alpha\) est de la forme \(\alpha=\left(m+\frac{1}{2}\right) \omega+n \widetilde{\omega} i\), et que \(F \alpha\) s'évanouit toutes les fois que \(\alpha\) est de la forme \(\alpha=m \omega+\left(n+\frac{1}{2}\right) \widetilde{\omega} i\). Or je dis que pour toute autre valeur de \(\alpha\), les fonctions \(\varphi \alpha, f \alpha, F \alpha\) auront nécessairement une valeur différente de zéro. Supposons en effet qu'on ait
\[
\varphi(\alpha+\beta i)=0,
\]
\(\alpha\) et \(\beta\) étant des quantités réelles. En vertu de la première des formules (10), cette équation peut s'écrire comme il suit:
\[
\frac{q \alpha \cdot f(\beta i) F(\beta i)+q(\beta i) f \alpha \cdot F \alpha}{1+e^2 c^2 \tau^2 \alpha \cdot \tau^2(\beta i)}=0 .
\]

Maintenant les quantités \(\varphi \mu, f(\beta i), F(\beta i)\) sont réelles et \(\varphi(\beta i)\) est de la forme \(i A\), où \(A\) est réel; donc cette équation ne peut subsister à moins qu'on n'ait séparément
\[
\varphi \alpha \cdot f(\beta i) F(\beta i)=0 ; \varphi(\beta i) f \alpha \cdot F^{\prime} \alpha=0 \text {. }
\]
%276
Ces équations ne peuvent être satisfaites que de deux manières, savoir en faisant
\[
\varphi \alpha=0, \varphi(\beta i)=0
\]

OII
\[
f(\beta i) F(\beta i)=0, f \alpha \cdot F \alpha=0 .
\]

Les deux premières équations donnent \(\alpha=m \omega ; \beta=n \widetilde{\omega}\). Les deux dernières, en remarquant que \(F \alpha\) et \(f(\beta i)\) ne peuvent jamais s'évanouir, donnent
d'où
\[
f \alpha=0, \quad F(\beta i)=0,
\]
\[
\alpha=\left(m+\frac{1}{2}\right) \omega, \beta=\left(n+\frac{1}{2}\right) \widetilde{w} .
\]

Mais pour ces valeurs de \(\alpha\) et \(\beta\), la valeur de \(\varphi(\alpha+\beta i)\) deviendra infinie; donc les seules valeurs de \(\alpha\) et \(\beta\) sont \(\alpha=m \omega\) et \(\beta=n \widetilde{\omega}\), et par conséquent tontes les racines de l'équation
\[
\varphi x=0
\]
peuvent être représentées par
\[
x=m \omega+n \widetilde{\omega} i .
\]

De la même manière on trouvera que toutes les racines de l'équation
\[
f x=0
\]
peuvent être représentées par
\[
x=\left(m+\frac{1}{2}\right) \omega+n \tilde{w} i
\]
et celles de l'équation
par
\[
\begin{gathered}
F x=0 \\
x=m \omega+\left(n+\frac{1}{2}\right) \bar{\omega} i
\end{gathered}
\]
7.

Les formules (26) font voir qu'on satisfait aux trois équations
\[
\varphi x=\frac{1}{0}, f x=\frac{1}{0}, F x=\frac{1}{0},
\]
en donnant à \(x\) une des valeurs de la forme
\[
x=\left(m+\frac{1}{2}\right) \omega+\left(n+\frac{1}{2}\right) \bar{\omega} i \text {. }
\]
%277
Or on peut démontrer que les équations en question n'ont pas d'autres racines. En effet, ayant
\[
\varphi x=\frac{i}{\rho c} \frac{1}{\varphi\left(x-\frac{w}{2}-\frac{i}{2} i\right)}, f x=\frac{b}{\rho} \frac{1}{f\left(x-\frac{i}{2} i\right)}, \quad F x=\frac{b}{c} \frac{1}{F\left(x-\frac{i \prime}{2}\right)},
\]
les équations en question entraîneront celles-ci:
\[
\varphi\left(x-\frac{\omega}{2}-\frac{\tilde{\omega}}{2} i\right)=0, f\left(x-\frac{\omega}{2} i\right)=0, F\left(x-\frac{\omega}{2}\right)=0 ;
\]
mais en vertu de ce qu'on vient de voir dans le numéro précédent, ces équations donnent respectivement
\[
\begin{gathered}
x-\frac{\omega}{2}-\frac{\tilde{\omega}}{2} i= \\
m \omega+n \widetilde{\omega} i ; x-\frac{\tilde{\omega}}{2} i=\left(m+\frac{1}{2}\right) \omega+n \widetilde{\omega} i, \\
x-\frac{\omega}{2}=m \omega+\left(n+\frac{1}{2}\right) \widetilde{\omega} i
\end{gathered}
\]
ces trois équations sont équivalentes à la suivante:
c. q. f. d.
\[
x=\left(m+\frac{1}{2}\right) \omega+\left(n+\frac{1}{2}\right) \widetilde{\omega} i
\]
8.

Ayant trouvé comme ci-dessus toutes les racines des équations
\[
\begin{aligned}
& \varphi x=0, f x=0, \quad F x=0, \\
& \varphi x=\frac{1}{11}, \quad f x=\frac{1}{0}, \quad F x=\frac{1}{0} ;
\end{aligned}
\]
je vais maintenant chercher les racines des équations plus générales
\[
\varphi x=\varphi a, f x=f a, F x=F a,
\]
où \(a\) est une quantité quelconque réelle ou imaginaire. Considérons d'abord l'équation
\[
\varphi x-\varphi a=0 \text {. }
\]

En faisant dans la seconde des formules (12)
\[
\alpha=\frac{x+a}{2}, \beta=\frac{x-a}{2},
\]
on trouvera
\[
\varphi x-\varphi a=\frac{2 \varphi\left(\frac{x-a}{2}\right) f\left(\frac{x+a}{2}\right) F\left(\frac{x+a}{2}\right)}{1+e^2 c^2 \cdot \varphi^2\left(\frac{x+a}{2}\right) \varphi^2\left(\frac{x-a}{2}\right)}=0
\]
%278
Cette équation ne peut subsister que dans l'un des cinq cas suivants:
1) si \(\varphi\left(\frac{x-a}{2}\right)=0\), d'où \(x=a+2 m \omega+2 n \widetilde{\omega} i\),
2) si \(f\left(\frac{x+a}{2}\right)=0\), d'où \(x=-a+(2 m+1) \omega+2 n \widetilde{\omega} i\),
3) si \(F\left(\begin{array}{c}x+a \\ 2\end{array}\right)=0\), d'où \(x=-a+2 m \omega+(2 n+1) \widetilde{\omega} i\),
4) si \(\varphi\left(\frac{x-a}{2}\right)=\frac{1}{11}\), d'où \(x=a+(2 m+1) \omega+(2 n+1) \widetilde{\omega} i\),
5) si \(\varphi\left(\frac{x+a}{2}\right)=\frac{1}{11}\), d'où \(x=-a+(2 m+1) \omega+(2 n+1) \widetilde{\omega} i\).

La résolution de ces cinq équations est contenue dans les formules (27), \((28),(29),(30)\).
Des valeurs trouvées de \(x\) il faut rejeter celles que donne la formule
\[
x=-a+(2 m+1) \omega+(2 n+1) \widetilde{\omega} i
\]
cal une telle valeur de \(x\) : donne, en vertu de l'équation (22),
\[
\varphi x=-\varphi a
\]
tandis qu'on doit avoir \(\uparrow x=\varphi a\); mais les autres valeurs de \(x\), exprimées par les quatre premières formules, peuvent être admises. Elles sont, comme on le voit, contenues dans la seule formule:
\[
x=(-1)^{m+n} a+m \omega+n \widetilde{\omega} i .
\]

Telle est donc l'expression générale de toutes les racines de l'équation
\[
\varphi x=\varphi a^2 .
\]

On trouvera de la même manière que toutes les racines de l'équation
\[
f \cdot x=f a
\]
sont représentées par la formule
\[
x= \pm a+2 m \dot{\omega}+n \tilde{\omega} i
\]
et toutes celles de l'équation
par la formule
\[
F x=F a
\]
\[
x= \pm a+m \omega+2 n \widetilde{\omega} i .
\]
%279
§ II.
Formeles qui donnent les valenrs de \(\uparrow(n \alpha), f(n \alpha), F(n \alpha)\) esprimses en fonctions rationnelles de \(q \alpha, f \alpha, F \alpha\).
9.
Reprenons les formules (12). En faisant dans la \(1^e\), la \(3^e\) et la \(5^e\) \(\alpha=n \beta\), il viendra
\[
\left\{\begin{array}{l}
\tau(n+1) \beta=-\varphi(n-1) \beta+\frac{2 \varphi(n \beta) f \beta \cdot F \beta}{R}, \\
f(n+1) \beta=-f(n-1) \beta+\frac{2 f(n \beta) f \beta}{R}, \\
F(n+1) \beta=-F(n-1) \beta+\frac{2 F(n \beta) F \beta}{R},
\end{array}\right.
\]
où \(R=1+c^2 e^2 \varphi^2(n / \beta) \varphi^2 \beta\).
Ces formules doment la valeur de \(\varphi(n+1) \beta\) en \(\varphi(n-1) \beta\) et \(\varphi(n / \beta)\); celle de \(f(n+1) \beta\) en \(f(n-1) \beta\) et \(f(n \beta)\), et celle de \(F(n+1) \beta\) en \(F(n-1) \beta\) et \(F(n \beta)\). Donc en faisant successivement \(n=1,2,3 \ldots\), on trouvera successivement les valeurs des fonctions:
\[
\begin{array}{lll}
\varphi(2 \beta), & \varphi(3 \beta), & \varphi(4 \beta) \ldots \varphi(n \beta), \\
f(2 \beta), & f(3 \beta), & f(4 \beta) \ldots f(n \beta), \\
F(2 \beta), & F(3 \beta), & F(4 \beta) \ldots F(n \beta),
\end{array}
\]
exprimées en fonctions rationnelles des trois quantités
\[
\varphi \beta, f \beta, F \beta \text {. }
\]

En faisant p. ex. \(n=1\), on aura
\[
\left\{\begin{array}{l}
\varphi(2 \beta)=\frac{2 \varphi \beta \cdot f \beta \cdot F \beta}{1+e^2 e^2 \varphi^4 \beta}, \\
f(2 \beta)=-1+\frac{2 f^2 \beta}{1+e^2 e^2 \gamma^4 \beta} \\
F(2 \beta)=-1+\frac{2 F^2 \beta}{1+e^2 c^2 \gamma^{-1} \beta}
\end{array} .\right.
\]

Les fonctions \(\varphi(n \beta), f(n \beta), F(n / \beta)\) étant des fonctions rationnelles de \(\varphi \beta, f \beta, F \beta\), on peut toujours les réduire à la forme \(\frac{P}{Q}\), où \(P\) et \(Q\) sont
%280
des fonctions entières de \(\varphi \beta, f \beta, F \beta\). De même il est clair que le dénominateur \(Q\) aura la même valeur pour les trois fonctions que l'on considère. Soit done
\[
\varphi(n \beta)=\frac{P_n^{\prime}}{Q_n}, f(n \beta)=\frac{P_n^{\prime}}{Q_n}, F(n / \beta)=\frac{P_n^{\prime \prime}}{Q_n},
\]
on aura également
\[
\begin{aligned}
& \varphi(n+1) \beta=\frac{P_{n+1}}{Q_{n+1}}, f(n+1) \beta=\frac{P_{n+1}^{\prime}}{Q_{n+1}}, \quad F(n+1) \beta=\frac{P^{\prime \prime}{ }_{n+1}}{Q_{n+1}}, \\
& \uparrow(n-1) \beta=\frac{P_{n-1}}{Q_{n-1}}, f(n-1) \beta=\frac{P_{n-1}^{\prime}}{Q_{n-1}}, \quad F(n-1) \beta=\frac{P^{\prime \prime}{ }_{n-1}}{Q_{n-1}} .
\end{aligned}
\]

En substituant ces valeurs, la première des formules (34) deviendra
ou bien
\[
\frac{P_{n+1}}{Q_{n+1}}=-\frac{I_{n-1}}{Q_{n-1}}+\frac{2 f \beta \cdot F \beta \frac{P_n}{Q_n}}{1+c^2 e^2 \boldsymbol{f}^2 \beta \frac{P_n^2}{Q_n^2}},
\]
\[
\underset{Q_{n+1}}{P_{n+1}}=\frac{-P_{n-1}\left(Q_n^2+c^2 e^2 \gamma^2 \beta \cdot P_n^2\right)+2 P_n Q_n Q_{n-1} f \beta \cdot F \beta}{Q_{n-1}\left(Q_n^2+e^2 c^2 \tau^2 \beta \cdot P_n^2\right)} .
\]

En égalant les numérateurs et les dénominateurs de ces deux fractions, on aura
\[
\begin{aligned}
& P_{n+1}=-P_{n-1}\left(Q_n^2+c^2 e^2 \varphi^2 \beta \cdot P_n^2\right)+2 f \beta \cdot F \beta \cdot P_n Q_n Q_{n-1}^{\prime}, \\
& Q_{n+1}^{\prime}=Q_{n-1}\left(Q_n^2+e^2 c^2 \varphi^2 \beta \cdot P_n^2\right) .
\end{aligned}
\]

La seconde et la troisième des équations (34) donneront de la même manière
\[
\begin{aligned}
& P_{n+1}^{\prime}=-P_{n-1}^{\prime}\left(Q_n^2+c^2 e^2 \varphi^2 \beta \cdot P_n^2\right)+2 f \beta \cdot P_n^{\prime} Q_n Q_{n-1}, \\
& P_{n+1}^{\prime \prime}=-P_{n-1}^{\prime \prime}\left(Q_n^2+c^2 e^2 \varphi^2 \beta \cdot P_n^z\right)+2 F \beta \cdot P_n^{\prime \prime} Q_n Q_{n-1} .
\end{aligned}
\]

En faisant dans ces quatre formules \(n=1,2,3 \ldots\), et remarquant qu'on aura
\[
\begin{aligned}
& Q_0=1, Q_1=1, \quad P_0=0, \quad P_1=\varphi \beta, \\
& P_0^{\prime}=1, P_1^{\prime}=f \beta, P_0^{\prime \prime}=1, P_1^{\prime \prime}=F^{\prime} \beta,
\end{aligned}
\]
on trouvera successivement les fonctions entièress \(Q_n, P_n, P_n^{\prime}, P_n^{\prime \prime}\), pour toutes les valeurs de \(n\).
Soient pour abréger:
\[
\begin{gathered}
\oplus \beta=x, f \beta=y, \quad F \beta=z \\
R_n=Q_n^2+e^2 c^2 x^2 P_n^y,
\end{gathered}
\]
%281
les formules précédentes domeront
\[
\left\{\begin{array}{l}
Q_{n+1}=Q_{n-1} R_n, \\
P_{n+1}=-P_{n-1} R_n+2 y z P_n Q_n Q_{n-1} \\
P_{n+1}^{\prime}=-P_{n-1}^{\prime} R_n+2 y P_n^{\prime} Q_n Q_{n-1}, \\
P_{n+1}^{\prime \prime}=-P_{n-1}^{\prime \prime} R_n+2 z P_n^{\prime \prime} Q_n Q_{n-1} .
\end{array}\right.
\]

En posant \(n=1,2\), on aura
\[
\begin{aligned}
& \left\{\begin{array}{l}
R_1=Q_1^2+e^2 c^2 x^2 P_1^2=1+e^2 c^2 x^4 \\
Q_2=Q_0 R_1=1+e^2 c^2 x^4 \\
P_2=-P_0 R_1+2 y z P_1 Q_1 Q_0=2 x y z \\
P_2^{\prime}=-P_0^{\prime} R_1+2 y P_1^{\prime} Q_1 Q_0=-1-e^2 c^2 x^4+2 y^2 \\
P_2^{\prime \prime}=-P_0^{\prime \prime} R_1+2 z P_1^{\prime \prime} Q_1 Q_0=-1-e^2 c^2 x^4+2 z^2 .
\end{array}\right. \\
& R_2=Q_2^2+e^2 c^2 x^2 P_z^2=\left(1+e^2 c^2 x^4\right)^2+e^2 c^2 x^2 \cdot 4 x^2 y^2 z^2, \\
& Q_3=Q_1 R_2=R_2 \\
& P_3=-P_1 R_2+2 y z P_2 Q_2 Q_1=-x R_2+4 y^2 z^2 x Q_2 \\
& =x\left(4 y^2 z^2 Q_2-R_2\right) \\
& P_3^{\prime}=-P_1^{\prime} R_2+2 y P_2^{\prime} Q_2 Q_1=-y R_2+2 y P_2^{\prime} Q_2 \\
& =y\left(2 Q_2 P_2^{\prime}-R_2\right) \text {, } \\
& P_3^{\prime \prime}=z\left(2 Q_2 P_2^{\prime \prime}-R_2\right) \\
&
\end{aligned}
\]

En continuant de la sorte, et en remarquant que \(y^2=1-c^2 x^2\), \(z^2=1+e^2 x^2\), on verra aisément que les quantités
\[
Q_n, \frac{P_{2 n}}{x y z}, \frac{P_{2 n+1}}{x}, P_{2 n}^{\prime}, \frac{P_{2 n+1}^{\prime}}{y}, P_{2 n}^{\prime \prime}, \frac{P_{2 n+1}^{\prime \prime}}{z}
\]
sont des fonctions entières des trois quantités \(x^2, y^2, z^2\), et par conséquent aussi de l'une quelconque de ces quantités, pour une valeur entière quelconque de \(n\).

Cela fait voir que les expressions de \(\varphi(n \beta), f(n \beta), F(n \beta)\) seront de la forme suivante:
\[
\begin{cases}\varphi(2 n \beta)=\varphi \beta \cdot f \beta \cdot F \beta . T, & \varphi(2 n+1) \beta=\varphi \beta \cdot T^{\prime \prime} \\ f(2 n \beta)=T_1, & f(2 n+1) \beta=f \beta \cdot T^{\prime \prime} \\ F(2 n \beta)=T_2, & F(2 n+1) \beta=F \beta . T^{\prime \prime \prime}\end{cases}
\]
où \(T\) etc. représentent des fonctions rationnelles des quantités \((\varphi \beta)^2,(f \beta)^z\), \((\boldsymbol{F} \beta)^2\).
%282
\(\S\) III.
Résolution des équations
\[
\uparrow(n \beta)=\frac{P_n}{Q_n}, f(n \beta)=\frac{P_n^{\prime}}{Q_n}, H^{\prime}\left(n \beta^{\prime}\right)=\frac{P_n^{\prime \prime}}{Q_n} .
\]
-10 .
l'après ce qu'on a vu, les fonctions \(\varphi(n / \beta), f(n / \beta), F(n / \beta)\) s'expriment rationnellement en \(r, y, z\). Lía réciproque n'a pas lieu, car les équations \(\left(35^{\prime}\right)\) sont en général d'un degré très-élevé. Elles ont par cette raison un certain nombre de racines. Nous allons voir comment on peut aisément exprimer toutes ces racines au moyen des fonctions \(\varphi, f ; F\).
A. Considérons d'abord l'équation \(\varphi(n \beta)=\frac{P_n}{Q_n}\), ou \(Q_n \cdot \varphi(n \beta)=P_n\), et cherchons tontes les valeurs de \(x\). Il faut distinguer deux cas, selon que " est pair ou impair:
1) Si \(n\) est un nombre pair.
D'après ce qu'on a vu dans le pajagraphe précédent (45), on aura dans ce cas
\[
\psi(2 n \beta)=x y z \cdot \psi\left(x^2\right)
\]
(1), en vertu des formules
\[
\begin{gathered}
y=\sqrt{1-c^2 x^2, z=\sqrt{1+e^2 x^2}:} \\
\varphi(2 n / 3)=x \cdot \psi\left(x^2\right) \sqrt{\left(1-c^2 x^2\right)\left(1+e^2 x^2\right) .}
\end{gathered}
\]

Donc l'équation en \(x\) deviendra,
\[
\varphi^2(2 n \beta)=x^2\left(\psi x^2\right)^2\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)
\]

En désignant le second membre par \(\theta\left(x^2\right)\), on aura
\[
\varphi^2(2 n \beta)=\theta\left(x^2\right) \text {. }
\]
\(\varphi \beta\) étant une des valeurs de \(x\), on aura
\[
 \varphi^2(2 n \beta)=\theta\left(\varphi^2 \beta\right)
\]
équation qui a lieu, quelle que soit la valeur de \(\beta\). On trouvera comme il suit les autres valeurs de \(x\). Soit \(x=\varphi \alpha\) une racine quelconque, on doit avoir
\[
\varphi^2(2 n \beta)=\theta\left(\varphi^2 \alpha\right)
\]
%283
Or, en mettant dans (46) \(\alpha\) an lien de \(\beta\), il viendra
done:
\[
\begin{gathered}
\varphi^2(2 n \alpha)=\theta\left(\varphi^2 \alpha\right), \\
\varphi^2(2 n \beta)=\varphi^2(2 n \kappa),
\end{gathered}
\]
équation qui revient à ces deux que voici:
\[
\varphi(2 n \alpha)=\varphi(2 n \beta) \text { et } \varphi(2 n \alpha)=-\varphi(2 n \beta) .
\]

La première donne, en vertu de (31),
\[
2 n \alpha=(-1)^{m+\mu} 2 n \beta+m \omega+\mu \widetilde{\omega} i
\]
où m. et "l sont denx nombres entiers quelconqués, positifs on négatifs, zéro y compris.

La seconde donne les mêmes valeurs de \(2 n \alpha\), mais de signe contraire, comme il est aisé de le voir, en l'écrivant comme il suit:
\[
\varphi(-2 n \alpha)=\varphi(2 n \beta) \text {. }
\]

Toute valeur de 2 na qui satisfait à l'équation (47) peut done être représentée par.
\[
2 n \alpha= \pm\left[(-1)^{m+\mu} 2 n \beta+m \omega+\| \widetilde{\omega} i\right] \text {. }
\]

De la on tire la valeur de \(\alpha\), en divisant par \(2 n\), savoir
\[
\alpha= \pm\left((-1)^{m+\mu} \beta+\frac{m}{2 n} \omega+\frac{\mu}{2 n} \pi i\right) \text {. }
\]

Ayant la valeur de \(\alpha\), on aura
\[
\varphi \alpha= \pm \uparrow\left((-1)^{m+n} \beta+\frac{m}{2 n}(1)+\frac{\mu}{2 n} \widetilde{\omega} i\right)=x .
\]

Donc toutes les valeurs de \(x\) sont contenues dans cette expression, et on les trouvera en domnant aux nombres \(m\) et " toutes les valeurs entières depuis - jusqu’à \(+\infty\). Or pour avoir toutes celles qui sont différentes entre elles, il suffit de donner à \(m\) et " des valeurs entières moindres que 2" 1 . En effet, quels que soient ces nombres, on pent toujours les supposer réduits at la forme:
\[
m=2 n k+m^{\prime}, \quad, \quad=2 n=2 k^{\prime}+u^{\prime},
\]
oì \(k\), \(k^{\prime}\) sont des nombres entiers, et \(m^{\prime}, \mu^{\prime}\) des nombres entiers moindres que \(2 \%\). En substituant ces valeurs dans l'expression de \(x\), elle deviendra:
%284
or en vertu de (22) cette expression se réduit à
\[
x= \pm \varphi\left((-1)^{m^{\prime}+\mu^{\prime}} \beta+\frac{m^{\prime}}{2 n} \omega+\frac{\mu^{\prime}}{2 n} \widetilde{\omega} i\right) .
\]

Cette valeur de \(x\) est de la même forme que la précédente (48), seulement m et "l sont remplacés par \(m^{\prime}\) et \(\mu^{\prime}\), qui, -tous les deux, sont positifs et moindres que \(2 n\); donc on obtiendra toutes les valeurs différentes de \(x\), en domnant seulement à \(m\) et " toutes les valeurs entières depuis zéro jusqu’à \(2 n\) exclusivement. Toutes ces valeurs sont nécessairement différentes entre elles. En effet, supposons par exemple qu'on ait .
\[
\begin{aligned}
& \pm \varphi\left((-1)^{m^{\prime}+\mu^{\prime}} \beta+\frac{m^{\prime}}{2 n}(1)+\frac{\mu^{\prime}}{2 n} \widetilde{\omega} i\right) \\
= & \pm \varphi\left((-1)^{m+\mu} \beta+\frac{m}{2 n}(1)+\frac{\mu}{2 n} \widetilde{\omega} i\right),
\end{aligned}
\]
il s'ensuivrait, d'après (31),
\[
(-1)^{m^{\prime}+\mu^{\prime}} \beta+\frac{m^{\prime}}{2 n}(1)+\frac{\mu^{\prime}}{2 n} \widetilde{\omega} i= \pm\left((-1)^{m+\mu} \beta+\frac{m}{2 n}(1)+\frac{\mu}{2 n} \widetilde{\omega} i\right)+k(1)+k^{\prime} \widetilde{\omega} i
\]
\(k\) - et \(k^{\prime}\) étant des entiers. Cette équation dome
\[
\prime^{\prime}=k^{\prime} .2 n \pm \prime \prime, m^{\prime}=k .2 n \pm m,(-1)^{m^{\prime}+\mu^{\prime}}= \pm(-1)^{m+\mu} .
\]

Lés deux premières équations ne peuvent subsister à moins qu'on n'ait \(k^{\prime}=1\), \(k=1, \prime^{\prime}=2 n-u, m^{\prime}=2 n-m\), et alors la dernière deviendra
\[
(-1)^{4 n-m-\mu}=-(-1)^{m+\mu},
\]
d'où l'on tire
\[
(-1)^{2 m+2 \mu}=-1
\]
résultat absurde. Done toutes les valeurs de \(x\), contenues dans la formule (48) sont différentes entre elles, si \(m\) et \(\mu\) sont positifs et moindres que \(2 n\).

Le nombre total des valeurs. de \(x\) est, comme il est aisé de le voir, égal à \(2(2 n)^2=8 n^2\); or l'équation \(\varphi^2(2 n \beta)=\theta\left(x^2\right)\) ne peut avoir de racines égales, car dans ce cas on aurait \(\frac{d \theta\left(x^2\right)}{d x}=0\), ce qui donnerait pour \(x\) une valeur indépendante de \(\beta\). Donc: le degré de l'équation \(\left.\varphi^2(2 n \beta)\right)=\theta\left(x^2\right)\) est égal au nombre des racines, c'est-à-dire à \(8 n^2\). Si par exemple \(n=1\), on aura l'équation
\[
\psi^2(2 \beta)=\theta\left(x^2\right)=\frac{4 x^2\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)}{\left(1+\rho^2 c^2 x^4\right)^2}
\]
%285
on bien
\[
\left(1+e^2 e^2 x^4\right)^2 \uparrow^2(2 \beta)=4 x^2\left(1-c^2 x^2\right)\left(1+e^2 x^2\right),
\]
et, d'après la formule (48), les racines de cette équation, an nombre de huit, seront:
\[
\begin{aligned}
& x= \pm \uparrow \beta, x= \pm \uparrow\left(-\beta+\frac{1}{2}\right) \text {, } \\
& x= \pm \varphi\left(-\beta+\frac{\tilde{i}}{2} i\right), x= \pm \varphi\left(\beta+\frac{(1)}{2}+\frac{\tilde{\omega}}{2} i\right) . \\
&
\end{aligned}
\]
2) Si n est un nombre impari, égal à \(2 n+1\).

Dans ce cas \(\frac{P_{2 n+1}}{Q_{2 n+1}}\) est, comme nons l'avous vu, une fonction rationnelle de \(x\), et par conséquent l'équation en \(x\) sera:
\[
\varphi(2 n+1) \beta=\frac{P_{2 n+1}}{Q_{2 n+1}} .
\]

On trouvera, précisément comme dans le cas précédent, que toutes les racines de cette équation peuvent être représentées par
\[
x=\varphi\left((-1)^{m+\mu} \beta+\frac{m}{2 n+1}\left(\cdots+\frac{\mu}{2 n+1} \widetilde{w} i\right)\right.
\]
où il faut domner à \(m\) et " tontes les valeurs entières depuis \(-n\) jusqu’à \(+n\) inclusivement. Donc le nombre des racines différentes est \((2 n+1)^2\). C'est aussi le degré de l'équation en question. On peut anssi exprimer les racines par
\[
x=(-1)^{m+\mu} \cdot \underline{p}\left(\beta+\frac{m}{2 n+1}(1)+\frac{\mu}{2 n+1} \widetilde{\omega} i\right)
\]

Si par exemple \(n=1\), on aura une équation du degré \(3^{\circ}=9\). La formule (51) dome pour \(x\) les 9 valewrs snivantes:
\[
\begin{aligned}
& \text { \% }(\beta) \text {; } \\
& \psi\left(-\beta-\frac{(1)}{3}\right) \text {, } \\
& \varphi\left(-\beta+\frac{0}{3}\right), \\
& \varphi\left(-\beta-\stackrel{\pi}{3}_3^\pi\right) \text {, } \\
& \varphi\left(-\beta+\frac{i}{3}\right) \text {, } \\
&
\end{aligned}
\]
%286
\[
\begin{aligned}
& \varphi\left(\beta-\frac{\omega}{3}-\frac{\tilde{\omega}}{3} i\right), \\
& \varphi\left(\beta-\frac{\omega}{3}+\frac{\tilde{\omega}}{3} i\right), \\
& \varphi\left(\beta+\frac{\omega}{3}-\frac{\tilde{\omega}}{3} i\right), \\
& \varphi\left(\beta+\frac{\omega}{3}+\frac{\tilde{\omega}}{3} i\right) .
\end{aligned}
\]
B. Considérons maintenant l'équation
\[
f\left(n_\beta \beta\right)=\frac{P_n^{\prime}}{Q_n},
\]
et cherchons les valeurs de \(y\). qui satisfont à cette équation. I a fonction \(P_u^{\prime \prime}\) étant, comme on l'a vu plus haut, ratiomnelle en y, l'équation en ?, en faisant \(\frac{P_n^{\prime \prime}}{Q_n}=\psi ! y\), sera
\[
f(m \beta)=\psi \eta
\]
line des racines de cette équation est \(y=f \beta\), done, quelle que soit la valeur de \(\beta\),
\[
f(n \beta)=\psi(f \beta) .
\]

P'our trouver les autres valeurs de \(y\), désignons par \(\alpha\) une nouvelle inconnue, telle que \(y=f \alpha\); on aura
\[
f(n \beta)=\psi(f \alpha)
\]
or, en vertu de (53) le second membre est égal à \(f(n \alpha)\); done pour déterminer \(\alpha\), on aura l'équation
\[
f(n \alpha)=f(n \beta) \text {. }
\]

Ein vertu de la formule (32) cette équation donne pour expression générale de na:
\[
n u= \pm n \beta+2 m(i)+\mu \widetilde{\theta} i \text {, }
\]
m. et "étant deux nombres entiers positifs ou négatifs, zéro y compris. De lit on tire
\[
\alpha= \pm \beta+\frac{2 m}{n} \omega+\frac{\mu}{n} \widetilde{\omega} i
\]
et par conséquent:
\[
f \alpha=f\left( \pm \beta+\frac{2 m}{n}(1)+\frac{\mu}{n} \bar{w} i\right)=y
\]

C'est la valeur générale de \(y\).
%287
Maintenant pour avoir les valeurs différentes de \(y\), je dis qu'il suffit de prendre \(\beta\) avec le signe + et de donner à \(m\) et \(\boldsymbol{\|}\) toutes les valeurs entières, moindres que \(n\). En effet, comme on a \(f(+\alpha)=f(-\alpha)\), on aura d'abord
\[
f\left(-\beta+\frac{2 m}{n}(1)+\frac{\mu}{n} \bar{\omega} i\right)=f\left(\beta-\frac{2 m}{n} \omega-\frac{\mu}{n} \widetilde{\omega} i\right) .
\]

Done on peut toujours dans l'expression de y prendre \(\beta\) avec le signe + . Ainsi toutes les valeurs de \(y\) sont contenues dans l'expression
\[
y=f\left(\beta+\frac{2 m}{n} \omega+\frac{\mu}{n} \bar{w} i\right) \text {. }
\]

Maintenant, quels que soient les nombres \(m\) et \(" \prime\), on peut toujours supposer
\[
m=k \cdot n+m^{\prime}, \quad, \quad=k^{\prime} \cdot n+\boldsymbol{\prime}^{\prime}
\]
où \(k, k^{\prime}, m^{\prime}, \mu^{\prime}\) sont des nombres entiers, les deux derniers étant en même temps positif's et moindres que \(x\).
En substituant, il viendra
\[
y=f\left(\beta+\frac{2 m^{\prime}}{n} \omega+\frac{\mu^{\prime}}{n} \widetilde{\omega} i+2 k \omega+k^{\prime} \tilde{\omega} i\right) .
\]

Or, en vertu de la formule (22), le second membre de cette équation est égral à
\[
f\left(\beta+\frac{2 m^{\prime}}{n} \omega+\frac{\mu^{\prime}}{n} \widetilde{\omega} i\right)=y
\]
quantité de la même forme que le second membre de (54); seulement \(m^{\prime}\) et \(\mu^{\prime}\) sont positifs et moindres que \(n\). Donc etc.

En donnant ì \(m\) et "" toutes les valeurs possibles, moindres que \("\), on trouvera \(n^2\) valeurs de \(y\). Or, en général toutes ces quantités sont différentes entre elles. En effet, supposons par exemple
\[
f\left(\beta+\frac{2_m m}{n} \omega+\frac{\mu}{n} \widetilde{\omega} i\right)=f\left(\beta+\frac{2 m^{\prime}}{n} \omega+\frac{\mu^{\prime}}{n} \bar{\omega} i\right)
\]
on aura en vertu de la formule (32), en désignant par \(k, k^{\prime}\) deux nombres entiers,
\[
\beta+\frac{2 m}{n} \omega+\frac{\mu}{n} \tilde{\omega} i= \pm\left(\beta+\frac{2 m^{\prime}}{n} \omega+\frac{\mu^{\prime}}{n} \widetilde{\omega} i\right)+2 k\left(\omega+k^{\prime} \tilde{\omega} i .\right.
\]

Puisque \(\beta\) peut avoir une valeur quelconque, il est clair que cette équation
%288
ne pent subsister à moins quon ne preme dans le second membre le signe smpérieur. Alors il viendra
\[
\frac{2 m}{n}(1)+\frac{\mu}{n} \tilde{\omega} i=\frac{2 m^{\prime}}{n} \omega+\frac{\mu^{\prime}}{n} \bar{\omega} i+2 k(1)+k^{\prime} \bar{\omega} i
\]
d'où l'on tire, en égalant les parties réelles et les parties imaginaires,
\[
m=m^{\prime}+k n, \quad, \quad u^{\prime}+k^{\prime} n,
\]
équations absurdes, en remarquant que les nombres \(m\), \(m^{\prime}\), "l et \(\prime^{\prime}\) sont tous positifis et inférieurs à 1 . Donc en général l'équation
\[
f(n / \beta)=\psi y
\]
a \(11^2\) racines différentes entre elles et pas davantage. Or généralement toutes les racines de cette équation sont différentes entre elles. En effet, si deux d'entre elles étaient égales, on aurait à la fois
\[
f\left(u^\beta\right)=\psi^{\prime} y \text { et } 0=\psi^{\prime} y
\]
et cela est impossible, car on remarquera que les coefficiens de \(y\) dans \(\psi \prime y\) ne contiement pas \(\beta\). Donc généralement l'équation (52) est nécessairement du degré \(n^2\).
C. L’équation
\[
F(n / \beta)=\frac{P_n^{\prime \prime}}{Q_n},
\]
étant traitée par rapport à \(z\), absolument de la même manière que l'équation \(f(n / \beta)=\frac{P_n^{\prime}}{Q_n}\) l'a été par rapport à \(y\), donne pour expression, générale des valeurs de \(z\)
\[
z=F\left(\beta+\frac{m}{n} \omega+\frac{2 \mu}{n} \bar{\omega} i\right)
\]
où \(m\) et " " sont entiers, positifs et moindres que \(n\). Le nombre des valeurs de \(z\) est \(u^2\), et elles sont en général toutes différentes entre elles.
Donc généralement l'équation (56) est du degré \(n^2\).
11.
Nous avous trouvé ci-dessus toutes les racines des équations
\[
\psi(n \beta)=\frac{P_n^{\prime}}{Q_n}, f(n / \beta)=\frac{P_n^{\prime}}{Q_n}, \quad F(n / \beta)=\frac{P_n^{\prime \prime}}{Q_n},
\]
%289
racines, qui sont exprimées par les formules \((48),(51),(54),(57)\). Toutes ces racines sont différentes entre elles, excepté pour des valeurs particulières de \(\boldsymbol{\beta}\); mais pour ces valeurs, les racines différentes sont contenues dans les mêmes formules. - Dans ce dernier cas un certain nombre des valeurs des quantités \(x, y, z\) seront égales; mais il est clair que toutes ces valeurs égales ou inégales seront néanmoins les racines des équations dont il s'agit, Cela se fait voir en faisant converger \(\beta\) vers une valeur particulière qui donne pour \(x\), ou \(y\), ou \(z\) des valeurs égales.
En faisant dans la formule \((48) \quad \beta=\frac{\alpha}{2 n}\), on aura l'équation
\[
\varphi^2 \alpha=\frac{P_{2 n}{ }^2}{Q_{2 n}{ }^2}
\]
dont les racines sont
\[
x= \pm \varphi\left((-1)^{m+\mu} \frac{\alpha}{2 n}+\frac{m}{2 n} \omega+\frac{\mu}{2 n} \bar{\omega} i\right)
\]
où \(m\) ' et " ont toutes les valeurs entières et positives moindres que \(2 n\). En faisant de même dans la formule \((50) \quad \beta=\frac{\alpha}{2 n+1}\), on aura l'équation \(\varphi \alpha=\frac{P_{2 n+1}}{Q_{2 n+1}}\), dont les racines sont
\[
x=(-1)^{m+\mu} \varphi\left(\frac{\alpha}{2 n+1}+\frac{m \omega+\mu \tilde{\omega} i}{2 n+1}\right)
\]
\(m\) et, \(\boldsymbol{\prime}\) ayant pour valeurs tous les nombres entiers depuis \(-n\) jusqu'à \(+n\). Enfin en faisant dans les formules (52), (56) \(\beta=\frac{\alpha}{n}\), on aura l'équation \(f \alpha=\frac{P_n^{\prime}}{Q_n}\), dont les racines sont
\[
y=f\left(\frac{\alpha}{n}+\frac{2 m}{n} \omega+\frac{\mu}{n} \widetilde{\omega} i\right)
\]
et l'équation \(F \alpha=\frac{P_n^{\prime \prime}}{Q_n}\), dont les racines sont
\[
z=F\left(\frac{\alpha}{n}+\frac{m}{n} \omega+\frac{2 \mu}{n} \widetilde{\omega} i\right)
\]
où \(m\) et \("\) sont renfermés entre les limites 0 et \(n-1\) inclusivement. Si \(n\) est impair et égal à \(2 n+1\), on peut aussi supposer
\[
y=(-1)^m f\left(\frac{\alpha}{2 n+1}+\frac{m}{2 n+1} \omega+\frac{\mu}{2 n+1} \tilde{\omega} i\right)
\]
%290
\[
z=(-1)^\mu F\left(\frac{\iota}{2 n+1}+\frac{m}{2 n+1} \omega+\frac{\mu}{2 n+1} \widetilde{\omega} i\right)
\]
\(m\) et "l ayant toutes les valeurs entières de \(-n\) à \(+n\).
Dans toutes ces équations la quantité \(\alpha\) peut avoir une valeur quelconque.
Comme cas particuliers on doit remarquer les suivants:
1) En faisant dans (58) et (59) \(\alpha=0\), on aura les équations
\[
\left\{\begin{aligned}
P_{2 n}^{\prime \prime}=0, & \text { dont les racines sont } x= \pm \varphi\left(\frac{m}{2 n} \omega+\frac{\mu}{2 n} \widetilde{\omega} i\right) \\
& \text { (les limites de } m \text { et } \mu \text { étant } 0 \text { et } 2 n-1) \\
P_{2 n+1}=0, & \text { dont les racines sont } x=\varphi\left(\frac{m}{2 n+1} \omega+\frac{\mu}{2 n+1} \widetilde{\omega} i\right) \\
& \text { (les limites de } m \text { et } \mu \text { étant }-n \text { et }+n) .
\end{aligned}\right.
\]
2) En faisant dans \((60) \quad \alpha=\frac{(1)}{2}\) et dans (61) \(\alpha=\frac{\tilde{\omega}}{2} i\), et remarquant que \(f\left(\begin{array}{l}(\prime) \\ 2\end{array}\right)=0, F\left(\begin{array}{l}\hat{\omega} \\ 2\end{array}\right)=0\), on obtiendra les denx équations
\[
\begin{aligned}
& P_n^{\prime}=0, \text { dont les racines sont } y=f\left(\left(2 m+\frac{1}{2}\right) \frac{(1)}{n}+\frac{\mu}{n} \tilde{\omega} i\right) \\
& P_n^{\prime \prime}=0 \text {, dont les racines sont } z=F\left(\frac{m}{n} \omega+\left(2 \mu+\frac{1}{2}\right) \frac{\omega i}{n}\right)
\end{aligned}
\]
(les limites de \(m\) et \(\boldsymbol{\mu}\) étant 0 et \(n-1\) ).
3) En faisant dans (58) \(\alpha=\frac{\omega}{2}+\frac{\omega}{2} i\), et en remarquant que \(\varphi\left(\frac{\omega}{2}+\frac{\hat{\omega}}{2} i\right)=\frac{1}{0}\), on aura l'équation
\[
Q_{2 n}^2=0
\]
dont les racines seront
\[
x= \pm \varphi\left(\left[m+\frac{1}{2}(-1)^{m+\mu}\right] \frac{\omega}{2 n}+\left[\mu+\frac{1}{2}(-1)^{n+\mu}\right] \frac{\omega i}{2 n}\right) .
\]

Less valeurs de \(x\) doivent être égales deux à deux, et l'on verra aisément que les valeurs inégales peuvent être représentées par
\[
x=\varphi\left(\left(m+\frac{1}{2}\right) \frac{\omega}{2 n}+\left(\mu+\frac{1}{2}\right) \frac{\omega i}{2 n}\right),
\]
en domant à \(m\) et à , \(\boldsymbol{l}\) toutes les valeurs entières depuis () jusqu'à \(2 n-1\). Donc ce sont les racines de l'équation par rapport à \(x\)
\[
Q_{2 n}=0
\]
%291
En faisant de même dans (59) \(\alpha=\frac{\omega}{2}+\frac{\tilde{\omega}}{2} i\), on aura l'équation dont les racines seront
\[
Q_{2 n+1}=0
\]
\[
\left\{\begin{array}{l}
x=(-1)^{m+\mu} \varphi\left(\left(m+\frac{1}{2}\right) \frac{\omega}{2 n+1}+\left(\mu+\frac{1}{2}\right) \frac{\tilde{\omega} i}{2 n+1}\right) \\
y=(-1)^m \quad f\left(\left(m+\frac{1}{2}\right) \frac{\omega}{2 n+1}+\left(\mu+\frac{1}{2}\right) \frac{\tilde{\omega} i}{2 n+1}\right) \\
z=(-1)^\mu \quad F\left(\left(m+\frac{1}{2}\right) \frac{\omega}{2 n+1}+\left(\mu+\frac{1}{2}\right) \frac{\tilde{\omega} i}{2 n+1}\right)
\end{array}\right.
\]
\(m\) et \(" \mu\) ayant pour valeurs tous les nombres entiers de \(-n\) à \(+n\).
Parmi les valeurs de \(x, y, z\), il faut remarquer celles qui répondent à \(m=n, \mu=n\). Alors on a
\[
\begin{array}{r}
x=\uparrow\left(\frac{\omega}{2}+\frac{\tilde{\omega}}{2} i\right)=\frac{1}{\omega} . \\
y=(-1)^n f\left(\frac{\omega}{2}+\frac{\tilde{\omega}}{2} i\right)=\frac{1}{\omega} . \\
z=(-1)^n F\left(\frac{\omega}{2}+\frac{\tilde{\omega}}{2} i\right)=\frac{1}{\omega} .
\end{array}
\]

Ces valeurs infinies font voir que le degré de l'équation \(Q_{2 n+1}=0\) est moindre d'une unité que celui des équations dont elle sort. En écartant ces valeurs, celles qui restent, au nombre de \((2 n+1)^2-1\), seront les racines de l'équation \(Q_{2 n+1}=0\).
Resolution algébrique des équations
\[
\tau \alpha=\frac{P_{2 n+1}}{Q_{2 n+1}}, f \alpha=\frac{P_{2 n+1}^{\prime}}{Q_{2 n+1}}, \quad F \alpha=\frac{P_{2 n+1}^{\prime \prime}}{Q_{2 n+1}^{\prime}} .
\]
12.

Nous avons vu dans le paragraphe précédent, comment on peut aisément exprimer les racines des équations en question au moyen des fonctions \(\varphi, f, F\). Nous allons maintenant en dérluire la résolution de ces mêmes équations, on la détermination des fonctions \(\varphi \frac{\alpha}{n}, f \frac{\alpha}{n}, F \frac{\alpha}{n}\) en fonctions de \(\varphi x, f u, F u\).
%292
Comme on a
\[
\varphi \frac{\alpha}{m \mu}=\varphi\left(\frac{1}{m} \frac{\alpha}{\mu}\right)
\]
on pent supposer que \(n\) est un nombre premier. Nous considérerons d'abord le cas où \(n=2\), et ensuite celui où \(n\) est un nombre impair.
A. Expressions des fonclions \(\mathrm{\tau}_2^\alpha, f_2^\alpha, F_{\frac{\alpha}{2}}^\alpha\).
13.
Les valeurs de \(\varphi \frac{a}{2}, f_2^a, F_2^a\) peuvent être trouvées très facilement de la manière suivante. En supposant dans les formules (35) \(\beta=\frac{\alpha}{2}\), et en faisant
\[
r=\vartheta_2^\alpha, y=f_2^\alpha, \quad z=F_2^\alpha,
\]
il viendra
\[
f u=\frac{y^2-c^2 x^2 z^2}{1+e^2 c^2 \cdot x^4}, \quad F^{\prime} \alpha=\frac{z^2+e^2 y^2 x^2}{1+e^2 e^2 x^4},
\]
on bien, en substituant les valeu's de \(y^2\) et \(z^2\) en \(x^2\),
\[
f u=\frac{1-2 c^2 x^2-c^2 e^2 x^4}{1+e^2 c^2 x^4}, \quad F u=\frac{1+2 e^2 x^2-e^2 c^2 x^4}{1+e^2 c^4 x^4} .
\]

Ces équations donnent
d'où
\[
\begin{aligned}
& 1+f \alpha=\frac{2\left(1-c^2 x^2\right)}{1+e^2 c^2 x^4}, \quad 1-f \alpha=\frac{2 c^2 x^2\left(1+e^2 x^2\right)}{1+e^2 c^2 x^4}, \\
& F \alpha-1=\frac{2 e^2 x^2\left(1-c^2 x^2\right)}{1+e^2 c^2 x^4}, \quad F \alpha+1=\frac{2\left(1+e^2 x^2\right)}{1+e^2 c^2 x^4},
\end{aligned}
\]
\[
\frac{F \alpha-1}{1+f \alpha}=e^2 x^2, \frac{1-f \alpha}{F \alpha+1}=c^2 x^2,
\]
et par suite, en remarquant que \(y^2=1-c^2 x^2, z^2=1+e^2 x^2\),
\[
z^2=\frac{F \alpha+f \alpha}{1+f \alpha}, y^2=\frac{F \alpha+f \alpha}{1+F \alpha} .
\]

De ces équations on tire, en extrayant la racine carrée, et en remplacant \(x, y, z\) par leurs valeurs \(\psi \frac{\alpha}{2}, f_2^\alpha, F_2^\alpha\),
%293
\[
\left\{\begin{array}{l}
\varphi \frac{\alpha}{2}=\frac{1}{c} \sqrt{\frac{1-f \alpha}{1+F \alpha}}=\frac{1}{e} \sqrt{\frac{F \alpha-1}{f \alpha+1}}, \\
f_2^\alpha=\sqrt{\frac{F \alpha+f \alpha}{1+F \alpha}}, \quad F_2^\alpha=\sqrt{\frac{F \alpha+f \alpha}{1+f \alpha}}
\end{array} .\right.
\]

T'elles sont les formes les plus simples qu'on puisse donner aux valeurs des fonctions \(\varphi \frac{\alpha}{2}, f \frac{\alpha}{2}, F \frac{\alpha}{2}\). De cette manière on peut exprimer algébriquement \(\varphi \frac{\alpha}{2}, f \frac{\alpha}{2}, F \frac{\alpha}{2}\) en \(f \alpha, F \alpha\). De la même manière \(\varphi \frac{\alpha}{4}, f \frac{\alpha}{4}, F \frac{\alpha}{4}\) s'exprimeront en \(f_{\frac{\alpha}{2}}^\alpha, F \frac{\alpha}{2}\), et ainsi de snite. Donc en général les fonctions \(\varphi \frac{\alpha}{2^n}, f_{2^n}^\alpha, F_{\frac{\alpha}{2^n}}^\alpha\) peuvent être exprimées au moyen d'extractions de racines carrées, en fonctions des trois quantités \(\varphi \propto, f \alpha, F \propto\).

Pour appliquer les formules trouvées ci-dessus pour la hissection à un exemple, supposons \(\alpha=\frac{\omega}{2}\). Alors on aura \(f_{\frac{1}{2}}^2=0, F_{\frac{1}{2}}^2=\frac{\sqrt{e^2+c^2}}{c}\), donc en substituant,
\[
\begin{aligned}
& \varphi^{(1)}=\frac{1}{c} \sqrt{\frac{1}{1+\frac{1}{c} \sqrt{e^2+c^2}}}=\frac{1}{e} \sqrt{\frac{1}{c} \sqrt{e^2+c^2}-1} \\
& f_{\frac{(1)}{4}}=\sqrt{\frac{\frac{1}{c} \sqrt{e^2+c^2}}{1+\frac{1}{c} \sqrt{e^2}+c^2}}, \\
& F_4^{(u)}=\sqrt{\frac{1}{c} \sqrt{e^2+c^2}}
\end{aligned}
\]
ou bien
\[
\begin{aligned}
& \psi_4^{\prime \prime \prime}=\frac{1}{\sqrt{c^2+c \sqrt{e^2+c^2}}}=\frac{\sqrt{c \sqrt{e^2+c^2}-c^2}}{\rho}, \\
& f_{\frac{\omega}{4}}=\frac{\sqrt[4]{e^2+c^2}}{\sqrt{c+\sqrt{e^2+c^2}}}=\frac{1}{\rho} \sqrt{e^2+c^2-c \sqrt{c^2+c^2}}, \\
& F_4^{(1)}=\sqrt[4]{1+\frac{e^2}{e^2}}=\sqrt{F_{\frac{1}{2}}^{(1)}} \text {. } \\
&
\end{aligned}
\]
%294
B. Expressions des fonctions \(\varphi \frac{\alpha}{2 n+1}, f \frac{\alpha}{2 n+1}, F \frac{\alpha}{2 n+1}\) en fonctiom algélnrique des quantités qa, \(f \alpha, F \alpha\).
14.
Pour tronver les valeurs de \(\varphi \frac{\alpha}{2 n+1}, f \frac{\alpha}{2 n+1}, F_{\frac{\alpha}{2 n+1}}^{2 n+} \varphi \alpha, f \alpha\), \(F \alpha\), il faut résondre les équations
\[
\varphi \alpha=\frac{P_{2 n+1}}{Q_{2 n+1}}, f \alpha=\frac{P_{2 n+1}^{\prime}}{Q_{2 n+1}}, F \alpha=\frac{P_{2 n+1}^{\prime \prime}}{Q_{z n+1}},
\]
qui toutes sont du degré \((2 n+1)^2\). Nous allons voir qu’il est toujours possible d'effectuer algébriquement cette résolution.
Soient
\[
\Upsilon_1 \beta=\sum_{-n}^{+n} \uparrow\left(\beta+\frac{2 m \omega}{2 n+1}\right)
\]
et
\[
\psi_i^{\prime} \beta=\sum_{-n}^{+n} \theta^\mu \varphi_1\left(\beta+\frac{2 \mu \tilde{\omega} i}{2 n+1}\right), \quad \psi_1 \beta=\sum_{-n}^{+n} \theta^\mu \varphi_1\left(\beta-\frac{2 \mu \tilde{\omega} i}{2 n+1}\right),
\]
où \(\theta\) est une racine imaginaire quelconque de l'équation \(\theta^{2 n+1}-1=0\). Cela posé, je dis que les deux quantités
\[
\psi \beta \cdot \psi_1 \rho \text { et }(\psi \beta)^{2 n+1}+\left(\psi_1 \beta\right)^{2 n+1}
\]
pourront être exprimées rationnellement en \(\varphi(2 n+1) \beta\).
D'abord, en écrivant \(\varphi_1 \rho\) comme il suit:
\[
\begin{aligned}
\varphi_1 \beta=\varphi \beta+\sum_1^n\left[\varphi\left(\beta+\frac{2 m \omega}{2 n+1}\right)\right. & \left.+\varphi\left(\beta-\frac{2 m \omega}{2 n+1}\right)\right] \\
& =\varphi \beta+\sum_1^n \frac{2 \varphi^\beta \cdot f\left(\frac{2 m \omega}{2 n+1}\right) F\left(\frac{2 m \omega}{2 n+1}\right)}{1+\rho^2 c^2 \varphi^2\left(\frac{2 m \omega}{2 n+1}\right) \varphi^2 \beta},
\end{aligned}
\]
on voit que \(\varphi_1 \beta\) peut s'exprimer rationnellement en \(\varphi \beta\). Soit done \(\varphi_1 \beta\) \(=\chi(\varphi, \beta)\), on a de même
%295
ou bien, en faisant
\[
\varphi / \beta=x, f\left(\begin{array}{c}
2 \mu \hat{\omega} i \\
2 n+1
\end{array}\right) F\left(\begin{array}{c}
2 \mu \hat{\omega} i \\
2 n+1
\end{array}\right)=a, \varphi\left(\begin{array}{c}
2 \mu \hat{\omega} i \\
2 n+1
\end{array}\right)=b,
\]
et en substituant pour \(f \beta\) et \(F \beta\) leurs valeurs \(\sqrt{1-c^2 x^2}\) et \(\sqrt{1+e^2 x^2}\) :
\[
\digamma_1\left(\beta \pm \frac{2 \mu \omega i}{2 n+1}\right)=\chi\left(\frac{a x \pm b \sqrt{ }\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)}{1+e^2 e^2 b^2 x^2}\right)
\]
or, \(\chi\) désignant une fonction rationnelle, le second membre de cette équation pent se mettre sous la forme
\[
R_\mu \pm R_\mu^{\prime} \sqrt{\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)}
\]
où \(R_\mu\) et \(R_\mu^{\prime}\) sont des fonctions rationnelles de \(x\). Done on a
\[
\varphi_1\left(\beta \pm \frac{2 \mu \hat{\omega} i}{2 n+1}\right)=R_\mu \pm R_\mu^{\prime} \sqrt{\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)} .
\]

En substituant dans les expressions de \(\psi_\beta ;\) et \(\psi_1 \beta\), il viendra

Maintenant, \(R_\mu\) et \(R_\mu{ }^{\prime}\) étant des fonctions rationnelles de \(x\), les quantités \((2 n+1)^{\text {ieme }}\) puissance, les deux quantités \((\psi \beta)^{2 n+1}\) et \(\left(\psi_1 \beta\right)^{2 n+1}\) pourront se mettre sous la forme:
\[
\begin{gathered}
(\psi \beta)^{2 n+1}=t+t^{\prime} \sqrt{\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)} \\
\left(\psi_1 \beta\right)^{2 n+1}=t-t^{\prime} \sqrt{\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)}
\end{gathered}
\]
\(t\) et \(t^{\prime}\) étant des fonctions rationnelles de \(x\). En prenant la somme des valeurs de \((\psi \beta)^{2 n+1}\) et \(\left(\psi_1 \beta\right)^{2 n+1}\), on aura
\[
(\psi / \beta)^{2 n+1}+\left(\psi_1 \beta\right)^{2 n+1}=2 t .
\]

Donc la quantité \((\psi / \beta)^{2 n+1}+\left(\psi_1 \beta\right)^{2 n+1}\) peut être exprimée rationnellement en \(x\). Il en est de même du produit \(\psi \beta \cdot \psi_1 \beta\), comme on le voit par les équations \((70)\). Donc on peut faire
\[
\left\{\begin{array}{l}
\psi \beta \cdot \psi_1 \beta=\lambda x \\
(\psi \beta)^{2 n+1}+\left(\psi_1 \beta\right)^{2 n+1}=\lambda_1 x
\end{array}\right.
\]
%296
\(\lambda\) et \(\lambda_1 x\) désignant des fonctions rationnelles de \(x\). Or ces fonctions ont la propriété de ne pas changer de valeur, lorsqu'on met à la place de \(x\) une autre racine quelconque de l'équation
\[
\varphi(2 n+1) \beta=\frac{l_{2 n+1}}{Q_{2 n+1}} .
\]

Considérous d'abord la fonction \(\lambda x\). En remettant la valeur de \(x=\varphi \beta\), on antra
\[
\psi \beta \cdot \psi_1^{\prime} /=\lambda(\% / \beta)
\]
d'où l'on tire, en mettant \(\beta+\frac{2 h(1)}{2 u+1}+\frac{2 k^{\prime}(\bar{i}}{2 n+1}\) au lien de \(\beta\),
\[
i\left[\psi\left(\beta+\frac{2 k \omega}{2 n+1}+\frac{2 k^{\prime} \tilde{\omega} i}{2 n+1}\right)\right]=\psi\left(\beta+\frac{2 k^{\prime} \tilde{\omega} i}{2 n+1}+\frac{2 k(1)}{2 n+1}\right) \cdot \psi_1\left(\beta+\frac{2 k^{\prime} \tilde{\omega} i}{2 n+1}+\frac{2 k(\omega)}{2 n+1}\right) .
\]

Cela posé, en remarquant que

On anra, en faisant, dans l'expression de \(\varsigma_1 \beta, \beta=\beta+\frac{2 k \omega}{2 n+1}\),
\[
\begin{aligned}
\varphi_1\left(\beta+\frac{2 k(1)}{2 n+1}\right) & =\sum_{-n}^{+n} \varphi\left(\beta+\frac{2(k+m)}{2 n+1} \omega\right) \\
= & \varphi_1 \beta+\sum_1^k\left[\varphi\left(\beta+\frac{2(m+n)(1)}{2 n+1}\right)-\varphi\left(\beta+\frac{2(m-n-1)(1)}{2 n+1}\right)\right]
\end{aligned}
\]
or
\[
\varphi\left(\beta+\frac{2(m-n-1)}{2 n+1} \omega\right)=\varphi\left(\beta+\frac{2(m+n)}{2 n+1} \omega-2 \omega\right)=\varphi\left(\beta+\frac{2(m+n)}{2 n+1} \omega\right)
\]
done
\[
\varphi_1\left(\beta+\frac{2 k \omega}{2 n+1}\right)=\varphi_1 \beta
\]

En mettant dans l'expression de \(\psi \beta, \beta+\frac{2 k^{\prime} \omega i}{2 n+1}+\frac{2 k \omega}{2 n+1}\) an lieu de \(\beta\), on trouvera
\[
\psi\left(\beta+\frac{2 k^{\prime} \omega i}{2 n+1}+\frac{2 k \omega}{2 n+1}\right)={\stackrel{\Sigma}{-} \Sigma_\mu}^{2 n} \theta^\mu \varphi_1\left(\beta+\frac{2\left(k^{\prime}+\mu\right) \hat{\omega} i}{2 n+1}+\frac{2 k \omega}{2 n+1}\right)
\]
or en vertu de la formule (73) on a
\[
\varphi_1\left(\beta+\frac{2\left(k^{\prime}+\mu\right) \omega i}{2 n+1}+\frac{2 k \omega}{2 n+1}\right)=\varphi_1\left(\beta+\frac{2\left(k^{\prime}+\mu\right) \omega i}{2 n+1}\right)
\]
%297
done
\[
\psi\left(\beta+\frac{2 k^{\prime} \tilde{\omega} i}{2 n+1}+\frac{2 k(1)}{2 n+1}\right)=\sum_{-n}^{+n} \theta^\mu \varphi_1\left(\beta+\frac{2\left(k^{\prime}+\mu\right) \tilde{\omega} i}{2 n+1}\right) .
\]

En vertu de la formule (72) on a
\[
\begin{array}{r}
\sum_{-n}^{+n} \theta^\mu \varphi_1\left(\beta+\frac{2\left(k^{\prime}+\mu\right) \tilde{\omega} i}{2 n+1}\right) \\
=\theta^{-k^{\prime}} \sum_{-n}^{+n} \theta^\mu \varphi_1\left(\beta+\frac{2 \mu \tilde{\omega} i}{2 n+1}\right)+\sum_1^{k^{\prime}} \theta^{n+\mu-k^{\prime}} \varphi_1\left(\beta+\frac{2(\mu+n) \tilde{\omega} i}{2 n+1}\right) \\
\quad-\sum_1^{k^{\prime}} \theta^{\mu-n-1-k^{\prime}} \varphi_1\left(\beta+\frac{2(\mu-n-1) \tilde{\omega} i}{2 n+1}\right)
\end{array}
\]
donc, en remarquant que \(\boldsymbol{\theta}^{n+\mu-k^{\prime}}=\boldsymbol{\theta}^{\mu-n-1-k^{\prime}}\) et que
\[
\varphi_1\left(\beta+\frac{2(\mu-n-1) \tilde{\omega} i}{2 n+1}\right)=\varphi_1\left(\beta+\frac{2(\mu+n) \tilde{\omega} i}{2 n+1}-2 \widetilde{\omega} i\right)=\varphi_1\left(\beta+\frac{2(\mu+n) \tilde{\omega} i}{2 n+1}\right)
\]
il viendra
\[
\psi\left(\beta+\frac{2 k^{\prime} \omega i}{2 n+1}+\frac{2 k \omega}{2 n+1}\right)=\theta^{-k^{\prime}} \psi \beta .
\]

On trouvera de même
\[
\psi_1\left(\beta+\frac{2 k^{\prime} \tilde{\omega} i}{2 n+1}+\frac{2 k \omega^{\circ}}{2 n+1}\right)=\theta^{k^{\prime}} \psi_1 \beta .
\]

Ces deux équations donneront
\[
\begin{gathered}
\psi\left(\beta+\frac{2 k \omega+2 k^{\prime} \tilde{\omega} i}{2 n+1}\right) \cdot \psi_1\left(\beta+\frac{2 k \omega+2 k^{\prime} \tilde{\omega} i}{2 n+1}\right)=\psi \beta \cdot \psi_1 \beta \\
{\left[\psi\left(\beta+\frac{2 k \omega+2 k^{\prime} \omega i}{2 n+1}\right)\right]^{2 n+1}+\left[\psi_1\left(\beta+\frac{2 k \omega+2 k^{\prime} \omega i}{2 n+1}\right)\right]^{2 n+1}=(\psi \beta)^{2 n+1}+\left(\psi_1 \beta\right)^{2 n+1}}
\end{gathered}
\]

En vertu de ces équations on obtiendra, en mettant, dans les valeurs de \(\lambda(\varphi \beta)\) et \(\lambda_1(\varphi \beta), \beta+\frac{2 k \omega+2 k^{\prime}(i)}{2 n+1}\) au lieu de \(\beta\),
\[
\begin{aligned}
\lambda(\varphi \beta) & =\lambda\left[\varphi\left(\beta+\frac{2 k \omega+2 k^{\prime} \omega i}{2 n+1}\right)\right], \\
-\quad \lambda_1(\varphi / \beta) & =\lambda_1\left[\varphi\left(\beta+\frac{2 k \omega+2 k^{\prime}(i)}{2 n+1}\right)\right] .
\end{aligned}
\]

Or \(\varphi\left(\beta+\frac{2 k \omega+2 k^{\prime} \tilde{\omega} i}{2 n+1}\right)\) exprime une racine quelconque de l'équation
\[
\varphi(2 n+1) \beta=\frac{P_{2 n+1}}{Q_{2 n+1}} .
\]
%298
Donc, comme nous l'avons dit, les fonctions \(\lambda x\) et \(\lambda_1 x\) auront les mêmes valeurs, quelle que soit la racine qu'on mette à la place de \(x\). Soient \(x_0\), \(x_1, x_2 \ldots x_{2 v}\) ces racines, on aura
\[
\begin{aligned}
\lambda x & =\frac{1}{2 v+1}\left(\lambda x_0+\lambda x_1+\cdots+\lambda x_{2 \nu}\right), \\
\lambda_1 x & =\frac{1}{2 v+1}\left(\lambda_1 x_0+\lambda_1 x_1+\cdots+\lambda_1 x_{2 \nu}\right) .
\end{aligned}
\]

Or le second membre de ces équations est une fonction rationnelle et symétrique des racines de l'équation \(\varphi(2 n+1) \beta=\frac{P_{2 n+1}}{Q_{2 n+1}}\), donc \(\lambda x\) et \(\lambda_1 x\) pourront s'exprimer ratiomellement en \(\varphi(2 n+1) \beta\). En faisant
\[
\lambda x=B, \lambda_1 x=2 A ;
\]
les équatious (71) domneront
\[
\left(\psi_\beta \beta\right)^{2 n+1}\left(\psi_1 \beta\right)^{2 n+1}=B^{2 n+1},(\psi \beta)^{2 n+1}+\left(\psi_1 \beta\right)^{2 n+1}=2 A
\]
d'où l'on tire
\[
\psi_\beta=\sqrt{A n+1} / \sqrt{A^2-B^{2 n+1}}=\sum_{-n}^{+n} \theta^\mu \varphi_1\left(\beta+\frac{2 \mu \tilde{v} i}{2 n+1}\right) .
\]
15.

Ayant trouvé la valeur de \(\psi / \beta\), on en déduira facilement celle de \(\varphi_1 \beta\). En effet, en prenant pour \(\theta\) successivement toutes les racines imaginaires de l'équation \(\theta^{2 n+1}-1=0\), et en désignant les valeurs correspondantes de \(A\) et \(B\) par \(A_1, B_1, A_2, B_2\) etc., on obtiendra
\[
\begin{aligned}
& \sqrt[2 n+1]{A_1+\sqrt{A_1^2-B_1^{2 n+1}}}=\stackrel{\Sigma}{-n}_\mu^{+n} \theta_1^\mu \varphi_1\left(\beta+\frac{2 \mu \tilde{\omega} i}{2 n+1}\right), \\
& \sqrt[2 n+1]{A_2+\sqrt{A_2^2-B_2^{2 n+1}}}=\underset{-n}{\sum_\mu^{+n}} \theta_2^\mu \varphi_1\left(\beta+\frac{2 \mu \hat{\omega} i}{2 n+1}\right), \\
& \cdots \ldots \ldots \ldots \ldots \\
& \sqrt[2 n+1]{A_{2 n}+\sqrt{A_{2 n}^2-B_{2 n}^{2 n+1}}}=\stackrel{-}{+n}_\mu^{+n} \theta_{2 n}^\mu \varphi_1\left(\beta+\frac{2 \mu \hat{\omega} i}{2 n+1}\right) . \\
&
\end{aligned}
\]

On connaît de même la somme des racines:
\[
\sum_{-n}^{+n} \sum_{-n}^{+n} \varphi\left(\beta+\frac{2 m \omega}{2 n+1}+\frac{2 \mu \tilde{\omega} i}{2 n+1}\right)=\stackrel{\sum}{-n}_\mu^{+n} \varphi_1\left(\beta+\frac{2 \mu \tilde{\omega} i}{2 n+1}\right)
\]
%299
qui est égale à \((2 n+1) \varphi(2 n+1) \beta\), comme nous le verrons dans la suite. En ajoutant ces équations membre à membre, après avoir multiplié la première par \(\theta_1^{-k}\), la seconde par \(\theta_2^{-k}\), la-troisième par \(\theta_3^{-k} \ldots\) et la \((2 n)^{i \text { ìme }}\) par \(\theta_{2 n}^{-k}\), il viendra
\[
\begin{aligned}
\sum_{-n}^{+n}\left(1+\theta_1^{\mu-k}+\theta_2^{\mu-k}+\cdots+\theta_{2 n}^{\mu-k}\right) \varphi_1\left(\beta+\frac{2 \mu \tilde{\omega} i}{2 n+1}\right) & \\
= & (2 n+1) \varphi(2 n+1) \beta+\sum_1^{\sum_\mu} \theta_\mu^{-k} \cdot \sqrt{A_\mu+\sqrt{A_\mu^2-B_\mu^{2 n+1}}}
\end{aligned}
\]
or la somme
\[
1+\theta_1^{\mu-k}+\theta_2^{\mu-k}+\cdots+\theta_{2 n}^{\mu-k}
\]
se réduit à zéró pour toutes les valeurs de \(k\), excepté pour \(k=\mu\). Dans ce cas elle devient égale à \(2 n+1\). Donc le premier membre de l'équation précédente devient
\[
(2 n+1) \varphi_1\left(\beta+\frac{2 k \tilde{\omega} i}{2 n+1}\right)
\]
donc, en substituant et divisant par \((2 n+1)\), on a
\[
\begin{aligned}
& \varphi_1\left(\beta+\frac{.2 k \tilde{\omega} i}{2 n+1}\right)= \\
& \varphi(2 n+1) \beta+\frac{1}{2 n+1}\left[\theta_1^{-k} \sqrt{A_1+\sqrt{A_1^2-B_1^{2 n+1}}}+\theta_2^{-k} \sqrt{A_2+\sqrt{A_2^2-B_2^{2 n+1}}}\right. \\
&\left.+\cdots+\theta_{2 n}^{-k} \sqrt{A_{2 n}+\sqrt{A_{2 n}^2-B_{2 n}^{2 n+1}}}\right] .
\end{aligned}
\]

Pour \(k=0\), on a
\[
\begin{array}{r}
\varphi_1 \beta=\varphi(2 n+1) \beta+\frac{1}{2 n+1}\left[\sqrt{A_1+\sqrt{A_1^2-B_1^{2 n+1}}}+\sqrt{A_2+\sqrt{A_2^2-B_2^{2 n+1}}}\right. \\
\left.+\cdots+\sqrt{A_{2 n}+\sqrt{A_{2 n}^2-B_{2 n}^{2 n+1}}}\right]
\end{array}
\]
16.

Ayant ainsi trouvé la valeur de \(\tau_1 \beta\), il s'agit d'en tirer celle de \(\varphi \beta\). Or cela peut se faire aisément comme il suit. Soit
\[
\psi_2 \beta=\sum_{-n}^{+n} \theta^m \varphi\left(\beta+\frac{2 m \omega}{2 n+1}\right), \psi_3 \beta=\sum_{-n}^{+n} \theta^m \varphi\left(\beta-\frac{2 m \omega}{2 n+1}\right),
\]
%300
on a
\[
\varphi\left(\beta \pm \frac{2 m \omega}{2 n+1}\right)=\frac{\tau \beta \cdot f\left(\frac{2 m \omega}{2 n+1}\right) F\left(\frac{2 m \omega}{2 n+1}\right) \pm f \beta \cdot F \beta \cdot \tau\left(\frac{2 m \omega}{2 n+1}\right)}{1+e^2 c^2 \varphi^2\left(\frac{2 m \omega}{2 n+1}\right) \varphi^2 \beta} .
\]

Il suit de là qu'on peut faire
\[
\psi_2 \beta=r+f \beta . F \beta . s, \psi_3 \beta=r-f \beta . F \beta . s,
\]
oì \(r\) et \(s\) sont des fonctions rationnelles de \(q \beta\). De là on tire
\[
\left\{\begin{aligned}
\psi_2 \beta \cdot \psi_3 \beta & =\chi(\varphi \beta), \\
\left(\psi_2 \beta\right)^{2 n+1}+\left(\psi_3 \beta\right)^{2 n+1} & =\chi_1(\varphi \beta),
\end{aligned}\right.
\]
\(\chi(\varphi \beta)\) et \(\chi_1(\varsigma \beta)\) étant deux fonctions rationnelles de \(\varphi \beta\).
Cela posé, je dis que \(\chi(\varphi \beta)\) et \(\chi_1(\varphi \beta)\) pourront s'exprimer rationnellement en \(\varphi_1 \beta\). On a vu que
\[
\Upsilon_1 \beta=\varphi \beta+\sum_1^n \frac{2 \Upsilon \beta \cdot f\left(\frac{2 m \omega}{2 n+1}\right) F\left(\frac{2 m \omega}{2 n+1}\right)}{1+e^2 c^2 \varphi^2\left(\frac{2 m \omega}{2 n+1}\right) \varphi^2 \beta} .
\]

En faisant \(\varphi^\beta=x\), on aura une équation en \(x\) du degré \((2 n+1)\). Une racine de cette équation est \(x=\uparrow \beta\); or, en mettant \(\beta+\frac{2 k \omega}{2 n+1}\) au lieu de \(\beta, \varphi_1 \beta\) ne change pas de valeur; donc \(x=\varphi\left(\beta+\frac{2 k \omega}{2 n+1}\right)\) sera une racine, quel que soit le nombre entier \(k\). Or, en donnant à \(k\) toutes les valeurs entières depuis \(-n\) jusqu'd \(+n, \varphi\left(\beta+\frac{2 k \omega}{2 n+1}\right)\) prendra \(2 n+1\) valeurs différentes, done ces \(2 n+1\) quantités seront précisément les \(2 n+1\) racines de l'équation en \(x\).

Cela posé, en mettant \(\beta+\frac{2 k w}{2 n+1}\) an lien de \(\beta\) dans l'expression de \(\psi_z \beta\), il viendra en vertu de l'équation (72)
\[
\begin{aligned}
\psi_2\left(\beta+\frac{2 k \omega}{2 n+1}\right)=\sum_{-n}^{+n} \theta^m \varphi(\beta+ & \left.\frac{2(k+m) \omega}{2 n+1}\right) \\
& =\theta^{-k} \psi_2 \beta+\sum_1^k \theta^{m+n-k} \varphi\left(\beta+\frac{2(m+n) \omega}{2 n+1}\right) \\
& -\sum_1^k \theta^{m-n-1-k} \varphi\left(\beta+\frac{2(m-n-1) \omega}{2 n+1}\right),
\end{aligned}
\]
donc, puisque \(\theta^{m+n-k}=\theta^{m-n-1-k}\) et \(\varphi\left(\beta+\frac{2(m-n-1)}{2 n+1} \omega\right)=\varphi\left(\beta+\frac{2(m+n)(\omega}{2 n+1}\right)\),
%301
on en tirera
\[
\psi_2\left(\beta-1 \frac{2 k \omega}{2 n+1}\right)=\theta^{-k} \psi_2 \beta
\]

De même on aura
\[
\psi_3\left(\beta+\frac{2 k \omega}{2 n+1}\right)=\theta^{+k} \psi_3 \beta
\]

On voit par ces relations que les équations qui domnent les valeurs des fonctions \(\chi(\varphi \beta)\) et \(\chi_1(\varphi \beta)\), conduisent à ces deux égalités:
\[
\begin{aligned}
\chi\left[\varphi\left(\beta+\frac{2 k \omega}{2 n+1}\right)\right] & =\chi(\varphi \beta), \\
\chi_1\left[\varphi\left(\beta+\frac{2 k \omega}{2 n+1}\right)\right] & =\chi_1(\varphi \beta) .
\end{aligned}
\]

De là on tire
\[
\begin{aligned}
& \chi(\varphi \beta)=\frac{1}{2 n+1} \sum_{-n}^{+n} \chi\left[\varphi\left(\beta+\frac{2 k \omega}{2 n+1}\right)\right], \\
& \chi_1(\varphi \beta)=\frac{1}{2 n+1} \stackrel{+n}{\Sigma_{-n}} \chi_1\left[\varphi\left(\beta+\frac{2 k \omega}{2 n+1}\right)\right] .
\end{aligned}
\]

Or, ces valeurs de \(\chi(\varphi \beta)\). et \(\chi_1(\varphi \beta)\) sont des fonctions rationnelles et symétriques de toutes les racines de l'équation (80). Donc elles peuvent être exprimées rationnellement par les coefficièns de la même équation, c'est-à-dire rationnellement en \(\varphi_1 \beta\).
Soit
\[
\chi(\varphi \beta)=D, \chi_1(\varphi \beta)=2 C
\]
les équations (79) donneront
d'où, en remettant la valeur de \(\psi_z \beta\),
\[
\sqrt[2 n+1]{C+\sqrt{C^2-D^{2 n+1}}}=\sum_{-n}^{+n} \theta^m \varphi\left(\beta+\frac{2 m \omega}{2 n+1}\right) .
\]

De la on tire, en mettant \(\theta_\mu\) au lieu de \(\theta\), et en désignant les valeurs correspondantes de \(C\) et \(D\) par \(C_\mu\) et \(D_\mu\),
\[
\theta_\mu^{-k} \sqrt{C_\mu+\sqrt{C_\mu^2-D_\mu^{3 n+1}}}={\stackrel{\Sigma}{\Sigma_m}}_{-n} \theta_\mu^{m-k} \boldsymbol{\tau}\left(\beta+\frac{2 m \omega}{2 n+1}\right) .
\]

En y joignant l'équation
%302
\[
\varphi_1 \beta=\sum_m^{+n} \varphi\left(\beta+\frac{2 m \omega}{2 n+1}\right)
\]
on en tirera facilement
\[
(2 n+1) \cdot \varphi\left(\beta+\frac{2 k \omega}{2 n+1}\right)=\varphi_1 \beta+\sum_1^{2 n} \theta_\mu^{-k} \sqrt{C_\mu+\sqrt{C_\mu^2-D_\mu^{2 n+1}}} .
\]

En supposant \(k=0\), il viendra
\[
\varphi \beta=\frac{1}{2 n+1}\left(\varphi_1 \beta+V^{2 n+1} C_1+\sqrt{C_1^2-D_1^{2 n+1}}+\cdots+\sqrt{C_{2 n}+\sqrt{C_{2 n}^2-D_{2 n}^{2 n+1}}}\right) .
\]

Cette équation domne \(\varphi \beta\) en fonction algébrique de \(\varphi_1 \beta ;\) or nous avons trouvé précédemment \(\varphi_1 \beta\) en fonction algébrique de \(\varphi(2 n+1) \beta\). Donc en mettant \(\frac{\alpha}{2 n+1}\) au lieu de \(\beta\), on aura \(\varphi\left(\frac{\alpha}{2 n+1}\right)\) en fonction algébrique de \(\varphi \boldsymbol{\mu}\).

Par une analyse toute semblable on trouvera \(f\left(\frac{\alpha}{2 n+1}\right)\) en fonction de \(f \alpha\) et \(F\left(\frac{\alpha}{2 n+1}\right)\) en fonction de \(F \alpha\).
17.
Les expressions que nous venons de trouver des quantités \(\varphi_1 \beta\) et \(\varphi \beta\), la première en \(\varphi(2 n+1) \beta\), et la seconde en \(\varphi_1 \beta\), contiennent chacune la somme de \(2 n\) radicaux différens du \((2 n+1)^{\text {ième }}\) degré. Il en résultera pour \(\varphi \beta, \varphi_1 \beta,(2 n+1)^{2 n}\) valeurs, tandis que chacune de ces quantités est la racine d'une équation du \((2 n-1-1)^{\text {ième }}\) degré. Mais on peut donner aux expressions de \(\varphi \beta\) et \(\varphi_1 \beta\) une forme telle que le nombre des valeurs de ces quantités soit précisément égal à \(2 n+1\). Pour cela soit
on peut faire
\[
\theta=\cos \frac{2 \pi}{2 n+1}+i \cdot \sin \frac{2 \pi}{2 n+1} ;
\]
\[
\theta_1=\theta, \theta_2=\theta^2, \theta_3=\theta^3, \ldots \theta_{2 n}=\theta^{2 n} .
\]

Soient de même
\[
\left\{\begin{array}{l}
\psi^k \beta=\sum_\mu^{+n} \theta^{k \mu} \varphi_1\left(\beta+\frac{2 \mu \tilde{\omega} i}{2 n+1}\right) \\
\dot{\psi}_1^k \beta=\sum_{-n}^{+n} \theta^{k \mu} \varphi_1\left(\beta-\frac{2 \mu \tilde{\omega} i}{2 n+1}\right)
\end{array}\right.
\]
%303
on aura en vertu de l'équation (74)
\[
\begin{aligned}
& \psi^k\left(\beta+\frac{2 \nu \hat{\omega} i}{2 n+1}\right)=\theta^{-k v} \psi^k \beta, \\
& \psi_1^k\left(\beta+\frac{2 \nu \tilde{\omega} i}{2 n+1}\right)=\theta^{+k v} \psi_1^k \beta, \\
& \psi^1\left(\beta+\frac{2 \nu \tilde{\omega} i}{2 n+1}\right)=\theta^{-v} \psi^1 \beta, \\
& \psi_1^1\left(\beta+\frac{2 \nu \tilde{\omega} i}{2 n+1}\right)=\theta^{+v} \psi_1^1 \beta .
\end{aligned}
\]

Soit maintenant
\[
\left\{\begin{array}{l}
\frac{\psi^k \beta}{\left(\psi^1 \beta\right)^k}+\frac{\psi_1^k \beta}{\left(\psi_1^1 \beta\right)^k}=P(\varphi \beta), \\
\frac{\psi^k \beta}{\left(\psi^1 \beta\right)^{k-2 n-1}}+\frac{\psi_1^k \beta}{\left(\psi_1^{\mathbf{1}} \beta\right)^{k-2 n-1}}=Q(\varphi / \beta),
\end{array}\right.
\]
\(P(\varphi \beta)\) et \(Q(\varphi / \beta)\) seront des fonctions rationnelles de \(\varphi \beta\); or en mettant \(\beta+\frac{2 m \omega+2 \mu \tilde{\omega} i}{2 n+1}\) au lieu de \(\beta\), il est clair, en vertu des formules précédentes, que \(P\) et \(Q\) ne changent pas de valeur; done on aura
\[
P(\varphi \beta)=\frac{1}{(2 n+1)^2} \cdot \sum_{-n}^{+n} \underset{-n}{\sum_\mu^{+n}} P\left[\varphi\left(\beta+\frac{2 m \omega+2 \mu \tilde{\omega} i}{2 n+1}\right)\right]
\]
or, le second membre étant une fonction symétrique et rationnelle des racines de l'équation \(\varphi(2 n+1) \beta=\frac{P_{z_{n+1}}}{Q_{2 n+1}}, P(\varphi \beta)\) pourra s'exprimer rationnellement en \(\varphi(2 n+1) \beta\). Il en est de même de \(Q(\varphi \beta)\). Ces deux quantités étant connues, les équations (86) donneront
\[
\frac{\psi^k \beta}{\left(\psi^1 \beta\right)^k}\left[1-\left(\frac{\psi^1 \beta}{\psi_1^1 \beta}\right)^{2 n+1}\right]=P(\varphi \beta)-\frac{Q(\varphi \beta)}{\left(\psi_1^1 \beta\right)^{2 n+1}}
\]
or
\[
\begin{aligned}
& \left(\psi^1 \beta\right)^{2 n+1}=A_1+\sqrt{A_1^2-B_1^{2 n+1}}, \\
& \left(\psi_1^1 \beta\right)^{2 n+1}=A_1-\sqrt{A_1^2-B_1^{2 n+1}}
\end{aligned}
\]
done
\[
\frac{\psi^k \beta}{\left(\psi^1 \beta\right)^k} 2 \sqrt{A_1^2-B_1^{9 n+1}}=Q(\varphi \beta)-\left(A_1-\sqrt{A_1^2-B_1^{2 n+1}}\right) P\left(\varphi \beta^3\right)
\]

Done on aura
\[
\psi^k \beta=\left(\psi^1 \beta\right)^k \cdot\left(F_k+H_k \sqrt{A_1^2-B_1^{2 n+1}}\right),
\]
où \(F_k\) et \(H_k\) sont des fonctions rationnelles de \(\varphi(2 n+1) \beta\). En rempla-
%304
('ant \(A_1\) et \(B_1\) par \(A\) et \(B\) et substituant les valeurs de \(\psi^k \beta\) et \(\left(\psi^1 \beta\right)^k\), il viendra
\[
\sqrt[2 n+1]{A_k+\sqrt{A_k^2-B_k^{2 n+1}}}=\left(A+\sqrt{A^2-B^{2 n+1}}\right)^{\frac{k}{2 n+1}}\left(F_k+H_k \sqrt{A^2-B^{2 n+1}}\right),
\]
done la valeur de \(\varphi_1 \beta\) deviendra
\[
\begin{aligned}
\varphi_1 \beta=\varphi(2 n+1) \beta & +\frac{1}{2 n+1}\left[\left(A+\sqrt{A^2-B^{2 n+1}}\right)^{\frac{1}{2 n+1}}\right. \\
& +\left(F_2+I_2 \sqrt{A^2-B^{2 n+1}}\right)\left(A+\sqrt{A^2-B^{2 n+1}}\right)^{\frac{2}{2 n+1}} \\
& \left.+\cdots+\left(F_{2 n}+H_{2 n} \sqrt{A^2-B^{2 n+1}}\right)\left(A+\sqrt{A^2-B^{2 n+1}}\right)^{\frac{2 n}{2 n+1}}\right] .
\end{aligned}
\]

Par un procédé tout semblable on trouvera
\[
\begin{aligned}
\varphi^\beta=\frac{1}{2 n+1} & {\left[\varphi_1 \beta+\left(C+\sqrt{C^2-D^{2 n+1}}\right)^{\frac{1}{2 n+1}}\right.} \\
& +\left(K_2+L_2 \sqrt{C^2-D^{2 n+1}}\right)\left(C+\sqrt{C^2-D^{2 n+1}}\right)^{\frac{2}{2 n+1}} \\
& \left.+\cdots+\left(K_{2 n}+L_{2 n} \sqrt{C^2-D^{2 n+1}}\right)\left(C+\sqrt{C^2-D^{2 n+1}}\right)^{\frac{2 n}{2 n+1}}\right] .
\end{aligned}
\]
où \(K_2, L_2, K_3, L_3 \ldots K_{2 n}, L_{2 n}\) sont des fonctions rationnelles de \(\varphi_1 \beta\). Ces expressions de \(\varphi_1 \beta\) et \(\varphi_\beta ;\) n'ont que \(2 n+1\) valeurs différentes, qu'on obtiendra en attribuant aux radicaux leurs \(2 n+1\) valeurs. Il suit de notre analyse qu'on peut prendre \(\sqrt{A^2-B^{2 n+1}}\) et \(\sqrt{C^2-D^{2 n+1}}\) avec tel signe qu'on voudra.
18.
La valeur que nous avons trouvée pour \(\varphi \beta\) ou \(\varphi\left(\frac{\alpha}{2 n+1}\right)\) contient encore, outre la fonction \(\varphi \alpha\), les suivantes:
\[
\begin{gathered}
e, c, \theta, \\
\varphi\left(\frac{m \omega}{2 n+1}\right), \varphi\left(\frac{m \omega i i}{2 n+1}\right), f\left(\frac{m \omega}{2 n+1}\right), \\
f\left(\frac{m \omega \dot{\omega} i}{2 n+1}\right), F\left(\frac{m \omega}{2 n+1}\right), F\left(\frac{m \omega i}{2 n+1}\right),
\end{gathered}
\]
pour des valeurs quelconques de \(m\) depuis 1 jusqu'à \(2 n\). Maintenant, quelle que soit la valeur de \(m\), on peut toujours exprimer algébriquement \(\varphi\left(\frac{m \omega}{2 n+1}\right)\),
%305
\(f\left(\frac{m \omega}{2 n+1}\right), F\left(\frac{m \omega}{2 n+1}\right)\) en \(\varphi\left(\frac{\omega}{2 n+1}\right)\), et \(\varphi\left(\frac{m \tilde{\omega} i}{2 n+1}\right), f\left(\frac{m \tilde{\omega} i}{2 n+1}\right), F\left(\frac{m \tilde{\omega} i}{2 n+1}\right)\) en \(\varphi\left(\frac{\tilde{\omega} i}{2 n+1}\right)\). Tout est done connu dans l'expression de \(\varphi\left(\frac{\alpha}{2 n+1}\right)\), excepté les deux quantités indépendantes de \(\alpha, \varphi\left(\frac{\omega}{2 n+1}\right), \varphi\left(\frac{\tilde{\omega} i}{2 n+1}\right)\). Ces quantités dépendent seulement de \(c\) et \(e\), et elles peuvent être trouvées par la résolution d'une équation du degré \((2 n+1)^2-1\), savoir de l'équation \(\frac{P_{z n+1}}{x}=0\). Nous allons voir dans le paragraphe suivant comment on peut en ramener la résolution à celle d'équations moins élevées.
\(\S \mathrm{V}\).
C. Sur l'équation \(P_{3 n+1}=0\).
19.
L'expression que nous venons de trouver pour \(\varphi\left(\frac{\alpha}{2 n+1}\right)\) contiendra, comme nous l'avons vu, les deux quantités constantes \(\varphi\left(\frac{\omega}{2 n+1}\right)\) et \(\varphi\left(\frac{\tilde{\omega} i}{2 n+1}\right)\). On trouvera ces quantités en résolvant l'équation
\[
P_{2 n+1}=0 \text {, }
\]
dont les racines seront représentées par
\[
x=\varphi\left(\frac{m \omega+\mu \tilde{\omega} i}{2 n+1}\right)
\]
où \(m\) et \(\mu\) pourront être tous les nombres entiers depuis \(-n\) jusqu'd \(+n\). Une de ces racines, qui répond à \(m=0, \mu=0\), est égale à zéro. Done \(P_{2 n+1}\) est divisible par \(x\). En écartant ce facteur, on aura une équation du degré \((2 n+1)^2-1\),
\[
R=0 \text {. }
\]

En faisant \(x^2=r\), l'équation en \(r, R=0\), serà du degré \(\frac{(2 n+1)^2-1}{2}\) \(=2 n(n+1)\), et les racines de cette équation seront
\[
r=\varphi^2\left(\frac{m \omega \pm \mu \tilde{\omega} i}{2 n+1}\right)
\]
"l et \(m\) ayant toutes les valeurs positives au dessous de \(n+1\), en faisant abstraction de la racine zéro.
%306
Nous allons voir maintenant, comment on peut ramener la résolution de l'équation \(R=0\) à celle de deux équations, l'une du degré \(n\) et l'autre du degré \(2 n+2\). D'abord, je dis qu'on peut représenter toutes les valeurs de \(r\) par
\[
\varphi^2\left(\frac{m \omega}{2 n+1}\right) \text { et } \varphi^2\left(m \cdot \frac{\mu \omega+\tilde{\omega} i}{2 n+1}\right)
\]
en domant ì \(\mu\) tontes les valeurs entières depuis zéro jusqu’à \(2 n\), et à \(m\) toutes celles depuis 1 jusqu'à \(n\). En effet \(\varphi^2\left(\frac{m \omega}{2 n+1}\right)\) représente d'abord \(n\) valeurs de \(r\); or les autres peuvent être représentées par \(\varphi^2\left(m \frac{\mu \omega+\omega i}{2 n+1}\right)\). Soit, pour le démontrer, \(m_\iota,=(2 n+1) k+m^{\prime}\), où \(m^{\prime}\) est un nombre entier compris entre les limites \(-n\) et \(+n\). En substituant, on aura
\[
\begin{aligned}
\varphi^2\left(\begin{array}{c}
m(1)+\hat{\omega} i \\
2 n+1
\end{array}\right)=\varphi^2\left(k \omega+\frac{m^{\prime}(\omega+m \hat{\omega} i}{2 n+1}\right) & \\
=\varphi^2\left(\frac{m^{\prime} \omega+m \hat{\omega} i}{2 n+1}\right) & =\varphi^2\left(\frac{-m^{\prime} \omega-m \hat{\omega} i}{2 n+1}\right) .
\end{aligned}
\]
\(\varphi^2\left(m \frac{\mu(r)+\tilde{n} i}{2 n+1}\right)\) est donc une valeur de \(r\); maintenant, à chaque valeur de " répond une valeur différente de \(m^{\prime}\). Car si l'on avait
il s'ensuivrait
\[
m_i \iota_1=(2 n+1) k_1+m^{\prime} \text {. }
\]
\[
m\left(\prime \prime-\prime_1\right)=(2 n+1)\left(k-k_1\right),
\]
ce qui est impossible, puisque \(2 n+1\) est un nombre premier. Donc \(\varphi^2\left(m \frac{\mu \omega+\tilde{\omega} i}{2 n+1}\right)\), combiné avec \(\varphi^2\left(\frac{m \omega}{2 n+1}\right)\), représente toutes les valeurs de \(r\). Cela posé, soit
\[
\begin{aligned}
{\left[r-\varphi^2\left(\frac{(1)}{2 n+1}\right)\right]\left[r-\varphi^2\left(\frac{2 \omega}{2 n+1}\right)\right] \cdots\left[r-\varphi^2\left(\frac{n \omega}{2 n+1}\right)\right] } \\
=r^n+p_{n-1} r^{n-1}+p_{n-2} r^{n-2}+\cdots+p_1 r+p_0 .
\end{aligned}
\]

Les quantités \(p_0, p_1, \ldots p_{n-1}\), seront des fonctions rationnelles et symétriques de \(\varphi^2\left(\frac{\omega}{2 n+1}\right), \varphi^2\left(\frac{2 \omega}{2 n+1}\right) \cdots \varphi^2\left(\frac{n \omega}{2 n+1}\right)\); ces fonctions peuvent être trouvées an moyen d'une équation du degré \(2 n+2\). Soit \(p\) une fonction rationnelle et symétrique quelconque de \(\varphi^2\left(\frac{\omega^{\prime}}{2 n+1}\right), \varphi^2\left(\frac{2 \omega^{\prime}}{2 n+1}\right) \ldots\)
%307
\(\varphi^2\left(\frac{n \omega^{\prime}}{2 n+1}\right)\), où \(\omega^{\prime}\) désigne la quantité \(m \omega+\mu \varpi i\). En vertu des formules que nous avons données plus haut pour exprimer \(\varphi(n \beta)\) en \(\varphi \beta\), il est clair qu'on peut exprimer \(\varphi^2\left(m^{\prime} \frac{\omega^{\prime}}{2 n+1}\right)\) en fonction rationnelle de \(\varphi^2\left(\frac{\omega^{\prime}}{2 n+1}\right)\). Donc on peut faire
(94) \(p=\psi\left[\varphi^2\left(\frac{\omega^{\prime}}{2 n+1}\right)\right]=\theta\left[\varphi^2\left(\frac{\omega^{\prime}}{2 n+1}\right), \varphi^2\left(\frac{2 \omega^{\prime}}{2 n+1}\right) \cdots \varphi^2\left(\frac{n \omega^{\prime}}{2 n+1}\right)\right]\),
\(\theta\) désignant une fonction symétrique et rationnelle. En mettant \(\boldsymbol{\gamma}^{\prime} \boldsymbol{\omega}^{\prime}\) au lieu de \(\omega^{\prime}\), il viendra
\[
\psi\left[\varphi^2\left(\frac{v \omega^{\prime}}{2 n+1}\right)\right]=\theta\left[\varphi^2\left(\frac{v \omega^{\prime}}{2 n+1}\right), \varphi^2\left(\frac{2 v \omega^{\prime}}{2 n+1}\right) \cdots \varphi^2\left(\frac{n v\left(\omega^{\prime}\right.}{2 n+1}\right)\right]
\]
or en faisant
\[
a v=(2 n+1) k_a{ }^{\prime}+k_a,
\]
où \(k_a\) est entier et compris entre \(-n\) et \(+n\), la série
\[
k_1, k_2, \ldots k_n
\]
aura au signe près les mêmes termes que celle-ci:
\[
1,2,3 \ldots n
\]
donc il est clair que le second membre de l'équation (95) aura la même valeur que \(p\). Donc
\[
\text { - } \psi\left[\varphi^2\left(\frac{v \omega^{\prime}}{2 n+1}\right)\right]=\psi\left[\varphi^2\left(\frac{\omega^{\prime}}{2 n+1}\right)\right]
\]
équation qui, en faisant \(\omega^{\prime}=\omega\) et \(\omega^{\prime}=m \omega+\widetilde{\omega} i\), donnera les deux suivantes:
\[
\left\{\begin{array}{l}
\psi\left[\varphi^2\left(\frac{\nu(\omega}{2 n+1}\right)\right]=\psi\left[\varphi^2\left(\frac{\omega}{2 n+1}\right)\right], \\
\left.\psi\left[\varphi^2\left(\nu^{m(\omega)} \frac{\tilde{\omega} i}{2 n+1}\right)\right]=\psi\left[\varphi^2 \frac{m(1)+\tilde{\omega} i}{2 n+1}\right)\right],
\end{array}\right.
\]
donc, en faisant, pour abréger,
\[
\boldsymbol{\tau}^2\left(\frac{v \omega}{2 n+1}\right)=r_\nu, \quad \tau^2\left(\nu \frac{m \omega+\tilde{\omega} i}{2 n+1}\right)=r_{\nu, m},
\]
il viendra
\[
\psi r_v=\psi r_1 ; \psi r_{v, m}=\psi r_{1, m}
\]

Cela posé, soit
%308
\[
\left\{\begin{aligned}
\left(p-\psi r_1\right)\left(p-\psi r_{1,0}\right)\left(p-\psi r_{1,1}\right)\left(p-\psi r_{1,2}\right) & \cdots\left(p-\psi r_{1,2 n}\right) \\
= & q_0+q_1 \cdot p+q_2 \cdot p^2+\cdots+q_{2 n+1} \cdot p^{2 n+1}+p^{2 n+2}
\end{aligned}\right.
\]

Je dis qu'on pent exprimer les coefficiens \(q_0, q_1\) etc. rationnellement en \(e\) et \(c\). D'abord, en vertu des formules connues, on peut exprimer rationnellement ces coefficiens en \(t_1, t_2 \ldots t_{2 n+2}\), si l'on fait, pour abréger,
\[
t_k=\left(\psi r_1\right)^k+\left(\psi r_{1,0}\right)^k+\left(\psi r_{1,1}\right)^k+\cdots+\left(\psi r_{1,2 n}\right)^k .
\]

Il s'agit done de trouver les quantités \(t_1, t_2 \ldots\); or cela pourra aisément se faire au moyen des relations (99). En effet, en y faisant successivement \(v=1,2 \ldots n\), après avoir élevé les deux membres à la \(k^{\text {ième }}\) puissance, on en tirera sur le champ:
\[
\left\{\begin{aligned}
\left(\psi r_1\right)^k & =\frac{1}{n}\left[\left(\psi r_1\right)^k+\left(\psi r_2\right)^k+\cdots+\left(\psi r_n\right)^k\right] \\
\left(\psi r_{1, m}\right)^k & =\frac{1}{u}\left[\left(\psi r_{1, m}\right)^k+\left(\psi r_{2, m}\right)^k+\cdots+\left(\psi r_{n, m}\right)^k\right] .
\end{aligned}\right.
\]

Donc en mettant pour \(m\) tous les nombres entiers \(0,1 \ldots 2 n\), et en substituant ensuite dans l'expression de \(t_k\), il viendra:
\[
\left\{\begin{aligned}
n \cdot t_k & =\left(\psi r_1\right)^k+\left(\psi r_2\right)^k+\cdots+\left(\psi r_n\right)^k \\
& +\left(\psi r_{1,0}\right)^k+\left(\psi r_{2,0}\right)^k+\cdots+\left(\psi r_{n, 0}\right)^k \\
& +\left(\psi r_{1,1}\right)^k+\left(\psi r_{2,1}\right)^k+\cdots+\left(\psi r_{n, 1}\right)^k \\
& +\cdots \cdots \cdots \\
& +\left(\psi r_{1,2 n}\right)^k+\left(\psi r_{2,2 n}\right)^k+\cdots \cdots+\left(\psi r_{n, 2 n}\right)^k
\end{aligned}\right.
\]

Cette valeur de \(t_k\) est, comme on le voit, une fonction rationnelle et symétrique des \(n(2 n+2)\) quantités \(r_1, r_2 \ldots r_n, r_{1,0}, r_{2,0} \ldots r_{n, 0} \ldots r_{1,2 n}, r_{2,2 n}\) \(\ldots r_{n, 2 n}\), qui sont les \(n(2 n+2)\) racines de l'équation \(R=0\). Donc, comme on sait, \(t_k\) pourra s'exprimer rationnellement par les coefficiens de cette équation, et par suite en fonction rationnelle de \(e\) et \(c\). Ayant ainsi trouvé les quantités \(t_k\), on en tire les valeurs de \(q_0, q_1 \ldots q_{2_{n+1}}\), qui seront également des fonctions rationnelles de \(e\) et \(c\).
20.
Cela posé, en faisant
\[
0=q_0+q_1 p+q_2 p^2+\cdots+q_{2 n+1} p^{2 n+1}+p^{2 n+2}
\]
%309
on aura une équation du \((2 n+2)^{\text {ième }}\) degré, dont les racines seront
\[
\psi r_1, \psi r_{1,0}, \psi r_{1,1}, \psi r_{1,2} \ldots \psi r_{1,2 n} \text {. }
\]

La fonction \(\psi r_1\), c'est-à-dire une fonction quelconque rationnelle et symétrique des racines \(r_1, r_2, r_3 \ldots r_n\) pourra donc être trouvée al moyen d'une équation du degré \(2 n+2\). Donc on aura de cette manière les coefficiens
Ayant déterminé \(p_0, p_1 \ldots\), on aura, en résolvant l'équation
\[
0=p_0+p_1 r+\cdots+p_{n-1} r^{n-1}+r^n
\]
les valeurs des quantités.
\[
r_1, r_2 \ldots r_n ; r_{1,0}, r_{2,0} \ldots r_{n, 0} ; r_{1,1}, r_{2,1} \ldots r_{n, 1} \text { etc. }
\]
dont la première est égale à \(\varphi^2\left(\frac{\omega}{2 u+1}\right)\). Donc la détermination de cette quantité, ou bien la résolution de l'équation \(R=0\), qui est du degré \((2 n+2) n\), est réduite à celle d'équations des degrés \((2 n+2)\) et \(n\).

Mais on peut encore simplifier le procédé précédent. En effet, comme nous le verrons, pour avoir les quantités \(p_0, p_1 \ldots\), il suffit de comnaître l'une quelconque d'entre elles, et alor's on peut exprimer les autres rationnellement par celle-là. Soient généralement \(p, q\) deux fonctions rationnelles et symétriques des quantités \(r_1, r_2 \ldots r_n\), on pent faire, comime nous l'avons vu,
\[
p=\psi r_1, q=\theta r_1,
\]
\(\psi r_1\) et \(\theta r_1\) désignant deux fonctions rationnelles de \(r_1\), qui ont cette propriété de rester les mêmes, si l'on change \(r_1\) en une autre quelconque des quantités \(r_1, r_2 \ldots r_n\). Supposons maintenant
\[
\boldsymbol{s}_k=\left(\psi r_1\right)^k \theta r_1+\left(\psi r_{1,0}\right)^k \theta r_{1,0}+\left(\psi r_{1,1}\right)^k \theta r_{1,1}+\cdots+\left(\psi r_{1,2 n}\right)^k \theta r_{1,2 n},
\]
je dis que \(s_k\) pourra être exprimé rationnellement en \(e\) et \(c\). En effet, on a
\[
\begin{aligned}
& \left(\psi r_1\right)^k \theta r_1=\left(\psi r_v\right)^k \theta r_v=\frac{1}{n}\left[\left(\psi r_1\right)^k \theta r_1+\left(\psi r_2\right)^k \theta r_2+\cdots+\left(\psi r_n\right)^k \theta r_n\right], \\
& \text { - }\left(\psi r_{1, m}\right)^k \boldsymbol{\theta} r_{1, m}=\left(\psi r_{\nu, m}\right)^k \theta r_{v, m}=\frac{1}{u}\left[\left(\psi r_{1, m}\right)^k \theta r_{1, m}+\left(\psi r_{2, m}\right)^k \theta r_{2, m}+\cdots\right. \\
& \left.+\left(\psi r_{n, m}\right)^k \theta r_{n, m}\right\rceil \text {. } \\
&
\end{aligned}
\]

En faisant \(m=0,1,2 \ldots 2 n\), et en sulistituant dans l'expression de \(s_k\), on verra que \(s_k\) est une fonction rationnelle et symétrique des racines \(r_1, r_2\)
%310
\(\ldots r_{1,0} \ldots\) de l'équation \(R=0\); donc \(s_k\) pourra s'exprimer rationnellement en \(\boldsymbol{e}\) et \(c\).

Comnaissant \(s_k\), on obtiendra, en faisant \(k=0,1,2 \ldots 2 n, 2 n+1\) équations, desquelles on tirera aisément la valeur de \(\theta r_1\), en fonction rationnelle de \(\psi r_1\). Donc, une fonction de la forme \(p\) étant donnée, on peut exprimer une autre fonction quelconque de la même forme en fonction rationnelle de \(p\). Donc, comme nous l'avons dit, on peut exprimer les coefficiens \(p_0, p_1, \cdots p_{n-1}\) rationnellement par l'un quelconque d'entre eux. Done enfin, pour en avoir les valeurs, il suffit de résoudre une seule équation du degré \(2 n+2\), et par conséquent, pour avoir les racines de l'équation \(R=0\), il suffit de résoudre une équation du degré \(2 n+2\), et \(2 n+2\) équations du degré \(n\).
21.
Maintenant, parmi les équations dont dépend la détermination des quantités \(\uparrow\left(\frac{\omega}{2 n+1}\right), \varphi\left(\frac{\tilde{\omega} i}{2 n+1}\right)\), celles du degré \(n\) peuvent être résolues algébriquement. Le procédé par lequel nous allons effectuer cette résolution est entièrement semblable à celui qui est dû à M. Gauss pour la résolution de l'équation
\[
\theta^{2 n+1}-1=0
\]

Soit proposée l'équation
\[
0=p_0+p_1 r+p_2 r^2+\cdots+p_{n-1} r^{n-1}+r^n
\]
dont les racines sont:
\[
\varphi^2\left(\frac{\omega^{\prime}}{2 n+1}\right), \varphi^2\left(\frac{2 \omega^{\prime}}{2 n+1}\right), \ldots \varphi^2\left(\frac{n \omega^{\prime}}{2 n+1}\right)
\]
où \(\omega^{\prime}\) a une des valeurs \(\omega, m \omega+\widetilde{\omega} i\). Désignons par \(\boldsymbol{\alpha}\) une des racines primitives du nombre \(2 n+1\), c'est-d-dire un nombre entier tel que \(\boldsymbol{\prime}=\) \(2 n+1\) soit le nombre le plus petit qui rende \(\alpha^{\mu-1}-1\) divisible par \(2 n+1\) : je dis que les racines de l'équation (106) peuvent aussi être représentées par (107)
\[
\varphi^2(\varepsilon), \varphi^2(\alpha \varepsilon), \varphi^2\left(\alpha^2 \varepsilon\right), \varphi^2\left(\alpha^3 \varepsilon\right) \ldots \varphi^2\left(\alpha^{n-1} \varepsilon\right)
\]
où \(\varepsilon=\frac{\omega^{\prime}}{2 n+1}\).
Soit
%311
\[
\boldsymbol{\alpha}^m=(2 n+1) k_m \pm a_m
\]
où \(k\) est entier, et \(a_m\) entier, positif et moindre que \(n+1\), je dis que les termes de la série
\[
1, a_1, a_2 \ldots a_{n-1}
\]
seront tous différens entre eux. En effet, si l'on a
\[
a_m=a_\mu
\]
il en résulte, ou
\[
\alpha^m-\alpha^\mu=(2 n+1)\left(k_m-k_\mu\right)
\]
ou
\[
\alpha^m+\alpha^\mu=(2 n+1)\left(k_m+k_\mu\right) \text {. }
\]

Il faut done que l'une des quantités \(\alpha^m-\alpha^\mu, \alpha^m+\alpha^\mu\) soit divisible par \(2 n+1\); or supposons \(m>\mu\), ce qui est permis, il faut que \(\alpha^{m-\mu}-1\) ou \(\alpha^{m-\mu}+1\) soit divisible par \(2 n+1\); or cela est impossible, car \(m-\mu\) est moindre que \(n\). Done les quantités \(1, a_1, a_2 \ldots a_{n-1}\) sont différentes entre elles, et par conséquent elles coïncident, mais dans un ordre différent, avec les rombres \(1,2,3,4 \ldots n\). Donc, en remarquant que
\[
\varphi^2\left[\left((2 n+1) k_m \pm a_m\right) \varepsilon\right]=\varphi^2\left(a_m \varepsilon\right)
\]
on voit que les quantités (107) sont les mêmes que celles-ci:
\[
\varphi^2(\varepsilon), \varphi^2(2 \varepsilon) \ldots \varphi^2(n \varepsilon)
\]
c'est-à-dire les racines de l'équation (106) c. q. f. d.
Il y a encore à remarquer, qu'ayant
on aura
\[
\begin{gathered}
\alpha^n=(2 n+1) k_n-1, \\
\alpha^{n+m}=(2 n+1) k_n \alpha^m-\alpha^m \\
a_{n+m}=-a_m \\
\varphi^2\left(\alpha^{n+m} \varepsilon\right)=\varphi^2\left(\alpha^m \varepsilon\right) .
\end{gathered}
\]
done
et
Cela posé, soit \(\theta\) une racine imaginaire quelconque de l'équation
\[
\theta^n-1=0
\]
et
\[
\psi(\varepsilon)=\varphi^2(\varepsilon)+\varphi^2(\alpha \varepsilon) \theta+\varphi^2\left(\alpha^2 \varepsilon\right) \theta^2+\cdots+\varphi^2\left(\alpha^{n-1} \varepsilon\right) \theta^{n-1} .
\]

En vertu de ce que nous avous vu précédemment, le second membre de
%312
cette équation peut être transformé en une fonction rationnelle de \(\varphi^2(\varepsilon)\). Faisons
\[
\psi \varepsilon=\chi\left(\varphi^2 \varepsilon\right)
\]

En mettant daus la première expression de \(\psi(\varepsilon), \alpha^n \varepsilon\) au lieu de \(\varepsilon\), il viendra
\[
\begin{aligned}
\psi\left(\alpha^m \varepsilon\right)= & \varphi^2\left(\alpha^m \varepsilon\right)+\varphi^2\left(\alpha^{m+1} \varepsilon\right) \theta+\varphi^2\left(\alpha^{m+2} \varepsilon\right) \theta^2+\cdots \\
& +\varphi^2\left(\alpha^{n-1} \varepsilon\right) \theta^{n-m-1}+\varphi^2\left(\alpha^n \varepsilon\right) \theta^{n-m}+\cdots+\varphi^2\left(\alpha^{n+m-1} \varepsilon\right) \theta^{n-1}
\end{aligned}
\]
mais nous avous vu que \(\varphi^2\left(\alpha^{n+m} \varepsilon\right)=\varphi^2\left(\alpha^m \varepsilon\right)\), done
\[
\begin{aligned}
& \not \prime\left(\alpha^m \varepsilon\right)=\theta^{n-m} \varphi^2(\varepsilon)+\theta^{n-m+1} \varphi^2(\alpha \varepsilon)+\theta^{n-m+2} \varphi^2\left(\alpha^2 \varepsilon\right)+\cdots \\
& \quad+\theta^{n-1} \varphi^2\left(\alpha^{m-1} \varepsilon\right)+\varphi^2\left(\alpha^m \varepsilon\right)+\theta \varphi^2\left(\alpha^{m+1} \varepsilon\right)+\cdots+\theta^{n-m-1} \varphi^2\left(\alpha^{n-1} \varepsilon\right) .
\end{aligned}
\]

En multipliant par \(\theta^m\), le second membre deviendra égal à \(\psi \varepsilon\), done
\[
\psi\left(\boldsymbol{\alpha}^m \varepsilon\right)=\boldsymbol{\theta}^{-m} \psi \varepsilon
\]
on bien
\[
\psi \varepsilon=\theta^m \chi\left[\varphi^2\left(\alpha^m \varepsilon\right)\right]
\]
d'où l'ou tire, en élevant les denx membres à la \(n^{\text {ìme }}\) puissance, et en tenant compte de la relation \(\theta^{m n}=1\),
\[
(\psi \varepsilon)^n=\left[\chi\left(\varphi^2\left(\alpha^m \varepsilon\right)\right)\right]^n .
\]

Cette formule donue, en faisant successivement \(m=0,1,2,3 \ldots n-1\), \(n\) équations qui, ajoutées membre à membre donneront la suivante:
\[
\begin{aligned}
n(\psi \varepsilon)^n=\left[\chi\left(\varphi^2 \varepsilon\right)\right]^n+\left[\chi\left(\varphi^2(\alpha \varepsilon)\right)\right]^n+\left[\chi\left(\varphi^2\left(\alpha^2 \varepsilon\right)\right)\right]^n & +\cdots \\
& +\left[\chi\left(\varphi^2\left(\alpha^{n-1} \varepsilon\right)\right)\right]^n
\end{aligned}
\]
or le second membre de cette équation est une fonction rationnelle et symétrique des quantités \(\varphi^2 \varepsilon, \varphi^2(\alpha \varepsilon) \cdots \varphi^2\left(\alpha^{n-1} \varepsilon\right)\), c'est-à-dire des racines de l'équation (106); donc \((\psi \varepsilon)^n\) peut être exprimé en fonction ratiounelle de \(p_0\), \(p_1 \ldots p_{n-1}\), par conséquent en fonction rationnelle de l'une quelconque de ces quantités. Soit \(v\) la valeur de \((\psi \varepsilon)^n\), on aura
\[
\sqrt[n]{v}=\varphi^2 \varepsilon+\theta \varphi^2(\alpha \varepsilon)+\theta^2 \varphi^2\left(\alpha^2 \varepsilon\right)+\cdots+\theta^{n-1} \varphi^2\left(\alpha^{n-1} \varepsilon\right)
\]

Cela posé, soit \(\theta=\cos \frac{2 \pi}{n}+i \sin \frac{2 \pi}{n}\). Les racines imaginaires de l'équation \(\theta^n-1\) peuvent être représentées par
\[
\theta, \theta^2, \ldots \theta^{n-1} \text {. }
\]
%313
Done en faisant successivement \(\theta\) égal à chacune de ces racines et en désignant les valeurs correspondantes de \(v\) par \(v_1, v_2 \ldots v_{n-1}\), il viendra
\[
\begin{aligned}
& \sqrt[n]{v_1}=\varphi^2(\varepsilon)+\theta \varphi^2(\alpha \varepsilon)+\cdots+\theta^{n-1} \varphi^2\left(\alpha^{n-1} \varepsilon\right), \\
& \sqrt[n]{v_2}=\varphi^2(\varepsilon)+\theta^2 \varphi^2(\alpha \varepsilon)+\cdots \cdots+\theta^{2 n-8} \varphi^2\left(\alpha^{n-1} \varepsilon\right) \\
& \cdots \cdots \ldots \ldots \ldots \ldots \ldots \\
& \sqrt[n]{v_{n-1}}=\varphi^2(\varepsilon)+\theta^{n-1} \varphi^2(\alpha \varepsilon)+\cdots \cdots \theta^{(n-1)^2} \varphi^2\left(\alpha^{n-1} \varepsilon\right) .
\end{aligned}
\]

En combinant ces équations avec la suivante:
\[
-p_{n-1}=\varphi^2(\varepsilon)+\varphi^2(\alpha \varepsilon)+\cdots+\varphi^2\left(\alpha^{n-1} \varepsilon\right)
\]
on en tire aisément
\[
\begin{array}{lr}
\varphi^2\left(\alpha^m \varepsilon\right)=\frac{1}{n}\left(-p_{n-1}+\theta^{-m} \sqrt[n]{v_1}+\theta^{-2 m} \sqrt[n]{v_2}+\theta^{-3 m} \sqrt[n]{v_3}+\cdots\right. & \\
m=0 & \left.+\theta^{-(n-1) m} \sqrt[n]{v_{n-1}}\right)
\end{array}
\]
et pour \(m=0\),
\[
\varphi^2(\varepsilon)=\frac{1}{n}\left(-p_{n-1}+\sqrt[n]{v_1}+\sqrt[n]{v_2}+\cdots+\sqrt[n]{v_{n-1}}\right)
\]
22.

Tontes les racines de l'équation (106) sont contenues dans la formule (115), mais puisque leur nombre n'est que \(n\), il reste encore à donner à \(\varphi^2(\varepsilon)\) une forme qui ne contienne pas de racines étrangères à la question. Or cela se fait aisément comme il suit. Soit
\[
s_k=\frac{\sqrt[n]{v_k}}{\left(\sqrt[n]{v_1}\right)^k}
\]

En posant ici \(\alpha^m \varepsilon\) au lieu de \(\varepsilon, \sqrt[n]{v_k}\) se changera en \(\theta^{-k m} \sqrt[e^n]{v_k}\), et \(v_1\), en \(\theta^{-m} v_1\), done \(s_k\) se changera en
\[
\frac{\theta^{-k m} \sqrt[n]{v_k}}{\left(\theta^{-m} \sqrt[n]{v_1}\right)^k}=\frac{\sqrt[n]{\sqrt{v_k}}}{\left(\sqrt[n]{v_1}\right)^k} .
\]

La fonction \(s_k\), comme on le voit, ne change pas de valeur, en mettant \(a^m \varepsilon\)
%314
au lieu de \(\varepsilon\). Or \(s_k\) est une fonction rationnelle de \(\varphi^2(\varepsilon)\). Done, en désignant \(s_k\) par \(\lambda\left[\varphi^2(\delta)\right]\), on aura
\[
s_k=\lambda\left[\varphi^2\left(\alpha^m \varepsilon\right)\right]
\]
quel que soit le nombre entier \(m\). De là on tirera, de la même manière que nous a avons trouvé \((\psi \varepsilon)^n\), la valeur de \(s_k\) en fonction rationnelle de l'une des quantités \(p_0, p_1 \cdots p_{n-1}\). Connaissant \(s_k\), on a
\[
\sqrt[n]{v_k}=s_k\left(\sqrt[n]{v_1}\right)^k
\]

Donc en mettant \(v\) au lieu de \(v_1\), l'expression de \(\varphi^2\left(\alpha^m \varepsilon\right)\) deviendra
\[
\varphi^2\left(\alpha^m \varepsilon\right)=\frac{1}{n}\left(-p_{n-1}+\theta^{-m} v^{\frac{1}{n}}+s_2 \theta^{-2 m} v^{\frac{2}{n}}+\cdots+s_{n-1} \theta^{-(n-1) m} v^{\frac{n-1}{n}}\right)
\]
pour \(m=0\) :
\[
\varphi^2(\varepsilon)=\frac{1}{n}\left(-p_{n-1}+v^{\frac{1}{n}}+s_2 v^{\frac{2}{n}}+s_3 v^{\frac{3}{n}}+\cdots+s_{n-1} v^{\frac{n-1}{n}}\right) .
\]

Cette expression n'a que \(n\) valeurs différentes, qui répondent aux \(n\) valeurs de \(v^{\frac{1}{n}}\). Done en dernier lieu la résolution de l'équation \(P_{2 n+1}=0\) est réduite à celle d'une seule équation du degré \(2 n+2\); mais en général cette équation ne paraît pas être résoluble algébriquement. Néanmoins on peut la résoudre complètenent dans plusieurs cas particuliers, par exemple, lorsque \(e=c\), \(e=c \sqrt{3}, e=c(2 \pm \sqrt{3})\) etc. Dans le cours de ce mémoire je m'occuperai de ces cas, dont le premier surtout est remarquable, tant par la simplicité de la solution, que par sa belle application dans la géométrie.
En effet entre autres théorèmes je suis parvenu à celui-ci:
"On peut diviser la circonférence entière de la lemniscate en \(m\) parties "égales par la règle et le compas seuls, si \(m\) est de la forme \(2^n\) ou " \(2^n+1\), ce dernier nombre étant en même temps premier; ou bien si " \(m\) est un produit de plusieurs nombres de ces deux formes."
Ce théorème est, comme on le voit, précisément le même que celui de M. Gauss, relativement au cercle.
%315
\(\S\) VI.
Expressions diverses des fonctions \(\varphi(n \beta), f(n \beta), F(n \beta)\).
23.

En faisant usage des formules connues, qui donnent les valeurs des coefficiens d'une équation algébrique en fonction des racines, on peut tirer plusieurs expressions des fonctions \(\varphi(n \beta), f(n \beta), F(n \beta)\) des formules du paragraphe précédent. Je vais considérer les plus remarquables. Pour abréger les formules, je me servirai des notations suivantes. Je désignerai
1) Par \(\sum_k^{k^{\prime}} \psi m\) la somme, et par \(\prod_k^{k^{\prime}} \psi m\) le produit de toutes les quantités de la forme \(\psi m\), qu'on obtiendra en domnant à \(m\) toutes les valeurs entières, depuis \(k\) jusqu'à \(k^{\prime}\), les limites \(k\) et \(k^{\prime}\) y comprises.
2) \(\operatorname{Par} \sum_k^{k^{\prime}} \sum_\nu^{v^{\prime}} \psi(m, \mu)\) la somme, et par \(\prod_k^{\Pi_m^{\prime}} \Pi_\nu^{\nu^{\prime}} \psi(m, \mu)\) le produit de toutes les quantités de la forme \(\psi(m, \mu)\) qu'on obtiendra en donnant à \(m\) toutes les valeurs entières de \(k\) à \(k^{\prime}\), et à \(\mu\) les valeurs entières de \(\boldsymbol{\nu} \grave{\lambda} \nu^{\prime}\), en y comprenant toujours les limites.
D'après cela il est clair qu'on aura
\[
\begin{aligned}
& \sum_k^{k^{\prime}} \psi(m)=\psi(k)+\psi(k+1)+\cdots+\psi\left(k^{\prime}\right), \\
& \prod_m^{k^{\prime}} \psi(m)=\psi(k) \cdot \psi(k+1) \ldots \psi\left(k^{\prime}\right),
\end{aligned}
\]
\[
\begin{aligned}
& \sum_k^{k^{\prime}} \sum_\nu^{v^{\prime}} \psi(m, \mu)=\sum_\nu^{v^{\prime}} \psi(k, \mu)+\sum_\nu^{v^{\prime}} \psi(k+1, \mu)+\cdots+\sum_\nu^{\nu^{\prime}} \psi\left(k^{\prime}, \mu\right), \\
& \prod_k^{k^{\prime}} \prod_\nu^{\nu^{\prime}} \psi(m, \mu)=\prod_\nu^{\nu^{\prime}} \psi(k, \mu) \cdot \prod_\nu^{v^{\prime}} \psi(k+1, \mu) \ldots \ldots \prod_\mu^{\nu^{\prime}} \psi\left(k^{\prime}, \mu\right) . \\
&
\end{aligned}
\]

Cela posé, considérons les équations
\[
\left\{\begin{array}{l}
\varphi(2 n+1) \beta=\frac{P_{2 n+1}}{Q_{2 n+1}}, \\
f(2 n+1) \beta=\frac{P_{2 n+1}^{\prime}}{Q_{2 n+1}} \\
F(2 n+1) \beta=\frac{P_{2 n+1}^{\prime \prime}}{Q_{2 n+1}}
\end{array}\right.
\]

Nous avons vu que \(P_{2 n+1}\) est une fonction rationnelle de \(x\) du degré \(40 *\)
%316
\((2 n+1)^2\) et de la forme \(x \cdot \psi\left(x^2\right)\). De même \(P_{2 n+1}^{\prime}\) et \(P_{2 n+1}^{\prime \prime}\) sont des fonctions de cette même forme, la première par rapport à \(y\) et la seconde par rapport à \(z\). Enfin \(Q_{2 n+1}\) est une fonction qui, exprimée indifféremment en \(x, y\) ou \(z\), sera du degré \((2 n+1)^2-1\), et contiendra seulement des puissances paires. Donc on aura
\[
\begin{aligned}
P_{2 n+1} & =A x^{(2 n+1)^2}+\cdots+B x \\
P_{2 n+1}^{\prime} & =A^{\prime} y^{(2 n+1)^2}+\cdots+B^{\prime} y \\
P_{2 n+1}^{\prime \prime} & =A^{\prime \prime} z^{(2 n+1)^2}+\cdots+B^{\prime \prime} z \\
Q_{2 n+1} & =C x^{(2 n+1)^2-1}+\cdots+D \\
Q_{2 n+1} & =C^{\prime} y^{(2 n+1)^2-1}+\cdots+D^{\prime} \\
Q_{2 n+1} & =C^{\prime \prime} z^{(2 n+1)^2-1}+\cdots+D^{\prime \prime}
\end{aligned}
\]

En substituant ces valeurs dans l'équation (123), il viendra
\[
\begin{aligned}
\left(A x^{(2 n+1)^2}+\cdots+B x\right) & =\varphi(2 n+1) \beta \cdot\left(C x^{(2 n+1)^2-1}+\cdots+D\right) \\
\left(A^{\prime} y^{(2 n+1)^2}+\cdots+B^{\prime} y\right) & =f(2 n+1) \beta \cdot\left(C^{\prime} y^{(2 n+1)^2-1}+\cdots+D^{\prime}\right) \\
\left(A^{\prime \prime} z^{(2 n+1)^2}+\cdots+B^{\prime \prime} z\right) & =F(2 n+1) \beta \cdot\left(C^{\prime \prime} z^{(2 n+1)^2-1}+\cdots+D^{\prime \prime}\right) .
\end{aligned}
\]

Dans la première de ces équations \(A\) est le coefficient du premier terme, \(-\varphi(2 n+1) \beta . C\) celui du second, et \(-\varphi(2 n+1) \beta . D\) le dernier terme. Donc \(\frac{C}{A} \varphi(2 n+1) \beta\) est égal à la somme, et \(\frac{D}{A} \varphi(2 n+1) \beta\) égal au produit des racines de l'équation dont il s'agit, équation qui est la même que celle-ci:
\[
\varphi(2 n+1) \beta=\frac{P_{2 n+1}}{Q_{2 n+1}} .
\]

Donc en remarquant que \(A, C\) et \(D\) (et en général tous les coefficiens) sont indépendants de \(\beta\), on voit que \(\varphi(2 n+1) \beta\) est (à un coefficient constant près) égal à la somme et au produit de toutes les racines de l'équation (124).

De la même manière on voit que \(f(2 n+1) \beta\) et \(F(2 n+1) \beta\) sont respectivement égaux au produit ou à la somme des racines des équations
\[
f(2 n+1) \beta=\frac{P_{2 n+1}^{\prime}}{Q_{2 n+1}}, F(2 n+1) \beta=\frac{P^{\prime \prime}{ }_{2 n+1}}{Q_{2 n+1}},
\]
en ayant soin de multiplier le résultat par un coefficient constant, choisi convenablement.

Maintenant d'après le \(n^0 11\) les racines des équations (123) sont respectivement:
%317
\[
\begin{gathered}
x=(-1)^{m+\mu} \varphi\left(\beta+\frac{m}{2 n+1} \omega+\frac{\mu}{2 n+1} \widetilde{\omega} i\right) \\
y=(-1)^m f\left(\beta+\frac{m}{2 n+1} \omega+\frac{\mu}{2 n+1} \widetilde{\omega} i\right) \\
z=(-1)^\mu F\left(\beta+\frac{m}{2 n+1} \omega+\frac{\mu}{2 n+1} \widetilde{\omega} i\right),
\end{gathered}
\]
où les limites de \(m\) et \(\mu\) sont \(-n\) et \(+n\). Done en vertu de ce qu'on vient de voir, et en faisant usage des notations adoptées, on aura les formules suivantes:

Pour déterminer les quantités constantes \(A, A^{\prime}, A^{\prime \prime}, B, B^{\prime}, B^{\prime \prime}\), il fauldra donner à \(\beta\) une valeur particulière. Ainsi en faisant dans les trois premières formules \(\beta=\frac{\omega}{2}+\frac{\sigma}{2} i\), après avoir divisé les deux membres par \(\varphi \beta\), il viendra, en remarquant que \(\varphi\left(\frac{\omega}{2}+\frac{\tilde{\omega}}{2} i\right)=\frac{1}{0}\),
\[
\left.\begin{array}{c}
A=\frac{q(2 n+1) \beta}{q \beta} \\
A^{\prime}=\frac{f(2 n+1) \beta}{f \beta} \\
A^{\prime \prime}=\frac{F^{\prime}(2 n+1) \beta}{F^{\prime} \beta}
\end{array}\right\} \text { pour } \beta=\frac{\omega}{2}+\frac{\tilde{\omega}}{2} i .
\]

Soit \(\beta=\frac{(1)}{2}+\frac{\omega}{2} i+\alpha\), on a
%318
\[
\begin{aligned}
& A=\frac{\varphi\left((2 n+1) \alpha+n \omega+n \tilde{\omega} i+\frac{\omega}{2}+\frac{\varpi}{2} i\right)}{\varphi\left(\alpha+\frac{\omega}{2}+\frac{\tilde{\omega}}{2} i\right)} \\
& =\frac{\varphi\left((2 n+1) \alpha+\frac{\omega}{2}+\frac{\widetilde{\omega}}{2} i\right)}{\varphi\left(\alpha+\frac{\omega}{2}+\frac{\widetilde{\omega}}{2} i\right)}=\frac{\varphi \alpha}{\varphi(2 n+1) \alpha}, \\
& A^{\prime}=\frac{f\left((2 n+1) \alpha+n \omega+n \tilde{\omega} i+\frac{\omega}{2}+\frac{\varpi}{2} i\right)}{f\left(\alpha+\frac{\omega}{2}+\frac{\varpi}{2} i\right)} \\
& =(-1)^n \frac{f\left((2 n+1) \alpha+\frac{\omega}{2}+\frac{\varpi}{2} i\right)}{f\left(\alpha+\frac{\omega}{2}+\frac{\omega}{2} i\right)}=(-1)^n \frac{f\left(\alpha+\frac{\omega}{2}\right)}{f\left((2 n+1) \alpha+\frac{\omega}{2}\right)} \\
& A^{\prime \prime}=\frac{F\left((2 n+1) \alpha+n \omega+n \tilde{\omega} i+\frac{\omega}{2}+\frac{\tilde{\omega}}{2} i\right)}{F\left(\alpha+\frac{\omega}{2}+\frac{\tilde{\omega}}{2} i\right)} \\
& \left.=(-1)^n \frac{F\left((2 n+1) \alpha+\frac{\omega}{2}+\frac{\varpi}{2} i\right)}{F\left(\alpha+\frac{\omega}{2}+\frac{\varpi}{2} i\right)}=(-1)^n \frac{F\left(\alpha+\frac{\varpi}{2} i\right)}{F\left((2 n+1) \alpha+\frac{\varpi}{2} i\right)} \cdot\right) \\
&
\end{aligned}
\]
pour \(\alpha=0\).

Ces expressions de \(A, A^{\prime}, A^{\prime \prime}\) deviendront de la forme \(\frac{0}{0}\) en faisant \(\alpha=0\), donc on trouvera d'après les règles connues
\[
A=\frac{1}{2 n+1}, A^{\prime}=A^{\prime \prime}=\frac{(-1)^n}{2 n+1} \text {. }
\]

D'après cela les trois premières formules deviendront
\[
\left\{\begin{array}{l}
\varphi(2 n+1) \beta=\frac{1}{2 n+1} \sum_{-n}^{+n} \sum_{-n}^{+n}(-1)^{m+\mu} \varphi\left(\beta+\frac{m \omega+\mu \tilde{v} i}{2 n+1}\right) \\
f(2 n+1) \beta=\frac{(-1)^n}{2 n+1} \sum_m^{+n} \sum_\mu^{+n}(-1)^m f\left(\beta+\frac{m \omega+\mu \tilde{\omega} i}{2 n+1}\right) \\
F(2 n+1) \beta=\frac{(-1)^n}{2 n+1} \sum_m^{+n} \sum_{-n}^{+n}(-1)^\mu F\left(\beta+\frac{m \omega+\mu \tilde{\omega} i}{2 n+1}\right) .
\end{array}\right.
\]

Pour avoir la valeur des constantes \(B, B^{\prime}, B^{\prime \prime}\), je remarque qu'on aura
%319
En appliquant cette transformation aux formules (125), en divisant la première par \(\varphi \beta\), la seconde par \(f \beta\) et la troisième par \(F \beta\), en faisant ensuite dans la première \(\beta=0\), dans la seconde \(\beta=\frac{\omega}{2}\) et dans la troisième \(\beta=\frac{\tilde{\omega}}{2} i\), et en remarquant que \(\frac{\varphi(2 n+1) \beta}{\varphi \beta}=2 n+1\), pour \(\beta=0\), que \(\frac{f(2 n+1) \beta}{f \beta}=(-1)^n\) \((2 n+1)\), pour \(\beta=\frac{\omega}{2}\), et que \(\frac{F(2 n+1) \beta}{F \beta}=(-1)^n(2 n+1)\), pour \(\beta=\frac{\omega}{2} i\), on trouvera
\[
\begin{aligned}
& \times \prod_1^n \prod_1^n F^2\left(\frac{\tilde{\omega}}{2} i+\frac{m \omega+\mu \tilde{\omega} i}{2 n+1}\right) F^2\left(\frac{\tilde{\omega}}{2} i+\frac{m \omega-\mu \tilde{\omega} i}{2 n+1}\right) . \\
&
\end{aligned}
\]

En tirant de ces équations les valeurs de \(B, B^{\prime}, B^{\prime \prime}\), et les substituant ensuite dans les formules transformées, il viendra
%320
\[
\begin{aligned}
& \times \stackrel{n}{1}_i \underset{1}{\Pi_\mu} \frac{f\left(\beta+\frac{m \omega+\mu \omega \tilde{\omega}}{2 n+1}\right) f\left(\beta-\frac{m \omega+\mu \omega i}{2 n+1}\right)}{f^2\left(\frac{\omega}{2}+\frac{m \omega+\mu \omega i}{2 n+1}\right)} \frac{f\left(\beta+\frac{m \omega-\mu \omega i}{2 n+1}\right) f\left(\beta-\frac{m \omega-\mu \omega i}{2 n+1}\right)}{f^2\left(\frac{\omega}{2}+\frac{m \omega-\mu \omega i}{2 n+1}\right)}, \\
& F(2 n+1) \beta= \\
& (-1)^n(2 n+1) F \beta \prod_1^n \frac{F\left(\beta+\frac{m \omega}{2 n+1}\right) F\left(\beta-\frac{m \omega}{2 n+1}\right)}{F^2\left(\frac{\infty}{2} i+\frac{m \omega}{2 n+1}\right)} \prod_1 \frac{F\left(\beta+\frac{\mu \omega i}{2 n+1}\right) F\left(\beta-\frac{\mu \omega i}{2 n+1}\right)}{F^2\left(\frac{\omega}{2} i+\frac{\mu \omega i}{2 n+1}\right)} \\
& \times \prod_1^n \prod_1^n \Pi_\mu \frac{F\left(\beta+\frac{m \omega+\mu \omega i}{2 n+1}\right) F\left(\beta-\frac{m \omega+\mu \omega i}{2 n+1}\right)}{F^2\left(\frac{\omega}{2} i+\frac{m \omega+\mu \omega i}{2 n+1}\right)} \frac{F\left(\beta+\frac{m \omega-\mu \omega i}{2 n+1}\right) F\left(\beta-\frac{m \omega-\mu \omega i}{2 n+1}\right)}{F^2\left(\frac{\omega}{2} i+\frac{m \omega-\mu \omega i}{2 n+1}\right)} . \\
&
\end{aligned}
\]

On peut donner à ces expressions des formes plus simples, en faisant usage des formules suivantes:
\[
\begin{aligned}
& \frac{\varphi(\beta+\alpha) \varphi(\beta-\alpha)}{\varphi^2 \alpha}=-\frac{1-\frac{q^2 \beta}{\varphi^2 \alpha}}{1-\frac{\varphi^2 \beta}{\varphi^2\left(\alpha+\frac{\omega}{2}+\frac{\omega}{2} i\right)}}, \\
& \frac{f(\beta+\alpha) f(\beta-\alpha)}{f^2\left(\frac{\omega}{2}+\alpha\right)}=-\frac{1-\frac{f^2 \beta}{f^2\left(\frac{\omega}{2}+\alpha\right)}}{1-\frac{f^2 \beta}{f^2\left(\alpha+\frac{\omega}{2}+\frac{\omega}{2} i\right)}}, \\
& \frac{F(\beta+\alpha) F(\beta-\alpha)}{F^2\left(\frac{\omega}{2} i+\alpha\right)}=-\frac{1-\frac{F^2 \beta}{F^2\left(\frac{\omega}{2} i+\alpha\right)}}{1-\frac{F^2 \beta}{F^2\left(\frac{\omega}{2}+\frac{\omega}{2} i+\alpha\right)}}, \\
&
\end{aligned}
\]
%321
qu'on vérifiera aisément au moyen des formules \((13),(16),(18)\).
En vertu de ces formules il est clair qu'on peut mettre les équations (129) sous la forme:
(130)
%322
Ces formules donnent, comme on le voit, les valeurs de \(\varphi(2 n+1) \beta\), \(f(2 n+1) \beta\) et \(F(2 n+1) \beta\), exprimées respectivement en fonction rationnelle de \(\varphi \beta, f \beta\) et \(F \beta\) sous forme de produits.

Nous domnerons encore les valeurs de \(f(2 n+1) \beta, F(2 n+1) \beta\) sous une autre forme, qui sera utile dans la suite.
On a \(f_o^2 \beta=1-c^2 \varphi^2 \beta\), done
et
\[
1-\frac{f^2 \beta}{f^2 \alpha}=\frac{c^2\left(q^2 \beta-\varphi^2 \alpha\right)}{f^2 \alpha}
\]
\[
1-\frac{f^2 \beta}{f^2\left(\frac{\oplus}{2} i+\alpha\right)}=\frac{c^2\left[\varphi^2 \beta-\varphi^2\left(\frac{\varpi}{2} i+\alpha\right)\right]}{f^2\left(\frac{\varpi}{2} i+\alpha\right)}
\]
or en vertu de l'équation (18) on a
done
\[
f^2\left(\frac{\tilde{v}}{2} i+\alpha\right)=\frac{e^2+c^2}{e^2} \cdot \frac{1}{f^2 \alpha}
\]
\[
\frac{1-\frac{f^2 \beta}{f^2 \alpha}}{1-\frac{f^2 \beta}{f^2\left(\frac{\grave{\omega}}{2} i+\alpha\right)}}=\frac{1}{f^4 \alpha} \frac{e^2+c^2}{e^2} \cdot \frac{\varphi^2 \alpha}{\varphi^2\left(\frac{\varpi}{2} i+\alpha\right)} \frac{1-\frac{\varphi^2 \beta}{\varphi^2 \alpha}}{1-\frac{\varphi^2 \beta}{\varphi^2\left(\frac{\varpi}{2} i+\alpha\right)}} .
\]

On trouvera de même
\[
\frac{1-\frac{F^2 \beta}{F^2 \alpha}}{1-\frac{F^2 \beta}{F^2\left(\frac{\omega}{2}+\alpha\right)}}=\frac{1}{F^4 \alpha} \frac{e^2+c^2}{c^2} \cdot \frac{\varphi^2 \alpha}{\varphi^2\left(\frac{\omega}{2}+\alpha\right)} \frac{1-\frac{\varphi^2 \beta}{\varphi^2 \alpha}}{1-\frac{\varphi^2 \beta}{\varphi^2\left(\frac{\omega}{2}+\alpha\right)}} .
\]

En vertu de ces formules, et en faisant \(\beta=0\) pour déterminer le facteur constant, il est clair qu'on peut écrire les expressions de \(f(2 n+1) \beta\), \(F(2 n+1) \beta\), conme il suit:
%323
\(\left(130^{\prime}\right)\)
Dans ce paragraphe nous n'avons considéré les fonctions \(\varphi(n \beta), f(n \beta)\), \(F(n \beta)\) que dans le cas des valeurs impaires de \(n\). On pourrait trouver des expressions analogues de ces fonctions pour des valeurs paires de \(n\); mais comme il n'y a à cela aucune difficulté, et que d'ailleurs les formules auxquelles nous sommes parvenus sont celles qui nous seront les plus utiles dans la suite, je ne m'en occuperai pas.
§ VII.
Développement des fonctions \(q \alpha, f \alpha, F \alpha\) en séries et en produits infinis.
24.
En faisant dans les formules du paragraphe précédent \(\beta=\frac{\alpha}{2 n+1}\), on obtiendra des expressions des fonctions \(\varsigma \alpha, f \alpha, F \alpha\), qui, à cause du nombre indéterminé \(n\), penvent être variées d'une infinité de manières.
%324
Parmi toutes les formules qu'on obtiendra ainsi, celles qui résultent de la supposition de \(n\) infini sont les plus remarquables. Alors les fonctions \(\varphi, f, F\) disparaîtront des valeurs de \(\varphi \alpha, f \alpha, F \alpha\), et on obtiendra pour ces fonctions des expressions algébriques, mais composées d'une infinité de ter-mes. Pour avoir ces expressions, il faut faire, dans les formules \((\mathbf{1 2 6}),(\mathbf{1 3 0})\), \(\beta=\frac{\alpha}{2 n+1}\), et ensuite chercher la limite du second membre de ces équations pour des valeurs toujours croissantes de \(n\). Pour abréger, soit \(v\) une quantité dont la limite est zéro pour des valeurs toujours croissantes de \(n\). Cela posé, considérons successivement les trois formules (126).

En faisant dans la première des formules (126) \(\beta=\frac{\alpha}{2 n+1}\), et remarquant que
(131)
\[
\begin{aligned}
& \underset{-n}{\sum_m} \sum_\mu^{+n} \boldsymbol{\theta}(m, \mu) \stackrel{\operatorname{man}}{=} \boldsymbol{\theta}(0,0)+\sum_1^n[\boldsymbol{\theta}(m, 0)+\boldsymbol{\theta}(-m, 0)]+\sum_{\boldsymbol{1}}^n[\boldsymbol{\theta}(0, \mu)+\boldsymbol{\theta}(0,-\mu)] \\
& +\sum_1^n \sum_1^n[\boldsymbol{\theta}(m, \boldsymbol{\mu})+\boldsymbol{\theta}(-m,-\boldsymbol{\mu})+\boldsymbol{\theta}(m,-\boldsymbol{\mu})+\boldsymbol{\theta}(-m, \boldsymbol{\mu})], \\
&
\end{aligned}
\]
il est clair qu'on peut mettre la formule dont il s'agit sous la forme:
\[
\begin{array}{r}
\varphi \alpha=\frac{1}{2 n+1} \cdot \varphi\left(\frac{\alpha}{2 n+1}\right)+\frac{1}{2 n+1} \sum_1^n(-1)^m\left[\varphi\left(\frac{\alpha+m \omega}{2 n+1}\right)+\varphi\left(\frac{\alpha-m \omega}{2 n+1}\right)\right] \\
+\frac{1}{2 n+1} \sum_1^n(-1)^\mu\left[\varphi\left(\frac{\alpha+\mu \tilde{\omega} i}{2 n+1}\right)+\varphi\left(\frac{\alpha-\mu \tilde{\omega} i}{2 n+1}\right)\right]-\frac{i}{e c} \sum_1^n \sum_1^n \sum_\mu(-1)^{m+\mu} \psi(n-m, n-\mu) \\
+\frac{i}{e c} \sum_1^n \sum_1^n \sum_\mu^n(-1)^{m+\mu} \psi_1(n-m, n-\mu),
\end{array}
\]
où l'on a fait pour abréger,
Maintenant, en remarquant que
\[
\varphi\left(\frac{\alpha+m \omega}{2 n+1}\right)+\varphi\left(\frac{\alpha-m \omega}{2 n+1}\right)=\frac{2 \varphi\left(\frac{\alpha}{2 n+1}\right) \cdot f\left(\frac{m \omega}{2 n+1}\right) \cdot F\left(\frac{m \omega}{2 n+1}\right)}{1+e^2 c^2 \cdot \varphi^2\left(\frac{m \omega}{2 n+1}\right) \cdot \varphi^2\left(\frac{\alpha}{2 n+1}\right)}=\frac{A_m}{2 n+1},
\]
%325
\[
\varphi\left(\begin{array}{c}
\alpha+\mu \tilde{\omega} i \\
2 n+1
\end{array}\right)+\varphi\left(\begin{array}{l}
\alpha-\mu \tilde{\omega} i \\
2 n+1
\end{array}\right)=\frac{2 \varphi\left(\frac{\alpha}{2 n+1}\right) \cdot f\left(\frac{\mu \omega i}{2 n+1}\right) \cdot F\left(\frac{\mu \omega i}{2 n+1}\right)}{1+e^2 c^2 \cdot \varphi^2\left(\frac{\mu \tilde{\omega} i}{2 n+1}\right) \cdot \varphi^2\left(\frac{\alpha}{2 n+1}\right)}=\frac{B_\mu}{2 n+1},
\]
où \(A_m\) et \(B_\mu\) sont des quantités finies, le second membre de l'équation (132) jusqu'au terme qui a le signe —, prendra la forme
\[
\frac{1}{2 n+1} \varphi \frac{\alpha}{2 n+1}+\frac{1}{(2 n+1)^2} \sum_1^n(-1)^m\left(A_m+B_m\right)
\]
or la limite de cette quantité est évidemment zéro; donc, en prenant la limite de la formule (132), on aura
\[
\begin{aligned}
\varphi \alpha=-\frac{i}{e c} \lim . \sum_1^n \sum_1^n(-1)^{m+\mu} \psi(n-m, n-\mu) \\
+\frac{i}{e c} \lim . \sum_1^n \sum_1^n(-1)^{m+\mu} \psi_1(n-m, n-\mu)
\end{aligned}
\]
ou bien:
\[
\begin{aligned}
\varphi \alpha=-\frac{i}{e c} \lim . \sum_0^{n-1} \sum_0^{n-1} \sum_\mu(-1)^{m+\mu} \psi & (m, u) \\
& +\frac{i}{e c} \lim . \sum_0^{n-1} \sum_0^{n-1} \sum_\mu(-1)^{m+\mu} \psi_1(m, u) .
\end{aligned}
\]

Il suffit de connaître l'une de ces limites, car on aura l'autre en changeant seulement le signe de \(i\). Cherchons la limite de
\[
\sum_0^{n-1} \sum_0^{n-1}(-1)^{m+\mu} \psi(m, \mu)
\]

Pour cela, il faut essayer de mettre la quantité précédente sous la forme
\[
P+v
\]
où \(P\) est indépendant de \(n\), et \(v\) une quantité qui a zéro pour limite; car alors la quantité \(P\) sera précisément la limite dont il s'agit.
25.
Considérons d'abord l'expression
\[
\sum_0^{n-1}(-1)^\mu \psi(m, \mu) .
\]

Soit
\[
\theta(m,, \prime)=\frac{2 \alpha}{\alpha^2-\left[\left(m+\frac{1}{2}\right) \omega+\left(\mu+\frac{1}{2}\right) \tilde{\omega} i\right]^2},
\]
%326
et faisons
\[
\psi(m, \mu)-\theta(m, \mu)=\frac{2 \alpha}{(2 u+1)^2} R_\mu
\]
on aura

Cela posé, je dis que le second membre de cette équation est une quantité de la forme \(\frac{v}{2 n+1}\).
I'après les formules (12), (13) on aura
\[
\frac{1}{\varphi(\beta+\varepsilon)}+\frac{1}{\varphi(\beta-\varepsilon)}=\frac{\varphi(\beta+\varepsilon)+\varphi(\beta-\varepsilon)}{\varphi(\beta+\varepsilon) \cdot \varphi(\beta-\varepsilon)}=\frac{2 \varphi \beta \cdot f \varepsilon \cdot F \varepsilon}{\varphi^2 \beta-\varphi^2 \varepsilon}
\]
done, en faisant \(\beta=\frac{\alpha}{2 n+1}\) et \(\varepsilon=\frac{\left(m+\frac{1}{2}\right)\left(\omega+\left(\mu+\frac{1}{2}\right) \tilde{\omega} i\right.}{2 n+1}=\frac{\varepsilon_\mu}{2 n+1}\) et \(f_{\varepsilon} \cdot F_{\varepsilon}=\theta \varepsilon\), on a
\[
\psi(m, \|)=\frac{1}{2 n+1} \cdot \frac{2 \uparrow\left(\frac{\alpha}{2 n+1}\right) \cdot \theta\left(\frac{\varepsilon_\mu}{2 n+1}\right)}{\digamma^2\left(\frac{\alpha}{2 n+1}\right)-\digamma^2\left(\frac{\varepsilon_\mu}{2 n+1}\right)} .
\]

Or on a
\[
\varphi\left(\frac{\alpha}{2 n+1}\right)=\frac{\alpha}{2 n+1}+\frac{A \alpha^3}{(2 n+1)^3}
\]
done
\[
\psi(m, \mu)=\frac{\theta\left(\frac{\varepsilon_\nu}{2 n+1}\right)}{\uparrow^2\left(\frac{\alpha}{2 n+1}\right)-\varphi^2\left(\frac{\varepsilon_\mu}{2 n+1}\right)}\left(\frac{2 \alpha}{(2 n+1)^2}+\frac{2 A \alpha^3}{(2 n+1)^4}\right),
\]
et par conséquent
\[
\begin{aligned}
& \psi(m, \mu)-\theta(m, \mu)=\frac{2 \alpha}{(2 n+1)^2}\left|\frac{\theta\left(\frac{\varepsilon_\mu}{2 n+1}\right)}{\varphi^2\left(\frac{\alpha}{2 n+1}\right)-\psi^2\left(\frac{\varepsilon_\mu}{2 n+1}\right)}-\frac{1}{\left(\frac{\alpha}{2 n+1}\right)^2-\left(\frac{\varepsilon_\mu}{2 n+1}\right)^2}\right| \\
& +\frac{2 A \alpha^3}{(2 n+1)^4} \cdot \frac{\theta\left(\frac{\varepsilon_\mu}{2 n+1}\right)}{\varphi^2\left(\frac{\alpha}{2 n+1}\right)-\varphi^2\left(\frac{\varepsilon_\mu}{2 n+1}\right)} \text {. } \\
&
\end{aligned}
\]

Donc la valeur de \(R_\mu\) deviendra
(138) \(R_\mu=\frac{\theta\left(\frac{\varepsilon_\mu}{2 n+1}\right)}{\vartheta^2\left(\frac{\alpha}{2 n+1}\right)-\uparrow^2\left(\frac{\varepsilon_\mu}{2 n+1}\right)}\left(1+\frac{A \alpha^2}{(2 n+1)^2}\right)-\frac{1}{\left(\frac{\alpha}{2 n+1}\right)^2-\left(\frac{\varepsilon_\mu}{2 n+1}\right)^2}\).
%327
Cela posé, il y a deux cas à considérer, suivant que \(\frac{\varepsilon_\mu}{2 n+1}\) a zéro pour limite ou non.
a) \(\mathrm{Si} \frac{\varepsilon_\mu}{2 n+1}\) a zéro pour limite, on aura
\[
\begin{gathered}
\varphi^2\left(\frac{\varepsilon_\mu}{2 n+1}\right)=\frac{\varepsilon_\mu^2}{(2 n+1)^2}+\frac{B_\mu \varepsilon_\mu^4}{(2 n+1)^4} \\
\theta\left(\frac{\varepsilon_\mu}{2 n+1}\right)=\sqrt{1-c^2 \varphi^2\left(\frac{\varepsilon_\mu}{2 n+1}\right)} \sqrt{1+e^2 \varphi^2\left(\frac{\varepsilon_\mu}{2 n+1}\right)}=1+\frac{C_\mu \varepsilon_\mu^2}{(2 n+1)^2} \\
\varphi^2\left(\frac{\alpha}{2 n+1}\right)=\frac{\alpha^2}{(2 n+1)^2+\frac{I \alpha^4}{(2 n+1)^4}}
\end{gathered}
\]
où \(B_\mu, C_\mu, D\) ont des limites finies; donc, en substituant,
\[
\begin{aligned}
R_\mu=A \alpha^2 \cdot \frac{\frac{1}{\varepsilon_\mu^2}+\frac{C_\mu}{(2 n+1)^2}}{\frac{\alpha^2}{\varepsilon_\mu^2}-1+\frac{D \alpha^4}{(2 n+1)^2 \cdot \varepsilon_\mu^2}-B_\mu \frac{\varepsilon_\mu^2}{(2 n+1)^2}} \\
+\frac{C_\mu \frac{\alpha^2}{\varepsilon_\mu^2}-\frac{D \alpha^4}{\varepsilon_\mu^4}-C_\mu+B_\mu}{\left(1-\frac{\alpha^2}{\varepsilon_\mu^2}\right)^2-\left(1-\frac{\alpha^3}{\varepsilon_\mu^2}\right)\left(\frac{D \alpha^4}{(2 n+1)^2 \varepsilon_\mu^2}-B_\mu(2 n+1)_\mu^2\right)}
\end{aligned}
\]
or que \(\varepsilon_\mu\) soit fini ou infini, il est clair que cette quantité convergera toujours vers une quantité finie pour des valeurs toujours croissantes de \(n\). Donc on aura
\[
R_\mu=r_\mu+v_\mu
\]
où \(r_\mu\) est une quantité finie indépendante de \(n\).
b) Si \(\frac{\varepsilon_\mu}{2 n+1}\) a pour limite une quantité finie, il est clair qu'en nommant cette limite \(\delta_\mu\), on aura
\[
R_\mu=-\frac{\theta\left(\delta_\mu\right)}{\rho^2\left(\delta_\mu\right)}+\frac{1}{\delta_\mu^2}+v_\mu{ }^{\prime} .
\]
- Cela posé, considérons l'expression \(\stackrel{n-1}{0}_\mu(-1)^\mu \frac{R_\mu}{(2 n+1)^2} \cdot \quad\) On a
\[
\begin{aligned}
& \text { (142) } \sum_0^{n-1}(-1)^\mu \frac{R_\mu}{(2 n+1)^2}=\frac{1}{(2 n+1)^2} \cdot\left[R_0-R_1+R_2-R_3+\cdots\right. \\
& \left.+(-1)^{\nu-1} R_{\nu-1}+(-1)^\nu\left(R_\nu-R_{\nu+1}+R_{\nu+2}-R_{\nu+3}+\cdots+(-1)^{n-\nu-1} R_{n-1}^{\prime}\right)\right] .
\end{aligned}
\]
%328
Supposons d'abord que \(\frac{\varepsilon_\mu}{2 n+1}\) ait pour limite une quantité finie, quelle que soit la valeur de \(\mu\). Alors, en remarquant que
on aura
\[
\begin{gathered}
\delta_{\mu+1}=\delta_\mu, \\
R_\mu \div R_{\mu+1}=v_\mu^{\prime}-v_{\mu+1}^{\prime}
\end{gathered}
\]
done
\[
\begin{gathered}
\delta_{\mu+1}=\delta_\mu \\
R_\mu-R_{\mu+1}=v_\mu^{\prime}-v_{\mu+1}^{\prime}
\end{gathered}
\]
\[
\begin{aligned}
\sum_0^{n-1} \sum_\mu(-1)^\mu \frac{R_\mu}{(2 n+1)^2}=\frac{1}{(2 n+1)^2}\left(v_0{ }^{\prime}-v_1{ }^{\prime}+v_2{ }^{\prime}-v_3{ }^{\prime}+\cdots\right. & +\cdots \\
& \left.+v_{k-2}^{\prime}-v_{k-1}^{\prime}\right)+\frac{B}{(2 u+1)^2}
\end{aligned}
\]
où \(k=n\) ou \(n-1\), selon que \(n\) est pair ou impair. La quantité \(B\) a tonjours pour limite une quantité finie, savoir \(B=0\) si \(n\) est pair, et \(B=R_{n-1}\) si \(n\) est impair.
Maintenant on sait qu'une somme telle que
\[
v_0{ }^{\prime}-v_1{ }^{\prime}+v_2{ }^{\prime}-\cdots+v_{k-2}^{\prime}-v_{k-1}^{\prime}
\]
peut être mise sous la forme \(k v, v\) ayant zéro pour limite. Donc en substituant
\[
\sum_0^{n-1}(-1)^\mu \frac{R_\mu}{(2 n+1)^2}=\frac{k v+B}{(2 n+1)^2}
\]
or, \(k\) étant égal à \(n\) ou à \(n-1\), et \(B\) fini, la limite de \(\frac{k v+B}{2 n+1}\) sera zéro, done
\[
\sum_0^{n-1}(-1)^\mu \frac{R_\mu}{(2 n+1)^2}=\frac{v}{2 n+1} .
\]

Supposons maintenant que \(\frac{m}{2 n+1}\) ait zéro pour limite. Alors \(\frac{\varepsilon_\mu}{2 n+1}\) a également zéro pour limite, à moins qu'en même temps \(\frac{\mu}{2 n+1}\) n'ait pour limite une quantité finie. Soit dans ce cas \(v\) le nombre entier immédiatement inférieur à \(\sqrt{n}\), et considérons la somme
\[
R_0-R_1+R_2-R_3+\cdots+(-1)^{\nu-1} R_{\nu-1} \text {. }
\]

En supposant que \(\mu\) soit un des nombres \(0,1, \ldots v\), il est clair que \(\frac{\varepsilon_\mu}{(2 n+1)}=\frac{\left(m+\frac{1}{2}\right) \omega+\left(\mu+\frac{1}{2}\right) \hat{u} i}{2 n+1}\) a zéro pour limite; donc, selon ce qu'on a vu, \(R_\mu\) sera une quantité finie, et par conséquent
\[
R_0-R_1+R_2-\cdots+(-1)^{v-1} R_{v_{-1}}=\nu \cdot R
\]
%329
où \(R\) est également une quantité finie.
Considérons maintenant la somme
\[
(-1)^v\left(R_v-R_{v+1}+R_{v+2}-\cdots+(-1)^{n-v-1} \cdot R_{n-1}\right) .
\]

Si \(\frac{\varepsilon_\mu}{2 u+1}\) a pour limite une quantité différente de zéro, on a, comme on l'a vu,
\[
R_\mu-R_{\mu+1}=v_\mu^{\prime}-v_{\mu+1}^{\prime}
\]
si au contraire \(\frac{\varepsilon_\mu}{2 u+1}\) a pour limite zéro, on a
\[
R_\mu=r_\mu+v^{\prime}{ }^{\prime}
\]
or, si en même temps \(\mu>\sqrt{n}\), il est clair qu'en vertu de la valeur de \(l_\mu\),
\[
r_\mu=B_\mu-C_\mu
\]
or il est clair que \(B_\mu\) et \(C_\mu\), tous deux, ont pour limites des quantités indépendantes de,\(\mu\), done en nommant ces limites \(B\) et \(C\), on aura
\[
R_\mu=B-C+v_\mu
\]
et par suite, aussi dans ce cas,
\[
R_\mu-R_{\mu+1}=v_\mu-v_{\mu+1} .
\]

Donc, comme dans le cas où \(\frac{\varepsilon_\mu}{2 u+1}\) aurait une limite différente de zéro pour toutes les valeurs de \(\mu\), on démontrera que
\[
\frac{(-1)^v}{(2 n+1)^2}\left(R_v-R_{v+1}+\cdots+(-1)^{n-v-1} R_{n-1}\right)=\frac{v}{(2 n+1)} .
\]

Maintenant en combinant les équations ci-dessus, on en tirera
\[
\sum_0^{n-1}(-1)^\mu \frac{R_\mu}{(2 n+1)^2}=\frac{1}{(2 n+1)^2} \cdot \nu R+\frac{v}{2 n+1}
\]
or \(\frac{\nu}{2 n+1}\) a zéro pour limite, donc
\[
\sum_0^{n-1}(-1)^\mu \frac{R_\mu}{(2 n+1)^2}=\frac{v}{2 n+1} .
\]

Donc cette formule a toujours lieu, et par conséquent la formule (137) deviendra
\[
\sum_0^{n-1}(-1)^\mu \psi(m, \mu)-\sum_0^{n-1}(-1)^\mu \theta(m, \mu)=\frac{v}{2 n+1} .
\]
%330
Or c'est ce qu'on peut faire comme il suit. On a
\((145)\left\{\begin{array}{l}n=1 \\ \sum_\mu(-1)^\mu \boldsymbol{\theta}(m, \boldsymbol{\mu})=\sum_0^{\infty}(-1)^\mu \boldsymbol{\theta}(m, \boldsymbol{\mu})-\sum_n^{\infty}(-1)^\mu \boldsymbol{\theta}(m, \boldsymbol{\mu}), \\ \vdots \\ \sum_n^{\infty}(-1)^\mu \boldsymbol{\theta}(m, \mu)=(-1)^n[\boldsymbol{\theta}(m, n)-\boldsymbol{\theta}(m, n+1)+\boldsymbol{\theta}(m, n+2)-\cdots]\end{array}\right.\)
Or d'après une formule commue on a
\[
\begin{aligned}
& \boldsymbol{\theta}(m, n)-\boldsymbol{\theta}(m, n+1)+\boldsymbol{\theta}(m, n+2)-\cdots \\
& \quad=\frac{1}{2} \boldsymbol{\theta}(m, n)+A \frac{d \theta(m, n)}{d n}+B \frac{d^3 \theta(m, n)}{d n^3}+\cdots,
\end{aligned}
\]
où \(A, B \ldots\) sont des nombres; or
\[
\boldsymbol{\theta}(m, n)=\frac{2 \alpha}{\alpha^2-\left[\left(m+\frac{1}{2}\right) \omega+\left(n+\frac{1}{2}\right) \omega i\right]^2},
\]
done en substituant
\[
\begin{aligned}
\boldsymbol{\theta}(m, n) & -\boldsymbol{\theta}(m, n+1)+\cdots \\
= & \frac{\alpha}{\alpha^2-\left[\left(m+\frac{1}{2}\right) \omega+\left(n+\frac{1}{2}\right) \tilde{\omega} i\right]^2}+\frac{4 A \alpha \omega i\left[\left(m+\frac{1}{2}\right)\left(\omega+\left(n+\frac{1}{2}\right) \tilde{\omega} i\right]\right.}{\left[\alpha^2-\left(\left(m+\frac{1}{2}\right)\left(\omega+\left(n+\frac{1}{2}\right) \tilde{\omega}\right)^2\right]^2\right.}+\cdots
\end{aligned}
\]

De là il suit que
\[
\boldsymbol{\theta}(m, n)-\boldsymbol{\theta}(m, n+1)+\cdots=\frac{\alpha}{\omega^2 n^2}+\frac{v}{n^2}=\frac{v}{2 n+1} .
\]

Done en vertu des équations (145)
et par conséquent
\[
{\underset{0}{0}}_{n-1}^{\Sigma_\mu}(-1)^\mu \psi(m, \mu)=\stackrel{\Sigma}{0}_\mu^{\infty}(-1)^\mu \cdot \theta(m, \mu)+\frac{v}{2 n+1} .
\]
26.

Ayant transformé de cette sorte la quantité \({ }_0^{n-1} \Sigma_\mu(-1)^\mu \cdot \psi(m, \mu)\), on tire de l'équation (146)
%331
\[
\sum_0^{n-1} \sum_0^{n-1}(-1)^{m+\mu} \psi(m, \mu)=\stackrel{n}{0}_{\Sigma}^{\Sigma}(-1)^m \cdot \varrho_m+\sum_0^{n-1} \frac{v_m}{2 n+1},
\]
en faisant
\[
\varrho_m=\sum_0^{\infty}(-1)^\mu \cdot \theta(m, \mu)
\]
or
\[
\sum_0^{n-1} \frac{v_m}{2 n+1}=\frac{v_0+v_1+v_2+\cdots+v_{n-1}}{2 n+1}=\frac{n v}{2 n+1}=\frac{v}{2},
\]
\(v\) ayant zéro pour limite. Done l'équation (147) domnera, en faisant \(n\) in- . fini,
\[
\lim . \sum_0^{n-1} \sum_0^{n-1}(-1)^{m+\mu} \psi(m,, \prime)=\sum_0^{\infty}(-1)^m \cdot \Theta_m .
\]

De même, si l'on fait, pour abrégerer,
\[
\left\{\begin{array}{l}
\theta_1(m, \mu)=\frac{2 \alpha}{\alpha^2-\left[\left(m+\frac{1}{2}\right)\left(\omega-\left(\mu+\frac{1}{2}\right) \tilde{\omega} i\right]^2\right.}, \\
\varrho_m{ }^{\prime}=\sum_0^{\infty}(-1)^\mu \theta_1(m, \mu),
\end{array}\right.
\]
on allia
\[
\lim . \sum_0^{n-1} \sum_0^{n-1} \sum_\mu(-1)^{m+\mu} \psi_1(m, \mu)=\sum_0^{\infty}(-1)^m \varrho_m{ }^{\prime} .
\]

Ayant trouvé les deux quantités dont l'expression de \(q \alpha\) est composée, on aura en substituant
\[
\varphi \alpha=-\frac{i}{e c} \sum_0^{\infty}(-1)^m \varrho_m+\frac{i}{e c} \sum_0^{\infty}(-1)^m \varrho_m^{\prime}=\frac{i}{e c} \cdot \sum_0^{\infty}(-1)^m\left(\varrho_m{ }^{\prime}-\varrho_m\right),
\]
ou bien, en remettant les valeurs de \(\varrho_m{ }^{\prime}\) et \(\varrho_m\), (152) \(\varphi \alpha=\)

Maintenant
\[
\frac{2 \alpha}{\alpha^2-\left[\left(m+\frac{1}{2}\right) \omega \pm\left(\mu+\frac{1}{2}\right) \tilde{\omega} i\right]^2}=\frac{1}{\alpha-\left(m+\frac{1}{2}\right) \omega \mp\left(\mu+\frac{1}{2}\right) \tilde{\omega} i}+\frac{1}{\alpha+\left(m+\frac{1}{2}\right) \omega \pm\left(\mu+\frac{1}{2}\right) \tilde{\omega} i} .
\]
done
\[
\begin{aligned}
& \frac{2 \alpha}{\alpha^2-\left[\left(m+\frac{1}{2}\right) \omega-\left(\mu+\frac{1}{2}\right) \tilde{\omega} i\right]^2}-\frac{2 \alpha}{\alpha^2-\left[\left(m+\frac{1}{2}\right) \omega+\left(\mu+\frac{1}{2}\right) \tilde{\omega} i\right]^2} \\
& =\frac{(2 \mu+1) \tilde{\omega} i}{\left[\alpha+\left(m+\frac{1}{2}\right) \omega\right]^2+\left(\mu+\frac{1}{2}\right)^2 \tilde{\omega}^2}-\frac{(2 \mu+1) \tilde{\omega} i}{\left[\alpha-\left(m+\frac{1}{2}\right) \omega\right]^3+\left(\mu+\frac{1}{2}\right)^2 \tilde{\omega}^2}, \\
&
\end{aligned}
\]
%332
donc l'expression de \(\varphi \alpha\) prendra la forme réelle:
(153) \(\varphi \alpha=\)
\[
\frac{1}{e c} \cdot \sum_m^{\infty}(-1)=\sum_0^{\infty}(-1)^\mu\left(\frac{(2 \mu+1) \tilde{\omega}}{\left[\alpha-\left(m+\frac{1}{2}\right) \omega\right]^2+\left(\mu+\frac{1}{2}\right)^2 \tilde{\omega}^2}-\frac{(2 \mu+1) \tilde{\omega}}{\left[\alpha+\left(m+\frac{1}{2}\right) \omega\right]^2+\left(\mu+\frac{1}{2}\right)^2 \hat{\omega}^z}\right),
\]
c'est-à-dire qu'on aura
\[
\begin{aligned}
\varphi \alpha= & \frac{\tilde{\omega}}{e c}\left(\delta_0-\delta_1+\delta_2-\delta_3+\cdots+(-1) \delta_m \ldots\right) \\
& -\frac{\tilde{\omega}}{e c}\left(\delta_0^{\prime}-\delta_1^{\prime}+\delta_2^{\prime}-\delta_3^{\prime}+\cdots+(-1)^m \delta_m^{\prime} \ldots\right),
\end{aligned}
\]
vù
\[
\left\{\begin{array}{l}
\delta_m=\frac{1}{\left[\alpha-\left(m+\frac{1}{2}\right)(\cdot]^2+\frac{\sigma^2}{4}\right.}-\frac{3}{\left[\alpha-\left(m+\frac{1}{2}\right)(\omega]^2+\frac{9 \omega^2}{4}\right.}+\frac{5}{\left[\alpha-\left(m+\frac{1}{2}\right)(\omega]^2+\frac{25 \omega^2}{4}\right.}-\cdots \\
\delta_m^{\prime}=\frac{1}{\left[\alpha+\left(m+\frac{1}{2}\right)(\omega]^2+\frac{\omega^2}{4}\right.}-\frac{3}{\left[\alpha+\left(m+\frac{1}{2}\right)(\omega]^2+\frac{9 \omega^2}{4}\right.}+\frac{5}{\left[\alpha+\left(m+\frac{1}{2}\right)(\omega]^2+\frac{25 \omega^2}{4}\right.}-\cdots
\end{array}\right.
\]

Si l'on commence la recherche de la limite de la fouction \(\Sigma_0^{n-1} \Sigma_0^{n-1} \Sigma_\mu(-1)^{m+\mu} \psi(m, \mu)\) par celle de \(\sum_0^{n-1}(-1)^m \psi(m, \mu)\) au lieu de celle de \(\sum_0^{n-1}(-1)^\mu \psi(m, \mu)\), comme nous l'avons fait, on trouvera, au lieu de la formule (153), la suivante
(156) \(\varphi \alpha=\)
\[
\frac{1}{e} \cdot \sum_0^{\infty}(-1)^\mu \sum_0^{\infty}(-1)=\left(\frac{(2 \mu+1) \tilde{\omega}}{\left[\alpha-\left(m+\frac{1}{2}\right) \omega\right]^2+\left(\mu+\frac{1}{2}\right)^3 \tilde{\omega}^2}-\frac{(2 \mu+1) \tilde{\omega}}{\left[\alpha+\left(m+\frac{1}{2}\right) \omega\right]^2+\left(\mu+\frac{1}{2}\right)^2 \tilde{\omega}^2}\right),
\]
c'est-à-dire
\[
\begin{aligned}
\varphi \alpha & =\frac{\tilde{v}}{e c}\left(\varepsilon_0-3 \dot{\varepsilon}_1+5 \varepsilon_2-7 \varepsilon_3+\cdots+(-1)^\mu(2 \mu+1) \varepsilon_\mu+\ldots\right) \\
& -\frac{\tilde{\omega}}{e c}\left(\varepsilon_0^{\prime}-3 \varepsilon_1^{\prime}+5 \varepsilon_2^{\prime}-7 \varepsilon_3^{\prime}+\cdots+(-1)^\mu(2 u+1) \varepsilon_\mu^{\prime}+\ldots\right),
\end{aligned}
\]
où
\[
\left\{\begin{array}{l}
\varepsilon_\mu=\frac{1}{\left(\alpha-\frac{\omega}{2}\right)^2+\left(\mu+\frac{1}{2}\right)^2 \tilde{\omega}^3}-\frac{1}{\left(\alpha-\frac{3 \omega}{2}\right)^2+\left(\mu+\frac{1}{2}\right)^2 \tilde{v}^2}+\frac{1}{\left(\alpha-\frac{5 \omega}{2}\right)^2+\left(\mu+\frac{1}{2}\right)^2 \tilde{\omega}^2}-\cdots \\
\varepsilon_\mu^{\prime}=\frac{1}{\left(\alpha+\frac{\omega}{2}\right)^2+\left(\mu+\frac{1}{2}\right)^2 \tilde{\omega}^2}-\frac{1}{\left(\alpha+\frac{3 \omega}{2}\right)^2+\left(\mu+\frac{1}{2}\right)^2 \tilde{\omega}^2}+\frac{1}{\left(\alpha+\frac{5 \omega}{2}\right)^2+\left(\mu+\frac{1}{2}\right)^2 \hat{\omega}^2}-\cdots
\end{array}\right.
\]
%333
27.
Cherchons maintenant l'expression de \(f \alpha\) au moyen de la deuxième des formules (126). En vertu de l'équation (131) le second membre prend la forme suivante:

En y faisant \(\beta=\frac{\alpha}{2 n+1}\), et en remarquant qu'alors la linite des quantités contenues dans les deux premières lignes devient égale à zéro, on aura
\[
\begin{aligned}
f \alpha & =\lim \cdot(-1)^n \sum_m^n \sum_1^n(-1)^m \cdot \psi(n-m, n-! \prime) \\
& +\lim .(-1)^n \sum_1^n \sum_1^n(-1)^m \cdot \psi_1(n-m, n-u),
\end{aligned}
\]
oì l'on a fait, pour abréger,
\[
\begin{aligned}
& \psi(n-m, n-\mu)=\frac{1}{2 n+1}\left[f\left(\frac{\alpha+m \omega+\mu \tilde{\omega} i}{2 n+1}\right)+f\left(\frac{\alpha-m \omega-\mu(\tilde{\omega} i}{2 n+1}\right)\right], \\
& \psi_1(n-m, n-\mu)=\frac{1}{2 n+1}\left[f\left(\frac{\alpha+m \omega-\mu \tilde{\omega} i}{2 n+1}\right)+f\left(\frac{\alpha-m \omega+\mu(\tilde{\omega} i}{2 n+1}\right)\right] .
\end{aligned}
\]

Maintenant on a
\[
f(\beta+\varepsilon)+f(\beta-\varepsilon)=\frac{2 f \beta \cdot f \varepsilon}{1+e^3 e^2 q^2 \varepsilon \cdot q^2 \beta}=\frac{f \varepsilon}{e^2 c^2 q^2 \varepsilon} \cdot \frac{2 f \beta}{q^2 \beta+\frac{1}{e^2 c^2 q^3 \varepsilon}} .
\]

Soit
\[
\varepsilon=\frac{m(1)+\mu \tilde{0} i}{2 n+1},
\]
on allra
\[
\frac{1}{{ }^\nu \varepsilon}=-i e c \cdot \varphi\left(\frac{(1)}{2}+\frac{\tilde{n})}{2} i-\varepsilon\right)=-i e c \cdot \varphi\left(\frac{\left(n-m+\frac{1}{2}\right) \omega+\left(n-n+\frac{1}{2}\right) \cdots i}{2 n+1}\right)
\]
%334
\[
\begin{aligned}
\frac{f \varepsilon}{{ }^f \varepsilon}=-\frac{i \sqrt{e^2+c^2}}{F\left(\varepsilon-\frac{i i}{2} i\right)}=-i \sqrt{e^2+e^2} \cdot \frac{c}{\sqrt{e^2+c^2}} \cdot F\left(\varepsilon-\frac{\omega}{2}-\frac{\hat{v}}{2} i\right) \\
=-c i \cdot F\left(\frac{\left(n-m+\frac{1}{2}\right) \omega+\left(n-\mu+\frac{1}{2}\right) \tilde{\omega} i}{2 n+1}\right)
\end{aligned}
\]

Done on aura, en substituant et en mettant \(m\) et \(\mu\) respectivement au lieu de \(n-m\) et \(n-"\),

On aura la valeur de \(\psi_1(m, n)\), en changeant seulement le signe de \(i\). En faisant maintenant
et
\[
\theta(m,, \prime)=-\frac{(2 m+1) \omega+(2 \mu+1) \tilde{\omega} i}{\alpha^2-\left[\left(m+\frac{1}{2}\right) \omega+\left(\mu+\frac{1}{2}\right) \tilde{\omega} i\right]^2}
\]
\[
\theta_1(m, \prime \prime)=-\frac{(2 m+1) \omega-(2 \mu+1) \tilde{\omega} i}{\alpha^2-\left[\left(m+\frac{1}{1}\right) \omega-\left(\mu+\frac{1}{2}\right) \tilde{\omega} i\right]^2},
\]
et en cherchant ensuite la limite de la fonction
\[
\sum_0^{n-1} \sum_0^{n-1}(-1)^m \cdot \psi(m, \prime \prime)
\]
de la même manière que précédemment, on trouvera
\[
\lim . \sum_0^{n-1} \sum_0^{n-1}(-1)^m \cdot \psi(m, \mu)=\frac{1}{e} \cdot \sum_0^{\infty}\left(\sum_0^{\infty}(-1)^m \cdot \theta(m, \mu)\right)
\]
et
\[
\lim . \sum_0^{n-1} \sum_0^{n-1}(-1)^m \cdot \psi_1(m,, \prime)=\frac{1}{e} \cdot \sum_0^{\infty}\left(\sum_0^{\infty}(-1)^m \cdot \theta_1(m,, \prime)\right)
\]
donc en substituant dans (159), et en remettant les valeurs de \(\boldsymbol{\theta}(m, \boldsymbol{\prime \prime})\) et \(\theta_1(m, \prime \prime)\), on a
\[
\text { (160) } f \alpha=
\]
\(-\frac{1}{e} \cdot \sum_0^{\infty} \sum_0^{\infty}(-1)^m\left(\frac{(2 m+1) \omega+(2 \mu+1) \tilde{\omega} i}{\alpha^2-\left[\left(m+\frac{1}{2}\right) \omega+\left(\mu+\frac{1}{2}\right) \omega i\right]^2}+\frac{(2 m+1) \omega-(2 \mu+1) \hat{\omega} i}{\alpha^2-\left[\left(m+\frac{1}{2}\right) \omega-\left(\mu+\frac{1}{2}\right) \omega i\right]^2}\right)\).
La quantité renfermée entre les crochets peut aussi se mettre sous la forme
\[
\frac{2\left[\alpha-\left(m+\frac{1}{2}\right) \omega\right]}{\left[\mu-\left(m+\frac{1}{2}\right) \omega\right]^2+\left(\mu+\frac{1}{2}\right)^2 \hat{\omega}^2}-\frac{2\left[\alpha+\left(m+\frac{1}{2}\right) \omega\right]}{\left[\mu+\left(m+\frac{1}{2}\right) \omega\right]^2+\left(\mu+\frac{1}{2}\right)^2 \hat{\omega}^2}
\]
%335
donc on a aussi
(161) \(f \alpha=\)
\[
\frac{1}{e} \cdot \sum_0^{\infty}\left(\sum_0^{\infty}(-1)^m \frac{2\left[\alpha+\left(m+\frac{1}{2}\right)(\omega]\right.}{\left[\alpha+\left(m+\frac{1}{2}\right)(\omega]^2+\left(\mu+\frac{1}{2}\right)^2 \hat{\theta}^2\right.}-\sum_0^{\infty}(-1)^m \cdot \frac{2\left[\alpha-\left(m+\frac{1}{2}\right)(\omega]\right.}{\left[\alpha-\left(m+\frac{1}{2}\right)(\omega]^z+\left(\mu+\frac{1}{2}\right)^2 \hat{\omega}^z\right.}\right) .
\]

On aura de la même manière
(162) \(F \alpha=\)
28.
Venons maintenant aux formules (130). Pour trouver la valeur du second membre, après avoir fait \(\beta=\frac{\alpha}{2 n+1}\), et supposé \(n\) infini, nous allons d'abord chercher la limite de l'expression suivante:
\[
t=\prod_1^n \prod_1^n \frac{1-\frac{\varphi^2\left[\frac{\alpha}{2 n+1}\right]}{\varphi^2\left[\frac{m \omega+\mu \omega i+k}{2 n+1}\right]}}{1-\frac{\varphi^2\left[\frac{\alpha}{2 n+1}\right]}{\varphi^2\left[\frac{m \omega+\mu \dot{i} i+l}{2 n+1}\right]}},
\]
où \(k\) et \(l\) sont deux quantités indépendantes de \(n, m, u\).
En prenant le logarithme, et en faisant pour abréger
on allia
\[
\log t=\sum_1^n \sum_1^n \psi(m, 11)
\]

Considérons d'abord l'expression \(\sum_1^n \mu(m, \mu)\). Soit
%336
\[
\theta(m, \mu)=\log \frac{1-\frac{\mu^3}{(m \omega+\mu \dot{\omega} i+k)^3}}{1-\frac{\alpha^2}{(m \omega+\mu \omega i+l)^2}}
\]
oll allia

Cela posé, je dis que le second membre de cette équation est pour toute valeur de \(m\) et " de la forme
\[
\psi(m, \prime \prime)-\theta(m, \prime \prime)=\frac{v}{(2 n+1)^2} .
\]

Pour le démontrer, il faut distinguer deux cas, suivant que la limite de \(\frac{m(1)+\mu(u i i}{2 n+1}\) est une quantité différente de zéro, ou égale à zéro.
a) Dans le premier cas on aura, en nommant \(a\) la limite dont il s'agit,
\[
\begin{gathered}
\varphi^2\left(\frac{m(1)+\mu \tilde{v} i+k}{2 n+1}\right)=\varphi^2 a+v, \\
\varphi^2\left(\frac{m(1)+\mu \tilde{\omega} i+l}{2 n+1}\right)=\varphi^2 a+v^{\prime}, \\
\varphi^2\left(\frac{\alpha}{2 n+1}\right)=\frac{\alpha^2}{(2 n+1)^2}+\frac{v^{\prime \prime}}{(2 n+1)^2},
\end{gathered}
\]
done
\[
\begin{aligned}
& 1-\frac{\varphi^2\left[\frac{\alpha}{2 n+1}\right]}{\varphi^2\left[\frac{m \omega+\mu \omega \dot{\omega} i+k}{2 n+1}\right]}=1-\frac{\alpha^2}{(2 n+1)^2 \varphi^2 a}+\frac{v}{(2 n+1)^2}, \\
& 1-\frac{\varphi^2\left[\frac{\alpha}{2 n+1}\right]}{\varphi^2\left[\frac{m \omega+\mu \omega i+l}{2 n+1}\right]}=1-\frac{\alpha^2}{(2 n+1)^2 \varphi^2 a}+\frac{v^{\prime}}{(2 n+1)^2} .
\end{aligned}
\]

On a de même
\[
\begin{aligned}
& 1-\frac{\alpha^2}{(m \omega+\mu \omega i+k)^2}=1-\frac{\alpha^2}{(2 n+1)^2\left[\frac{m \omega+\mu \omega i+k}{2 n+1}\right]^2}=1-\frac{\alpha^2}{(2 n+1)^2 a^2}+\frac{v}{(2 n+1)^2} \\
& 1-\frac{\alpha^2}{(m \omega+\mu \omega i+l)^2}=1-\frac{\alpha^2}{(2 n+1)^2 a^2}+\frac{v^{\prime}}{(2 n+1)^2}
\end{aligned}
\]
%337
En substituant ces valeur's, l'expression de \(\psi(m, \mu)-\boldsymbol{\theta}(m, \|)\) prendra la forme:
\[
\psi(m, \mu)-\theta(m, \mu)=\log \left\{\frac{1-\frac{v}{(2 n+1)^2}}{1-\frac{v^{\prime}}{(2 n+1)^2}} \cdot \frac{1-\frac{v_1}{(2 n+1)^2}}{1-\frac{v_1^{\prime}}{(2 n+1)^2}}\right\},
\]
les quantités \(v, v^{\prime}, v_1, v_1{ }^{\prime}\) ayant toutes zéro pour limite. On a
\[
\log \left(1-\frac{v}{(2 n+1)^2}\right)=\frac{v}{(2 n+1)^2} \text { etc.; }
\]
par conséquent
\[
\psi(m, \prime \prime)-\theta(m, \prime \prime)=\frac{v}{(2 n+1)^2} .
\]
b) Si la limite de la quantité \(\frac{m(\omega)+\mu \omega \hat{i}}{2 n+1}\) est égale à zéro, on aura
\[
\begin{gathered}
\varphi^2\left(\frac{m(1)+\mu \tilde{\omega} i+k}{2 n+1}\right)=\frac{(m(1)+\mu \tilde{\omega} i+k)^2}{(2 n+1)^2}+A \cdot \frac{\left(m(\omega)+\mu(\tilde{\omega} i+k)^4\right.}{(2 n+1)^4}, \\
\varphi^2\left(\frac{\alpha}{2 n+1}\right)=\frac{\alpha^2}{(2 n+1)^2}+A^{\prime} \cdot \frac{\alpha^4}{(2 n+1)^4}
\end{gathered}
\]
donc
\[
1-\frac{\digamma^2\left[\frac{\alpha}{2 n+1}\right]}{\varphi^2\left[\frac{m(\omega+\mu) i+k}{2 n+1}\right]}=1-\frac{\alpha^2+A^{\prime} \frac{\mu^4}{(2 n+1)^2}}{(m \omega+\mu(\omega) i+k)^2+A \frac{(m \omega)+\mu(\omega) i+k)^4}{-(2 n+1)^2}} .
\]

Si maintenant \(m \omega+\mu \widetilde{\omega} i\) ne va pas en angmentant indéfiniment avec \(n\), on aura
\[
1-\frac{\tau^2\left[\frac{n}{2 n+1}\right]}{f^2\left[\frac{m(\omega)+\mu \omega i+k}{2 n+1}\right]}=1-\frac{\alpha^3}{(m(\omega)+\mu \hat{\omega} i+k)^2}+\frac{B}{(2 n+1)^2}
\]
de même
\[
1-\frac{\tau^2\left[\frac{\|}{2 n+1}\right]}{\tau^2\left[\frac{m(1)+\mu(i) i+l}{2 n+1}\right]}=1-\frac{\alpha^3}{\left(m(1)+\mu(\tilde{u} i+l)^2\right.}+\frac{C}{(2 n+1)^2}
\]
done dans ce cas
\[
\psi(m,, \prime)-\theta(m, \mu)=\log \frac{1-\frac{B^{\prime}}{(2 n+1)^2}}{1-\frac{C^{\prime \prime}}{(2 n+1)^2}}
\]
\(B^{\prime}\) et \(C^{\prime \prime}\) ayant des limites finies, on bien
%338
\[
\psi(m, \mu)-\theta(m, \mu)=\frac{D}{(2 n+1)^2}
\]
la limite de \(D\) étant également une quantité finie.
Si all contraire la quantité \(m \omega+\mu \widetilde{0} i\) augmente indéfiniment avec \(n\), on a
or les quantités \(\frac{1}{m \omega+\mu \tilde{\omega} i+k}, \frac{m \omega+\mu \tilde{\omega} i+k}{2 n+1}\) ont zéro pour limite; donc la quantité précédente sera de la forme
\[
1+\frac{\alpha^2}{(2 n+1)^2} \cdot A^{\prime \prime}
\]
\(A^{\prime \prime}\) ayant une quantité tinie pour limite. En changeant \(k\) en \(l\), et désignant la valeur correspondante de \(A^{\prime \prime}\) par \(A_1{ }^{\prime \prime}\), la valeur de \(\psi(m, \mu)-\theta(m, \|)\) deviendra
\[
\psi(m, \|)-\theta(m, \mu)=\log \frac{1+\frac{\alpha^2}{(2 n+1)^2} A^{\prime \prime}}{1+\frac{\alpha^2}{(2 n+1)^2} A_1^{\prime \prime}}=\frac{\alpha^2\left(A^{\prime \prime}-A_1^{\prime \prime}\right)}{(2 n+1)^2}+\frac{v}{(2 n+1)^2} .
\]

Maintenant la limite de \(A^{\prime \prime}\) est la même que celle de \(A\); or il est clair que cette dernière limite est indépendante de \(k, m, "\) (elle est en effet égale au coefficient de \(\alpha^4\) dans le développement de \(\varphi^2 \alpha\) ). Donc on aura
\[
A^{\prime \prime}=M+v
\]
et en changeant \(k\) en \(l\),
\[
A_1^{\prime \prime}=M+v^{\prime}
\]
d'où \(A^{\prime \prime}-A_1^{\prime \prime}=v-v^{\prime}=v\). Donc \(A^{\prime \prime}-A_1^{\prime \prime}\) a zéro pour limite, et par conséquent on a
\[
\psi(m, \mu)-\theta(m, \|)=\frac{v}{(2 n+1)^2} .
\]

Done nous avons démontré, qu'en faisant
\[
\psi(m, \mu)-\theta(m, \mu)=\frac{A_{m, \mu}}{(2 n+1)^2}
\]
%339
la limite de \(A_{m, \mu}\) sera égale à zéro toutes les fois que \(m \omega+\mu \bar{\omega} i\) augmente indéfiniment avec \(n\), et qu'elle sera égale ì une quantité finie dans le cas contraire.
29.
Cela posé, considérons la quantité \(\sum_1^n \psi(m, ı)\). En substituant la valeur de \(\psi(m, \prime \prime)\), il viendra:
\[
\sum_1^n \psi(m, \mu)=\sum_\mu^n \theta(m, \mu)+\frac{1}{(2 n+1)^2} \cdot \sum_1^n A_{m, \mu^*}
\]

Soit \(y\) le plus grand nombre entier contenu dans \(\sqrt{n}\), on pent faire
\[
\begin{aligned}
\sum_1^n A_{m, \mu}= & A_{m, 1}+A_{m, 2}+\cdots+A_{m, v} \\
& +A_{m, v+1}+A_{m, v+2}+\cdots+A_{m, n} .
\end{aligned}
\]

Or, d'après la nature des quantités \(A_{m, \mu}\), la somme contenue dans la première ligne sera égale à. \(\boldsymbol{v}^{\prime} \cdot A_m\), et la seconde égale à \(A_m{ }^{\prime}(n-v)\), où \(A_m\) est une quantité finie et \(A_m{ }^{\prime}\) une quantité qui a zéro pour limite, donc
\[
\sum_1^n A_{m, \mu}=\nu A_m+(n-\nu) A_m^{\prime}=(2 n+1) B_m
\]
où
\[
B_m=\frac{v}{2 n+1} A_m+\frac{n-v}{2 n+1} A_m^{\prime} .
\]

Done la quantité \(B_m\) a zéro pour limite, \(v\) ne surpassant pas \(\sqrt{n}\). Par la l'expression de \(\sum_1^n \psi(m, \|)\) se change en
\[
\sum_1^n \psi(m,, u)=\sum_1^n \theta(m, \mu)+\frac{B_m}{2 n+1} .
\]

Pour avoir la limite de \(\sum_1^n \theta(m, \mu)\), j'écris
\[
\sum_1^n \theta(m, \mu)=\sum_1^{\infty} \theta(m, \mu)-\sum_{n+1}^{\infty} \theta(m, \mu)=\sum_1^{\infty} \theta(m, \mu)-\sum_1^{\infty} \theta(m, \mu+n) \text {. }
\]

Or on peut trouver la valeur de \(\sum_1^{\infty} \theta(m, \prime \prime+n)\) comme il suit. On a
%340
\[
\begin{aligned}
& \theta(m,, l+n)=\log \frac{1-\frac{\alpha^2}{[m \omega+(\mu+n) \omega i+k]^2}}{1-\frac{\alpha^2}{[m \omega+(, \mu+n) \omega i+l]^2}} \\
& =\alpha^2\left(\frac{1}{\left[m(v+(\mu+n) \tilde{v} i+l]^2\right.}-\frac{1}{\left[m(v+(\mu+n) \tilde{v} i+k]^2\right.}\right) \\
& +\frac{1}{2} \alpha^4\left(\frac{1}{[m \omega+(\mu+n) \tilde{v} i+l]^4}-\frac{1}{[m \omega+(\mu+n) \tilde{\omega} i+k]^4}\right)+\cdots \\
&
\end{aligned}
\]

De lì on tire
\[
\sum_1^\mu \theta(m, n+n)=\frac{\alpha^2}{n} \cdot \Sigma \frac{1}{n} \theta\left(\frac{\mu}{n}\right)+\frac{\alpha^4}{2 n^3} \cdot \Sigma \frac{1}{n} \theta_1\left(\frac{\mu}{n}\right)+\cdots
\]
où
\[
\begin{aligned}
& \theta\left(\frac{\mu}{n}\right)=\frac{1}{\left[\frac{m(1)+l}{n}+\tilde{\omega} i+\frac{\mu}{n} \tilde{\omega} i\right]^2}-\frac{1}{\left[\frac{m \omega+k}{n}+\tilde{\omega} i+\frac{\mu}{n} \tilde{\omega} i\right]^2}, \\
& \theta_1\left(\frac{\mu}{n}\right)=\frac{1}{\left[\frac{m(\omega+l}{n}+\tilde{\omega} i+\frac{\mu}{n} \tilde{\omega} i\right]^4}-\frac{1}{\left[\frac{m \omega+k}{n}+\tilde{\omega} i+\frac{\mu}{n} \tilde{\omega} i\right]^4}, \text { etc. }
\end{aligned}
\]

Or on sait que la limite de \(\sum_1^\mu \frac{1}{u} \theta\left(\frac{\mu}{u}\right)\) est égale à \(\int_0^x \theta x . d x\), done
\[
\begin{aligned}
& \sum_1^\mu \frac{1}{n} \theta\left(\frac{\mu}{n}\right)=\int_0^x \theta x \cdot d x+v, \\
& \sum_1^\mu \frac{1}{n} \theta_1\left(\frac{\mu}{n}\right)=\int_0^x \theta_1 x \cdot d x+v_1, \text { etc., }
\end{aligned}
\]
et par conséquent en substituant
\[
\sum_1^\mu \theta(m, \mu+n)=\frac{\alpha^2}{n} \cdot \int_0^x \theta x \cdot d x+\frac{\alpha^4}{2 n^3} \cdot \int_0^x \theta_1 x \cdot d x+\cdots+\frac{v \alpha^8}{n}+\frac{v_1 \alpha^4}{2 n^3}+\cdots ;
\]
or
\[
\theta x=\frac{1}{\left[\frac{m \omega+l}{n}+\tilde{\omega} i+v \tilde{v} i\right]^2}-\frac{1}{\left[\frac{m \omega+k}{n}+\tilde{\omega} i+x \tilde{\omega} i\right]^2}, \text { etc. }
\]
done on aura
%341
La limite de cette expression de \(\int_0^x \theta x . d x\) est zéro pour une valeur quelconque de \(x\). De même on trouvera que la limite de \(\int_0^x \theta_1 x \cdot d x\) est zéro, done
\[
\begin{aligned}
\sum_1^\mu \theta(m,, \prime+n) & =\frac{\alpha^2}{n} v+\frac{\alpha^4}{2 n^3} v^{\prime}+\frac{\alpha^6}{3 n^5} v^{\prime \prime}+\cdots \\
& =\frac{\alpha^2}{2 n+1} \cdot\left(v+\frac{\alpha^2}{2 n^2} v^{\prime}+\frac{\alpha^4}{3 n^4} v^{\prime \prime}+\cdots\right) \frac{2 n+1}{n}=\frac{v}{2 n+1},
\end{aligned}
\]
donc aussi, en faisant \(\boldsymbol{\mu}=\infty\),
\[
\sum_1^{\infty} \theta(m, \boldsymbol{u}+n)=\frac{v}{2 n+1},
\]
d'où
\[
\sum_1^n \theta(m, u)=\stackrel{\Sigma}{1}_\mu^{\infty} \theta(m, \|)-\frac{v}{2 n+1},
\]
et
\[
\sum_1^n \psi(m, \|)=\sum_1^{\infty} \theta(m,, u)+\frac{v_m}{2 n+1},
\]
\(v_m\) ayant zéro pour limite. De là on tire
\[
\sum_1^n \sum_1^n \psi(m, \mu)=\sum_1^n\left(\sum_1^{\infty} \theta(m, \prime)\right)+\sum_1^n \frac{v_m}{2 n+1} .
\]

En prenant la limite des deux membres et remarquant que
\[
\sum_1^n \frac{v_m}{2 n+1}=\frac{v_1+v_2+\cdots+v_n}{2 n+1}=v
\]
on allia
\[
\lim . \sum_1^n \sum_1^n \psi(m, \mu)=\sum_1^{\infty}\left(\sum_1^{\infty} \theta(m, \mu)\right) .
\]

En remettant les valeurs de \(\psi(m, \|)\) et \(\theta(m, \|)\), et passant des logarithmes anix nombres, on en tire
%342
Par une analyse tonte semblable ì la précédente, mais plus simple, on trouvera de même
30.
Maintenant rien n'est plus facile que de trouver les valeurs de \(\varphi \alpha, f \alpha\), \(F \alpha\). Considérons d'abord la première formule (130). On a
done
\[
\begin{aligned}
& =\prod_1^n \prod_1^n \frac{1-\frac{\varphi^2 \beta}{\varphi^2\left[\frac{m \omega+\mu(\omega i}{2 n+1}\right]}}{\varphi^2 \beta} \text {. } \\
& \tau^2\left\{\frac{\left[m \omega+\mu(\omega)-\frac{\omega}{2}-\frac{\bar{\omega}}{2} i\right]}{2 n+1}\right\} \\
&
\end{aligned}
\]

Cela posé, si l'on fait \(\beta=\frac{\alpha}{2 n+1}\) et qu'on suppose \(n\) infini, il viendra,
%343
en faisant usage des formules \((172),(173),(174)\), et en rêmarquant que la limite de \((2 n+1) \varphi\left(\frac{\alpha}{2 n+1}\right)\) est égale à \(\alpha\),

I ees deux formules \(\left(130^{\prime}\right)\) domneront de la même manière, en faisant \(\beta=\frac{\alpha}{2 n+1}\), et remarquant que \(f(0)=1, F(0)=1\),
(176) \(f \alpha=\)
\[
\prod_1^{\infty}\left(1-\frac{\alpha^2}{\left(m-\frac{1}{2}\right)^2 \omega^2}\right) \cdot \prod_1^{\infty}\left\{\prod_1^{\infty} \frac{1-\frac{\alpha^2}{\left[\left(m-\frac{1}{2}\right)(m+\mu \bar{\omega} i]^2\right.}}{1-\frac{\alpha^2}{\left[\left(m-\frac{1}{2}\right)\left(\omega+\left(\mu-\frac{1}{2}\right) \dot{\omega} i\right]^2\right.}} \cdot \frac{1-\frac{\alpha^2}{\left[( m - \frac { 1 } { 2 } ) \left(\omega-\mu(\bar{\omega} i]^2\right.\right.}}{1-\frac{\alpha^2}{\left[\left(m-\frac{1}{2}\right)\left(\omega-\left(\mu-\frac{1}{2}\right)(\dot{\omega})\right]^2\right.}}\right\},
\]
(177) \(F_\alpha=\)
\[
\prod_1^{\infty}\left(1+\frac{\alpha^2}{\left(\mu-\frac{i}{2}\right)^2 \tilde{v}^2}\right) \cdot \prod_1^{\infty}\left\{\prod_1^{\infty} \frac{1-\frac{\alpha^2}{\left[m \omega+\left(\mu-\frac{1}{2}\right) \tilde{\omega} i\right]^2}}{1-\frac{\alpha^2}{\left[\left(m-\frac{1}{2}\right) \omega+\left(\mu-\frac{1}{2}\right) \tilde{\omega} i\right]^2}} \cdot \frac{1-\frac{\alpha^2}{\left[m\left(\omega+\left(\mu-\frac{1}{2}\right) \dot{\omega} i\right]^2\right.}}{1-\frac{\alpha^2}{\left[\left(m-\frac{1}{2}\right) \omega-\left(\mu-\frac{1}{2}\right) \dot{\omega} i\right]^2}}\right\} .
\]

On peut aussi domner une forme réelle aux expressions précédentes comme il suit,
\[
\begin{aligned}
\varphi \alpha=\alpha \cdot \Pi_\mu^{\infty}\left(1+\frac{\alpha^2}{\mu^2 \omega^2}\right) \cdot \Pi_1^{\infty}\left(1-\frac{\alpha^2}{m^2 \omega^2}\right) \\
\quad \times \underset{1}{\infty} \prod_1^{\infty} \prod_\mu^{\infty} \frac{1+\frac{\left(\alpha+m(\omega)^2\right.}{\mu^2 \omega^2}}{1+\frac{\left[\alpha+\left(m-\frac{1}{2}\right) \omega\right]^2}{\left(\mu-\frac{1}{2}\right)^2 \omega^2}} \cdot \frac{1+\frac{(\alpha-m \omega)^2}{\mu^2 \omega^2}}{1+\frac{\left[\alpha-\left(m-\frac{1}{2}\right) \omega\right]^2}{\left(\mu-\frac{1}{2}\right)^2 \omega^2}} \cdot\left\{\frac{1+\frac{\left(m-\frac{1}{2}\right)^2()^2}{\left(\mu-\frac{1}{2}\right)^2 \omega^2}}{1+\frac{m^2 \omega^2}{\mu^2 \omega^2}}\right\},
\end{aligned}
\]
(179)
\[
\begin{aligned}
& F \alpha=\Pi_1^{\infty}\left(1+\frac{\alpha^2}{\left(\mu-\frac{1}{2}\right)^2 \tilde{\omega}^2}\right) \\
& \times \prod_1^{\infty} \prod_1^{\infty} \frac{1+\frac{(\alpha+m \omega)^2}{\left(\mu-\frac{1}{2}\right)^2 \omega^2}}{1+\frac{\left[\alpha+\left(m-\frac{1}{2}\right)(\omega]^2\right.}{\left(\mu-\frac{1}{2}\right)^2 \omega^2}} \cdot \frac{1+\frac{\left(\mu-m(\omega)^2\right.}{\left(\mu-\frac{1}{2}\right)^2 \omega^2}}{1+\frac{\left(\alpha-\left(m-\frac{1}{2}\right) \omega\right]^2}{\left(\mu-\frac{1}{2}\right)^2 \omega^2}} \cdot\left\{\frac{1+\left.\frac{\left(m-\frac{1}{2}\right)^2\left(\omega^2\right.}{\left(\mu-\frac{1}{2}\right)^2 \omega^2}\right|^2}{1+\frac{m^2 \omega^2}{\left(\mu-\frac{1}{2}\right)^2 \omega^2}}\right\}^2 \text {. } \\
&
\end{aligned}
\]
%344
Ces transformations s'opèrent aisément au moyen de la formule
\[
\begin{aligned}
\left(1-\frac{\alpha^2}{(a+b i)^2}\right) & \left(1-\frac{\alpha^2}{(a-b i)^2}\right)=\left(1+\frac{\alpha}{a+b i}\right)\left(1+\frac{\alpha}{a-b i}\right)\left(1-\frac{\alpha}{a+b i}\right)\left(1-\frac{\alpha}{a-b i}\right) \\
= & \frac{(\alpha+a)^2+b^2}{a^2+b^2} \cdot \frac{(\alpha-a)^2+b^2}{a^2+b^2}=\left(1+\frac{(\alpha+a)^2}{b^2}\right)\left(1+\frac{(\alpha-a)^2}{b^2}\right) \cdot \frac{1}{\left[1+\frac{a^2}{b^2}\right]^2} .
\end{aligned}
\]
31.

Dans ce qui précède nous sommès parvenus à deux espèces d'expressions des fonctions \(\varphi \alpha, f \alpha, F \alpha\); les unes donnent ces fonctions décomposées en fractions partielles, dont la totalité forme des séries infinies doubles, les autres donnent ces mêmes fonctions décomposées en un nombre infini de facteurs, dont chacun est à son tour composé d'une infinité de facteurs. Or on peut beaucoup simplifier les formules précédentes au moyen des fonctions exponentielles et circulaires. ('est ee que nous allons voir par ce qui suit.

Considérons d'abord les équations (178), (179), (180). En vertu de formules connues, on a
\[
\frac{\sin y}{y}=\prod_\mu^{\infty}\left(1-\frac{y^2}{\mu^2 x^2}\right) ; \quad \cos y=\prod_1^{\infty}\left(1-\frac{y^2}{\left(\mu-\frac{1}{2}\right)^2 x^2}\right)
\]
done

En vertu de ces formules il est clair que les expressions de \(\varphi \alpha, f \alpha\), \(F \alpha\) peuvent être mises sous la forme
\[
\begin{aligned}
& \varphi \alpha=\frac{\tilde{\omega}}{\pi} \frac{\sin \left[\alpha \frac{\pi i}{\omega}\right]}{i} \prod_m^{\infty}\left(1-\frac{\alpha^2}{m^2 \omega^2}\right) \\
& \times \Pi_1^{\infty}\left\{\frac{\sin (\alpha+m \omega) \frac{\pi i}{\grave{\omega}} \cdot \sin (\alpha-m \omega) \frac{\pi i}{\omega} \cdot \cos ^2\left(m-\frac{1}{2}\right) \omega \frac{\pi i}{\omega}}{\cos \left[\alpha+\left(m-\frac{1}{2}\right) \omega\right] \frac{\pi i}{\omega} \cdot \cos \left[\alpha-\left(m-\frac{1}{2}\right) \omega\right] \frac{\pi i}{\grave{\omega}} \cdot \sin ^2 m \omega\left(\frac{\pi i}{\omega}\right.} \cdot \frac{\left[m \omega \frac{\pi i}{\grave{\omega}}\right]^2}{(\alpha+m \omega)(\alpha-m \omega) \frac{\pi^2 i^2}{\omega^2}}\right\}, \\
& f \alpha=\prod_1^{\infty}\left(1-\frac{\alpha^2}{\left(m-\frac{1}{2}\right)^2 \omega^2}\right) \\
& \times \underset{1}{\infty}\left(\operatorname{tang}\left[\alpha+\left(m-\frac{1}{2}\right) \omega\right] \frac{\pi i}{\omega} \cdot \operatorname{tang}\left[\alpha-\left(m-\frac{1}{2}\right) \omega\right] \frac{\pi i}{\omega} \cdot \cot ^2\left(m-\frac{1}{2}\right) \omega \frac{\pi i}{\omega} \cdot \frac{\left(m-\frac{1}{2}\right)^2\left(\omega^2\right.}{\alpha^2-\left(m-\frac{1}{2}\right)^2 \omega^2}\right), \\
&
\end{aligned}
\]
%345
\[
F_\alpha^{\prime}=\cos \alpha \frac{\pi i}{\tilde{\omega}} \cdot \prod_1^{\infty} \frac{\cos (\alpha+m \omega) \frac{\pi i}{\omega} \cdot \cos \left(\alpha-m(\omega) \frac{\pi i}{\omega} \cdot \cos ^2\left(m-\frac{1}{2}\right) \omega \frac{\pi i}{\omega}\right.}{\cos \left[\alpha+\left(m-\frac{1}{2}\right) \omega\right] \frac{\pi i}{\omega} \cdot \cos \left[\alpha-\left(m-\frac{1}{2}\right) \omega\right] \frac{\pi i}{\omega} \cdot \cos ^2 m(\omega) \frac{\pi i}{\omega}} .
\]

On trouvera des expressions réelles, en substituant au lieu des fonctions circulaires leurs expressions en fonctions exponentielles. On a
\[
\begin{aligned}
& \sin (a-b) \cdot \sin (a+b)=\sin ^2 a-\sin ^2 b \\
& \cos (a+b) \cdot \cos (a-b)=\cos ^2 a-\sin ^2 b
\end{aligned}
\]
done
\[
\begin{aligned}
& \frac{\sin (\alpha+m(1)) \frac{\pi i}{(i)} \cdot \sin (\alpha-m(1)) \frac{\pi i}{\ddot{\omega}}}{\sin ^2 m(1) \frac{\pi i}{\check{\omega}}}=-\left\{1-\frac{\sin ^2 \alpha \frac{\pi i}{(i)}}{\sin ^2 m(1) \frac{\pi i}{\ddot{\omega}}}\right\}, \\
& \frac{\cos \left[\alpha+\left(m-\frac{1}{2}\right) \omega\right] \frac{\pi i}{\grave{\omega}} \cdot \cos \left[\alpha-\left(m-\frac{1}{2}\right)(\omega] \frac{\pi i}{(i)}\right.}{\cos ^2\left(m-\frac{1}{2}\right) \omega \frac{\pi i}{i}}=1-\frac{\sin ^2 \alpha \frac{\pi i}{(i)}}{\cos ^2\left(m-\frac{1}{2}\right) \omega \frac{\pi i}{\grave{\omega}}}, \\
& \operatorname{tang}\left[\alpha+\left(m-\frac{1}{2}\right) \omega\right] \frac{\pi i}{\tilde{\omega}} \cdot \operatorname{tang}\left[\alpha-\left(m-\frac{1}{2}\right) \omega\right] \frac{\pi i}{\tilde{\omega}} \cdot \cot ^2\left(m-\frac{1}{2}\right) \omega \frac{\pi i}{\tilde{\omega}} \\
& =-\frac{1-\frac{\sin ^2 \alpha \frac{\pi i}{\omega}}{\sin ^2\left(m-\frac{1}{2}\right) \omega \frac{\pi i}{\omega}}}{1-\frac{\sin ^2 \alpha \frac{\pi i}{\omega}}{\cos ^2\left(m-\frac{1}{2}\right) \omega \frac{\pi i}{\omega}}} . \\
&
\end{aligned}
\]

D'après cela, et en remarquant que
\[
\frac{m^2 \omega^2}{\alpha^2-m^2 \omega^2}=-\frac{1}{1-\frac{\alpha^2}{m^2 \omega^2}} \text { et } \frac{\left(m-\frac{1}{2}\right)^2 \omega^2}{\alpha^2-\left(m-\frac{1}{2}\right)^2 \omega^2}=-\frac{1}{1-\frac{\alpha^2}{\left(m-\frac{1}{2}\right)^2 \omega^2}},
\]
il est clair qu'on attra
%346
\[
\begin{aligned}
& f \alpha=\prod_0^{\infty} \frac{1-\frac{\sin ^2 \alpha \frac{\pi}{\ddot{\omega}} i}{\sin ^2\left(m+\frac{1}{2}\right) \omega \frac{\pi}{\grave{\omega}} i}}{1-\frac{\sin ^2 \alpha \frac{\pi}{\grave{\omega}} i}{\cos ^2\left(m+\frac{1}{2}\right) \omega \frac{\pi}{\omega} i}}, \\
& F_\kappa \alpha=\cos \left(\frac{a}{\omega} \pi i\right) \prod_1^{\infty} \frac{1-\frac{\sin ^2 \frac{a}{\omega} \pi i}{\cos ^2 m \frac{(\omega)}{\omega} \pi i}}{1-\frac{\sin ^2 \frac{a}{\omega} x i}{\cos ^2\left(m-\frac{1}{2}\right) \frac{(1)}{\omega} \pi i}} . \\
&
\end{aligned}
\]

En substituant au lieu des cosinus et sinus d'ares imaginaires leurs valeurs en quantités exponentielles, ces formules deviendront
où \(h\) est le nombre \(2,718281 \ldots\)
On peut encore transformer ces formules de la manière suivante. Si l'on remplace \(a\) par \(\alpha i\), on aura les valeurs de \(q(\alpha i), f(\alpha i), F(\alpha i)\). Fn changeant maintenant \(c\) en \(e\) et \(e\) en \(c\), les quantités
%347
\[
\omega, \widetilde{\omega}, \varphi(\alpha i), f(\alpha i), F(\alpha i)
\]
se changeront respectivement en
\[
\widetilde{\omega}, \omega, \quad \text { ipre, } \quad F \alpha, \quad f \alpha,
\]
done les formules précédentes donneront
32.
Considérons maintenant les formules \((160),(161),(162)\). On a
\[
\sum_0^{\infty}(-1)^\mu \frac{(2 \mu+1) \pi}{y^2+\left(\mu+\frac{1}{2}\right)^2 \pi^2}=\frac{2}{h^y+h-y},
\]
done, en faisant
\[
\begin{gathered}
y=\left[\alpha \pm\left(m+\frac{1}{2}\right) \omega\right] \frac{\pi}{\tilde{\omega}}: \\
\sum_0^{\infty}(-1)^\mu \frac{(2 \mu+1) \tilde{\omega}}{\left[\alpha \pm\left(m+\frac{1}{2}\right) \omega\right]^2+\left(\mu+\frac{1}{2}\right)^2 \omega^2}=\frac{2 \pi}{\tilde{\omega}} \cdot \frac{1}{h^{(\alpha \pm(m+1)(\omega)} \frac{\pi}{\omega}+h^{-(\alpha \pm(m+1) \omega) \frac{\pi}{\omega}}} \cdot 
\end{gathered}
\]
%348
En vertu de cette formule il est aisé de voir que les expressions (153), (162) de \(\varphi \alpha\) et \(F \alpha\) deviendront
(190) \(\varphi \propto=\)
(191) \(F \alpha=\)
\[
\frac{2}{\widetilde{\omega}} \sum_0^{\infty}\left\{\frac{1}{h^{\left(\alpha-\left(m+\frac{1}{2}\right)(\omega) \frac{\pi}{\tilde{\omega}}\right.}+h^{-\left(\alpha-\left(m+\frac{1}{2}\right)(\omega)\right.} \frac{n}{\tilde{\omega}}}+\frac{1}{h^{\left(\alpha+\left(m+\frac{1}{2}\right)(\omega) \frac{\pi}{\widetilde{\omega}}\right.}+h^{-\left(\alpha+\left(m+\frac{1}{l}\right)(\omega)\right.} \frac{\pi}{\widetilde{\omega}}}\right\} .
\]

Les expressions précédentes de \(\varphi \alpha, F \alpha\), peuvent être mises encore sous beaucoup d'autres formes; je vais rappeler les plus remarquables. D'abord en réunissant les termes du second membre, on trouvera

Si, pour abréger, on suppose
\[
h^{\frac{\alpha \pi}{\tilde{\omega}}}=\varepsilon \text { et } h^{\frac{\omega * \pi}{\widetilde{\omega}}}=r^2
\]
ces formules, en développant le second membre, deviendront. (195) \(\uparrow \alpha=\)
(196) \(F \alpha=\)
\[
\frac{2}{c} \cdot \frac{\pi}{a}\left(\varepsilon+\frac{1}{\varepsilon}\right)\left\{\frac{r+\frac{1}{r}}{r^2+\varepsilon^8+\frac{1}{\varepsilon^2}+\frac{1}{r^8}}+\frac{r^3+\frac{1}{r^8}}{r^6+\varepsilon^8+\frac{1}{s^2}+\frac{1}{r^6}}+\frac{r^5+\frac{1}{r^5}}{r^{10}+\varepsilon^2+\frac{1}{\varepsilon^2}+\frac{1}{r^{10}}}+\cdots\right\} \text {, }
\]

En mettant \(\alpha i\) au lieu de \(\alpha\) dans les formules (192), (193), en changeant ensuite \(c\) en \(e\) et \(e\) en \(c\), et remarquant que les quantités
%349
\[
\omega, \widetilde{\omega}, \varphi(\alpha i), F(\alpha i), h^{\alpha i \frac{\pi}{\tilde{\omega}}}-h^{-\alpha i \frac{\pi}{\omega}}, h^{\alpha i \frac{\pi}{\widetilde{\omega}}}+h^{-\alpha i \frac{\pi}{\omega}}
\]
se changeront respectivement en
\[
\widetilde{\omega}, \omega, \operatorname{iq}(\alpha), \quad f \alpha, \quad 2 i \cdot \sin \alpha \frac{\pi}{\omega}, \quad 2 \cos \alpha \frac{\pi}{\omega},
\]
il viendr’a
En faisant pour abréger
\[
h^{\frac{\tilde{\omega} \iota}{2 \omega}}=0
\]
et en développant, on obtiendra
\[
\text { (200) } \uparrow\left(\alpha \frac{\omega}{2}\right)=
\]
\[
\frac{4}{\rho c} \frac{\pi}{(1)} \sin \left(\alpha \frac{\pi}{2}\right)\left\{\frac{\varrho-\frac{1}{\varrho}}{\varrho^2+2 \cos (\alpha / \tau)+\frac{1}{\varrho^2}}-\frac{\varrho^3-\frac{1}{\rho^8}}{\varrho^6+2 \cos (\alpha \pi)+\frac{1}{\rho^6}}+\frac{\varrho^5-\frac{1}{\rho^5}}{\varrho^{10}+2 \cos (\alpha \pi)+\frac{1}{\varrho^{10}}}-\cdots\right\} \text {, }
\]
(201) \(f\left(x \frac{(1)}{2}\right)=\)

En substituant dans les formules \((190),(191)\) an lien de \(h^{\pi^{\frac{\pi}{6}}}\) et \(h^{\frac{2 \pi \pi}{300}}\) leurs valeurs \(\varepsilon\) et \(r\), il viendra
(202) \(\quad \rho \alpha=\frac{2}{e c} \frac{x}{\tilde{m}} \sum_0^{\infty}(-1)^m\left(\frac{1}{\varepsilon r^{-(3 m+1)}+\varepsilon^{-1} r^{2 m+1}}-\frac{1}{\varepsilon r^{2 m+1}+\varepsilon^{-1} r^{-(3 m+1)}}\right)\),
(203) \(\quad F^{\prime} \alpha=\frac{2}{c} \frac{\pi}{\tilde{\omega}} \sum_0^{\infty}\left(\frac{1}{\varepsilon r^{-2 m-1}+\varepsilon^{-1} r^{2 m+1}}+\frac{1}{\varepsilon r^{2 m+1}+\varepsilon^{-1} r^{-2 m-1}}\right)\).
En supposant maintenant \(a<\frac{(1)}{2}\), on aura
%350
\[
\begin{aligned}
& \frac{1}{\varepsilon r^{-2 m-1}+\varepsilon^{-1} r^{2 m+1}}=\frac{\varepsilon r^{-8 m-1}}{1+\varepsilon^2 r^{-4 m-2}}=\varepsilon r^{-8 m-1}-\varepsilon^3 r^{-6 m-3}+\varepsilon^5 r^{-10 m-5}-\cdots \\
& \frac{1}{\varepsilon r^{2 m+1}+\varepsilon^{-1} r^{-8 m-1}}=\frac{\varepsilon^{-1} r^{-2 m-1}}{1+\varepsilon^{-2} r^{-4 m-2}}=\varepsilon^{-1} r^{-2 m-1}-\varepsilon^{-3} r^{-6 m-3}+\varepsilon^{-5} r^{-10 m-5}-\cdots
\end{aligned}
\]
donc
\(\mathrm{O}_1\)
\[
\begin{aligned}
& \sum_0^{\infty}(-1)^m r^{-2 m-1}=r^{-1}-r^{-3}+r^{-5}-\cdots=\frac{r^{-1}}{1+r^{-8}}=\frac{r}{r^2+1}, \\
& \sum_0^{\infty}(-1)^m r^{-6 m-3}=r^{-3}-r^{-9}+r^{-15}-\cdots=\frac{r^{-3}}{1+r^{-6}}=\frac{r^3}{r^6+1}, \text { etc., }
\end{aligned}
\]
done
\[
\tau \alpha=\frac{2}{e c} \frac{\pi}{\widetilde{\omega}}\left(\frac{\varepsilon-\varepsilon^{-1}}{r+r^{-1}}-\frac{\varepsilon^3-\varepsilon^{-3}}{r^3+r^{-3}}+\frac{\varepsilon^5-\varepsilon^{-5}}{r^5+r^{-5}}-\cdots\right)
\]

De la même manière on trouvera
\[
F \alpha=\frac{2}{c} \frac{\pi}{\tilde{\omega}}\left(\frac{\varepsilon+\varepsilon^{-1}}{r-r^{-1}}-\frac{\varepsilon^3+\varepsilon^{-3}}{r^3-r^{-3}}+\frac{\varepsilon^5+\varepsilon^{-5}}{r^5-r^{-5}}-\cdots\right)
\]

En mettant \(\alpha \frac{\tilde{\omega}}{2} i\) au lieu de \(\alpha\), et changeant ensuite \(e\) en \(c\) et \(c\) en \(e\),
\[
\omega, \widetilde{\omega}, \boldsymbol{\varphi}\left(\alpha \frac{\tilde{\omega}}{2} i\right), F\left(\alpha \frac{\tilde{\omega}}{2} i\right), r, \quad \varepsilon^m+\varepsilon^{-m}, \quad \varepsilon^m-\varepsilon^{-m}
\]
se changent en
\[
\widetilde{\omega}, \omega, i \varphi\left(\alpha \frac{\tilde{\omega}}{2}\right), \quad f\left(\alpha \frac{\omega}{2}\right), \quad \varphi, 2 \cos \left(m \alpha \frac{\pi}{2}\right), 2 i \sin \left(m \alpha \frac{\pi}{2}\right) ;
\]
done
\[
\begin{aligned}
& \uparrow\left(\alpha \frac{\omega}{2}\right)=\frac{4}{e c} \frac{\pi}{\omega}\left\{\frac{\sin \left[\alpha \frac{\pi}{2}\right]}{\varrho+\frac{1}{\varrho}}-\frac{\sin \left[3 \alpha \frac{\pi}{2}\right]}{\varrho^3+\frac{1}{\varrho^8}}+\frac{\sin \left[5 \alpha \frac{\pi}{2}\right]}{\varrho^5+\frac{1}{\varrho^5}}-\cdots\right\} \\
& f\left(\alpha \frac{(1)}{2}\right)=\frac{4}{e} \frac{\pi}{\omega}\left\{\frac{\cos \left[\alpha \frac{\pi}{2}\right]}{\varrho-\frac{1}{\varrho}}-\frac{\cos \left[3 \alpha \frac{\pi}{2}\right]}{\varrho^3-\frac{1}{\varrho^8}}+\frac{\cos \left[5 \alpha \frac{\pi}{2}\right]}{\varrho^5-\frac{1}{\varrho^5}}-\cdots\right\}
\end{aligned}
\]

Ces quatre dernières formules offrent des expressions très simples des fonctions \(\varphi \alpha, f \alpha, F \alpha\). Par différentiation on intégration on peut en déduirc une foule d'autres plus on moins remarquables.
%351
33.

Dans le cas où \(e=c\), les formules précédentes prennent une forme plus simple, à cause de la relation \(\omega=\widetilde{\omega}\), qui a lieu dans ce cas. Soit pour plus de simplicité \(e=c=1\). On a
\[
r=h^{\frac{\omega x}{2 \tilde{\omega}}}=h^{\frac{\pi}{2}}, \varrho=h^{\frac{\tilde{\omega} x}{\overline{2} \omega}}=h^{\frac{\pi}{y}}
\]
donc, en substituant, et faisant dans \((204),(205) \alpha=\alpha \frac{\omega}{2}\), il vient
\[
\begin{aligned}
& \varphi\left(\alpha \frac{\omega}{2}\right)=\frac{4 \pi}{\omega}\left\{\sin \left(\alpha \frac{\pi}{2}\right) \frac{h^{\frac{\pi}{2}}}{1+h^\pi}-\sin \left(3 \alpha \frac{\pi}{2}\right) \frac{h^{3 \frac{\pi}{2}}}{1+h^{3 x}}+\sin \left(5 \alpha \frac{x}{2}\right) \frac{h^{\frac{\pi}{z}}}{1+h^{5 x}}-\cdots\right\} \text {, } \\
& f\left(\alpha \frac{(1)}{2}\right)=\frac{4 \pi}{\omega}\left\{\cos \left(\alpha \frac{\pi}{2}\right) \frac{h^{\frac{\pi}{2}}}{h^x-1}-\cos \left(3 \alpha \frac{\pi}{2}\right) \frac{h^{3 \frac{\pi}{2}}}{h^{3 \cdot \varepsilon}-1}+\cos \left(5 \alpha \frac{\pi}{2}\right) \frac{h^{5 \frac{\pi}{2}}}{h^{5 \pi}-1}-\cdots\right\} \text {. } \\
&
\end{aligned}
\]

Les fonctions \(\varphi, f, F\) sont déterminées par les équations
\[
\begin{gathered}
\alpha \frac{\omega}{2}=\int_0^x \frac{d x}{\sqrt{1-x^4}} ; \frac{\omega}{2}=\int_0^1 \frac{d x}{\sqrt{1-x^4}} \\
x=\varphi\left(\alpha \frac{\omega}{2}\right) ; \sqrt{1-x^2}=f\left(\alpha \frac{\omega}{2}\right) ; \sqrt{1+x^2}=F\left(\alpha \frac{\omega}{2}\right) .
\end{gathered}
\]

Si dans les deux dernières formules on fait \(\alpha=0\), et qu'on remarque qu'alors la valeur de \(\frac{\tau\left[\alpha \frac{\omega}{2}\right]}{\sin \left[\alpha \frac{\pi}{2}\right]}\) est égale à \(\frac{\omega}{\pi}\), et celle de \(\frac{\sin \left[m \alpha \frac{\pi}{2}\right]}{\sin \left[\alpha \frac{\pi}{2}\right]}\) égrale a \(m\), on trouvera
\[
\begin{gathered}
\frac{\omega}{2}=2 \pi\left\{\frac{h^{\frac{\pi}{2}}}{h^\pi-1}-\frac{h^{\frac{3 \pi}{2}}}{h^{3 \pi}-1}+\frac{h^{\frac{5 \pi}{8}}}{h^{5 \pi}-1}-\cdots\right\}=\int_0^1 \frac{d x}{\sqrt{1-x^4}}, \\
\frac{\omega^2}{4}=\pi^2\left\{\frac{h^{\frac{\pi}{2}}}{h^\pi+1}-3 \frac{h^{\frac{3 \pi}{2}}}{h^{3 \pi}+1}+5 \frac{h^{\frac{5 \pi}{8}}}{h^{5 \pi}+1}-\cdots\right\}=\left(\int_0^1 \frac{d x}{\sqrt{1-x^4}}\right)^2 .
\end{gathered}
\]
%352
§ VIII.
Eapression algébrique de la fonction \(\varphi\left(\frac{\omega}{n}\right)\) dans le cas où \(e=e=1\). Application à la lemniscate*).
34.

Dans le cinquième paragraphe nous avons traité l'équation \(P_n=0\), d'où dépend la détermination des fonctions \(\varphi\left(\frac{(1)}{x}\right)\) et \(\varphi\left(\frac{\omega i}{n}\right)\). Cette équation, prise dans toute sa généralité, ne paraît guère résoluble algébriquement pour des valeurs quelconques de \(e\) et \(c\); mais néammoins il y a des cas particuliers, où on pent la résoudre complètement, et par suite obtenir des expressions algébriques des quantités \(\varphi\left(\frac{(1)}{n}\right)\) et \(\uparrow\left(\frac{\tilde{\omega} i}{n}\right)\) en fonction de \(e\) et \(c\). C'est ce qui arrive toujours, si \(\uparrow\left(\begin{array}{c}\tilde{\omega} i \\ n\end{array}\right)\) peut être exprimé rationnellement pau\(\varphi\left(\frac{(1)}{n}\right)\) et des quantités connues, ce qui a lien pour une infinité de valeurs de \(\frac{c}{e}\). Dans tous ces cas l'équation \(P_n=0\) peut être résolue par une seule et même méthode uniforme, qui est applicable à une infinité d'autres équations de tous les degrés. J'exposerai cette méthode dans un mémoire séparé, et je me contenterai pour le moment à considérer le cas le plus simple, et qui résulte de la supposition \(e=c=1\) et \(n=4 v+1\). Dans ce cas on alura
\[
\begin{aligned}
& \alpha=\int_0 \frac{d x}{\sqrt{1-x^4}}, \text { où } x=\mathrm{\varphi} \alpha, \\
& f \alpha=\sqrt{1-\psi^2 \alpha}, \quad F \alpha=\sqrt{1+\tau^2 \alpha} . \\
&
\end{aligned}
\]

De même
\[
\varphi(\alpha i)=i \cdot \varphi \dot{\alpha}
\]
ce qui se fait voir, en mettant \(x i\) au lieu de \(x\). Cette formule donne ensuite
*) La première partie de ce mémoire contenant les sept premiers paragraphes a paru dans le deuxieme tome du Journal für die reine und angewandte Mathematik, la seconde partie se trouvo dans le troi siène tome.
Note des éditeurs.
%353
\[
f(\alpha i)=F \alpha ; \quad F(\alpha i)=f \alpha .
\]

Les deux quantités \(e\) et \(c\) étant égales entre elles, il est clair qu'il en sera de même des deux quantités que nous avons désignées par \(\omega\) et \(\bar{w}\). En effet on aura
\[
\frac{\omega}{2}=\frac{\tilde{\omega}}{2}=\int_0^1 \frac{d x}{\sqrt{1-x^4}}
\]
35.

En posant dans les formules (10) \(\beta i\) an lieu de \(\beta\), on en tirera, en ayant égard aux équations (209) et (210),

Donc, pour trouver les fonctions \(\varphi, f, F\) pour une valeur imaginaire quelconque de la variable, il suffira d'en connaître les valeurs pour des valeurs réelles.

En supposant \(\alpha=m \delta, \beta=\mu \delta\), on voit que \(\varphi(m+\mu i) \delta, f(m+, u i) \delta\), \(F(m+\| i) \delta\) pourront être exprimés rationnellement par les six fonctions suivintes:
\[
\begin{array}{lll}
\varphi\left(m \delta^{\prime}\right), & \varphi\left(\mu \delta^{\prime}\right), & f\left(m \delta^{\prime}\right), \\
f\left(\mu \delta^{\prime}\right), & F\left(m \delta^{\prime}\right), & F\left(\mu \delta^{\prime}\right),
\end{array}
\]
et par suite aussi par des fonctions rationnelles des trois fonctions \(\varphi \delta, f \delta\), \(F\) f), si \(m\) et \(\mu\) sont des nombres entiers. En suivant ce développement, on voit également, et sans peine, que dans le cas où \(m+\mu\) est un nombre impair, on aura
\[
\varphi(m+\mu i) d=\varphi d . T
\]
oì ' \(T\) ' est une fonction rationnelle de \(\left(\varphi^{\prime}\right)^2,\left(f \delta^{\prime}\right)^2,\left(F^{\prime}\right)^2\), e'est-à-dire de \(\left(\varphi \delta^{\prime}\right)^2\). Done en faisant \(\varphi \delta=x\), on aura
\[
\varphi(m+\mu i) d=x \cdot \psi\left(x^2\right) .
\]
%354
En changeant \(\delta\) en \(\delta^{\prime} i, \varphi \delta\) se changera en \(\varphi\left(\delta^{\circ} i\right)=i . \varphi \delta^{\prime}=i x\), et la fonction \(\varphi(m+\mu i) \delta\) en \(i \varphi(m+\mu i) \delta\), done
\[
\varphi(m+\mu i) \delta=x \cdot \psi\left(-x^2\right)
\]
par conséquent on doit avoir \(\psi\left(-x^2\right)=\psi\left(x^2\right)\), ce qui fait voir que la fonction \(\psi\left(x^2\right)\) ne contient que des puissances de la forme \(x^{4 n}\). Donc on aura
\[
\varphi(m+\mu i) \delta=x \cdot T,
\]
où \(T\) est une fonction ratiomelle de \(x^4\).
Cherchons par exemple l'expression de \(\varphi(2+i) d\) en \(x\). On a d'après les formules (212), en faisant \(\alpha=2 \delta\) et \(\beta=\delta\),
\[
\varphi(2+i) \delta=\frac{\varphi(2 \delta) \cdot f \delta \cdot F \delta+i \varphi \delta \cdot f(2 \delta) \cdot F(2 \delta)}{1-\left(\varphi^2 \delta\right)^2 \cdot \varphi^2 \delta} .
\]

Or les formules (10) domnent
\[
\varphi(2 \delta)=\frac{2 \varsigma \delta \cdot f \delta \cdot F \delta}{1+(\varsigma \delta)^4} ; f(2 \delta)=\frac{(f \delta)^2-(\varsigma \delta)^2 \cdot(F \delta)^2}{1+(\varsigma \delta)^4} ; F(2 \delta)=\frac{(F \delta)^3+(\tau \delta)^2 \cdot(f \delta)^2}{1+(\tau \delta)^4} ;
\]
c'est-à-dire, en remarquant quie \(\varphi \delta=x, f \delta=\sqrt{1-x^2}\) et \(F \delta=\sqrt{1+x^2}\),
\[
\varphi\left(2 \delta^{\prime}\right)=\frac{2 x^{\sqrt{ } 1-x^4}}{1+x^4} ; f\left(2 \delta^{\prime}\right)=\frac{1-2 x^2-x^4}{1+x^4} ; \quad F\left(2 \delta^{\prime}\right)=\frac{1+2 x^2-x^4}{1+x^4} .
\]

En substituant ces valeurs et en réduisant, il viendra
\[
\varphi(2+i) \delta=x \frac{2-2 x^8+i\left(1-6 x^4+x^8\right)}{1-2 x^4+5 x^8}=x i \frac{1-2 i-x^4}{1-(1-2 i) x^4} .
\]

Eitpression algélrique de \(\uparrow\left(\frac{\omega}{4 \nu+1}\right)\).
36.

On peut, comme on sait, décomposer le nombre \(4 v+1\) en deux carrés. Donc on peut supposer
\[
\alpha^2+\beta^2=4 v+1=(\alpha+\beta i)(\alpha-\beta i) .
\]

Nous chercherons d'abord la valeur de \(\varphi\left(\frac{\omega}{\alpha+\beta i}\right)\); car celle-ci étant trouvée, on en tirera facilement la valeur de \(\varphi\left(\frac{\omega}{4 v+1}\right)\).
%355
La somme des deux carrés \(\alpha^2\) et \(\beta^2\) étant impaire, l'un des nombres \(\alpha\) et \(\beta\) sera pair et l'antre impair. Done la somme \(\alpha+\beta\) est impaire. Done en vertu de la formule (213), on aura
\[
\varphi(\alpha+\beta i) \delta=x \frac{T}{s^{\prime}},
\]
où \(T\) et \(S\) sont des fonctions entières de \(x^4=\left(\varphi \delta^{\circ}\right)^4\). En supposant \(\delta=\) \(\frac{\omega}{\alpha+\beta i}\), le premier membre de l'équation (216) se réduit à zéro, et par conséquent \(x=\varphi\left(\frac{\omega}{\alpha+\beta i}\right)\) sera une racine de l'équation
\[
T=0 .
\]

Donc on aura la valeur de \(\varphi\left(\frac{\omega}{\alpha+\beta i}\right)\) au moyen de la résolution de cette équation.

D'abord on peut trouver toutes les racines de l'équation \(T\) ' \(=0\) à l'aide de la fonction \(\varphi\) de la manière suivante. Si \(T=0\), on doit avoir
\[
\varphi(\alpha+\beta i) \delta=0
\]
d'où l'on tire, en vertu de (27),
\[
(\alpha+\beta i) \delta=m \omega+\mu \widetilde{\omega} i=(m+\mu i) \omega
\]
et de là
\[
\delta=\frac{m+\mu i}{\alpha+\beta i} \omega
\]
et
\[
x=\varphi\left(\frac{m+\mu i}{\alpha+\beta i} \omega\right) .
\]

Dans cette expression sont conséquemment contenues toutes les racines de l'équation \(T=0\). On les trouvera en donnant à \(m\) et \(\mu\) toutes les valeurs entières depuis \(\rightarrow \infty\) jusqu’à \(+\infty\).

Or je dis que les valeurs de \(x\) qui sont différentes entre elles peuvent être représentées par la formule
\[
x=\varphi\left(\frac{\rho \omega}{\alpha+\beta i}\right),
\]
où \(\rho\) a toutes les valeurs entières depuis \(-\frac{\alpha^2+\beta^2-1}{2}\) jusqu' \(\lambda+\frac{\alpha^2+\beta^2-1}{2}\). Pour le démontrer, soient \(\lambda\) et \(\lambda^{\prime}\) denx nombres entiers qui satisfont à l'équation indéterminée
\[
\alpha \cdot \lambda^{\prime}-\beta \cdot \lambda=1
\]
%356
soit de plus \(t\) un nombre entier indéterminé, et faisons
\[
k=\mu \lambda+t \alpha, k^{\prime}=-\mu \lambda^{\prime}-t \beta ;
\]
on en déduira sans peine
et si l'on fait
\[
\varrho=m+\alpha k-\beta k^{\prime}
\]
on vérifiera aisément l'équation
\[
\frac{m+\mu i}{\alpha+\beta i}=\frac{\varrho}{\alpha+\beta i}-k-k^{\prime} i
\]

De là on tire
\[
\left.\varphi\left(\frac{m+\mu i}{\alpha+\beta i} \omega\right)=\varphi\left(\frac{\varrho(1)}{\alpha+\beta i}-k \omega\right)-k^{\prime} \omega i\right)
\]
or d'après la relation (22) le second membre se réduit à
\[
(-1)^{-k-k^{\prime}} \varphi\left(\frac{\varrho(1)}{\alpha+\beta i}\right)
\]
done
\[
\varphi\left(\frac{m+\mu i}{\alpha+\beta i} \omega\right)=(-1)^{-k-k^{\prime}} \varphi\left(\frac{\rho(1)}{\alpha+\beta i}\right)=\varphi\left(\frac{ \pm \varrho(1)}{\alpha+\beta i}\right) .
\]

Maintenant l'expression de \(\varrho\) deviendra, en y substituant les valeurs de \(k\) et \(k^{\prime}\),
\[
\varphi=m+\cdots\left(\lambda \alpha+\lambda^{\prime} \beta\right)+t\left(\alpha^2+\beta^2\right)
\]
d'où l'on voit qu'on peut prendre \(t\) tel que la valeur-de \(\rho\), positive ou négative, soit inférieure à \(\frac{\alpha^2+\beta^2}{2}\). Donc etc.

Toutes les racines de l'équation \(T=0\) seront représentées par la formule \(\left(218^{\prime}\right)\); or toutes ces racines sont différentes entre elles. En effet si l'on avait par exemple
\[
\varphi\left(\frac{\varrho^{\prime \prime \prime}}{\alpha+\beta i}\right)=\varphi\left(\frac{\varrho^{\prime}(1)}{\alpha+\beta i}\right)
\]
on aurait d'après la formule \((31)\), (en remarquant que \(\widetilde{\omega}=\omega\) )
\[
\frac{\varrho \omega}{\alpha+\beta i}=(-1)^{m+n} \frac{\varrho^{\prime} \omega}{\alpha+\beta i}+(m+n i) \omega
\]
d'où l'on tire
\[
\alpha n+\beta m=0 ; \Leftrightarrow=(-1)^{m+n} \varphi^{\prime}+\alpha m--\beta n .
\]
%357
La première de ces équations donne \(n=-\beta t ; m=\alpha t\), où \(t\) est un entier indéterminé. En vertı de ces relations, l'expression de p deviendrait
\[
\rho=(-1)^{m+n} \rho^{\prime}+\left(\alpha^2+\beta^2\right) t
\]
d'où l'on tire
\[
\frac{\varrho \pm \varrho^{\prime}}{\alpha^2+\beta^2}=t
\]
ce qui est impossible, car on remarquera que \(\varrho\), \(\varphi^{\prime}\) sont tous deux inférieurs à \(\frac{\alpha^2+\beta^2}{2}\). Done les racines différentes entre elles de l'équation \(T\) ' \(=0\) sont au nombre de \(\frac{\alpha^3+\beta^2-1}{2}\). Il fant voir encore, si l'équation en question a des racines égales. En différentiant l'équation (216) on en tirera, en remarquant que \(d \varphi \alpha=d \alpha \cdot f \alpha . F \alpha\),
\[
\begin{aligned}
(\alpha+\beta i) \cdot f(\alpha+\beta i) \delta \cdot F(\alpha+\beta i) \delta \cdot S+\left(\frac{d S}{d \delta}\right) \cdot q(\alpha+\beta i) \delta & \\
& =x \frac{d T}{d x} \cdot f d \cdot F \delta+T \cdot f d \cdot F \delta .
\end{aligned}
\]

Si maintenant \(T\) a des facteurs égaux, il faut que \(T\) et \(\frac{d T}{d x}\) soient égaux à zéro en même temps; done l'équation précédente donnera
\[
S \cdot f(\alpha+\beta i) \delta \cdot F(\alpha+\beta i) \delta=0
\]
or on a \(\varphi(\alpha+\beta i) \delta=0\), done \(f(\alpha+\beta i) \delta= \pm 1=F(\alpha+\beta i) \delta\), et par conséquent
\[
S=0
\]
ce qui est impossible, car nous supposons, ce qui est permis, que ' \(T\) ' et \(S\) n'aient point de facteurs communs. Par la on voit que l'équation
\[
T=0
\]
est du degré \(\alpha^2+\beta^2-1\) par rapport a \(x\), et aura pour racines les quantités:
\[
\pm \varphi\left(\frac{\omega}{\alpha+\beta i}\right), \pm \varphi\left(\frac{2 \omega}{\alpha+\beta i}\right), \cdots \pm \varphi\left(\frac{\alpha^8+\beta^2-1}{2} \cdot \frac{\omega}{\alpha+\beta i}\right) .
\]

En faisant \(x^2=r\), on aura une équation
\[
R=0
\]
du degré \(\frac{\alpha^2+\beta^2-1}{2}=2 v\), dont les racines seront.
%358
(220)
\[
\varphi^2\left(\delta^{\prime}\right), \varphi^2\left(2 \delta^{\prime}\right), \varphi^2\left(3 \mho^{\prime}\right) \cdots \varphi^2(2 \boldsymbol{\mho}),
\]
où pour abréger on a supposé \(\delta=\frac{\omega}{\alpha+\beta i}\)
Cela posé, on peut aisément résoudre l'équation \(R=0\), à l'aide de la méthode de M. Gauss.

Soit \(\varepsilon\) une racine primitive de \(\alpha^2+\beta^2\), je dis qu'on pent exprimer les racines comme il suit:

En effet, en faisant
\[
\varepsilon^m= \pm a_m+t\left(\alpha^2+\beta^2\right)
\]
où \(a_m\) est moindre que \(\frac{\alpha^2+\beta^2}{2}\), on aura
\[
\varphi\left(\varepsilon^m \delta\right)=\varphi\left( \pm a_m \delta+\frac{t\left(\alpha^2+\beta^2\right)}{\alpha+\beta i} \omega\right)=\varphi\left[ \pm a_m \delta+t(\alpha-\beta i) \omega\right]
\]
ou, en vertu de la formule (22),
et par slite
\[
\begin{gathered}
\varphi\left(\varepsilon^m \delta\right)= \pm \varphi\left(a_m \delta\right), \\
\varphi^2\left(\varepsilon^m \delta\right)=\varphi^2\left(a_m \delta\right) .
\end{gathered}
\]

Je dis maintenant que tous les nombres \(1, a_1, a_2, a_3, \ldots a_{2 v-1}\) sont inégaux entre eux. En effet soit par exemple \(a_m=a_n\), on aura
\[
\varepsilon^n= \pm a_m+t^{\prime}\left(\alpha^2+\beta^2\right) \text {. }
\]

Des deux équations (222) et (223) on tire, en éliminant \(a_m\),
\[
\frac{\varepsilon^m \pm \varepsilon^n}{\alpha^2+\beta^2}=\text { un nombre entier. }
\]

Donc en multipliant par \(\varepsilon^m \mp \varepsilon^n\), on trouve que \(\frac{\varepsilon^{2 m}-\varepsilon^{2 n}}{\alpha^2+\beta^2}\) est entier, et par suite \(\frac{\varepsilon^{2 m-2 n}-1}{\alpha^8+\beta^2}\), ce qui est impossible, car \(\varepsilon\) est wne racine primitive de \(\alpha^2+\beta^2\), et \(2 m-2 n\) est moindre que \(\alpha^2+\beta^2-1\). Donc les \(2 \nu\) nombres 1, \(a\), ete. sont différens entre eux, et par conséquent, pris dans un ordre différent, ils sont les mêmes que les suivans:
\[
1,2,3,4 \ldots 2 v-1 \text {. }
\]

On voit par la formule \(\varphi^2\left(\varepsilon^m \delta^{\prime}\right)=\varphi^2\left(a_m \delta^{\prime}\right)\), que les, quantités (220) et (221) coïncident, mais dans un ordre différent.
%359
Maintenant on pourra résoudre l'équation \(R=0\) exactement de la même manière que l'équation (106). On trouvera (116)
\[
\begin{aligned}
\varphi^2\left(\varepsilon^m \delta\right)=\frac{1}{2 \nu}\left(+A+\theta^{-m} \cdot v^{\frac{1}{2 v}}+s_2 \theta^{-2 m} \cdot v^{\frac{8}{2 v}}\right. & +\cdots \\
& \left.+s_{2 v-1} \theta^{-(2 v-1) m} \cdot v^{\frac{2 \nu-1}{2 v}}\right)
\end{aligned}
\]
où \(\theta\) est une racine imaginaire de l'équation \(\theta^{2 v}-1=0\), et \(v, s_2, s_3, \ldots\) \(s_{2 y-1}, A\) seront déterminés par les expressions
\[
\begin{aligned}
& A=\varphi^2(\delta)+\varphi^2(\varepsilon \delta)+\varphi^2\left(\varepsilon^2 \delta\right)+\cdots+\varphi^2\left(\varepsilon^{2 v-1} \delta\right), \\
&
\end{aligned}
\]
qui, par le procédé p. \(312,313,314\), peuvent être exprimées rationnellement par les coefficiens de l'équation \(R=0\), qui seront de la forme \(A+B i\), où \(A\) et \(B\) sont des nombres rationnels. Done la formule (224) donne l'expression algébrique, de toutes les racines de l'équation \(l=0\), et par conséquent les valeurs des fonctions
\[
\varphi\left(\frac{\omega}{\alpha+\beta i}\right), \varphi\left(\frac{2 \omega}{\alpha+\beta i}\right), \cdots \varphi\left(\frac{(2 v-1) \omega}{\alpha+\beta i}\right), \varphi\left(\frac{2 v \omega}{\alpha+\beta i}\right)
\]
37.

Ayant trouvé par ce qui précède la valeur de \(\varphi\left(\frac{m \omega}{\alpha+\beta i}\right)\), on en tirera celle de la fonction
\[
\varphi\left(\frac{(1)}{\alpha^2+\beta^2}\right)=\varphi\left(\frac{(1)}{4 \nu+1}\right)
\]
comme il suit. La valeur de \(\varphi\left(\frac{m(1)}{\alpha+\beta i}\right)\) donnera celle de \(\varphi\left(\frac{m \omega}{\alpha-\beta i}\right)\) en changeant senlement \(i\) en \(-i\). De la on tire la valeur de \(\varphi\left(\frac{m(1)}{\alpha+\beta i}+\frac{m(1)}{\alpha-\beta i}\right)\) par la formule (10), savoir
%360
or
\[
\frac{m(1)}{\alpha+\beta i}+\frac{m(\omega)}{\alpha-\beta i}=\frac{2 m \alpha(1)}{\alpha^2+\beta^2}=\frac{2 m \alpha(1)}{4 v+1},
\]
donc on aura la valeur de la fonction
\[
\varphi\left(\frac{2 m a v}{4 v+1}\right)
\]

Maintenant pour avoir la valeur de \(\varphi\left(\frac{n \omega}{4 v+1}\right)\), où \(n\) a une valeur déterminée quelconque, il suffit de déterminer \(m\) et \(t\) de la nanière que
\[
n=2 m \alpha-(4 v+1) t,
\]
ce qui est toujours possible, en remarquant que les deux nombres \(2 \alpha\) et \(4 v+1\) sont premiers entre eux; car alors on obtiendra
\[
\varphi\left(\frac{2 m \alpha \omega}{4 v+1}\right)=\varphi\left(\frac{n \omega}{4 v+1}+t \omega\right)=(-1)^t \varphi\left(\frac{n \omega}{4 v+1}\right) .
\]

En posant par exemple \(n=1\), on aura la valeur de \(\varphi\left(\frac{(1)}{4 \nu+1}\right)\).
38.
Le cas, où \(4 \boldsymbol{v}+1\), a la forme \(1+2^n\), est le plus remarquable; car alors l'expression de \(\varphi\left(\frac{(1)}{4 v+1}\right)\) ne contient que des racines carrées. En effet on a dans ce cas \(2 \boldsymbol{v}=2^{n-1}\), et par suite la formule (224) fait voir qu'on peut déduire \(\varphi\left(\varepsilon^m \delta\right)\) de \(\theta\) et \(v\), en extrayant seulement des racines carrées. Or \(v\) est une fonction rationnelle de \(\theta\) et de \(\sqrt{-1}\), et \(\theta\) est déterminée par l'équation \(\theta^{2^{n-1}}=1\), d'où l'on tire \(\theta\) par des racines carrées; done on trouve aussi \(v\) et la fonction
\[
\varphi\left(\varepsilon^m \mathcal{J}^{\prime}\right)=\varphi\left(\frac{a_m^{(\prime)}}{\alpha+\beta i}\right)
\]

Comnaissant de cette manière \(\varphi\left(\frac{m(1)}{\alpha+\beta i}\right)\), on aura de même \(\varphi\left(\frac{m(\prime)}{\alpha-\beta i}\right)\) et de la, par la formule (226) la valeur de \(\varphi\left(\frac{n \omega}{\alpha^2+\beta^2}\right)=\varphi\left(\frac{n \omega}{4 v+1}\right)\), en extrayant des racines carrées.
%361
39.
Un autre cas, où la valeur de \(\uparrow\left(\frac{m(1)}{n}\right)\) pent être déterminéc par des racines carrées est celui où \(n\) est une puissance de 2, comme nous l'avons vu \(n^0\) 13. Done on comnaît la fonction \(q\left(\frac{m \omega}{2^n}\right)\), et l'on connaît de même la fonction \(q\left(\frac{m(1)}{1+2^n}\right)\) si \(1+2^n\) est un nombre premier.

Soient maintenant \(1+2^n, 1+2^{n_1}, 1+2^{n_2}, \ldots 1+2^{n_\mu}\) plusieurs nombres premiers, on connaît les fonctions
\[
\varphi\left(\frac{m \omega}{2^n}\right), \varphi\left(\frac{m_1 \omega}{1+2^{n_1}}\right), \varphi\left(\frac{m_2 \omega}{1+2^{n_z}}\right), \cdots \varphi\left(\frac{m_\mu(\omega)}{1+2^{n_\mu}}\right),
\]
et par suite la fonction
\[
\begin{aligned}
& \varphi\left(\frac{m}{2^n}+\frac{m_1}{1+2^{n_1}}+\frac{m_2}{1+2^{n_2}}+\cdots+\frac{m_\mu}{1+2^{n_\mu}}\right) \omega \\
& =\varphi\left(\frac{m^{\prime} \omega}{2^n\left(1+2^{n_1}\right)\left(1+2^{n_3}\right) \cdots\left(1+2^{n_\mu \mu}\right)}\right), \\
&
\end{aligned}
\]
où \(m^{\prime}\) est un nombre entier, qui, à cause des indéterminées \(m, m_1, m_2, \ldots m_\mu\) peut avoir une valeur quelconque. On peut done établir le théorème suivant: "La valeur de la fonction \(\varphi\left(\frac{m \omega}{n}\right)\) peut être exprimée par des racines "carrées toutes les fois que \(n\) est un nombre de la forme \(2^n\) ou un nombre "premier de la forme \(1+2^n\), on même un produit de plusieurs nombres de "ces deux formes."
40.
Lin appliquant ce qui précède à la lemniscate, on parviendra au théorème énoncé \(\mathrm{n}^0 22\).

Soit l'are \(A M=\alpha\), la corde \(A M=x\) et l'angle \(M A P=\theta\), on aura
\[
d x=\frac{d x}{\sqrt{1-x^4}} .
\]
%362
En effet, l'équation polaire de la lemniscate est d'où
\[
x=\sqrt{\cos 2 \theta}
\]
\[
d \theta=-\frac{d x \cdot \sqrt{\cos 2 \theta}}{\sin 2 \theta}
\]
et
done
\[
d \alpha^2=d x^2+x^2 d \theta^2
\]
\[
d \alpha^2=d x^2\left(1+\frac{x^2 \cos 2 \theta}{(\sin 2 \theta)^2}\right) ;
\]
mais de l'équation \(x=\sqrt{\cos 2 \theta}\) on tire \(\cos 2 \theta=x^2, \cos ^2 2 \theta=x^4, 1-\cos ^2 2 \theta\) \(=1-x^4=(\sin 2 \theta)^2\), donc
et par suite
\[
d \alpha^2=d x^2\left(1+\frac{x^4}{1-x^4}\right)=\frac{d x^2}{1-x^4}
\]
\[
d \alpha=\frac{d x}{\sqrt{1-x^4}}
\]
et
\[
x=\varphi \alpha .
\]

Si l'on suppose \(x=1\), on aura \(\alpha=A M B=\frac{\omega}{2}\). Donc la circonférence \(A M B N=\) (o). Supposons maintenant qu'il s'agisse de diviser cette circonférence en \(n\) parties égales, et soit l'arc \(A M=\frac{m}{n} \cdot A M B N=\frac{m}{n} \omega\), on aura
\[
A M=\varphi\left(\frac{m(1)}{n}\right)
\]

Donc on aura la corde, et par suite le \(m^{\text {ième }}\) point de division, si l'on connaît la fonction \(\varphi\left(\frac{m(1)}{n}\right)\); or c'est ce qui a toujours lieu lorsque \(n\) est décomposable en nombres premiers de la forme 2 et \(1+2^n\), comme nous l'avons vu dans le numéro précédent. Done dans ce cas on peut construire les points de division à l'aide de la règle et du compas seulement, ou ce qui revient au même, par l'intersection de lignes droites et de cercles.
%363
\(\S I X\).
Usage des fonctions \(\varphi, f, F\) dans la transformation des fonctions elliptiques.
41.
M. Legendre a fait voir dans ses Exercices de calc. int., comment l'intégrale \(\int \frac{d \varphi}{\sqrt{1-e^2 \sin ^2 \varphi}}\), qui, en faisant \(\sin \varphi=x\), se change en \(\int \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}\), peut être transformée en d'autres intégrales de la même forme, avec un module différent. Je suis parvenu à généraliser cette théorie par le théorème suivant:

Si l'on désigne par \(\alpha\) la quantité \(\frac{(m+\mu)(\omega+(m-\mu) \tilde{a} i}{2 n+1}\), où l'un auı moins des deux nombres entiers \(m\) et \(" \prime\) est premier avec \(2 n+1\), on aura (227) où
\[
\int \frac{d y}{\sqrt{\left(1-c_1^2 y^2\right)\left(1+\rho_1^2 y^2\right)}}= \pm a \int \frac{d x}{\sqrt{\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)}},
\]
\[
\begin{aligned}
& y=f \cdot x \cdot \frac{\left(\tau^2 \alpha-x^2\right)\left(\tau^2 2 \alpha-x^2\right) \cdots\left(\tau^2 n \alpha-x^2\right)}{\left(1+e^2 c^2 \boldsymbol{\tau}^2 \alpha \cdot x^2\right)\left(1+e^8 c^2 \boldsymbol{\tau}^2 2 \alpha \cdot x^2\right) \cdots\left(1+e^8 c^2 \uparrow^3 n \alpha \cdot x^2\right)}, \\
& \frac{1}{c_1}=\frac{r}{c}\left[\varphi\left(\frac{\omega}{2}+\alpha\right) \cdot \varphi\left(\frac{(1)}{2}+2 \alpha\right) \ldots \varphi\left(\frac{(1)}{2}+n \alpha\right)\right]^2, \\
& \frac{1}{e_1}=\frac{f}{e}\left[\varphi\left(\frac{\tilde{\omega} i}{2}+\alpha\right) \cdot \varphi\left(\frac{\pi i}{2}+2 \alpha\right) \ldots \varphi\left(\frac{\tilde{\omega} i}{2}+n \alpha\right)\right]^2, \\
& a=f \cdot(\varphi \alpha \cdot \varphi 2 \alpha \cdot \varphi 3 \alpha \ldots \varphi n \alpha)^2 \text {, } \\
&
\end{aligned}
\]
\(f\) étant une indéterminée, de sorte qu'il n'existe qu'une seule relation entre les quantités \(c_1, e_1, c\),e. Les quantités \(e^2\) et \(e^2\) pourront être positives ou neggatives.

Par ce théorème on pent trouver une infinité de transformations difiérentes entre elles et de celles de M. Legendre.
42.
Soient \(m\) et \(" \mu\) deux nombres entiers, et faisons pour abréger
\[
\mu=\frac{(m+\mu)(\omega+(m-\mu) \tilde{\omega} i}{2 n+1}
\]
%364
où l'on suppose que l'un des deux nombres \(m\), " soit premier avec \(2 n+1\).
En désignant par \(\theta\) une quantité queleonque, il viendra, en vertu de la formule (22)
\[
\varphi[\theta+(2 n+1) \alpha]=\varphi \theta
\]

En mettant \(\boldsymbol{\theta}\)-na au lieu de \(\boldsymbol{\theta}\), on obtiendra
\[
\varphi[\theta+(n+1) \alpha]=\varphi(\theta-n \alpha) \text {. }
\]

Cela posé, considérons l'expression suivante
\[
\text { (231) } \varphi_1 \theta=\varphi \theta+\varphi(\theta+\alpha)+\cdots+\varphi(\theta+n \alpha)+\cdots+\varphi(\theta+2 n \alpha) .
\]

En mettant \(\theta+\alpha\) au lieu de \(\theta\), il viendra à cause de l'équation (229)
\[
\varphi_1(\theta+\alpha)=\varphi_1 \theta
\]
donc si \(m\) désigne un nombre entier quelconque,
\[
\varphi_1(\theta+m \alpha)=\varphi_1 \theta
\]

En vertu de l'équation (230) on peut écrire l'expression de \(\uparrow_1 \theta\), comme il suit:
\[
\begin{array}{r}
\varphi_1 \theta=\varphi \theta+\varphi(\theta+\alpha)+\varphi(\theta-\alpha)+\varphi(\theta+2 \alpha)+\varphi(\theta-2 \alpha)+\cdots \\
+\varphi(\theta+n \alpha)+\varphi(\theta-n \alpha)
\end{array}
\]
ou, en vertu de la formule

En faisant \(\varphi \theta=x, \varphi_1 \theta\) devient une fonction rationnelle de \(x\). En la désignant par \(\psi x\), on aura
\[
\psi x=x \cdot\left(1+\frac{2 f \alpha \cdot F \alpha}{1+e^2 c^2 \varphi^2 \alpha \cdot x^2}+\cdots+\frac{2 f n \alpha \cdot F n \alpha}{1+e^2 c^2 \varphi^2 n \alpha \cdot x^2}\right)
\]
43.

Maintenant soit \(\varepsilon\) une quantité quelconque, je dis qu'on aura
%365
En effet il est clair que la fonction
\[
R=\left(1-\frac{\psi x}{\tau_1 \varepsilon}\right)\left(1+e^2 c^2 \varphi^2 \alpha \cdot x^2\right) \ldots\left(1+e^2 c^2 \varphi^2 n \alpha \cdot x^2\right)
\]
sera entière et du degré \(2 n+1\); mais en faisant \(x=\uparrow \varepsilon, \psi x\) deviendra \(=\varphi_1 \varepsilon\), et par suite \(R\) se réduira à zéro pour cette valeur de \(x\). De même en faisant \(x=\varphi(\varepsilon+m \alpha)\), où \(m\) est entier, on aura \(\psi x=\varphi_1(\varepsilon+m \alpha)\), ou, en vertu de l'équation (233), \(\psi x=\varphi_1 \varepsilon\). Donc \(1-\frac{\psi^{\prime} x}{\varphi_1 \varepsilon}=0\), et par conséquent \(x=\varphi(\varepsilon+m \alpha)\) sera une racine de l'équation \(\boldsymbol{R}=0\), quel que soit le nombre entier \(m\). Or généralement toutes les quantités
\[
\varphi \varepsilon, \varphi(\varepsilon+\alpha), \varphi(\varepsilon+2 \alpha), \ldots \varphi(\varepsilon+2 n \alpha)
\]
sont différentes entre elles. En effet si l'on avait
\[
\varphi\left(\varepsilon+m^{\prime} \alpha\right)=\varphi\left(\varepsilon+\mu^{\prime} \alpha\right)
\]
il s'ensuivirait en vertu de la formule (31)
d'où
\[
\varepsilon+m^{\prime} \alpha=(-1)^{k+k^{\prime}}\left(\varepsilon+\mu^{\prime} \alpha\right)+k \omega+k^{\prime} \tilde{\omega} i
\]
\[
\begin{aligned}
& k+k^{\prime}=2 k^{\prime \prime}, \\
& k=k^{\prime \prime}+l, k^{\prime}=k^{\prime \prime}-l, \\
& \left(m^{\prime}-\mu^{\prime}\right) \alpha=\left(k^{\prime \prime}+l\right) \omega+\left(k^{\prime \prime}-l\right) \bar{\omega} i .
\end{aligned}
\]

De la, en substituant la valeur de \(\alpha=\frac{(m+\mu) \omega+(m-\mu) \omega i}{2 n+1}\), on tire
et
\[
\begin{aligned}
& \left(m^{\prime}-\mu^{\prime}\right)(m+\mu)=(2 n+1)\left(k^{\prime \prime}+l\right), \\
& \left(m^{\prime}-\mu^{\prime}\right)(m-\mu)=(2 n+1)\left(k^{\prime \prime}-l\right)
\end{aligned}
\]
\[
m^{\prime}-\mu^{\prime}=(2 n+1) \frac{k^{\prime \prime}}{m}=(2 n+1) \frac{l}{\mu},
\]
équation contradictoire, parce que nous avons supposé que l'un des deux nombres \(m\) et " soit premier avec \(2 n+1\), et que \(m^{\prime}-\mu^{\prime}\) est toujours moindre que \(2 n+1\). Maintenant les \(2 n+1\) quantités (239) étant différentes entre elles, elles sont précisément les \(2 n+1\) racines de l'équation \(R=0\). Donce on a
%366
\[
R=A\left(1-\frac{x}{\varphi \varepsilon}\right)\left(1-\frac{x}{\varphi(\varepsilon+\alpha)}\right) \cdots\left(1-\frac{x}{\varphi(\varepsilon+2 n \alpha)}\right)
\]
où \(A\) est un coefficient constant, qu'on trouvera en attribuant à \(x\) une valeur particulière; par exemple en faisant \(x=0\), on a \(R=A\); or l'équation (238) dome pour \(x=0: R=1\), donc \(A=1\), et par conséquent l'équation (237) a lieu.
En multipliant cette équation par \(p \varepsilon\) ét faisant ensuite \(\varepsilon=0\), il viendra
\[
\psi^{\prime}(x)=g x \frac{\left(1-\frac{x}{q^{\prime}}\right)\left(1-\frac{x}{q^2 u}\right) \cdots\left(1-\frac{x}{r^{2 n \alpha}}\right)}{\left(1+e^2 c^2 q^2 \alpha \cdot x^2\right) \cdots\left(1+e^2 c^2 \boldsymbol{q}^2 n \alpha \cdot x^2\right)},
\]
oì g) est la valeur de \(\frac{\tau_1 \varepsilon}{q_{\varepsilon}}\) pour \(\varepsilon=0\). En faisant, daus la formule (235), \(\theta=0\), après avoir divisé par \(\varphi \theta\), on trouve l'expression suivante de cette constante
\[
y=1+2 f \alpha \cdot F \alpha+2 f 2 \alpha \cdot F 2 \alpha+\cdots+2 f n \alpha . F n \alpha .
\]

En faisant dans la formule \((230) \theta=n \alpha-\left(m^{\prime}+1\right) \alpha\), on trouve
\[
\uparrow\left(2 n \alpha-m^{\prime} \alpha\right)=\uparrow\left[-\left(m^{\prime}+1\right) \alpha\right]=-\uparrow\left(m^{\prime}+1\right) \alpha .
\]

Done on pent écrire l'expression de \(\psi x\) comme il suit:
\[
\psi x=g x \frac{\left(1-\frac{x^2}{q^2 \alpha}\right)\left(1-\frac{x^2}{q^2 2 \kappa}\right) \cdots\left(1-\frac{x^2}{r^2 n x}\right)}{\left(1+e^2 c^2 q^2 \alpha \cdot x^2\right)\left(1+e^2 c^2 q^2 2 \alpha \cdot r^2\right) \cdots\left(1+e^2 c^2 \tau^2 n \alpha \cdot x^2\right)}
\]
44.

Maintenant faisons dans l'expression de \(1-\frac{\mu^{\prime} x}{q_1 \varepsilon}, \varepsilon=\frac{(1)}{2}\). En supposant pour abréger
\[
\varrho=\left(1+e^2 c^2 \varphi^2 \alpha \cdot x^2\right)\left(1+e^2 c^2 \varphi^2 2 \alpha \cdot x^2\right) \cdots\left(1+e^2 c^2 \varphi^2 n \alpha \cdot x^2\right),
\]
on aura
\(1-\frac{\psi x}{\tau_1 \frac{\omega}{2}}=\left\{1-\frac{x}{\tau \frac{\omega}{2}}\right\}\left\{1-\frac{x}{\tau\left(\frac{\omega}{2}+\alpha\right)}\right\}\left\{1-\frac{x}{\tau\left(\frac{\omega}{2}+2 \alpha\right)}\right\} \cdots\left\{1-\frac{x}{\tau\left(\frac{\omega}{2}+2 n \alpha\right)}\right\} \cdot \frac{1}{\varrho}\) or, en faisant dans la formule (230)
%367
\[
\theta=\frac{(\prime)}{2}+\left(n-m^{\prime}-1\right) \alpha
\]
on it
\[
\varphi\left(\frac{\omega}{2}+\left(2 n-m^{\prime}\right) \alpha\right)=\varphi\left(\frac{\omega}{2}-\left(m^{\prime}+1\right) \alpha\right)
\]
donc en vertu de la formule (17),
il viendra
\[
\varphi\left(\frac{\omega}{2}-\alpha\right)=\varphi\left(\frac{\omega}{2}+\alpha\right)
\]
\[
\varphi\left(\frac{\omega}{2}+\left(2 n-m^{\prime}\right) \alpha\right)=\varphi\left(\frac{\omega}{2}+\left(m^{\prime}+1\right) \alpha\right) .
\]

Cette équation fait voir qu'on peut écrire l'expression de \(1-\frac{\psi^{\prime} x}{r_1^{(1)}}\) comme il suit:
\[
\begin{aligned}
& 1-\frac{\psi_{i x}}{\varphi_1 \frac{\omega}{2}} \\
& =(1-c x)\left\{1-\frac{x}{\varphi\left(\frac{\omega}{2}+\alpha\right)}\right\}^2\left\{1-\frac{x}{\tau\left(\frac{\omega}{2}+2 \alpha\right)}\right\}^2 \cdots\left\{1-\frac{x}{\varphi\left(\frac{\omega}{2}+n \alpha\right)}\right\}^2 \cdot \frac{1}{\varrho} \cdot
\end{aligned}
\]

En mettant \(-x\) au lieu de \(+x\), on aura semblablement
(246) \(1+\frac{\psi^2}{\tau_1 \frac{\omega}{2}}\)
\[
=(1+c x)\left\{1+\frac{x}{\tau\left(\frac{\omega}{2}+\alpha\right)}\right\}^2\left\{1+\frac{x}{\tau\left(\frac{\omega}{2}+2 \alpha\right)}\right\}^3 \cdots\left\{1+\frac{x}{\varphi\left(\frac{\omega}{2}+n \alpha\right)}\right\}^2 \cdot \frac{1}{\varrho} .
\]

Dunc si l'on fait
\[
y=k \cdot \psi x, \quad c_1=\frac{1}{k \cdot \uparrow_1 \frac{\omega_2^2}{2}},
\]
où \(k\) est indéterminé, et
\[
\left\{\begin{array}{l}
t=\left\{1-\frac{x}{\uparrow\left(\frac{\omega}{2}+\alpha\right)}\right\} \cdots\left\{1-\frac{x}{\uparrow\left(\frac{\omega}{2}+u \alpha\right)}\right\} \\
t_1=\left\{1+\frac{x}{\uparrow\left(\frac{\omega}{2}+\alpha\right)}\right\} \cdots\left\{1+\frac{x}{\uparrow\left(\frac{\omega}{2}+n \alpha\right)}\right\},
\end{array}\right.
\]
%368
on aura
\[
1-c_1 y=(1-c x) \frac{t^2}{\varrho} ; 1+c_1 y=(1+c x) \frac{t_1^2}{\varrho} .
\]

De la même manière, en faisant
\[
\left\{\begin{array}{l}
s=\left\{1-\frac{x}{\uparrow\left(\frac{i}{2} i+\alpha\right)}\right\} \cdots\left\{1-\frac{x}{\uparrow\left(\frac{\omega}{2} i+n \alpha\right)}\right\}, \\
s_1=\left\{1+\frac{x}{\uparrow\left(\frac{\omega}{2} i+\alpha\right)}\right\} \cdots\left\{1+\frac{x}{\uparrow\left(\frac{\omega}{2} i+n c\right)}\right\},
\end{array}\right.
\]
et
\[
e_1= \pm \frac{i}{k \cdot \Upsilon_1\left(\frac{\tilde{\omega}}{2} i\right)}
\]
on trouvera ces deux équations:
\[
1 \mp e_1 i y=(1-e i x) \frac{s_1^2}{\varrho} ; 1 \pm e_1 i y=(1+e i x) \frac{s^2}{\varrho} .
\]

Les équations (249) et (252) donneront
\[
\left(1-c_1^2 y^2\right)=\left(1-c^2 x^2\right) \frac{t^2 t_1^2}{\varrho^2} ;\left(1+e_1^2 y^2\right)=\left(1+e^2 x^2\right) \frac{s^2 s_1^2}{\varrho^2}
\]
et par conséquent
\[
\sqrt{\left(1-c_1^2 y^2\right)\left(1+e_1^2 y^2\right)}= \pm \frac{t t_1 s s_1}{\varrho^2} \sqrt{\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)}
\]

Maintenant l'expression de \(y\) donne \(d y=\frac{P}{\varrho^2} d x\), où \(P\) sera une fonction entière de \(x\) du degrè \(4 n\), donc
\[
\frac{d y}{\sqrt{\left(1-c_1^2 y^2\right)\left(1+e_1^2 y^2\right)}}= \pm \frac{P}{t t_1 s s_1} \cdot \frac{d x}{\sqrt{\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)}} \cdot
\]

Or je dis que la fonction \(\frac{P}{t t_1 s s_1}\) se réduira à une quantité constante. En effet on a
\[
1-c_1 y=(1-c x) \frac{t^2}{\varrho}
\]
en différentiant, et mettant pour \(d y\) sa valeur \(\frac{P d x}{\varrho^2}\), on aura
%369
\[
P=\frac{t}{c_1}\left[\operatorname{ct} \varrho-(1-c x)\left(2 \varrho \frac{d t}{d x}-t \frac{d \varrho}{d x}\right)\right]
\]

On voit de là que \(P\) est divisible par \(t\). De la même manière on prouvera que \(P\) est divisible par les trois fonctions \(t_1, s, s_1\). Donc si deux quelconques des quatre fonctions \(t, t_1, s, s_1\) n'ont point de facteur commun, \(P\) sera divisible par leur produit. Or e'est ce qu'on peut voir aisément à l'aide des expressions de ces fonctions. Donc \(\frac{P}{t t_1 s s_1}\) est une fonction entière de \(x\). Or \(P\) est du degré \(4 n\), et chacune des fonctions \(t, t_1, s, s_1\) est du degré \(n\). Donc il est prouvé que \(\frac{P}{t t_1 s s_1}\) est une quantité constante. En la désignant par \(a\), il viendra
\[
\frac{d y}{\sqrt{\left(1-c_1^2 y^2\right)\left(1+e_1^2 y^2\right)}}= \pm a \frac{d x}{\sqrt{\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)}} .
\]

Pour déterminer \(a\) il suffit d'attribuer à \(x\) une valeur particulière. Én faisant par exemple \(x=0\), on aura
\[
t=t_1=s=s_1=1 ; \quad P=\varrho^8 \frac{d y}{d x}=\frac{d y}{d x}=k \psi^{\prime} x
\]

Or en différentiant l'expression de \(\psi x\), et faisant ensuite \(x=0\), il viendra \(\psi^{\prime} x=g\), donc
\[
a=k g .
\]

On peut donner aux expressions de \(c_1, e_1, g, a\) d'autres formes plus simples, et qui mettront en évidence plusieurs propriétés remarquables de ces quantités.

Par la formule \((240)\) on voit que le coefficient de \(x^{2 n+1}\) dans la fonction \(R\) est \(-\frac{A}{\rho \varepsilon \cdot \uparrow(\varepsilon+\alpha) \ldots q(\varepsilon+2 n c t)}\); or d'après les équations (238) et (243) le même coefficient sera
donc, puisque \(A=1\),
%370
En faisant dans les équations \((236),(243) x=\frac{1}{0}\), après avoir divisé par \(x\), on obtiendra deux valeurs de \(\frac{\psi x}{x}\), savoir
1 et \(\frac{g(-1)^n}{(e c)^{2 n}\left(\tau \alpha \cdot \gamma^2 \alpha \ldots q n \alpha\right)^4}\),
donc, en les égalant,
\[
g=(-1)^n(e c)^{2 n}(\varphi \alpha \cdot \varphi 2 \alpha \ldots \varphi n \alpha)^4
\]
et par conséquent
\[
\begin{array}{r}
\varphi_1(\varepsilon)=(e c)^{2 n}\left(\varphi \alpha \cdot \varphi^2 \alpha \ldots \varphi n \alpha\right)^2 \varphi \varepsilon \cdot \varphi(\varepsilon+\alpha) \cdot \varphi(\varepsilon+2 \alpha) \ldots \varphi(\varepsilon+2 n \alpha) \\
=\varphi(\varepsilon)+\varphi(\varepsilon+\alpha)+\varphi(\varepsilon+2 \alpha)+\cdots+\varphi(\varepsilon+2 n \alpha) .
\end{array}
\]

Cette équation exprime une propriété remarquable de la fonction \(\varphi\). En y posant \(\varepsilon=\frac{\omega}{2}\) et \(\varepsilon=\frac{\tilde{\omega}}{2} i\), on obtiendra
\[
(258)\left\{\begin{array}{l}
\varphi_1\left(\frac{\omega}{2}\right)=\frac{1}{k c_1}=(e c)^{2 n} \delta^2 \cdot \varphi\left(\frac{\omega}{2}\right) \cdot \varphi\left(\frac{\omega}{2}+\alpha\right) \cdots \varphi\left(\frac{\omega}{2}+2 n \alpha\right), \\
\varphi_1\left(\frac{\omega}{2} i\right)=\frac{ \pm i}{k e_1}=(e c)^{2 n} \delta^2 \cdot \varphi\left(\frac{\tilde{\omega}}{2} i\right) \cdot \varphi\left(\frac{\omega}{2} i+\alpha\right) \cdots \varphi\left(\frac{\tilde{\omega}}{2} i+2 n \alpha\right)
\end{array}\right.
\]
où l'on a fait pour abréger
\[
\delta=\varphi \alpha \cdot \varphi 2 \alpha \cdot \varphi 3 \alpha \ldots \varphi n \alpha .
\]

En remarquant que
et
\[
\varphi\left(\frac{\omega}{2}+\left(2 n-m^{\prime}\right) \alpha\right)=\varphi\left(\frac{\omega}{2}+\left(m^{\prime}+1\right) \alpha\right)
\]
\[
\varphi\left(\frac{\tilde{\omega}}{2} i+\left(2 n-m^{\prime}\right) \alpha\right)=\varphi\left(\frac{\tilde{\omega}}{2} i+\left(m^{\prime}+1\right) \alpha\right)
\]
et en faisant
\[
k\left(e^2 c^2\right)^n \delta^2=f
\]
on tire de ces équations
\((261)\left\{\begin{array}{l}\frac{1}{c_1}=\frac{f}{c}\left[\varphi\left(\frac{\omega}{2}+\alpha\right) \cdot \varphi\left(\frac{\omega}{2}+2 \alpha\right) \ldots \varphi\left(\frac{\omega}{2}+n \alpha\right)\right]^2, \\ \frac{1}{e_1}= \pm \frac{f}{e}\left[\varphi\left(\frac{\tilde{\omega}}{2} i+\alpha\right) \cdot \varphi\left(\frac{\omega}{2} i+2 \alpha\right) \ldots \varphi\left(\frac{\omega}{2} i+n \alpha\right)\right]^2,\end{array}\right.\)
Multipliant et remarquant qu'on a (18)
%371
on obtiendra
\[
\varphi\left(\frac{\omega}{2}+\alpha\right) \uparrow\left(\frac{\tilde{\omega}}{2} i+\alpha\right)=\frac{i}{e c}
\]
d'où
\[
\pm \frac{1}{c_1 e_1}=\frac{(-1)^n f^2}{(e c)^{2 n+1}}
\]
\[
c_1 e_1= \pm \frac{(-1)^n \cdot(c c)^{2 n+1}}{f^3}
\]

De même en divisant on obtiendra
\[
\left\{\begin{array}{l} 
\pm \frac{e_1}{c_1}=(-1)^n \frac{e}{c}(e c)^{2 n}\left[\Upsilon\left(\frac{\omega}{2}+\alpha\right) \cdot \varphi\left(\frac{(1)}{2}+2 \alpha\right) \ldots \varphi\left(\frac{(1)}{2}+n \alpha\right)\right]^4 \\
\pm \frac{c_1}{e_1}=(-1)^n \frac{c}{e}(e c)^{2 n}\left[\varphi\left(\frac{\tilde{\omega}}{2} i+\alpha\right) \cdot \varphi\left(\frac{\tilde{\omega}}{2} i+2 \alpha\right) \ldots \varphi\left(\frac{\tilde{\omega}}{2} i+n \alpha\right)\right]^4
\end{array}\right.
\]

Précédemment nous avons trouvé \(a=\log\), et \(g=(-1)^n(e c)^{2 n} J^4\), donc
\[
a=(-1)^n f \cdot \delta^2 \text {. }
\]

Également nous avons \(y=k . \psi x\), donc en vertu de l'équation (243)

Donc les valeurs précédentes de \(c_1, e_1, a\) et \(y\) donneront
d'oì
\[
\frac{d y}{\sqrt{\left(1-c_1^2 y^2\right)\left(1+e_1^2 y^2\right)}}= \pm \frac{a d x}{\sqrt{\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)}}
\]
\[
\int \frac{d y}{\sqrt{\left(1-c_1^2 y^2\right)\left(1+e_1^2 y^2\right)}}= \pm a \int \frac{d x}{\sqrt{\left(1-c^2 x^2\right)\left(1+e^2 x^2\right)}} .
\]
45.

Les formules (261) domnent les valeurs des quantités \(c_1\) et \(e_1\), exprimées en \(c\) et \(e\) à l'aide de la fonction \(\varphi\). Or on peut aussi les déterminer à l'airle d'une équation algébrique. En effet on a
et
\[
\begin{gathered}
{\left[\varphi\left(\frac{\omega}{2}+\alpha\right)\right]^2=\frac{1}{c^8}\left(\frac{f \alpha}{F^2 \alpha}\right)^2=\frac{1}{c^8} \cdot \frac{1-e^2 \varphi^2 \alpha}{1+e^2 q^2 \alpha}} \\
{\left[\tau\left(\frac{\omega}{2} i+\alpha\right)\right]^2=-\frac{1}{e^9}\left(\frac{F \alpha}{f \alpha}\right)^2=-\frac{1}{e^2} \cdot \frac{1+e^2 \varphi^2 \alpha}{1-c^2 \varphi^2 \alpha}}
\end{gathered}
\]
%372
donc il est clair que les valeurs de \(c_1\) et \(e_1\) pourront être exprimées en fonctions rationnelles et symétriques des quantités \(\varphi \alpha, \varphi 2 \alpha, \ldots \varphi n \alpha\). Donc si \(2 n+1\) est un nombre premier, on peut, en vertu de ce qu'on a vu ( \(\mathrm{V}\) ), déterminer \(c_1\) et \(e_1\) à l'aide d'une équation algébrique du \((2 n+2)^{\text {iàme }}\) degré. On peut encore démontrer que la même chose aura lieu daus le cas où \(2 n+1\) est un nombre composé. Alors on peut même déterminer \(c_l\) et \(e_1\) à l'aide d'une équation d'un degré moindre que \(2 n+2\).

Donc on anra un certain nombre de transformations correspondantes ì charue valeur de \(2 n+1\).
46.
On a supposé dans ce qui précède que \(e\) et \(c\) soient des quantités réelles et positives; mais ayant exprimé \(c_1\) et \(e_1\) en \(e\) et \(c\) par des équations algébriques, il est clair que la formule (266) aura lieu également en dommant à \(e\) et \(c\) des valeurs réelles et imaginaires quelconques. Dans le cas où \(e^2\), \(c^2\) sont réelles, on peut même se servir des expressions (261), (265). Mais alor's \(\omega\) et \(\widetilde{\omega}\) ne seront pas toujours des quantités réelles. An reste l'une des quantités \(c_1\) et \(e_1\), à cause de l'indéterminée \(f\), peut être prise à volonté; seulement il faut excepter les valeurs zéro et.l'infini.
47.
Si l'on suppose \(c\) et \(e\) réels et \(2 n+1\) premier, les valeurs de \(c_1\) et \(e_1\) seront imaginaires, excepté deux d'entre elles, dont l'une répond à
\[
\alpha=\frac{2 m \omega}{2 n+1}
\]
et l'autre à
\[
\alpha=\frac{2 \mu \tilde{\omega} i}{2 n+1}
\]
A. Supposons d'abord
\[
\alpha=\frac{2 m \omega}{2 n+1}
\]

Dans ce cas on aura (261)
\[
\frac{1}{c_x}=\frac{f}{c}\left[\varphi\left(\frac{\omega}{2}+\frac{2 m \omega}{2 n+1}\right) \cdot \varphi\left(\frac{\omega}{2}+2 \frac{2 m \omega}{2 n+1}\right) \cdots \varphi\left(\frac{\omega}{2}+n \frac{2 m \omega}{2 u+1}\right)\right]^2 .
\]
%373
Soit "ı. \(2 m=(2 n+1) t \pm a_\mu\), où \(t\) est entier, et \(a_\mu\) entier positif et moindre que \(\frac{2 n+1}{2}\), on aura
\[
\begin{aligned}
& \uparrow\left(\frac{(1)}{2}+11 \frac{2 m(1)}{2 n+1}\right)=\varphi\left(\frac{(1)}{2} \pm \frac{a_{\mu(1)}}{2 n+1}+t(1)\right)=(-1)^t \uparrow\left(\frac{(1)}{2} \pm \frac{a_\mu(1)}{2 n+1}\right) \\
&= \pm \uparrow\left(\frac{2 n+1-2 a_\mu(1)}{2 n+1}\right) .
\end{aligned}
\]

Or. les nombres \(a_1, a_2, a_3, \ldots a_n\) seront les mêmes que les suivans 1,2 , 3, ...n, mais dans un ordre différent; donc l'expression de \(\frac{1}{c_1}\) pourra être mise sous la forme
\[
\frac{1}{c_1}=\frac{f}{c}\left[\uparrow\left(\frac{1}{2 n+1} \frac{\omega}{2}\right) \uparrow\left(\frac{3}{2 n+1} \frac{\omega}{2}\right) \cdots \uparrow\left(\begin{array}{ccc}
2 n-1 & (1) \\
2 n+1 & 2
\end{array}\right)\right]^2 .
\]

De même l'équation (263) domnera

Soit maintenant \(c=1, c_1=1\), on aura, en posant \(\pm(-1)^n=1\),
\(\left(269^{\prime}\right) \quad e_1=e^{2 n+1}\left[\varphi\left(\frac{1}{2 n+1} \frac{(1)}{2}\right) \varphi\left(\frac{3}{2 n+1} \frac{(0}{2}\right) \cdots \varphi\left(\frac{2 n-1}{2 n+1} \frac{(1)}{2}\right)\right]^4\),
(270) \(\quad \int \frac{d y}{\sqrt{\left(1-y^2\right)\left(1+e_1^2 y^2\right)}}= \pm a \int \frac{d x}{\sqrt{\left(1-x^2\right)\left(1+e^2 x^2\right)}}+\) Const.
(271) \(y=\)
\[
(-1)^n f \cdot x \frac{\left[\tau^2\left(\frac{\omega}{2 n+1}\right)-x^2\right]\left[\tau^2\left(\frac{2 \omega}{2 n+1}\right)-x^2\right] \cdots\left[\Upsilon^2\left(\frac{n v}{2 n+1}\right)-x^2\right]}{\left[1+e^2 \eta^2\left(\frac{\omega}{2 n+1}\right) x^2\right]\left[1+e^2 \varphi^2\left(\frac{2 w}{2 n+1}\right) x^3\right] \cdots\left[1+e^3 \cdot \varphi^3\left(\frac{n v}{2 n+1}\right) x^3\right]},
\]
\[
f=\frac{e^{n+1}}{\sqrt{e_1}},
\]
ou bien
\[
a=(-1)^n\left\{\frac{\uparrow\left(\frac{\omega}{2 n+1}\right) \cdot \uparrow\left(\frac{2 \omega}{2 n+1}\right) \cdots \uparrow\left(\frac{n \omega}{2 n+1}\right)}{\tau\left(\frac{1}{2 n+1} \frac{\omega}{2}\right) \cdot \uparrow\left(\frac{3}{2 n+1} \frac{\omega}{2}\right) \cdots \uparrow\left(\frac{2 n-1}{2 n+1} \frac{\pi}{2}\right)}\right\}^8 .
\]

Si l'on suppose e moindre que l'unité ou égal à l'unité, \(e_1\) sera tonjours
%374
moindre que \(e\), et lorsque \(2 n+1\) est un très grand nombre, \(e_1\) sera extrèmement petit.
48.
I de \(x\). Il pourra être jugé aisément comme il suit. On a par ce qui précèle
\[
\sqrt{\left(1-y^2\right)\left(1+e_1^2 y^2\right)}= \pm \frac{t t_1 s s_1}{\varrho^2} \sqrt{\left(1-x^2\right)\left(1+e^2 x^2\right)}
\]

En supposant \(x\) réel, \(\varphi^2\) sera toujours fini et positif, de même que \(\sqrt{1}+c_1^2 y^2\) et \(\sqrt{1+e^2 x^2}\). Done le signe du second membre de l'équation est le même que celui de la quantité
\[
t t_1 s s_1 \sqrt{\frac{1-x^2}{1-y^2}}
\]
maintenant on a
\[
s s_1=\left\{1-\frac{x^2}{\tau^2\left(\frac{m}{2} i+\alpha\right)}\right\} \cdots\left\{1-\frac{x^2}{r^2\left(\frac{\omega}{2} i+n \alpha\right)}\right\}
\]
or \(\varphi\left(\frac{\tilde{\omega}}{2} i+\alpha\right)=\frac{i}{e} \cdot \frac{F \alpha}{f \alpha}\) etc., donc
\[
s s_1=\left[1+\left(\frac{e f \alpha \cdot x}{F_\alpha}\right)^2\right] \cdots\left[1+\left(\frac{e f n \alpha . x}{F n \alpha}\right)^2\right]
\]
done, en remarquant que \(\alpha\) est réel dans le cas que nous considérons, on voit que \(s s_1\) sera toujours une quantité positive; or \(t t_1\) est réel, done la quantité \(\sqrt{\frac{1-x^2}{1-y^2}}\) será positive également, et par conséquent le signe dont il s'agit sera le même que celui de la quantité \(t t_1\). Il n'est pas difficile de voir qu'en se servant de la formule (248) et en mettant pour \(\alpha\) sa valeur \(\frac{2 m \omega}{2 n+1}\), on aura
\[
t t_1=\left\{1-\frac{x^2}{\varphi^2\left(\frac{1}{2 n+1} \frac{\omega}{2}\right)}\right\}\left\{1-\frac{x^2}{\tau^2\left(\frac{3}{2 n+1}-\frac{\omega}{2}\right)}\right\} \cdots\left\{1-\frac{x^2}{\tau^2\left(\frac{2 n-1}{2 n+1} \frac{\omega}{2}\right)}\right\},
\]
quantité qui est positive depuis \(x=0\) jusqu’à \(x=\varphi\left(\frac{1}{2 n+1} \frac{\omega}{2}\right)\), négative
%375
depuis \(x=\varphi\left(\frac{1}{2 n+1} \frac{\omega}{2}\right)\) jusqu’d \(x=\varphi\left(\frac{3}{2 n+1} \frac{\omega}{2}\right)\), positive depuis \(x=\varphi\left(\frac{3}{2 n+1} \frac{\omega}{2}\right)\) jusqu'à \(x=\varphi\left(\frac{5}{2 n+1} \frac{\omega}{2}\right)\) etc.

Si \(x\) est plus grand que l'unité \(t t_1\) aura toujours le même signe, savoir \((-1)^n\). Donc, dans ce cas, l'équation (270) donnera, en intégrant à partir de \(x=1\),
\[
\int_1^y \frac{d y}{\sqrt{\left(y^2-1\right)\left(1+e_1^2 y^2\right)}}=a \int_1^x \frac{d x}{\sqrt{\left(x^2-1\right)\left(1+e^2 x^2\right)}} .
\]

Si la valeur de \(x\) est moindre que l'unité, on aura
\[
\int \frac{d y}{\sqrt{\left(1-y^2\right)\left(1+e_1^2 y^2\right)}}=a \int \frac{d x}{\sqrt{\left(1-x^2\right)\left(1+e^y x^2\right)}}+\text { Const. }
\]
entre les limites \(x=\varphi\left(\frac{4 m-1}{2 n+1} \frac{\omega}{2}\right)\) et \(x=\varphi\left(\frac{4 m+1}{2 n+1} \frac{\omega}{2}\right)\), et
\[
-\int \frac{d y}{\sqrt{\left(1-y^2\right)\left(1+e_1^2 y^2\right)}}=a \int \frac{d x}{\sqrt{\left(1-x^2\right)\left(1+e^2 x^2\right)}}+\text { Const. }
\]
entre les limites \(x=\varphi\left(\frac{4 m+1}{2 n+1} \frac{\omega}{2}\right)\) et \(x=\varphi\left(\frac{4 m+3}{2 n+1} \frac{\omega}{2}\right)\).
Si par exemple on suppose \(x\) renfermé entre les limites
\[
-\varphi\left(\frac{1}{2 n+1} \frac{\omega}{2}\right) \text { et }+\varphi\left(\frac{1}{2 n+1} \frac{(1)}{2}\right)
\]
on aura, en intégrant à partir de \(x=0\),
\[
\int_0^y \frac{d y}{\sqrt{\left(1-y^2\right)\left(1+e_1^2 y^2\right)}}=a \int_0^x \frac{d x}{\sqrt{\left(1-x^2\right)\left(1+e^2 x^2\right)}}
\]

En faisant \(x=\varphi\left(\frac{\omega}{(2 n+1) \cdot 2}\right)\), on alla \(y=(-1)^n\), et par suite
\[
\int_0^1 \frac{d y}{\sqrt{\left(1-y^2\right)\left(1+e_1^2 y^z\right)}}=\frac{u \omega}{2(2 n+1)}(-1)^n
\]
d'où
\[
(-1)^n a=\frac{4 n+2}{(1)} \int_0^1 \frac{d y}{\sqrt{\left(1-y^2\right)\left(1+e_1^2 y^2\right)}} .
\]

Cette expression de a est très commode pour le calcul. En néggligeant les quantités de l'ordre \(e_1^y\), on obtiendra
%376
\((279)\)
\[
(-1)^n a=(2 n+1) \frac{\pi}{\omega} \text {. }
\]

En substituant et négligeant toujours \(e_1^2\), la formule (277) donnera
1. Dans le cas où \(\alpha=\frac{2 \mu \hat{o} i}{2 n+1}\), on tronvera de la même manière la formule suivante
\[
\text { - } \int_0^x \cdot \frac{d x}{\sqrt{\left(1-x^2\right)\left(1+e^2 x^2\right)}}=a^{\prime} \int_0^y \frac{d y}{\sqrt{\left(1-y^2\right)\left(1+e_1^2 y^2\right)}}
\]
où

La formule précédente a lieu pour toutes les valeurs de \(x\) moindres que l'unité.
49.
Pour avoir une théorie complete de la transformation des fonctions elliptiques, il faudrait connaître toutes les transformations possibles; or je suis parvenu à démontrer, qu'on les obtient toutes, en combinant celle de M. Legendre avec celles contenues dans la formule ci-dessus, même en cherchant la relation la plus générale entre un nombre quelconque de fonctions elliptiques.
%377
Ce théorème, dont les conséquences embrassent presque toute la théorie des fonctions elliptiques, m'a conduit à un très grand nombre de belles propriétés de ces fonctions.
\(\S X\).
Sur l'intégration de l'équation séparée
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1+\mu y^2\right)}}=a \frac{d x}{\sqrt{\left(1-x^2\right)\left(1+\mu x^2\right)}} \text {. }
\]
50.

On peut toujours, comme on sait, présenter l'intégrale complète de cette équation sous une forme algébrique, lorsque la quantité constante \(a\) est un nombre rationnel, quelle que soit d'ailleurs la valeur réelle ou imaginaire de \(\mu\). Mais si a n'est pas un nombre rationnel, cela n'a pas lieu. A cet égard je suis parvenu aux théorèmes suivants:

Théorème I. En supposant \(a\) réel, et l'équation intégrable algébriquement, il faut nécessairement que \(a\) soit un nombre rationnel.

Théorème II. En supposant a imaginaire, et l'équation intégrable algébriquement, il faut nécessairement que \(a\) soit de la forme \(m \pm \sqrt{-1} \cdot \sqrt{n}\), où \(m\) et \(n\) sont des nombres rationnels. Dans ce cas la quantité \(\boldsymbol{\mu}\) n'est pas arbitraire; il faut qu'elle satisfasse à une équation qui a une infinité de racines réelles et imaginaires. Chaque valeur de \(\mu\) satisfait à la question.

La démonstration de ces théorèmes fait partie d'une théorie très étendue des fonctions elliptiques dont je m'occupe actuellement, et qui paraîtra aussitôt qu'il me sera possible. Je me borne ici à considérer un cas particulier, qu'on peut tirer des formules du paragraphe précédent.
Si dans la formule (270) on pose
\[
e_1=\frac{1}{e}
\]
et si l'on remplace \(y\) par \(\frac{e y}{i}\), il viendra
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1+e^2 y^2\right)}}=a \sqrt{-1} \frac{d x}{\sqrt{\left(1-x^2\right)\left(1+e^2 x^2\right)}},
\]
où
%378
\[
y= \pm \sqrt{-1} \cdot e^n x \frac{\left[\varphi^2\left(\frac{\omega}{2 n+1}\right)-x^2\right] \cdots\left[\varphi^2\left(\frac{n \omega}{2 n+1}\right)-x^2\right]}{\left[1+e^2 \varphi^2\left(\frac{\omega}{2 n+1}\right) x^2\right] \cdots\left[1+e^2 \varphi^2\left(\frac{n \omega}{2 n+1}\right) x^2\right]}
\]
\(e\) est déterminé par l'équation \(\left(269^{\prime}\right)\), qui deviendra
\[
(284)\left\{\begin{aligned}
1 & =e^{n+1}\left[\varphi\left(\frac{1}{2 n+1} \frac{\omega}{2}\right) \cdots \varphi\left(\frac{2 n-1}{2 n+1} \frac{\omega}{2}\right)\right]^2, \\
\text { et } a \text { par } & \\
a & = \pm \frac{1}{e}\left\{\frac{\varphi\left(\frac{\omega}{2 n+1}\right) \cdots \varphi\left(\frac{n \omega}{2 n+1}\right)}{\varphi\left(\frac{1}{2 n+1} \frac{\omega}{2}\right) \cdots \varphi\left(\frac{2 n-1}{2 n+1} \frac{\omega}{2}\right)}\right\}^2 .
\end{aligned}\right.
\]

Done on connaît une intégrale particulière de l'équation (282) et par conséquent on en pourra trouver l'intégrale complète.

Dans le cas que nous considérons, la valeur de \(a\) est \(\sqrt{2 n+1}\), ce qu'on démontrera aisément comme il suit:

En mettant dans l'équation (282) \(y=z \sqrt{-1}\), et intégrant entre les limites zéro et \(\varphi\left(\frac{\omega}{4 n+2}\right)\), il viendra
\[
\frac{\widetilde{\omega}}{2}=\int_0^{\frac{1}{e}} \frac{d z}{\sqrt{\left(1+z^2\right)\left(1-e^2 z^2\right)}}=a \frac{\omega}{4 n+2},
\]
en remarquant que les limites de \(z\) seront zéro et \(\frac{1}{e}\). En faisant de même \(x \sqrt{-1}=z\), et intégrant entre les limites zéro et \(\frac{1}{e}\), on trouvera que les limites de \(y\) seront zéro et l'unité et par conséquent
\[
\int_0^1 \frac{d y}{\sqrt{\left(1-y^2\right)\left(1+e^2 y^2\right)}}=\frac{\omega}{2}=a \int_0^{\frac{1}{e}} \frac{d z}{\sqrt{\left(1+z^2\right)\left(1-e^2 z^2\right)}}=a \frac{\tilde{\omega}}{2} .
\]

Done on a
\[
\frac{\omega}{2}=\frac{a}{2 n+1} \frac{\omega}{2}
\]
et
\[
\frac{\omega}{2}=u \frac{\tilde{\omega}}{2}
\]
d'où l'on tire
\[
\begin{aligned}
a & =\sqrt{2 n+1}, \\
\frac{\omega}{\omega} & =\sqrt{2 n+1} .
\end{aligned}
\]
%379
Done l'équation différentielle deviendra
\((287)\)
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1+e^2 y^2\right)}}=\sqrt{-1} \cdot \sqrt{2 n+1} \frac{d x}{\sqrt{\left(1-x^2\right)\left(1+e^2 x^2\right)}} .
\]
51.

Pour donner un exemple, considérons le cas où \(n=1\) et \(n=2\).
A. Si \(n=1\), on aura
\[
\begin{gathered}
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1+e^2 y^2\right)}}=\sqrt{-3} \frac{d x}{\sqrt{\left(1-x^2\right)\left(1+e^2 \cdot x^2\right)}}, \\
y=\sqrt{-1} \cdot e x \frac{\tau^2\left(\frac{\omega}{3}\right)-x^2}{1+e^2 \cdot \tau^2\left(\frac{\omega}{3}\right) \cdot x^2}
\end{gathered}
\]
e est déterminée par l'équation
\[
1=e^2\left[\uparrow\left(\begin{array}{ll}
1 & \omega \\
3 & 2
\end{array}\right)\right]^2
\]

On a
\[
\varphi\left(\frac{\omega}{6}\right)=\varphi\left(\frac{\omega}{2}-\frac{\omega}{3}\right)=\varphi\left(\frac{\omega}{2}\right) \frac{f\left(\frac{\omega}{3}\right)}{F\left(\frac{\omega}{3}\right)}=\frac{\sqrt{1-\varphi^2\left(\frac{\omega}{3}\right)}}{\sqrt{1+\tau^2 \varphi^2\left(\frac{\omega}{3}\right)}},
\]
done
\[
\begin{gathered}
1=e^2 \frac{1-\tau^2\left(\frac{\omega}{3}\right)}{1+e^2 \tau^2\left(\frac{\omega}{3}\right)}=\frac{e^2-e^2 \tau^2\left(\frac{\omega}{3}\right)}{1+e^2 \vartheta^2\left(\frac{\omega}{3}\right)}, \\
a=\frac{\tau^2\left(\frac{\omega}{3}\right)}{\vartheta^2\left(\frac{\omega}{6}\right)} \cdot \frac{1}{e} \cdot
\end{gathered}
\]

Maintenant on trouvera, en combinant ces équations et remettant pour \(a\) sa valeur \(\sqrt{3}\),
\[
\sqrt{3}=e \varphi^2\left(\frac{\omega}{3}\right)
\]
done
\[
\varphi^2\left(\frac{\omega}{3}\right)=\frac{\sqrt{3}}{e}
\]
et par suite
%380
\[
1=\frac{e^2-e \sqrt{3}}{1+e \sqrt{3}}
\]
d'où
\[
e^2-2 \sqrt{3} \cdot e=1
\]
et
\[
e=\sqrt{3}+2 \text {. }
\]

Ayànt trouvé \(e\), on aura
\[
\varphi^2\left(\frac{(1)}{3}\right)=\frac{\sqrt{3}}{2+\sqrt{3}}=2 \sqrt{3}-3 .
\]

Donc on aura l'équation différentielle
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left[1+(2+\sqrt{3})^2 y^2\right]}}=\sqrt{-3} \cdot \frac{d x}{\sqrt{\left(1-x^2\right)\left[1+(2+\sqrt{3})^2 x^2\right]}},
\]
qui sera satisfaite par l'intégrale algébrique
\[
y=\sqrt{-1} \cdot x \frac{\sqrt{3}-(2+\sqrt{3}) x^2}{1+\sqrt{3}(2+\sqrt{3}) x^2} .
\]

Si l'on pose \(x \sqrt{2-\sqrt{3}}\) au lieu de \(x\), et \(y \sqrt{2-\sqrt{3}} \cdot \sqrt{-1}\) au lieu de \(y\), on obtiendra l'équation
\[
\frac{d y}{\sqrt{1-2 \sqrt{3} \cdot y^2-y^4}}=\sqrt{3} \frac{d x}{\sqrt{1+2 \sqrt{3} \cdot x^2-x^4}},
\]
qui sera satisfaite par
\[
y=x \frac{\sqrt{3}-x^2}{1+\sqrt{3} \cdot x^2}
\]
B. Si \(n=2\), on aura l'équation différentielle
où
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1+e^2 y^2\right)}}=\sqrt{-5} \frac{d x}{\sqrt{\left(1-x^2\right)\left(1+e^2 x^2\right)}},
\]
\[
\begin{aligned}
& y=\sqrt{-1} \cdot e^2 x \frac{\varphi^2\left(\frac{\omega}{5}\right)-x^2}{1+e^2 \varphi^2\left(\frac{\omega}{5}\right) \cdot x^2} \cdot \frac{\varphi^2\left(\frac{2 \omega}{5}\right)-x^2}{1+e^2 \varphi^2\left(\frac{2 \omega}{5}\right) \cdot x^2} \\
& 1=e^3 \varphi^2\left(\frac{\omega}{10}\right) \varphi^2\left(\frac{3 \omega}{10}\right) ; \sqrt{5}=e^2 \varphi^2\left(\frac{\omega}{5}\right) \varphi^2\left(\frac{2 \omega}{5}\right) .
\end{aligned}
\]

On a
\[
1=e^3 \varphi^2\left(\frac{\omega}{10}\right) \varphi^2\left(\frac{3 \omega}{10}\right) ; \sqrt{5}=e^2 \varphi^2\left(\frac{\omega}{5}\right) \varphi^2\left(\frac{2 \omega}{5}\right) .
\]
%381
(291)
\[
\begin{aligned}
& \left\{\begin{array}{l}
\varphi^2\left(\frac{\omega}{10}\right)=\varphi^2\left(\frac{\omega}{2}-\frac{2 \omega}{5}\right)=\frac{f^2\left(\frac{2 \omega}{5}\right)}{F^2\left(\frac{2 \omega}{5}\right)}, \\
\varphi^2\left(\frac{3 \omega}{10}\right)=\varphi^2\left(\frac{\omega}{2}-\frac{\omega}{5}\right)=\frac{f^2\left(\frac{\omega}{5}\right)}{F^2\left(\frac{\omega}{5}\right)},
\end{array}\right. \\
& \frac{f\left(\frac{2 \omega}{5}+\frac{\omega}{5}\right)}{F\left(\frac{2 \omega}{5}+\frac{\omega}{5}\right)}=\frac{f\left(\frac{3 \omega}{5}\right)}{F\left(\frac{3 \omega}{5}\right)}=\frac{f\left(\frac{2 \omega}{5}\right) f\left(\frac{\omega}{5}\right)-\varphi\left(\frac{2 \omega}{5}\right) \uparrow\left(\frac{\omega}{5}\right) F\left(\frac{2 \omega}{5}\right) F\left(\frac{\omega}{5}\right)}{F\left(\frac{2 \omega}{5}\right) F\left(\frac{\omega}{5}\right)+e^2 \uparrow\left(\frac{2 \omega}{5}\right) \uparrow\left(\frac{\omega}{5}\right) f\left(\frac{2 \omega}{5}\right) f\left(\frac{\omega}{5}\right)}, \\
& \frac{f\left(\frac{2 \omega}{5}-\frac{\omega}{5}\right)}{F\left(\frac{2 \omega}{5}-\frac{\omega}{5}\right)}=\frac{f\left(\frac{\omega}{5}\right)}{F\left(\frac{\omega}{5}\right)}=\frac{f\left(\frac{2 \omega}{5}\right) f\left(\frac{\omega}{5}\right)+\uparrow\left(\frac{2 \omega}{5}\right) \uparrow\left(\frac{\omega}{5}\right) F\left(\frac{2 \omega}{5}\right) F\left(\frac{\omega}{5}\right)}{F\left(\frac{2 \omega}{5}\right) F\left(\frac{\omega}{5}\right)-e^2 \uparrow\left(\frac{2 \omega}{5}\right) \uparrow\left(\frac{\omega}{5}\right) f\left(\frac{2 \omega}{5}\right) f\left(\frac{\omega}{5}\right)} \text {. } \\
&
\end{aligned}
\]

En multipliant ces valeurs de \(\frac{f\left(\frac{3 \omega}{5}\right)}{F\left(\frac{3 \omega}{5}\right)}\) et \(\frac{f\left(\frac{\omega}{5}\right)}{F\left(\frac{\omega}{5}\right)}\) entre elles, et remarquant que
\[
\begin{aligned}
& f\left(\frac{3 \omega}{5}\right)=-f\left(\frac{2 \omega}{5}\right), \\
& F\left(\frac{3 \omega}{5}\right)=F\left(\frac{2 \omega}{5}\right),
\end{aligned}
\]
on obtiendra
\[
-P=\frac{P^2-\varphi^2\left(\frac{\omega}{5}\right) \varphi^2\left(\frac{2 \omega}{5}\right)}{1-e^4 \cdot \uparrow^2\left(\frac{\omega}{5}\right) \Upsilon^2\left(\frac{2 \omega}{5}\right) \cdot P^2}
\]
où l'on a fait pour abréger
\[
P=\frac{f\left(\frac{2 \omega}{5}\right) f\left(\frac{\omega}{5}\right)}{F\left(\frac{2 \omega}{5}\right) F\left(\frac{\omega}{5}\right)}
\]

Cela posé les équations \((290,291)\) domneront
\[
1=e^3 P^2, \quad \varphi^2\left(\frac{\omega}{5}\right) \varphi^2\left(\frac{2 \omega}{5}\right)=\frac{\sqrt{5}}{e^2},
\]
donc, en substituant,
\[
-\frac{1}{e \sqrt{e}}=\frac{\frac{1}{e^8}-\frac{\sqrt{5}}{e^8}}{1-\frac{\sqrt{5}}{e}}=\frac{1}{e^2} \frac{1-e \sqrt{5}}{e-\sqrt{5}}
\]
%382
d'où
\[
\begin{gathered}
-\sqrt{e}=\frac{1-e \sqrt{5}}{e-\sqrt{5}}, \\
e^3-1-(5+2 \sqrt{5}) e(e-1)=0 .
\end{gathered}
\]

Les racines de cette équation sont
\[
e=1, e=2+\sqrt{5}-2 \sqrt{2+\sqrt{5}}, e=2+\sqrt{5}+2 \sqrt{2+\sqrt{5}}
\]

La dernière de ces racines,
\[
c=2+\sqrt{5}+2 \sqrt{2+\sqrt{5}}=\left[\frac{\sqrt{5}+1}{2}+\sqrt{\frac{\sqrt{5}+1}{2}}\right]^2
\]
répond à la question, car l'équation
\[
1=e^3 \varphi^2\left(\frac{(1)}{10}\right) \varphi^2\left(\frac{3 \omega}{10}\right)
\]
fait voir que e doit être plus grand que l'unité. Connaissant \(e\), on trouve la valeur des quantités \(\varphi\left(\frac{\omega}{5}\right)\) et \(\varphi\left(\frac{2(1)}{5}\right)\) comme il suit.
Nous avons
\[
1=e^3 P^2=e^3 \frac{f^2\left(\frac{\omega}{5}\right) f^2\left(\frac{2 \omega}{5}\right)}{F^2\left(\frac{\omega}{5}\right) F^2\left(\frac{2 \omega}{5}\right)}
\]
or en faisant \(\varphi\left(\frac{\omega}{5}\right)=\alpha\) et \(\varphi\left(\frac{2 \omega}{5}\right)=\beta\), on aura
\[
\begin{aligned}
& f^2\left(\frac{\omega}{5}\right)=1-\alpha^2, \quad f^2\left(\frac{2 \omega}{5}\right)=1-\beta^2, \\
& F^2\left(\frac{\omega}{5}\right)=1+e^2 \alpha^2, \quad F^2\left(\frac{2 \omega}{5}\right)=1+e^2 \beta^2,
\end{aligned}
\]
done
\[
\begin{aligned}
\left(1+e^2 \alpha^2\right)\left(1+e^2 \beta^2\right) & =e^3\left(1-\alpha^2\right)\left(1-\beta^2\right) \\
1+e^2\left(\alpha^2+\beta^2\right)+e^4 \alpha^2 \beta^2 & =e^3-e^3\left(\alpha^2+\beta^2\right)+e^3 \alpha^2 \beta^2 \\
e^3-1-e^3(e-1) \alpha^2 \beta^2 & =e^2(e+1)\left(\alpha^2+\beta^2\right)
\end{aligned}
\]
or nous avons trouvé plus haut, \(\alpha^2 \beta^2=\frac{\sqrt{5}}{e^2}\), donc
\[
e^3-1-e(e-1) \sqrt{5}=e^2(e+1)\left(\alpha^2+\beta^2\right) \text {. }
\]
%383
Donc on connaît \(\alpha^2 \beta^2\) et \(\alpha^2+\beta^2\), et par suite \(\alpha^2\) et \(\beta^2\) par la résolution d'une équation du second degré. On a donc aussi la valeur de \(y\), qui satisfait à l'équation
\[
\begin{aligned}
& \frac{d y}{\sqrt{\left(1-y^2\right)\left[1+\left(2+\sqrt{5}+2 \sqrt{\left.2+\sqrt{5})^2 y^2\right]}\right.\right.}} \\
& \quad=\sqrt{-5} \frac{d x}{\sqrt{\left(1-x^2\right)\left[1+\left(2+\sqrt{5}+2 \sqrt{\left.2+\sqrt{5})^2 x^2\right]}\right.\right.}}
\end{aligned}
\]

Si l'on pose \(\frac{x}{\sqrt{e}}\) au lieu de \(x\), et \(\frac{y \sqrt{-1}}{\sqrt{e}}\) au lieu de \(y\), on obtiendra l'équation
\[
\frac{d y}{\sqrt{1-4 \sqrt{2+\sqrt{5}} \cdot y^2-y^4}}=\sqrt{5} \frac{d x}{\sqrt{1+4 \sqrt{2+\sqrt{5}} \cdot x^2-x^4}}
\]
où
\[
y=x \cdot \frac{\sqrt{5}-\sqrt{10+10 \sqrt{5}} \cdot x^2+x^4}{1+\sqrt{10+10 \sqrt{5}} \cdot x^2+\sqrt{5} \cdot x^4} .
\]
52.

Dans les deux cas que nous venons de considérer, il n'était pas difficile de trouver la valeur de la quantité \(e\), mais la valeur de \(n\) étant plus grande, on parviendra à des équations algébriques, qui peut-être ne seront pas résolubles algébriquement.

Néanmoins on peut dans tous les cas exprimer la valeur de \(e\) par des séries, et comme leur forme est très remarquable, je vais les rapporter ici.

En faisant dans la formule (206) \(\alpha=1\), on aura, en remarquant que \(c=1, \varphi\left(\frac{\omega}{2}\right)=\frac{1}{c}\),
\[
e \omega=4 \pi\left(\frac{\varrho}{\varrho^2+1}+\frac{\varrho^3}{\varrho^6+1}+\frac{\varrho^5}{\varrho^{10}+1}+\cdots\right)
\]
où
\[
\rho=h^{\frac{\varpi}{\omega} \frac{\pi}{2}} \text {. }
\]

En faisant de même dans la formule (204) \(\alpha=\frac{\tilde{0}}{2} i\), on aura \(\psi\left(\begin{array}{c}\tilde{\omega} \\ 2\end{array}\right)\) \(=\frac{i}{e} ; \varepsilon=h^{\frac{\pi}{2} i}=\cos \frac{\pi}{2}+i \sin \frac{\pi}{2}=i\), donc
%384
\[
\frac{i}{e}=\frac{2}{e} \frac{\pi}{\hat{\omega}}\left(\frac{i-i^{-1}}{r+r^{-1}}-\frac{i^3-i^{-3}}{r^3+r^{-3}}+\cdots\right)
\]
c'est-ì-dire
\[
\widetilde{\omega}=4 \pi\left(\frac{r}{r^2+1}+\frac{r^3}{r^6+1}+\frac{r^5}{r^{10}+1}+\cdots\right)
\]
où
\[
r=h^{\frac{\omega}{\widetilde{\omega}} \frac{\pi}{2}} \text {. }
\]

Maintenant dans le cas que nous considérons, on a
\[
\frac{\omega}{\omega}=\sqrt{2 n+1}
\]
et par conséquent
\[
\omega=4 \pi \sqrt{2 n+1}\left\{\frac{h^{\frac{\pi}{2} \sqrt{2 n+1}}}{h^{\pi \sqrt{2 n+1}}+1}+\frac{h^{\frac{3 \pi}{2} \sqrt{2 n+1}}}{h^{3 \pi \sqrt{2 n+1}}+1}+\cdots\right\}
\]

Cette formule dome la valeur de
\[
\omega=2 \int_0^1 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1+e^2 x^2\right)}} .
\]

Ensuite on aura la valeur de e par la formule (294) qui donne, en substituant pour \(\varrho\) sa valeur \(h^{\frac{\varpi}{\omega} \frac{\pi}{2}}=h^{\frac{1}{\sqrt{2 n+1}} \frac{\pi}{2}}\),
\[
e=\frac{4 \pi}{\omega}\left\{\frac{h^{\frac{\pi}{2} \frac{1}{\sqrt{2 n+1}}}}{h^{\frac{\pi}{\sqrt{2 n+1}}}+1}+\frac{h^{\frac{3 \pi}{2}} \frac{1}{\sqrt{2 n+1}}}{\frac{3 \pi}{h^{\sqrt{2 n+1}}}+1}+\cdots\right\}
\]
\(h\) est le nombre \(2,7182818 \ldots\)
Addition au mémoire précédent.
Ayant terminé le mémoire précédent sur les fonctions elliptiques, une note sur les mêmes fonctions par M. C. G. J. Jacobi, inserée dans le n \({ }^0 123\), année 1827, du recueil de M. Schumacher qui a pour titre "Astronomische Nachrichten", m'est venue sous les yeux. M. Jacobi donne le théorème suivant:
%385
Soit \(p\) un nombre impair et \(\theta^{\prime}\) un angle tel qu'on ait, en désignant lintégrale \(\int \frac{d \theta}{\sqrt{1-k^2 \sin ^2 \theta}}\), prise de 0 jusqu'à \(\theta\), par \(F(k, \theta)\),
\[
F^{\prime}\left(k, \theta^{\prime}\right)=\frac{1}{p} F\left(k, 90^{\circ}\right),
\]
et en général \(\boldsymbol{\theta}^{(m)}\) un angle tel qu’on ait
\[
F\left(k, \theta^{(m)}\right)=\frac{m}{p} F^{\prime}\left(k, 90^{\circ}\right) ;
\]
soit déterminé encore l'angle \(\psi\) par l'équation
\[
\operatorname{tang}\left(45^0-\frac{1}{2} \psi\right)=\frac{\operatorname{tang} \frac{1}{2}\left(\theta^{\prime}-\theta\right)}{\operatorname{tang} \frac{1}{2}\left(\theta^{\prime}+\theta\right)} \cdot \frac{\operatorname{tang} \frac{1}{2}\left(\theta^{\prime \prime \prime}+\theta\right)}{\operatorname{tang} \frac{1}{2}\left(\theta^{\prime \prime \prime}-\theta\right)} \cdots \frac{\operatorname{tang} \frac{1}{2}\left(\theta^{(p-2)} \pm \theta\right)}{\operatorname{tang} \frac{1}{2}\left(\theta^{(p-2)} \mp \theta\right)} \operatorname{tang}\left(45^0 \mp \frac{1}{2} \theta\right):
\]
on aura
\[
F(k, \theta)=\mu \cdot F(\lambda, \psi)
\]

Il faut admettre le signe supérieur si \(p\) est de la forme \(4 n+1\), et lo signe inférieur, si \(p\) est de la forme \(4 n-1\). \(\psi\) doit être pris entre \(\frac{m}{2} \pi\) et \(\frac{m+1}{2} \pi\), si \(\theta\) tombe entre \(\theta^{(m)}\) et \(\theta^{(m+1)}\). Les constantes \(\boldsymbol{\mu}\) et \(\lambda\) se déterminent de différentes manières. On a par exemple
\[
\begin{aligned}
\mu & =\frac{1}{2\left(\operatorname{cosec} \theta^{\prime}-\operatorname{cosec} \theta^{\prime \prime \prime}+\cdots \mp \operatorname{cosec} \theta^{(p-2)} \pm \frac{1}{2}\right)}, \\
\lambda & =2 k \mu\left(\sin \theta^{\prime}-\sin \theta^{\prime \prime \prime}+\cdots \mp \sin \theta^{(p-2)} \pm \frac{1}{2}\right) .
\end{aligned}
\]

Ce théorème élégant que M. Jacobi donne sans démonstration est contenu comme cas particulier dans la formule (227) du mémoire précédent, et au fond il est le même que celui de la formule (270). Nous allons le démontrer.
En faisant dans l'intégrale
\[
\begin{array}{cc}
x=\int_0^x \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-k^2 x^2\right)}}, \\
x=\int_0^\theta \frac{d \theta}{\sqrt{1-k^2 \sin ^2 \theta} ;} \\
x=\varphi \alpha,
\end{array}
\]
%386
done
\[
\alpha=F(k, \theta) \text { donne } \sin \theta=\varphi \alpha .
\]

Si \(\theta=90^{\circ}\), on a \(x=1\), donc
\[
\frac{\omega}{2}=F\left(k, 90^{\circ}\right)
\]

Donc en faisant \(\boldsymbol{\theta}=\boldsymbol{\theta}^{(m)}\), on aura
\[
F\left(k, \theta^{(m)}\right)=\frac{m}{p} \frac{\omega}{2} \text { et } \sin \theta^{(m)}=\varphi\left(\frac{m}{p} \frac{\omega}{2}\right) .
\]

Cela posé, faisons dans les formules \(\left(269^{\prime}\right)\) et \((270)\),
\[
\begin{gathered}
e_1^2=-\lambda^2, e^2=-k^2, \quad,=\frac{(-1)^n}{a}, \\
x=(-1)^n \sin \theta, \quad y=\sin \psi, 2 n+1=p,
\end{gathered}
\]
il viendra
\[
\int \frac{d \theta}{\sqrt{1-k^2 \sin ^2 \theta}}= \pm \| \int \frac{d \psi^{\prime}}{\sqrt{1-\lambda^2 \sin ^2 \psi^{\prime}}}+C
\]
où les quantités \(\mu, \lambda, \psi\) sont déterminées par les équations
\[
\begin{aligned}
& \lambda=k^{2 n+1}\left(\sin \theta^{\prime} \cdot \sin \theta^{\prime \prime \prime} \ldots \sin \theta^{(2 n-1)}\right)^4, \\
& \mu=\left(\frac{\sin \theta^{\prime} \cdot \sin \theta^{\prime \prime \prime} \ldots \sin \theta^{(2 n-1)}}{\sin \theta^{\prime \prime} \cdot \sin \theta^{\prime \prime \prime \prime} \ldots \sin \theta^{(2 n)}}\right)^2
\end{aligned}
\]
(2) \(\sin \psi\)
\[
=\frac{k^{n+1}}{\sqrt{\lambda}} \sin \theta \frac{\left(\sin ^2 \theta^{\prime \prime}-\sin ^2 \theta\right)\left(\sin ^2 \theta^{\prime \prime \prime \prime}-\sin ^2 \theta\right) \ldots\left(\sin ^2 \theta^{(2 n)}-\sin ^2 \theta\right)}{\left(1-k^2 \sin ^2 \theta^{\prime \prime} \sin ^2 \theta\right)\left(1-k^2 \sin ^2 \theta^{\prime \prime \prime \prime} \sin ^2 \theta\right) \ldots\left(1-k^2 \sin ^2 \theta^{(2 n)} \sin ^2 \theta\right)}
\]

Nous supposons \(k\) moindre que l'unité, car dans le cas contraire \(\omega\) serait une quantité imaginaire.

Cela posé, considérons les équations (249). En remarquant que \(c_1=c\) \(=1\), on en tire
\[
\sqrt{\frac{1-y}{1+y}}=\frac{t}{t_1} \sqrt{\frac{1-x}{1+x}}
\]
où
\[
\frac{t}{t_1}=\frac{\varphi\left(\frac{\omega}{2}+\alpha\right)-x}{\Psi\left(\frac{\omega}{2}+\alpha\right)+x} \cdot \frac{\uparrow\left(\frac{\omega}{2}+2 \alpha\right)-x}{\Upsilon\left(\frac{\omega}{2}+2 \alpha\right)+x} \cdots \frac{\uparrow\left(\frac{\omega}{2}+n \alpha\right)-x}{\uparrow\left(\frac{\omega}{2}+n \alpha\right)+x}
\]
%387
ou, en faisant \(\alpha=\frac{2 m \omega}{2 n+1}\) et \(m=-1\),
\[
\frac{t}{t_1}=\frac{\uparrow\left(\frac{2 n-1}{2 n+1} \frac{\omega}{2}\right)+x}{\uparrow\left(\frac{2 n-1}{2 n+1} \frac{\omega}{2}\right)-x} \cdot \frac{\uparrow\left(\frac{2 n-3}{2 n+1} \frac{\omega}{2}\right)-x}{\uparrow\left(\frac{2 n-3}{2 n+1} \frac{\omega}{2}\right)+x} \cdots \frac{(-1)^n \uparrow\left(\frac{1}{2 n+1} \frac{\omega}{2}\right)-x}{(-1)^n \uparrow\left(\frac{1}{2 n+1} \frac{\omega}{2}\right)+x} .
\]

Maintenant on a
\[
x=(-1)^n \sin \theta, \text { et } \varphi\left(\frac{m}{2 n+1} \frac{\omega}{2}\right)=\sin \theta^{(m)},
\]
donc en sulbstituant:
\[
\sqrt{\frac{1-\sin \psi^{\prime \prime}}{1+\sin \psi \prime}}=\sqrt{\frac{1-(-1)^n \sin \theta}{1+(-1)^n \sin \theta}} \cdot \frac{\sin \theta^{\prime}-\sin \theta}{\sin \theta^{\prime}+\sin \theta} \cdot \frac{\sin \theta^{\prime \prime \prime}+\sin \theta}{\sin \theta^{\prime \prime \prime}-\sin \theta} \cdots \frac{\sin \theta^{(2 n-1)}+(-1)^n \sin \theta}{\sin \theta^{(2 n-1)}-(-1)^n \sin \theta},
\]
et de lì
tang \(\left(45^{\circ}-\frac{1}{2} \psi\right)\)
\[
=\frac{\operatorname{tang} \frac{1}{2}\left(\theta^{\prime}-\theta\right)}{\operatorname{tang} \frac{1}{2}\left(\theta^{\prime}+\theta\right)} \cdot \frac{\operatorname{tang} \frac{1}{2}\left(\theta^{\prime \prime \prime}+\theta\right)}{\operatorname{tang} \frac{1}{2}\left(\boldsymbol{\theta}^{\prime \prime \prime}-\theta\right)} \cdots \frac{\operatorname{tang} \frac{1}{2}\left[\theta^{(2 n-1)}+(-1)^n \theta\right]}{\operatorname{tang} \frac{1}{2}\left[\theta^{(2 n-1)}-(-1)^n \theta\right]} \operatorname{tang}\left[45^0-(-1)^n \frac{1}{2} \theta\right] .
\]

C'est précisément la formule de M. Jacobi.
Dans la formule (1), on peut toujours supposer le second membre positif. En effet, en différentiant, on aura
\[
\pm \mu d \psi=\frac{\sqrt{1-\lambda^2 \sin ^2 \psi}}{\sqrt{1-k^2 \sin ^2 \theta}} \cdot d \theta
\]

En supposant \(\theta\) toujours croissant, le second membre sera toujours positif. Donc en déterminant la valeur \(\psi\) de sorte qu'elle soit croissante et décroissante en même temps que O, on doit prendre le signe supérieur. (On a done
\[
\int_0 \frac{d \theta}{\sqrt{1-k^2 \sin ^2 \theta}}=\mu \int_0 \frac{d \psi}{\sqrt{1-\lambda^2 \sin ^2 \psi}}
\]
on bien
\[
F(k, \theta)=\mu F(\lambda, \psi) .
\]

En remarquant que \(\psi\) doit être croissant et décroissant en même temps que \(\theta\), et en ayant égard à la formule (2), on tirera aisément la conséquence que \(\psi\) doit tomber entre \(\frac{m}{2} \pi\) et \(\frac{m+1}{2} \pi\), si \(\theta\) tombe entre \(\theta^{(m)}\) et \(\theta^{(m+1)}\).
%388
Quant aux quantités \(\lambda\) et \(\mu\), il est évident qu'elles ont nécessairement les mêmes valeurs que celles de M. Jacothi. Mais les expressions que j’ai domnées seront plus commodes pour l'application, et font voir clairement que \(\lambda\) est extrêmement petit, si \(n\) est un peu grand. Au reste on peut sans difficulté démontrer leur identité à l'aide de la formule (257).
%389
XVII.

SUR LES FONCTIONS QUI SATISFONT \(\Lambda\) L'ÉQUATION
\[
\uparrow x+\lceil y=\psi(x f y+y f x) \text {. }
\]

Journal für die reine und angewandte Mathematik, herausgegeben von Crelle, Bd. 2, Berlin 1827.

L'équation
est satisfaite lorsque
\[
\varphi x+\varphi y=\psi(x f y+y f x)
\]
car cela donne
\[
f y=\frac{1}{2} y \text { et } \varphi x=\psi x=\log x
\]
de même lorsque
\[
\log x+\log y=\log x y
\]
ce qui donne
\[
f y=\sqrt{1-y^2} \text { et } \rho x=\psi x=\arcsin x
\]
\[
\arcsin x+\arcsin y=\arcsin \left(x \sqrt{1-y^2}+y \sqrt{1-x^2}\right) .
\]

Il serait possible qu'on pût encore satisfaire à la même équation d'autres manières. C'est ce que nous allons examiner. Soit pour abréger
\[
x f y+y f x=r
\]
l'équation de condition devient
\[
\varphi x+\varphi y=\psi r .
\]

En différentiant cette équation par rapport à \(x\) et à \(y\), on aura, en faisant usage de la notation de Lagrange,
%390
\[
\varphi^{\prime} x=\psi^{\prime} r \frac{d r}{d x} \text { et } \varphi^{\prime} y=\psi^{\prime} r \frac{d r}{d y} \text {. }
\]

De ces équations on tire, en éliminant la fonction \(\psi^{\prime} r\),
\[
\varphi^{\prime} x \frac{d r}{d y}=\varphi^{\prime} y \frac{d r}{d x} .
\]

Or l'expression de \(r\) donne
\[
\frac{d r}{d x}=f y+y f^{\prime} x \text { et } \frac{d r}{d y}=f x+x f^{\prime} y
\]
done en substituant,
\[
\varphi^{\prime} y\left(f y+y f^{\prime} x\right)=\varphi^{\prime} x\left(f x+x f^{\prime} y\right)
\]

En donnant maintenant à la quantité variable y la valeur particulière zéro, ce qui est permis parce que \(x\) et \(y\) sont des quantités indépendantes entre elles, et en faisant pour abréger
\[
\varphi^{\prime}(0)=a, f(0)=\alpha, f^{\prime}(0)=\alpha^{\prime},
\]
l'équation (3) prendra la forme
\[
a \alpha-\varphi^{\prime} x\left(f x+\alpha^{\prime} x\right)=0
\]
d'où l'on tire, en écrivant \(y\) au lieu de \(x\),
\[
a \alpha-\varphi^{\prime} y\left(f y+\alpha^{\prime} y\right)=0
\]

Ces deux équations donnent
\[
\varphi^{\prime} x=\frac{a \alpha}{f x+\alpha^{\prime} x} \text { et } \varphi^{\prime} y=\frac{a \alpha}{f y+\alpha^{\prime} y}
\]
donc en intégrant,
\[
\varphi x=a \alpha \int \frac{d x}{f x+\alpha^{\prime} x} .
\]

De cette manière la fonction \(\rho x\) est déterminée par \(f x\). Il s'agit donc de trouver la fonction \(f x\). En substituant dans l'équation (3) les expressions
(4) des fonctions \(\varphi^{\prime} x\) et \(\varphi^{\prime} y\), et réduisant, on trouvera
(6)
\[
\left(f x+\alpha^{\prime} x\right)\left(f y+y f^{\prime} x\right)=\left(f y+\alpha^{\prime} y\right)\left(f x+x f^{\prime} y\right)
\]
d'où l'on tire, en développant,
\[
\begin{aligned}
f x \cdot f y+\alpha^{\prime} x f y+ & +y f x \cdot f^{\prime} x+\alpha^{\prime} x y f^{\prime} x \\
& -f x \cdot f y-\alpha^{\prime} y f x-x f y \cdot f^{\prime} y-\alpha^{\prime} x y f^{\prime} y=0
\end{aligned}
\]
%391
ou bien
(8) \(\quad x\left(\alpha^{\prime} f y-f y \cdot f^{\prime} y-\alpha^{\prime} y f^{\prime} y\right)-y\left(\alpha^{\prime} f x-f x \cdot f^{\prime} x-\alpha^{\prime} x f^{\prime} x\right)=0\), ou en divisant par \(x y\)
(9) \(\frac{1}{y}\left(\alpha^{\prime} f y-f y \cdot f^{\prime} y-\alpha^{\prime} y f^{\prime} y\right)-\frac{1}{x}\left(\alpha^{\prime} f x-f x \cdot f^{\prime} x-\alpha^{\prime} x f^{\prime} x\right)=0\).

Les quantités \(x\) et \(y\) étant indépendantes entre elles, cette équation ne peut avoiv lieu à moins qu'on n'ait
\[
\frac{1}{y}\left(\alpha^{\prime} f y-f y \cdot f^{\prime} y-\alpha^{\prime} y f^{\prime} y\right)=\frac{1}{x}\left(\alpha^{\prime} f x-f x \cdot f^{\prime} x-\alpha^{\prime} x f^{\prime} x\right)=\text { Const. }
\]

Soit done
\[
\frac{1}{x}\left(\alpha^{\prime} f x-f x \cdot f^{\prime} x-\alpha^{\prime} x f^{\prime} x\right)=m
\]
on aura
\[
f^{\prime} x\left(f x+\alpha^{\prime} x\right)+\left(m x-\alpha^{\prime} f x\right)=0 .
\]

Par cette équation la fonction \(f x\) est déterminée. On peut l'intégrer en faisant
\[
f x=x z
\]
car alors on a
\[
f^{\prime} x \cdot d x=z d x+x d z
\]
d'où l'on tire en substituant,
\[
(z d x+x d z)\left(x z+\alpha^{\prime} x\right)+\left(m x-\alpha^{\prime} x z\right) d x=0,
\]
ce qui domne, en divisant par \(x\),
\[
(z d x+x d z)\left(z+\alpha^{\prime}\right)+\left(m-\alpha^{\prime} z\right) d x=0,
\]
oll
\[
\left[z\left(z+\alpha^{\prime}\right)+m-\alpha^{\prime} z\right] d x+x d z\left(z+\alpha^{\prime}\right)=0,
\]
ou bien
\[
\left(z^z+m\right) d x+x d z\left(z+\alpha^{\prime}\right)=0,
\]
on en divisant par \(x\left(z^2+m\right)\),
\[
\frac{d x}{x}=-\frac{d z\left(z+\alpha^{\prime}\right)}{z^2+m},
\]
donc en intégrant,
\[
\int \frac{d x}{x}=-\int \frac{z d z}{z^2+m}-\alpha^{\prime} \int \frac{d z}{z^2+m}
\]
%392
Soit \(m=-n^2\), on aura
\[
\int \frac{d x}{x}=\log x, \int \frac{z d z}{z^2-n^2}=\frac{1}{2} \log \left(z^2-n^2\right), \int \frac{d z}{z^2-n^2}=\frac{1}{2 n} \log \frac{z-n}{z+n},
\]
donc en substituant et en ajoutant une constante \(c\),
\[
\log c-\log x=\frac{1}{2} \log \left(z^2-n^2\right)+\frac{\alpha^{\prime}}{2 n} \log \frac{z-n}{z+n},
\]
oll
\[
\log \frac{c}{x}=\log \left\{\left(z^2-n^2\right)^{\frac{1}{2}}\left(\frac{z-n}{z+n}\right)^{\frac{\alpha^{\prime}}{2 n}}\right\}
\]
d'où
\[
\frac{c}{x}=\left(z^2-n^2\right)^{\frac{1}{2}}\left(\frac{z-n}{z+n}\right)^{\frac{\alpha^{\prime}}{2 n}}
\]

Mais on avait \(f x=x z\); done \(z=\frac{f x}{x}\), et par suite en substituant, ou bien
\[
\frac{c}{x}=\frac{\left[(f x)^2-n^2 x^2\right]^{\frac{1}{2}}}{x}\left(\frac{f x-n x}{f x+n x}\right)^{\frac{\alpha^{\prime}}{2 n}}
\]
\[
c=(f x-n x)^{\frac{1}{2}+\frac{\alpha^{\prime}}{2 n}}(f x+n x)^{\frac{1}{2}-\frac{\alpha^{\prime}}{2 n}}
\]
ou en élevant à la \(2 n^{\text {ième }}\) puissance,
\[
c^{2 n}=(f x-n x)^{n+\alpha^{\prime}}(f x+n x)^{n-\alpha^{\prime}} ;
\]
\(x=0\) donne \(c=\alpha\), à cause de \(f(0)=\alpha\).
Voila l'équation de laquelle dépend la fonction \(f x\). Elle n'est pas en général résoluble, parce que \(n\) et \(\alpha^{\prime}\) sont deux quantités indéterminées, qui peuvent même être imaginaires. L'équation (12) contient la forme la plus générale de la fonction \(f x\), et on peut démontrer qu'elle satisfait à l'équation de condition donnée dans toute sa généralité. En effet la fonction \(f x\) satisfait à l'équation (11), et on voit par la forme de l'équation (9) qu'elle satisfait aussi à cette équation. Or l'équation (6) est l'équation (9) sous une forme différente. Donc la fonction \(f x\) satisfait anssi à l'équation (6). De l'équation (6) on tire l'équation (3) en faisaut \(\varphi^{\prime} x=\frac{a \alpha}{f x+\alpha^{\prime} x}\), et l'équation (3) donne, en faisant \(x f y+y f x=r\),
\[
\varphi^{\prime} x \frac{d r}{d y}-\varphi^{\prime} y \frac{d r}{d x}=0
\]
%393
En intégrant cette équation différentielle partielle par les règles comnues, on trouvera
d'où
\[
r=F(\varphi x+\varphi y)
\]
ou bien
\[
\begin{aligned}
\varphi x+\varphi y & =\psi r, \\
\varphi x+\varphi y & =\psi(x f y+y f x),
\end{aligned}
\]
ce qui est l'équation de condition donnée.
Il reste encore à trouver la fonction \(\psi\). \(A\) cet effet soit \(y=0\), on aura, en remarquant que \(f(0)=\alpha\),
\[
\varphi x=\psi(\alpha x)-\varphi(0),
\]
ou, en mettant \(\frac{x}{\alpha}\) au lieu de \(x\)
\[
\psi x=\varphi\left(\frac{x}{\alpha}\right)+\varphi(0) .
\]

On trouve donc, en résumant, que les formes les plus générales des fonctions satisfaisant à l'équation de condition
\[
\varphi x+\varphi y=\psi(x f y+y f x)
\]
sont les suivantes :
\[
\varphi x=a \alpha \int \frac{d x}{f x+\alpha^{\prime} x}
\]
et
\[
\psi x=\varphi(0)+\varphi\left(\frac{x}{\alpha}\right)=a \alpha \int \frac{d x}{\alpha f\left(\frac{x}{\alpha}\right)+\alpha^{\prime} x}+\varphi(0),
\]
où \(f x\) dépend de l'équation
\[
\alpha^{2 n}=(f x-n x)^{n+\alpha^{\prime}}(f x+n x)^{n-\alpha^{\prime}} .
\]

Soit par exemple
on alura
\[
n=\alpha^{\prime}=\frac{1}{2}
\]
done
\[
\alpha=f x-\frac{1}{2} x
\]
\[
f x=\alpha+\frac{1}{2} x,
\]
et par suite
\[
\begin{gathered}
\varphi x=a \alpha \int \frac{d x}{\alpha+x}=a \alpha \log (\alpha+x)+k \\
\psi x=\varphi(0)+\varphi\left(\frac{x}{\alpha}\right)=2 k+a \alpha \log \alpha+a \alpha \log \left(\alpha+\frac{x}{\alpha}\right)
\end{gathered}
\]
%394
ou
\[
\psi x=2 k+a \alpha \log \left(\alpha^2+x\right) .
\]

L'équation de condition devient done
\[
\begin{aligned}
k+a \alpha \log (\alpha+x)+k+a \alpha & \log (\alpha+y) \\
& =2 k+a \alpha \log \left[\alpha^2+x\left(\alpha+\frac{1}{2} y\right)+y\left(\alpha+\frac{1}{2} x\right)\right]
\end{aligned}
\]
ce qui a effectivement lieu, car les deux membres de cette équation se réduisent à
\[
2 k+a \alpha \log \left(\alpha^2+\alpha x+\alpha y+x y\right) .
\]

La fonction \(\varphi x\) est trouvée ci-dessus sous forme d'intégrale. On peut aussi trouver une forme finie pour cette fonction par des logarithmes, en supposant la fonction \(f x\) connue. Soit
\[
f x+n x=v \text { et } f x-n x=t,
\]
l'équation (12) donne
done
\[
\alpha^{2 n}=v^{n-\alpha^{\prime}} t^{n+\alpha^{\prime}}
\]
d'où
\[
t^{n+\alpha^{\prime}}=\alpha^{2 n} v^{\alpha^{\prime}-n}
\]
\[
t=\alpha^{\frac{2 n}{n+\alpha^{\prime}}} v^{\frac{\alpha^{\prime}-n}{\alpha^{\prime}+n}}
\]

Or \(f x=\frac{1}{2}(v+t)\) et \(n x=\frac{1}{2}(v-t)\), done
et
\[
f x=\frac{1}{2}\left(v+\alpha^{\frac{2 n}{n+\alpha^{\prime}}} v^{\frac{\alpha^{\prime}-n}{\alpha^{\prime}+n}}\right)
\]
\[
x=\frac{1}{2 n} v-\frac{1}{2 n} \alpha^{\frac{2 n}{n+\alpha^{\prime}}} v^{\frac{\alpha^{\prime}-n}{\alpha^{\prime}+n}},
\]
d'où l'on tire en différentiant
\[
d x=\left\{\frac{1}{2 n}-\frac{\alpha^{\prime}-n}{2 n\left(\alpha^{\prime}+n\right)} \alpha^{\frac{2 n}{n+\alpha^{\prime}}} v^{\frac{-2 n}{\alpha^{\prime}+n}}\right\} d v .
\]

On trouve de même
\[
f x+\alpha^{\prime} x=\left(\frac{1}{2}+\frac{\alpha^{\prime}}{2 n}\right) v+\left(\frac{1}{2}-\frac{\alpha^{\prime}}{2 n}\right) \alpha^{\frac{2 n}{n+\alpha^{\prime}}} v^{\frac{\alpha^{\prime}-n}{\alpha^{\prime}+n}}
\]
ou bien
\[
f x+\alpha^{\prime} x=\left(n+\alpha^{\prime}\right)\left\{\frac{1}{2 n}-\frac{\alpha^{\prime}-n}{2 n\left(\alpha^{\prime}+n\right)} \alpha^{\frac{2 n}{n+\alpha^{\prime}}} v^{-\frac{2 n}{\alpha^{\prime}+n}}\right\} v
\]
done
%395
\[
\frac{d x}{f x+\alpha^{\prime} x}=\frac{d v}{\left(n+\alpha^{\prime}\right) v},
\]
ce qui donne en intégrant,
\[
\int \frac{d x}{f x+\alpha^{\prime} x}=\frac{1}{n+\alpha^{\prime}} \log c v=\frac{r x}{a \alpha}
\]
où \(c\) est une constante arbitraire. En mettant donc pour \(v\) sa valeur \(f x+n x\), on aura
\[
\varphi x=\frac{a \alpha}{n+\alpha^{\prime}} \log (c n x+c f x) .
\]

Dans les deux cas \(\alpha^{\prime}=\infty\), et \(n=0\), la fonction \(f x\) prend une valeur particulière. Pour la tronver, il faut recourir à l'équation différentielle (11).
Soit d'abord \(n=0\), l'équation (11) donne, à cause de \(m=-n^2\),
\[
f^{\prime} x\left(f x+\alpha^{\prime} x\right)-\alpha^{\prime} f x=0 .
\]

Soit
\[
f x=z x
\]
on trouvera
\[
\frac{d x}{x}=-\frac{d z\left(z+\alpha^{\prime}\right)}{z^2}=-\frac{d z}{z}-\frac{\alpha^{\prime} d z}{z^2},
\]
et en intégrant
\[
\log c^{\prime}+\log x=-\log z+\frac{\alpha^{\prime}}{z}, \text { on } \log \left(c^{\prime} x z\right)=\frac{\alpha^{\prime}}{z}
\]
ou, puisque \(z=\frac{f \dot{x}}{x}\),
\[
\log \left(c^{\prime} f x\right)=\frac{\alpha^{\prime} x}{f x}, \text { ou } \alpha^{\prime} x=f x \cdot \log \left(c^{\prime} f x\right) \text {. }
\]

Pour \(x=0\), on a \(0=\alpha \log c^{\prime} \alpha\), done \(c^{\prime} \alpha=1\) et \(c^{\prime}=\frac{1}{\alpha}\), donc
\[
\alpha^{\prime} x=f x \cdot \log \left(\frac{f x}{\alpha}\right)
\]
où
\[
e^{\alpha^{\prime} x}=\left(\frac{f x}{\alpha}\right)^{f x}
\]

Cette équation détermine donc la fonction \(f x\) dans le cas où \(n=0\). L'équation (13) donne dans ce cas
\[
\varphi x=\frac{a \alpha}{\alpha^{\prime}} \log (c f x)=\frac{a \alpha}{\alpha^{\prime}} \log (c \alpha)+\frac{a \alpha}{\alpha^{\prime}} \log \left(\frac{f x}{\alpha}\right)
\]
%396
en vertu de (14) on a
done
\[
\log \left(\frac{f x}{\alpha}\right)=\frac{\alpha^{\prime} x}{f x}
\]
\[
\varphi x=\frac{a \alpha}{\alpha^{\prime}} \log c \alpha+\frac{u \alpha x}{f, x}
\]

De plus
\[
\psi x=\varphi(0)+\varphi\left(\frac{x}{\alpha}\right)=\frac{2 a \alpha}{\alpha^{\prime}} \log c \alpha+\frac{a x}{f\left(\frac{x}{\alpha}\right)} .
\]

L'équation de condition devient donc
\[
\frac{a \alpha}{\alpha^{\prime}} \log c \alpha+\frac{a \alpha x}{f x}+\frac{a \alpha}{\alpha^{\prime}} \log c \alpha+\frac{a \alpha y}{f y}=\frac{2 a \alpha}{\alpha^{\prime}} \log c \alpha+\frac{a(x f y+y f x)}{f\left(\frac{x f y+y f x}{\alpha}\right)}
\]
c'est-à-dire qu'on aura
\[
\alpha f\left(\frac{x f y+y f x}{\alpha}\right)=f x \cdot f y .
\]

Pour examiner cette équation, nous mettrons au lieu de \(x\) et de \(y\) leurs valeurs \(\frac{f x}{\alpha^{\prime}} \log \frac{f x}{\alpha}\) et \(\frac{f y}{\alpha^{\prime}} \log \frac{f y}{\alpha}\) tirées de l'équation (14), ce qui donne
\[
\alpha f\left\{\frac{f x \cdot f y \log \frac{f x \cdot f y}{\alpha^2}}{\alpha \alpha^{\prime}}\right\}=f y \cdot f x=\alpha f r,
\]
en faisant pour abréger
\[
\frac{f x \cdot f y \cdot \log \frac{f x \cdot f y}{\alpha^2}}{\alpha \alpha^{\prime}}=r .
\]

Il s'ensuit
\[
2 \log \alpha+\log \frac{f r}{\alpha}=\log (f x \cdot f y) .
\]

Or en vertu de l'équation (14) on a \(\log \frac{f r}{\alpha}=\frac{\alpha^{\prime} r}{f r}\), done en substituant,
\[
2 \log \alpha+\frac{\alpha^{\prime} r}{f r}=\log (f x \cdot f y)
\]

Mais puisque \(f r=\frac{f x \cdot f y}{\alpha}(18)\), on a en vertu de (19) \(\frac{f r \cdot \log \left(\frac{f x \cdot f y}{\alpha^2}\right)}{\alpha^{\prime}}=r\), donc \(\frac{\alpha^{\prime} r}{f r}=\log \left(\frac{f x \cdot f y}{\alpha^2}\right)\), et par conséquent: \(2 \log \alpha+\log \left(\frac{f x \cdot f y}{\alpha^2}\right)\) \(=\log (f x \cdot f y)\), ce qui a effectivement lieu comme on le voit aisément.
%397
Soit ensuite \(\alpha^{\prime}=\infty\). En mettant dans ce cas l'équation (11) sous la forme
\[
\frac{f x \cdot f^{\prime} x}{\alpha^{\prime}}+x f^{\prime} x+\frac{m x}{\alpha^{\prime}}-f x=0
\]
il est clair qu'on doit avoir \(x f^{\prime} x-f x=0\), lorsque \(m\) est fini. Il faut .done que
\(\mathrm{Si}\)
\[
\frac{f^{\prime} x \cdot d x}{f x}=\frac{d x}{x}, \text { on } f x=c x
\]
on a
\[
m=-p \alpha^{\prime}
\]

Soit
\[
x f^{\prime} x-p x-f x=0 .
\]
on aura
\[
f x=x z
\]
\[
x(x d z+z d x)-(p x+x z) d x=0
\]
ou
done
\[
x d z=p d x
\]
\[
z=p \log c x=\frac{f x}{x}
\]
et par suite
\[
f x=p x \log c x
\]

Pour trouver \(\varphi x\), on substituera la valeur de la fonction \(f x\) daus l'équation (3); on aura, à cause de \(f^{\prime} x=p \log c x+p\),
\[
\varphi^{\prime} y\left(p y \log ^{\circ} c y+y p \log c x+p y\right)-\varphi^{\prime} x(p x \log c x+x p \log c y+p x)=0
\]
donc, en divisant par \(p\left(\log c^2 x y+1\right)\),
\[
y \varphi^{\prime} y-x \varphi^{\prime} x=0
\]
done
\[
x \varphi^{\prime} x=k \text { et } \operatorname{de} x=\frac{k d x}{x}
\]
d'où
\[
\varphi x=k \log m x
\]

L'équation de condition donnée deviendra donc
\[
\begin{aligned}
k \log m x+k \log m y & =\psi(x p y \log c y+y p x \log c x), \\
k \log m^2 x y & =\psi\left(p x y \log c^2 x y\right)
\end{aligned}
\]
ou, en faisant \(p x y \log c^2 x y=r\) et \(x y=v\),
%398
\[
\psi r=k \log m^2 v
\]

Par le même procédé, qui a donné ci-dessus les fonctions qui satisfont à l'équation
\[
\varphi x+\varphi y=\psi(x f y+y f x),
\]
on peut trouver les fonctions inconnues dans toute autre équation à deux quantités variables. En effet, on peut, par des différentiations successives par rapport aux deux quantités variables, trouver autant d'équations qu'il est nécessaire pour éliminer des fonctions quelconques, de sorte qu'on parviendra à une équation qui ne contient qu'une seule de ces fonctions, et qui sera en général une équation différentielle d'un certain ordre. On peut donc en général trouver chacune de ces fonctions par une seule équation. Il s'ensuit qu'une telle équation n'est que très rarement possible. Car, comme la forme d'une fonction quelconque contenue dans l'équation de condition donnée, en vertu de l'équation même, doit être indépendante des formes des autres fonctions, il est évident qu'en général on ne peut considérer aucune de ces fonctions comme donnée. Ainsi par exemple l'équation ci-dessus ne pourrait plus être satisfaite, si la fonction \(f x\) avait eu une forme différente de celle qu'on vient de trouver.
%399
XVIII.

NOTE SUR UN MÉMOIRE DE M. L. OLIVIER, AYANT POUR TITRE "REMARQUES SUR LES SÉRIES INFINIES ET LEUR CONVERGENCE."
Journal für die reine und angewandte Mathematik, herausgegeben von C'rclk, 13d. 3, Berlin 1828.
On trouve p. 34 de ce mémoire le théorème suivant pour reconnaître si une série est convergente ou divergente:
"Si l'on trouve que dans une série infinie le produit du \(n^{\text {ième }}\) terme, ou "du \(n^{\text {ieme }}\) des groupes de termes qui conservent le même signe, par \(n\), est "zéro pour \(n=\infty\), on peut regarder cette seule circonstance comme une "marque, que la série est convergente; et réciproquement, la série ne peut "pas être convergente si le produit \(n . a_n\) n'est pas nul pour \(n=\infty\)."

La dernière partie de ce théorème est très juste, mais la première ne semble pas l'être. Par exemple la série
\[
\frac{1}{2 \log 2}+\frac{1}{3 \log 3}+\frac{1}{4 \log 4}+\cdots+\frac{1}{n \log n}+\cdots
\]
est divergente, quoique \(n a_n=\frac{1}{\log n}\) soit zéro pour \(n=\infty\). En effet les logarithmes hyperboliques, dont il est question, sont toujours moindres que leurs nombres moins 1, c'est-à-dire, qu'on a toujours \(\log (1+x)<x\). Si \(x>1\) cela est évident. Si \(x<1\) on a
\[
\log (1+x)=x-x^2\left(\frac{1}{2}-\frac{1}{3} x\right)-x^4\left(\frac{1}{4}-\frac{1}{5} x\right)-\cdots,
\]
donc aussi dans ce dernier cas \(\log (1+x)<x\), puisque \(\frac{1}{2}-\frac{1}{3} x, \frac{1}{4}-\frac{1}{3} x\) ... sont tous positifs. En faisant \(x=\frac{1}{n}\), cela donne
%400
\[
\log \left(1+\frac{1}{n}\right)<\frac{1}{n} \text { on bien } \log \frac{1+n}{n}<\frac{1}{n}
\]
ou
\[
\log (1+n)<\frac{1}{n}+\log n=\left(1+\frac{1}{n \log n}\right) \log n
\]
done
\[
\log \log (1+n)<\log \log n+\log \left(1+\frac{1}{n \log n}\right)
\]

Mais puisque \(\log (1+x)<x\), on a \(\log \left(1+\frac{1}{n \log n}\right)<\frac{1}{n \log n}\), done, en vertu de l'expression précédente,
\[
\log \log (1+n)<\log \log n+\frac{1}{n \log n} .
\]

En faisant successivement \(n=2,3,4, \ldots\), on trouve
\[
\begin{aligned}
& \log \log (1+n)<\log \log n+\frac{1}{n \log n}, \\
&
\end{aligned}
\]
\[
\log \log (1+n)<\log \log n+\frac{1}{n \log n}
\]
donc, en prenant la somme,
\[
\log \log (1+n)<\log \log 2+\frac{1}{2 \log 2}+\frac{1}{3 \log 3}+\frac{1}{4 \log 4}+\cdots+\frac{1}{n \log n} .
\]

Mais \(\log \log (1+n)=\infty\) pour \(n=\infty\), donc la somme de la série proposée \(\frac{1}{2 \log 2}+\frac{1}{3 \log 3}+\frac{1}{4 \log 4}+\cdots+\frac{1}{n \log n}+\cdots\) est infiniment grande, et par conséquent cette série est divergente. Le théorème énoncé dans l'endroit cité est done en défaut dans ce cas.

En général on peut démontrer qu’il est impossible de trouver une fonction \(\varphi n\) telle qu'une série quelconque \(a_0+a_1+a_2+a_3+\cdots+a_n+\cdots\), dont nous supposons tous les termes positifs, soit convergente si \(\varphi n \cdot a_n\) est zéro pour \(n=\infty\), et divergente dans le cas contraire. C'est ce qu'on peut faire voir à l'aide du théorème suivant:
Si la série \(a_0+a_1+a_2+\cdots+a_n+\cdots\) est divergente, la suivante
%401
\[
\frac{a_1}{a_0}+\frac{a_2}{a_0+a_1}+\frac{a_8}{a_0+a_1+a_2}+\cdots+\frac{a_n}{a_0+a_1+\cdots+a_{n-1}}+\cdots
\]
le sera atussi.
En effet, en remarquant que les quantités \(a_0, a_1, a_2, \ldots\) sont positives, on a en vertu du théorème \(\log (1+x)<x\), démontré ci-dessus,
\[
\log \left(a_0+a_1+a_2+\cdots+a_n\right)-\log \left(a_0+a_1+a_2+\cdots+a_{n-1}\right)
\]
c'est-à-dire
\[
\log \left(1+\frac{a_n}{a_0+a_1+a_2+\cdots+a_{n-1}}\right)<\frac{a_n}{a_0+a_1+a_2+\cdots+a_{n-1}},
\]
donc, en faisant successivement \(n=1,2,3, \ldots\),
\[
\begin{aligned}
& \log \left(a_0+a_1\right)-\log a_0<\frac{a_1}{a_0}, \\
& \log \left(a_0+a_1+a_2\right)-\log \left(a_0+a_1\right)<\frac{a_2}{a_0+a_1}, \\
& \log \left(a_0+a_1+a_2+a_3\right)-\log \left(a_0+a_1+a_2\right)<\frac{a_8}{a_0+a_1+a_2} \\
& \left.\ldots \ldots \ldots \ldots \ldots \ldots+a_n\right)-\ldots \ldots+\log \left(a_0+a_1+\cdots+a_{n-1}\right)<\frac{a_n}{a_0+a_1+\cdots+a_{n-1}}
\end{aligned}
\]
et en prenant la somme,
\[
\log \left(a_0+a_1+\cdots+a_n\right)-\log a_0<\frac{a_1}{a_0}+\frac{a_2}{a_0+a_1}+\cdots+\frac{a_n}{a_0+a_1+\cdots+a_{n-1}} .
\]

Mais si la série \(a_0+a_1+a_2+\cdots+a_n+\cdots\) est divergente, sa somme est infinie, et le logarithme de cette somme l'est également; done la somme de la série \(\frac{a_1}{a_0}+\frac{a_2}{a_0+a_1}+\cdots+\frac{a_n}{a_0+a_1+\cdots+a_{n-1}}+\cdots\) est aussi infiniment grande, et cette série est par conséquent divergente, si la série \(a_0+a_1\) \(+a_2+\cdots+a_n+\cdots\) l'est. Cela posé, supposons que qn soit une fonetion de \(n\), telle que la série \(a_0+a_1+a_2+\cdots+a_n+\cdots\) soit convergente ou divergente selon que \(\varphi n\). \(a_n\) est zéro ou non pour \(n=\infty\). Alors la série
\[
\frac{1}{\tau(1)}+\frac{1}{\tau_{(2)}}+\frac{1}{\tau_{(3)}}+\frac{1}{\tau_{(4)}}+\cdots+\frac{1}{\tau^n}+\cdots
\]
sera divergente, et la série
%402
\[
\begin{aligned}
& \frac{1}{\tau(2) \cdot \frac{1}{q(1)}}+\frac{1}{\tau(3)\left(\frac{1}{q(1)}+\frac{1}{q(2)}\right)}+\frac{1}{q(4)\left(\frac{1}{q(1)}+\frac{1}{q(2)}+\frac{1}{q(3)}\right)}+\cdots \\
& +\frac{1}{\varphi n\left(\frac{1}{q(1)}+\frac{1}{q(2)}+\frac{1}{q(3)}+\cdots+\frac{1}{\varphi(n-1)}\right)}+\cdots
\end{aligned}
\]
convergente; car dans la première on a \(a_n \varphi n=1\) et dans la seconde \(a_n \varphi n=0\) pour \(n=\infty\). Or, selon le théorème établi plus haut, la seconde série est nécessairement divergente en même temps que la première; donc une fonction \(q n\) telle qu'on l'a supposée n'existe pas. En faisant \(\varphi n=n\), les denx séries en question deviendront
\[
1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\cdots+\frac{1}{n}+\cdots
\]
et
\[
\frac{1}{2.1}+\frac{1}{3\left(1+\frac{1}{2}\right)}+\frac{1}{4\left(1+\frac{1}{2}+\frac{1}{3}\right)}+\cdots+\frac{1}{n\left(1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n-1}\right)}+\cdots
\]
qui par conséquent sont divergentes toutes deux.
%403
XIX.

SOLUTION D'UN PROBLİME GÉNÉRAL CONCERNANT LA TRANSFORMATION DES FONCTIONS ELLIPTIQUES.
Astronomische Nachrichten, herausgegeben von Sehumacher, Bd. 6, Nr. 138. Altona 1828.
Dans le \(\mathrm{n}^0 127\) de ce journal M. Jacobi démontre un théorème très élégant relatif à la transformation des fonctions. elliptiques. Ce théorème est un cas particulier d'un autre plus général, auquel je suis parvenu depuis longtemps sans connaître le mémoire de M. Jacobi. On en trouve la démonstration dans un mémoire inséré dans le journal de M. Crelle, et qui a pour titre "Recherches sur les fonctions elliptiques." Mais on pent envisager cette théorie sous un point de vue beancoup plus général, en se proposant comme un problème d'analyse indéterminée de trouver toutes les transformations possibles d'une fonction elliptique qui peuvent s'effectuer d'une certaine manière. Je suis parvenu à résoudre completement \(u\) grand nombre de problèmes de cette espèce. Parmi eux est le suivant, qui est d'une graude importance dans la théorie des fonctions elliptiques:
"Trouver tous les cas possibles dans lesquels on pourra satisfaire à l'é"quation différentielle:
\[
\frac{d y}{\sqrt{\left(1-c_1^2 y^2\right)\left(1-e_1^2 y^2\right)}}= \pm a \frac{d x}{\sqrt{\left(1-c^8 x^2\right)\left(1-e^3 x^2\right)}},
\]
"en mettant pour \(y\) une fonction algébrique de \(x\), rationnelle ou irra"tionnelle."
Ce problène, vu la généralité de la fonction y, paraît au premier \(51 *\)
%404
coup d'oeil bien difficile, mais on peut le ramener au cas où l'on suppose \(y\) rationnelle. En effet on peut démontrer que si l'équation (1) a lieu pour une valeur irratiomnelle de \(y\), on en pourra toujours déduire une autre de la même forme, dans laquelle y est rationnelle, en changeant convenablement le coefficient \(a\), les quantités \(c_1, e_1, c, e\) restant les mêmes. I La méthode qui s'offie d'abord pour résoudre le problème dans le cas où \(y\) est rationnelle est celle des coefficiens indéterminés; or on serait bientôt fatigué à cause de l'extrème complication des équations à satisfaire. Je crois donc que le procédé suivant, qui conduit de la manière la plus simple à une solution complète, doit peut-être mériter l'attention des géomètres.
En faisant
\[
\theta=\int_0 \frac{d x}{\sqrt{\left(1-c^2 x^2\right)\left(1-e^2 x^2\right)}},
\]
la quantité \(x\) sera une certaine fonction de \(\theta\); nous la désignerons par \(\boldsymbol{\lambda} \theta\). De même nous désignerons par \(\frac{\omega}{2}\) et \(\frac{\omega^{\prime}}{2}\) les valeurs de \(\theta\) qui répondent respectivement à \(x=\frac{1}{c}\) et à \(x=\frac{1}{e}\), et par \(\Delta \theta\) la fonction \(\sqrt{\left(1-c^2 x^2\right)\left(1-e^2 x^2\right)}\). Cela posé, on pourra démontrer les théorèmes suivans:

Théorème I. En désignant par \(\theta\) et \(\theta^{\prime}\) denx quantités quelconques, on aura toujours
\[
\lambda\left(\theta \pm \theta^{\prime}\right)=\frac{\lambda \theta \cdot \Delta \theta^{\prime} \pm \lambda \theta^{\prime} \cdot \Delta \theta}{1-c^2 e^2 \lambda^2 \theta \cdot \lambda^2 \theta^{\prime}}
\]
(Voy. Exercices de calcul int., t. I, p. 23).
Théorème II. On satisfait de la manière la plus geénérale à l'équation
\[
\lambda \theta^{\prime}=\lambda \theta
\]
en prenant
\[
\boldsymbol{\theta}^{\prime}=(-1)^{m+m^{\prime}} \boldsymbol{\theta}+m \boldsymbol{m}+m^{\prime} \boldsymbol{\omega}^{\prime},
\]
où \(m\) et \(m^{\prime}\) sont des nombres entiers quelconques positifs on négatifs. On aura done
\[
\lambda\left[(-1)^{n+m^{\prime}} \theta+m \omega+m^{\prime} \omega^{\prime}\right]=\lambda \theta .
\]

Ce théorème a lieu généralement, quelles que soient les quantités \(e\) et \(c\), réelles ou imaginaires. Je l'ai démontré pour le cas où \(e^2\) est négatif et \(c^8\) positif dans le mémoire cité plus haut (Crelle's Jominal fiir die reine und
%405
angewandte Mathematik, Bd. 2, p. 114). Les quantités \(\omega, \omega^{\prime}\) sont toujours dans un rapport imaginaire. Elles jouent d'ailleurs dans la théorie des fonctions elliptiques le même rôle que le nombre \(\pi\) dans celle des fonctions circulaires.

Nous allons voir comment à l'aide de ces deux théorèmes on pourra déterminer facilement l'expression générale de \(y\), et les valeurs qui en résulteront pour \(c_1\) et \(e_1\).
Soit
\[
y=\psi(x)
\]
la fonction rationnelle cherchée. Si l'on considère \(x\) comme fonction de \(y\), sa valeur sera déterminée par l'équation (5), qui aura un certain nombre de racines. Or il existe entre ces racines des relations qui nous conduiront à l'expression de \(\psi(x)\).

Si l'équation (5) passe le premier degré par rapport à \(x\), désignons par \(x_1\) une autre racine, et par \(\theta_1\) la valeur correspondante de \(\theta\), de sorte que \(x_1=\lambda \theta_1, y=\psi(x)=\psi\left(x_1\right)\).

En vertu de la formule (2), l'équation (1) deviendra, en désignant le radical du premier membre par \(\sqrt{R}\),
\[
\frac{d y}{\sqrt{R}}= \pm a d \theta
\]

En changeant \(x\) en \(x_1\), ou, ce qui revient au même, \(\theta\) en \(\theta_1\), la valeur de y reste la même, et par conséquent \(\frac{d y}{\sqrt{R}}\) reste le même, ou se change en \(-\frac{d y}{\sqrt{R}} \cdot\) On aura donc
\[
\pm \frac{d y}{\sqrt{R}}= \pm a d \theta_1
\]
et par suite \(d \theta_1= \pm d \theta\), d'où l'on tire en intégrant \(\theta_1=\alpha \pm \theta, \alpha\) étant une quantité indépendante de \(\theta\). On aura par conséquent \(x_1=\lambda(\alpha \pm \theta)\). Il suffit de prendre \(\theta\) avec le signe + ; car on a, d'après la formule (4), en y faisant \(m=1, m^{\prime}=0, \lambda \theta=\lambda(\omega-\theta)\) et par conséquent \(\lambda(\alpha-\theta)=\lambda(\omega-\alpha+\theta)\), où \(\omega-\alpha\) est une nouvelle constante. On pourra done faire \(x_1=\lambda(\theta+\alpha)\). On a ainsi établi ce théorème.

Théorème III. "Si une racine de l'équation \(y=\psi(x)\) est représentée "par \(\lambda \theta\), une autre racine quelconque sera de la forme \(\lambda(\theta+\alpha)\), où \(\alpha\) est "nune quantité constante."
%406
Si l'on pouvait parvenir à trouver toutes les valeurs de \(\alpha\), rien ne serait plus facile que de déterminer ensuite celle de \(y\). Or c'est ce que nous allons faire à l'aide du Théorème II. Les quantités \(\lambda \theta\) et \(\lambda(\theta+\alpha)\) étant des racines, on aura ì la fois:
\[
y=\psi(\lambda \theta)=\psi[\lambda(\theta+\alpha)]
\]
équation qui doit avoir lieu pour une valeur quelconque de \(\theta\). On en tire, en mettant au lieu de \(\theta\) successivement \(\theta+\alpha, \theta+2 \alpha, \ldots \theta+k \alpha\),
\[
\psi(\lambda \theta)=\psi[\lambda(\theta+\alpha)]=\psi[\lambda(\theta+2 \alpha)]=\cdots=\psi[\lambda(\theta+k \alpha)],
\]
done on aura
\[
y=\psi[\lambda(\theta+k \alpha)]
\]
k désignant un nombre entier quelconque. On voit par là que, non senlement \(\lambda(\theta+\alpha)\), mais toute quantité de la forme \(\lambda(\theta+k \alpha)\) sera une racine de l'équation \(y=\psi(x)\). Or, \(k\) pouvant avoir une infinité de valeurs différentes, il faut nécessairement que plusieurs des quantités \(\lambda(\theta+k \alpha)\) soient égales pour des valeurs différentes de \(k\), car l'équation \(y=\psi(x)\) n'a qu'un nombre limité de racines.

Soit done \(\lambda(\theta+k \alpha)=\lambda\left(\theta+k^{\prime} \alpha\right)\), où nous supposons \(k\) plus grand que \(k^{\prime}\). En mettant \(\theta-k^{\prime} \alpha\) au lien de \(\theta\), il viendra: \(\lambda\left[\theta+\left(k-k^{\prime}\right) \alpha\right]=\lambda \theta\), on bien, en faisant \(k-k^{\prime}=n\),
\[
\lambda(\theta+n \alpha)=\lambda \theta
\]

Cette équation détermine la valeur de \(\alpha\), car en vertu du théorème II on en tire
\[
\theta+n \alpha=(-1)^{m+m^{\prime}} \theta+m \omega+m^{\prime} \omega^{\prime},
\]
ce qui domne, en remarquant que \(\theta\) est variable, \((-1)^{m+m^{\prime}}=1\) et \(n \alpha=m \omega\) \(+m^{\prime} \omega^{\prime} ; m+m^{\prime}\) doit done être un nombre pair, et alors on anra
\[
\alpha=\frac{m}{n} \omega+\frac{m^{\prime}}{n} \omega^{\prime}
\]
\(\frac{m}{n}\) et \(\frac{m^{\prime}}{n}\) pouvant désigner des quantités rationnèlles quelconques; on voit done que, pour que la quantité \(\lambda(\theta+\alpha)\) puisse être racine de l'équation \(y=\psi(x)\) en même temps que \(\lambda \theta\), il faut que la constante \(\alpha\) ait la forme
\[
\alpha=\mu \omega+\mu^{\prime} \omega^{\prime}
\]
où \(\mu\) et \(\mu^{\prime}\) sont des quantités ratiomnelles positives ou négatives. I La quaun-
%407
tité \(\alpha\) ayant une telle valeur, l'expression \(\lambda(\theta+k \alpha)\) n'aura qu'un nombre limité de valeurs différentes, car ayant \(\lambda(\theta+n \alpha)=\lambda \theta\), on aura de même \(\lambda[\theta+(n+1) \alpha]=\lambda(\theta+\alpha) ; \lambda[\theta+(n+2) \alpha]=\lambda(\theta+2 \alpha)\) etc.

Cela posé, si le degré de l'équation \(y=\psi(x)\) surpasse le nombre des valeurs inégales de \(\lambda(\theta+k \alpha)\), soit \(\lambda\left(\theta+\alpha_1\right)\) une nouvelle racine, différente des racines \(\lambda(\theta+k \alpha)\); on doit avoir de la même manière: \(\alpha_1=\mu_1 \omega+\mu_1^{\prime} \omega^{\prime}\) et \(\psi(\lambda \theta)=\psi\left[\lambda\left(\theta+k_1 \alpha_1\right)\right]\). En mettant \(\theta+k \alpha\) au lieu de \(\theta\), il viendra, en remarquant que \(\psi[\hat{\lambda}(\theta+k \alpha)]=\psi(\hat{\lambda} \theta)=y\),
\[
y=\psi\left[\lambda\left(\theta+k \alpha+k_1 \alpha_1\right)\right]
\]
donc \(\lambda\left(\theta+k \alpha+k_1 \alpha_1\right)\) sera une racine quels que soient les nombres entiers \(k\) et \(k_1\). Si maintenant le degré de l'équation \(y=\psi(x)\) surpasse le nombre des valeurs inégales de l'expression \(\lambda\left(\theta+k \alpha+k_1 \alpha_1\right)\), soit \(\lambda\left(\theta+\alpha_2\right)\) une nouvelle racine; on doit avoir \(\alpha_2=\mu_2 \omega+\mu_2^{\prime} \omega^{\prime}\) et \(\psi(\lambda \theta)=\psi\left[\lambda\left(\theta+h_z \alpha_z\right)\right]\), d'où l'on tire, en mettant \(\theta+k \alpha+k_1 \alpha_1\) an lieu de \(\theta\),
\[
y=\psi\left[\lambda\left(\theta+k \alpha+k_1 \alpha_1+k_2 \alpha_2\right)\right]
\]
et par conséquent toutes les quantités contenues dans l'expression \(\lambda(\theta+k \alpha\) \(\left.+k_1 \alpha_1+k_8 \alpha_8\right)\) seront des racines, quels que soient les nombres entiers \(k, k_1, k_2\). En continuant ce raisomnement jusqu’à ce qu'on ait épuisé toutes les racines de l'équation \(y=\psi(x)\), on aura le théorème suivant:

Théorème IV. Toutes les racines de l'équation \(y=\psi(x)\) pourront être représentées par les valeurs inégales de l'expression:
\[
\lambda\left(\theta+k_1 \alpha_1+k_8 \alpha_8+k_3 \alpha_3+\cdots+k_\nu \alpha_\nu\right)
\]
en donnant it \(k_1, k_8, \ldots k_\nu\) toutes les valeurs entières, et les quantités \(\alpha_1, \alpha_2, \ldots \alpha_v\) étant de la forme
\[
\mu \omega+\mu^{\prime} \omega^{\prime}
\]
où " et " \(\mu^{\prime}\) sont des quantités rationnelles.
Cela posé, désignons ces valeurs de l'expression \(\lambda\left(\theta+k_1 \alpha_1+k_2 \alpha_2\right.\) \(\left.+\cdots+k_\nu \alpha_\nu\right)\) par \(\lambda(\theta), \lambda\left(\theta+\alpha_1\right), \lambda\left(\theta+\alpha_2\right), \ldots \lambda\left(\theta+\alpha_{m-1}\right)\), et faisons \(\psi(x)=\frac{p}{q}, p\) et \(q\) étant des fonctions entières de \(x\) sans diviscur commun, on aura
\[
p-q y=A(x-\lambda \theta)\left[x-\lambda\left(\theta+\alpha_1\right)\right]\left[x-\lambda\left(\theta+\alpha_y\right)\right] \ldots\left[x-\lambda\left(\theta+\alpha_{m-1}\right)\right],
\]
équation qui a lieu pour une valeur quelconque de \(x\). \(A\) est le coefficient
%408
de \(x^m\) dans \(p-q y\), il est done de la forme \(f-g y\), où \(f\) et \(g\) sont des constantes. On aura par conséquent
\[
p-q y=(f-g y)[x-\lambda \theta]\left[x-\lambda\left(\theta+\alpha_1\right)\right] \ldots\left[x-\lambda\left(\theta+\alpha_{m-1}\right)\right] .
\]

De là on déduira une expression de \(y\) en \(\boldsymbol{\theta}\), en attribuant à \(x\) une valeur particulière, ou bien en comparant les coefficiens d'une même puissance de \(x\) dans les deux membres. Une telle expression de \(y\) contiendra trois quantités constantes inconnues, et le problème se réduit maintenant à trouver tous les cas dans lesquels ces trois quantités pourront être déterminées de telle sorte que l'équation proposée soit satisfaite. Or nous allons voir tout-à-l'heure que cela sera toujours possible, quelles que soient les quantités \(\alpha_1, \alpha_2, \ldots \alpha_\nu\), en déterminant convenablement deux des quantités \(a, e_1, c_1\). Mais avant de considérer le cas général nous allons commencer par celui où \(p\) et \(q\) sont du premier degré, car un théorème qui en résulte nous sera utile pour parvenir à la solution dı problème général.
Soit done
\[
y=\frac{f^{\prime}+f x}{g^{\prime}+g x},
\]
on en tire
\[
\begin{gathered}
1 \pm c_1 y=\frac{g^{\prime} \pm c_1 f^{\prime}+\left(g \pm c_1 f\right) x}{g^{\prime}+g x}, \quad 1 \pm e_1 y=\frac{g^{\prime} \pm e_1 f^{\prime}+\left(g \pm e_1 f\right) x}{g^{\prime}+g x} \\
d y=\frac{f g^{\prime}-f^{\prime} g}{\left(g^{\prime}+g x\right)^2} d x
\end{gathered}
\]

Par là l'équation (1) deviendra, en substituant,
\[
\begin{gathered}
\frac{f g^{\prime}-f^{\prime} g}{\sqrt{\left(g^{\prime 2}-c_1^2 f^{\prime 2}\right)\left(g^{\prime 2}-e_1^2 f^{\prime 2}\right)}} \cdot \frac{d x}{\sqrt{\left(1+\frac{g+c_1 f}{g^{\prime}+c_1 f^{\prime}} x\right)\left(1+\frac{g-c_1 f}{g^{\prime}-c_1 f^{\prime}} x\right)\left(1+\frac{g+e_1 f}{g^{\prime}+e_1 f^{\prime}} x\right)\left(1+\frac{g-e_1 f}{g^{\prime}-e_1 f^{\prime}} x\right)}} \\
= \pm a \frac{d x}{\sqrt{\left(1-c^2 x^2\right)\left(1-e^2 x^2\right)}}
\end{gathered}
\]

On trouve aisement que cette formule ne peut être satisfaite que de l'ume des manières suivantes:
\[
\begin{aligned}
& y=a x, \quad c_1^2=\frac{c^2}{a^2}, \quad e_1^2=\frac{e^2}{a^2} \\
& y=\frac{a}{e c} \cdot \frac{1}{x}, \quad c_1^2=\frac{c^2}{a^2}, \quad e_1^2=\frac{e^2}{a^2}
\end{aligned}
\]
%409
\[
\left\{\begin{array}{l}
y=m \frac{1-x \sqrt{e c}}{1+x \sqrt{e c}}, \quad c_1=\frac{1}{m} \frac{\sqrt{c}-\sqrt{e}}{\sqrt{c}+\sqrt{e}}, \\
e_1=\frac{1}{m} \frac{\sqrt{c}+\sqrt{e}}{\sqrt{c}-\sqrt{e}}, \quad a=\frac{m \sqrt{-1}}{2}(c-e) .
\end{array}\right.
\]

On peut prendre les quantités \(c, e, \sqrt{c}, \sqrt{e}\) avec le signe qu'on voudra. Cela posé, reprenons l'équation (9). En désignant par \(f^{\prime}\) et \(g^{\prime}\) les coefficiens de \(x^{m-1}\) dans \(p\) et \(q\), on aura
\[
f^{\prime}-g^{\prime} y=-(f-g y)\left[\lambda \theta+\lambda\left(\theta+\alpha_1\right)+\lambda\left(\theta+\alpha_z\right)+\cdots+\lambda\left(\theta+\alpha_{m-1}\right)\right]
\]
d'où l'on tire, en faisant pour abréger
\[
\begin{gathered}
\varphi \theta=\lambda \theta+\lambda\left(\theta+\alpha_1\right)+\lambda\left(\theta+\alpha_2\right)+\cdots+\lambda\left(\theta+\alpha_{m-1}\right), \\
y=\frac{f^{\prime}+f \cdot \varphi^\theta}{g^{\prime}+g \cdot \varphi^\theta},
\end{gathered}
\]
équation qui pourra servir à déterminer la fonction \(y\), excepté dans le cas où \(\varphi \theta\) se réduit à une quantité constante.

Selon l'hypothèse, \(y\) doit être une fonction rationnelle de \(x\), donc la fonction \(\varphi \theta\) doit l'être de même. Il faut donc examiner d'abord dans quels cas cela pourra avoir lieu.

Soit \(\lambda(\theta+\alpha)\) une quelconque des quantités \(\lambda\left(\theta+\alpha_1\right), \lambda\left(\theta+\alpha_2\right), \ldots\), il suit de ce qui précède que \(\lambda(\theta+k \alpha)\) sera de même égale à l'une d'entre elles. Or soit \(\lambda(\theta+n \alpha)=\lambda \theta\), ce qui a toujours lien en déterminant convenablement le nombre entier \(n\), on aura, en mettant \(\theta-\alpha\) au lieu de \(\theta\), \(\lambda[\theta+(n-1) \alpha]=\lambda(\theta-\alpha)\); donc \(\lambda(\theta-\alpha)\) sera encore contenue parmi les quantités dont il s'agit. Il suit de là que si \(\lambda\left(\theta-\alpha_1\right)\) est différente de \(\lambda\left(\theta+\alpha_1\right)\), la quantité \(\lambda\left(\theta-\alpha_1\right)\) sera égale à l'une des quantités \(\lambda\left(\theta+\alpha_2\right)\), \(\lambda\left(\theta+\alpha_3\right), \ldots\) Cherchons donc d'abord les valeurs de \(\alpha\) qui domneront \(\lambda(\theta-\alpha)=\lambda(\theta+\alpha)\); c'est-à-dire \(\lambda(\theta+2 \alpha)=\lambda \theta\). D'après l'équation (7) on aura
\[
\alpha=\frac{m}{2} \omega+\frac{m^{\prime}}{2} \omega^{\prime}
\]
où \(m+m^{\prime}\) est \(u\) nombre pair. En domant à \(m\) et \(m^{\prime}\) à partir de zéro toutes les valeurs entières telles que \(m+m^{\prime}\) soit pair, \(\lambda(\theta+\alpha)\) prendra les valeurs suivantes:
%410
\[
\begin{gathered}
\lambda \theta, \lambda(\theta+\omega), \lambda\left(\theta+\omega^{\prime}\right), \lambda\left(\theta+\frac{\omega}{2}+\frac{\omega^{\prime}}{2}\right), \lambda\left(\theta+\frac{3 \omega^{\prime}}{2}+\frac{\omega^{\prime}}{2}\right), \\
\lambda\left(\theta+\omega+\omega^{\prime}\right), \text { etc. }
\end{gathered}
\]
mais, d'après le théorème II, il est clair que les seules de ces valeurs qui soient différentes entre elles sont celles-ci
\[
\lambda \theta, \lambda(\theta+\omega), \lambda\left(\theta+\frac{\omega}{2}+\frac{\omega^{\prime}}{2}\right), \lambda\left(\theta+\frac{3 \omega}{2}+\frac{\omega^{\prime}}{2}\right),
\]
donc, puisque \(\lambda(\theta+\alpha)\) doit être différent de \(\lambda \theta, \lambda(\theta+\alpha)\) ne pourra avoir que l'une de ces trois valeurs
\[
\lambda(\theta+\omega), \lambda\left(\theta+\frac{\omega}{2}+\frac{\omega^{\prime}}{2}\right), \lambda\left(\theta+\frac{3 \omega}{2}+\frac{\omega^{\prime}}{2}\right) .
\]

En exceptant ces quantités, il répond done toujours à \(\lambda(\theta+\alpha)\) un autre terme \(\lambda(\theta-\alpha)\). De là il suit qu’on pourra écrire l'expression de \(\varphi \theta\) comme il suit:
\[
\begin{aligned}
& \text { (15) } \varphi \theta=\lambda \theta+k \cdot \lambda(\theta+\omega)+k^{\prime} \cdot \lambda\left(\theta+\frac{\omega}{2}+\frac{\omega^{\prime}}{2}\right)+k^{\prime \prime} \cdot \lambda\left(\theta+\frac{3 \omega}{2}+\frac{\omega^{\prime}}{2}\right) \\
& +\lambda\left(\theta+\alpha_1\right)+\lambda\left(\theta-\alpha_1\right)+\lambda\left(\theta+\alpha_2\right)+\lambda\left(\theta-\alpha_2\right)+\cdots+\lambda\left(\theta+\alpha_n\right)+\lambda\left(\theta-\alpha_n\right),
\end{aligned}
\]
où \(k, k^{\prime}, k^{\prime \prime}\) sont égaux à zéro on à l'unité.
Pour avoir maintenant l'expression de \(\varphi \theta\) en \(x\), il faut recourir à la formule (3). En y faisant d'abord \(\theta^{\prime}=\frac{\omega}{2}\); on aura \(\lambda \theta^{\prime}=\frac{1}{c}\), donc \(\Delta\left(\theta^{\prime}\right)\) \(=0\), et par conséquent
\[
\lambda\left(\theta \pm \frac{\omega}{2}\right)= \pm \frac{1}{c} \cdot \frac{\Delta \theta}{1-e^2 \lambda^2 \theta}
\]
or \(\Delta \theta=\sqrt{\left(1-e^2 x^2\right)\left(1-c^2 x^2\right)}\), done
\[
\lambda\left(\theta \pm \frac{\omega}{2}\right)= \pm \frac{1}{c} \sqrt{\frac{1-c^2 x^2}{1-e^2 x^2}} .
\]

On aura de la même manière, en faisant \(\theta^{\prime}=\frac{\omega^{\prime}}{2}\),
\[
\lambda\left(\theta+\frac{\omega^{\prime}}{2}\right)=\frac{1}{e} \sqrt{\frac{1-e^2 x^2}{1-c^2 x^2}} .
\]

La première formule donne
\[
\lambda\left(\theta-\frac{\omega}{2}\right)=-\lambda\left(\theta+\frac{\omega}{2}\right)
\]
%411
donc, en mettant \(\theta+\frac{\omega}{2}\) an lieu de \(\theta\),
\[
\lambda(\theta+\omega)=-\lambda \theta=-x .
\]

En multipliant \(\lambda\left(\theta-\frac{\omega}{2}\right)\) par \(\lambda\left(\theta+\frac{\omega^{\prime}}{2}\right)\), on aura
\[
\lambda\left(\theta-\frac{\omega}{2}\right) \cdot \lambda\left(\theta+\frac{\omega^{\prime}}{2}\right)=-\frac{1}{e c},
\]
d'où l'on tire, en mettant \(\theta+\frac{\omega}{2}\) et \(\theta+\frac{3 \omega}{2}\) au lieu de \(\theta\),
\[
\left\{\begin{array}{l}
\lambda\left(\theta+\frac{\omega}{2}+\frac{\omega^{\prime}}{2}\right)=-\frac{1}{e c} \cdot \frac{1}{\lambda \theta}=-\frac{1}{e c} \cdot \frac{1}{x}, \\
\lambda\left(\theta+\frac{3 \omega}{2}+\frac{\omega^{\prime}}{2}\right)=-\frac{1}{e c} \cdot \frac{1}{\lambda(\theta+\omega)}=\frac{1}{e c} \cdot \frac{1}{x} .
\end{array}\right.
\]

La formule (3) donne encore, en faisant \(\theta^{\prime}=\alpha\),
\[
\lambda(\theta+\alpha)+\lambda(\theta-\alpha)=\frac{2 x \cdot A \alpha}{1-e^2 c^2 \lambda^2 \alpha \cdot x^2} .
\]

On voit par la que l'expression de \(\varphi \theta\) sera toujours une fonction rationnelle de \(x\), savoir
\[
\varphi \theta=(1-k) x+\frac{k^{\prime \prime}-k^{\prime}}{e c} \cdot \frac{1}{x}+\Sigma \frac{2 x \cdot \Delta \alpha}{1-e^2 c^2 \lambda^2 \alpha \cdot x^2},
\]
en employant pour abréger le signe de sommation \(\Sigma\).
Cela posé, il faut considérer plusieurs cas, selon les valeurs différentes de \(k, k^{\prime}, k^{\prime \prime}\).
Premier cas. Si \(k=k^{\prime}=k^{\prime \prime}=0\).
Si les trois quantités \(k, k^{\prime}, k^{\prime \prime}\), sont égales à zéro, l'expression de \(\varphi \theta\) deviendra
et
\[
\begin{array}{r}
\varphi \theta=\lambda \theta+\lambda\left(\theta+\alpha_1\right)+\lambda\left(\theta-\alpha_1\right)+\lambda\left(\theta+\alpha_2\right)+\lambda\left(\theta-\alpha_2\right)+\cdots \\
+\lambda\left(\theta+\alpha_n\right)+\lambda\left(\theta-\alpha_n\right)
\end{array}
\]
\[
\varphi \theta=x+2 x \Sigma \frac{d \alpha}{1-e^2 c^2 \lambda^2 \alpha \cdot x^2} .
\]

Done la première condition, que \(y\) soit rationnelle en \(x\), est remplie. Il faut \(52 *\)
%412
maintenant substituer son expression dans l'équation proposée et voir si elle pourra être satisfaite.
On tire d'abord de l'équation (14)
\[
\begin{aligned}
& 1 \pm c_1 y=\frac{g^{\prime} \pm c_1 f^{\prime}+\left(g \pm c_1 f\right) \varphi^\theta,}{g^{\prime}+g \varphi^\theta}, \\
& 1 \pm e_1 y=\frac{g^{\prime} \pm e_1 f^{\prime}+\left(g \pm e_1 f\right) \varphi^\theta}{g^{\prime}+g \varphi^\theta} .
\end{aligned}
\]

Cela posé, désignons par \(\delta, \delta^{\prime}, \varepsilon, \varepsilon^{\prime}\) des valeurs de \(\boldsymbol{\theta}\) qui répondent respectivement à \(y=+\frac{1}{c_1}, y=-\frac{1}{c_1}, y=+\frac{1}{e_1}, y=-\frac{1}{e_1}\), on doit avoir
\[
\left\{\begin{array}{l}
g^{\prime}-c_1 f^{\prime}+\left(g-c_1 f\right) \varphi \delta=0, g^{\prime}+c_1 f^{\prime}+\left(g+c_1 f\right) \varphi \delta^{\prime}=0 \\
g^{\prime}-e_1 f^{\prime}+\left(g-e_1 f\right) \varphi \varepsilon=0, g^{\prime}+e_1 f^{\prime}+\left(g+e_1 f\right) \varphi \varepsilon^{\prime}=0 .
\end{array}\right.
\]

En vertu de ces équations les valeurs de \(1-c_1 y, 1+c_1 y, 1-e_1 y, 1+e_1 y\) deviendront, en faisant pour abréger
\[
\left\{\begin{array}{c}
g^{\prime}+g \varphi \theta=r: \\
1-c_1 y=\frac{g^{\prime}-c_1 f^{\prime}}{r}\left(1-\frac{\varphi^\theta}{\varphi \delta}\right), \\
1+c_1 y=\frac{g^{\prime}+c_1 f^{\prime}}{r}\left(1-\frac{\varphi \theta}{\varphi \delta^{\prime}}\right), \\
1-e_1 y=\frac{g^{\prime}-e_1 f^{\prime}}{r}\left(1-\frac{\varphi^\theta}{\varphi \varepsilon}\right), \\
1+e_1 y=\frac{g^{\prime}+e_1 f^{\prime}}{r}\left(1-\frac{\varphi^\theta}{\varphi \varepsilon^{\prime}}\right)
\end{array}\right.
\]

En substituant dans \(1-\frac{\varphi^\theta}{\varphi^\delta}\) l'expression de \(\varphi \theta\) en \(x\), on obtiendra un résultat de la forme
\[
1-\frac{\varphi^\theta}{\varphi^\delta}=\frac{1+A_1 x+A_2 x^2+\cdots+A_{2 n+1} x^{2 n+1}}{\left(1-e^2 c^2 \lambda^2 \alpha_1 x^2\right)\left(1-e^2 c^2 \lambda^2 \alpha_2 x^2\right) \cdots\left(1-e^2 c^2 \lambda^2 \alpha_n x^2\right)} .
\]

En faisant \(\theta=\delta\) le second membre s'évanouira, mais il est clair par ce qui précède que \(\varphi(\theta)\) ne change pas de valeur si l'on met au lieu de \(\boldsymbol{\theta}\) l'une quelconque des quantités \(\theta \pm \alpha_1, \theta \pm \alpha_2 \ldots \theta \pm \boldsymbol{\alpha}_n\). Done le numérateur du second membre doit s'évanouir toutes les fois que \(x\) a l'une des valeurs \(\lambda \delta, \lambda\left(\delta \pm \alpha_1\right), \lambda\left(\delta \pm \alpha_2\right), \ldots \lambda\left(\delta \pm \alpha_n\right)\). Donc, puisque le nombre de
%413
ces valeurs, en général toutes différentes entre elles, est \(2 n+1\), il s'ensuit que
\[
\begin{array}{r}
1+A_1 x+\cdots+A_{2 n+1} x^{2 n+1}=\left(1-\frac{x}{\lambda \delta}\right)\left(1-\frac{x}{\lambda\left(\delta+\alpha_1\right)}\right)\left(1-\frac{x}{\lambda\left(\delta-\alpha_1\right)}\right) \\
\cdots\left(1-\frac{x}{\lambda\left(\delta+\alpha_n\right)}\right)\left(1-\frac{x}{\lambda\left(\delta-\alpha_n\right)}\right)
\end{array}
\]
donc en substituant et faisant pour abréger,
\[
\varrho=\left(1-e^2 c^2 \lambda^2 \alpha_1 x^2\right)\left(1-e^2 c^2 \lambda^2 \alpha_2 x^2\right) \ldots\left(1-e^2 c^2 \lambda^2 \alpha_n x^2\right),
\]
it viendra
\[
\begin{array}{r}
1-\frac{\varphi^\theta}{\varphi \delta}=\frac{1}{\varrho} \cdot\left(1-\frac{x}{\lambda \delta}\right)\left(1-\frac{x}{\lambda\left(\delta+\alpha_1\right)}\right)\left(1-\frac{x}{\lambda\left(\delta-\alpha_1\right)}\right) \\
\ldots\left(1-\frac{x}{\lambda\left(\delta+\alpha_n\right)}\right)\left(1-\frac{x}{\lambda\left(\delta-\alpha_n\right)}\right)
\end{array}
\]
formule qui a lieu pour des valeurs quelconques de \(\delta\) et \(\boldsymbol{\theta}\).
A l'aide de cette formule il sera facile de trouver les cas dans lesquels on pourra satisfaire à l'équation proposée. On peut écrire cette équation comme il suit:
\[
\sqrt{\left(1-c_1^2 y^2\right)\left(1-e_1^2 y^2\right)}=\frac{1}{a} \frac{d y}{d x} \sqrt{\left(1-c^2 x^2\right)\left(1-e^2 x^2\right)},
\]
ce qui nous fait voir que l'une des quatre fonctions \(1 \pm c_1 y, 1 \pm e_1 y\) doit s'évanouir en attribuant à \(x\) une des quatre valeurs \(\pm \frac{1}{c}, \pm \frac{1}{e}\), c'est-à-dire it \(\theta\) une des valeurs \(\pm \frac{\omega}{2}, \pm \frac{\omega^{\prime}}{2}\).

Supposons d'abord \(1-c_1 y=0\) pour \(\theta=\frac{\omega}{2}, 1+c_1 y=0\) pour \(\theta=\) \(-\frac{\omega}{2}, 1-e_1 y=0\) pour \(\theta=\frac{\omega^{\prime}}{2}, 1+e_1 y=0\) pour \(\theta=-\frac{\omega^{\prime}}{2}\), on pourra prendre \(\delta=\frac{\omega}{2}, \delta^{\prime}=-\frac{\omega}{2}, \varepsilon=\frac{\omega^{\prime}}{2}, \varepsilon^{\prime}=-\frac{\omega^{\prime}}{2}\). En substituant ces valeurs dans les équations (24) et remarquant que \(\varphi\left(-\frac{\omega}{2}\right)=-\varphi\left(\frac{\omega}{2}\right)\), \(\varphi\left(-\frac{\omega^{\prime}}{2}\right)=-\varphi\left(\frac{\omega^{\prime}}{2}\right)\), on en tire
\[
g^{\prime}=c_1 f \cdot \varphi\left(\frac{\omega}{2}\right)=e_1 f \cdot \varphi\left(\frac{\omega^{\prime}}{2}\right) ; f^{\prime}=\frac{g}{c_1} \varphi\left(\frac{\omega}{2}\right)=\frac{g}{e_1} \varphi\left(\frac{\omega^{\prime}}{2}\right) .
\]

On satisfait à ces équations en prenant
%414
ces valeurs, en général toutes différentes entre elles, est \(2 n+1\), il s'ensuit que
\[
\begin{array}{r}
1+A_1 x+\cdots+A_{2 n+1} x^{2 n+1}=\left(1-\frac{x}{\lambda \delta}\right)\left(1-\frac{x}{\lambda\left(\delta+\alpha_1\right)}\right)\left(1-\frac{x}{\lambda\left(\delta-\alpha_1\right)}\right) \\
\cdots\left(1-\frac{x}{\lambda\left(\delta+\alpha_n\right)}\right)\left(1-\frac{x}{\lambda\left(\delta-\alpha_n\right)}\right)
\end{array}
\]
donc en substituant et faisant pour abréger,
\[
\varrho=\left(1-e^2 c^2 \lambda^2 \alpha_1 x^2\right)\left(1-e^2 c^2 \lambda^2 \alpha_2 x^2\right) \ldots\left(1-e^2 c^2 \lambda^2 \alpha_n x^2\right),
\]
it viendra
\[
\begin{array}{r}
1-\frac{\varphi^\theta}{\varphi \delta}=\frac{1}{\varrho} \cdot\left(1-\frac{x}{\lambda \delta}\right)\left(1-\frac{x}{\lambda\left(\delta+\alpha_1\right)}\right)\left(1-\frac{x}{\lambda\left(\delta-\alpha_1\right)}\right) \\
\ldots\left(1-\frac{x}{\lambda\left(\delta+\alpha_n\right)}\right)\left(1-\frac{x}{\lambda\left(\delta-\alpha_n\right)}\right)
\end{array}
\]
formule qui a lieu pour des valeurs quelconques de \(\delta\) et \(\boldsymbol{\theta}\).
A l'aide de cette formule il sera facile de trouver les cas dans lesquels on pourra satisfaire à l'équation proposée. On peut écrire cette équation comme il suit:
\[
\sqrt{\left(1-c_1^2 y^2\right)\left(1-e_1^2 y^2\right)}=\frac{1}{a} \frac{d y}{d x} \sqrt{\left(1-c^2 x^2\right)\left(1-e^2 x^2\right)},
\]
ce qui nous fait voir que l'une des quatre fonctions \(1 \pm c_1 y, 1 \pm e_1 y\) doit s'évanouir en attribuant à \(x\) une des quatre valeurs \(\pm \frac{1}{c}, \pm \frac{1}{e}\), c'est-à-dire it \(\theta\) une des valeurs \(\pm \frac{\omega}{2}, \pm \frac{\omega^{\prime}}{2}\).

Supposons d'abord \(1-c_1 y=0\) pour \(\theta=\frac{\omega}{2}, 1+c_1 y=0\) pour \(\theta=\) \(-\frac{\omega}{2}, 1-e_1 y=0\) pour \(\theta=\frac{\omega^{\prime}}{2}, 1+e_1 y=0\) pour \(\theta=-\frac{\omega^{\prime}}{2}\), on pourra prendre \(\delta=\frac{\omega}{2}, \delta^{\prime}=-\frac{\omega}{2}, \varepsilon=\frac{\omega^{\prime}}{2}, \varepsilon^{\prime}=-\frac{\omega^{\prime}}{2}\). En substituant ces valeurs dans les équations (24) et remarquant que \(\varphi\left(-\frac{\omega}{2}\right)=-\varphi\left(\frac{\omega}{2}\right)\), \(\varphi\left(-\frac{\omega^{\prime}}{2}\right)=-\varphi\left(\frac{\omega^{\prime}}{2}\right)\), on en tire
\[
g^{\prime}=c_1 f \cdot \varphi\left(\frac{\omega}{2}\right)=e_1 f \cdot \varphi\left(\frac{\omega^{\prime}}{2}\right) ; f^{\prime}=\frac{g}{c_1} \varphi\left(\frac{\omega}{2}\right)=\frac{g}{e_1} \varphi\left(\frac{\omega^{\prime}}{2}\right) .
\]

On satisfait à ces équations en prenant
%414
\[
g=f^{\prime}=0, \frac{f}{g^{\prime}}=\frac{1}{k}, c_1=\frac{k}{\varphi\left(\frac{\omega}{2}\right)}, e_1=\frac{k}{\varphi\left(\frac{\omega^{\prime}}{2}\right)}
\]
où \(k\) est arbitraire.
La valeur de \(y\) deviendra
\[
y=\frac{1}{k} \varphi \theta
\]
et l'on aura ensuite
\[
1 \pm c_1 y=1 \pm \frac{\varphi^\theta}{\varphi\left(\frac{\omega}{2}\right)}, \quad 1 \pm e_1 y=1 \pm \frac{\varphi^\theta}{\varphi\left(\frac{\omega^{\prime}}{2}\right)} .
\]

Cela posé, faisons dans la formule (28) \(\delta= \pm \frac{\omega}{2}, \pm \frac{\omega^{\prime}}{2}\), on obtiendra
\[
\begin{aligned}
& 1-\frac{\varphi^\theta}{\tau\left(\frac{\omega}{2}\right)}=\frac{1}{\varrho}\left\{1-\frac{x}{\lambda \frac{\omega}{2}}\right\}\left\{1-\frac{x}{\lambda\left(\frac{\omega}{2}+\alpha_1\right)}\right\}\left\{1-\frac{x}{\lambda\left(\frac{\omega}{2}-\alpha_1\right)}\right\} \cdots \\
& \cdots\left\{1-\frac{x}{\lambda\left(\frac{\omega}{2}+\alpha_n\right)}\right\}\left\{1-\frac{x}{\lambda\left(\frac{\omega}{2}-\alpha_n\right)}\right\} \text {; } \\
&
\end{aligned}
\]
or \(\lambda\left(\frac{\omega}{2}\right)=\frac{1}{c}\), et d'après la formule (16) on aura \(\lambda\left(\frac{\omega}{2}+\alpha\right)=\lambda\left(\frac{\omega}{2}-\alpha\right)\), done
\[
\begin{array}{r}
1-\frac{\varphi \theta}{\varphi\left(\frac{\omega}{2}\right)}=\frac{1}{\varrho}(1-c x)\left\{1-\frac{x}{\lambda\left(\frac{\omega}{2}-\alpha_1\right)}\right\}^2\left\{1-\frac{x}{\lambda\left(\frac{\omega}{2}-\alpha_2\right)}\right\}^2 \cdots \\
\cdots\left\{1-\frac{x}{\lambda\left(\frac{\omega}{2}-\alpha_n\right)}\right\}^2
\end{array}
\]

On aura des expressions analogues pour \(1+\frac{\varphi^\theta}{\varphi\left(\frac{\omega}{2}\right)}, 1 \pm \frac{\varphi^\theta}{\varphi\left(\frac{\omega^{\prime}}{2}\right)}\) en faisant \(\delta=-\frac{\omega}{2}, \delta= \pm \frac{\omega^{\prime}}{2}\).
En faisant donc pour abréger
\[
\left\{\begin{array}{l}
t=\left\{1-\frac{x^2}{\lambda^2\left(\frac{\omega}{2}-\alpha_1\right)}\right\}\left\{1-\frac{x^2}{\lambda^2\left(\frac{\omega}{2}-\alpha_2\right)}\right\} \cdots\left\{1-\frac{x^2}{\lambda^2\left(\frac{\omega}{2}-\alpha_n\right)}\right\} \\
t^{\prime}=\left\{1-\frac{x^2}{\lambda^2\left(\frac{\omega^{\prime}}{2}-\alpha_1\right)}\right\}\left\{1-\frac{x^2}{\lambda^2\left(\frac{\omega^{\prime}}{2}-\alpha_2\right)}\right\} \cdots\left\{1-\frac{x^2}{\lambda^2\left(\frac{\omega^{\prime}}{2}-\alpha_n\right)}\right\}
\end{array}\right.
\]
%415
on trouvera
\[
1-c_1^2 y^2=\left(1-c^2 x^2\right) \frac{t^2}{\varrho^2}, \quad 1-e_1^2 y^2=\left(1-e^2 x^2\right) \frac{t^{\prime 2}}{\varrho^2}
\]
et de là
\[
\sqrt{\left(1-c_1^2 y^2\right)\left(1-e_1^2 y^2\right)}= \pm \frac{t t^{\prime}}{\varrho^2} \sqrt{\left(1-c^2 x^2\right)\left(1-e^2 x^2\right)}
\]

Maintenant les deux équations (35) nous montrent que \(\rho^2 \frac{d y}{d x}\) est une fonction entière de \(x\), qui est divisible par les deux fonctions entières \(t\) et \(t^{\prime}\); donc, puisque ces fonctions n'ont point de diviseur commun, il en résulte que \(\varrho^2 \frac{d y}{d x}\) sera divisible par leur produit; mais le degré de la fonction \(\varrho^2 \frac{d y}{d x}\) est précisément le même que celui de la fonction \(t t^{\prime}\), savoir \(4 n\). Donc l'expression \(\frac{\varrho^2 \frac{d y}{d x}}{t t^{\prime}}\) se réduit à une constante. En la désignant par \(a\), on aura done
\[
4 d y=a \frac{t t^{\prime}}{\varrho^2} d x
\]
et par suite l'équation (36) domnera
\[
\frac{d y}{\sqrt{\left(1-c_1^2 y^2\right)\left(1-e_1^2 y^2\right)}}= \pm a \frac{d x}{\sqrt{\left(1-c^2 x^2\right)\left(1-e^2 x^2\right)}},
\]
c'est-ì-dire l'équation proposée.
Pour déterminer le coefficient \(a\) faisons dans (37) \(x\) infini, on obtiendra, d'après les valeurs des fonctions \(\varrho, t, t^{\prime}\),
\[
\frac{d y}{d x}=\frac{a}{\left(-e^2 c^2\right)^{2 n} \cdot \lambda^4 \alpha_1 \ldots \lambda^4 \alpha_n \cdot \lambda^2\left(\frac{\omega}{2}-\alpha_1\right) \ldots \lambda^2\left(\frac{\omega}{2}-\alpha_n\right) \cdot \lambda^2\left(\frac{\omega^{\prime}}{2}-\alpha_1\right) \ldots \lambda^2\left(\frac{\omega^{\prime}}{2}-\alpha_n\right)} ;
\]
mais d'après la formule (18) on a \(\lambda^2\left(\frac{\omega}{2}-\alpha\right) \cdot \lambda^2\left(\frac{\omega^{\prime}}{2}-\alpha\right)=\frac{1}{c^2 e^2}\), done
\[
\frac{d y}{d u}=\frac{a}{\lambda^4 \alpha_1 \cdot \lambda^4 \alpha_2 \ldots \lambda^4 \alpha_n} \cdot \frac{1}{\left(e^2 c^2\right)^n}
\]
or, en différentiant- l'équation
\[
y=\frac{1}{k} \varphi \theta=\frac{1}{k}\left(x+2 x \geq \frac{I(\alpha)}{1-e^2 c^2 \lambda^2 \alpha \cdot x^2}\right)
\]
%416
et en faisant ensuite \(x=\frac{1}{0}\), on aura \(\frac{d y}{d x}=\frac{1}{k}\). En égalant cette valeur à la précédente on en tire
\[
a=\left(e^2 c^2\right)^n \frac{1}{k} \lambda^4 \alpha_1 \cdot \lambda^4 \alpha_2 \ldots \lambda^4 \alpha_n \text {. }
\]

On pourra donner à l'expression de \(y\) une antre forme plus simple à quelques égards. En multipliant les deux membres de l'équation (28) par \(\varphi \delta\) et faisant ensuite \(\delta=0\), il viendra
\[
\varphi \theta=\frac{A x}{\varrho}\left(1-\frac{x^2}{\lambda^2 \alpha_1}\right)\left(1-\frac{x^2}{\lambda^2 \alpha_2}\right) \cdots\left(1-\frac{x^2}{\lambda^2 \alpha_n}\right)
\]
où \(A\) est une quantité constante. En attribuant à \(x\). la valeur \(\frac{1}{0}\), après avoir divisé par \(x\), on trouvera
\[
A=\left(e^2 c^2\right)^n \cdot \lambda^4 \alpha_1 \cdot \lambda^4 \alpha_2 \ldots \lambda^4 \alpha_n=\alpha k .
\]

L'expression de \(y\) deviendra done

Il y a encore une antre manière d'exprimer \(y\) qui est très simple. En faisant dans (28) \(x=\frac{1}{0}\), après avoir divisé les deux membres par \(x\), on trouvera
\[
\begin{aligned}
& \boldsymbol{\delta} \delta= \\
& \begin{array}{l}
\left(e^2 c^2\right)^n \lambda^2 \alpha_1 \cdot \lambda^2 \alpha_2 \ldots \lambda^2 \alpha_n \cdot \lambda \delta \cdot \lambda\left(\alpha_1+\delta\right) \lambda\left(\alpha_1-\delta\right) \ldots \lambda\left(\alpha_n+\delta\right) \lambda\left(\alpha_n-\delta\right) . \\
\quad=\lambda \delta+\lambda\left(\delta+\alpha_1\right)+\lambda\left(\delta-\alpha_1\right)+\cdots+\lambda\left(\delta+\alpha_n\right)+\lambda\left(\delta-\alpha_n\right),
\end{array}
\end{aligned}
\]
formule qui a lieu pour une valeur quelconque de \(\delta\).
En mettant donc \(\theta\) au lieu de \(\delta\) et multipliant par \(\frac{1}{k}\), on aura \(y\) exprimé comme il suit:
\[
y=\frac{1}{k}(e c)^{2 n} b \cdot \lambda \theta \cdot \lambda\left(\alpha_1+\theta\right) \cdot \lambda\left(\alpha_1-\theta\right) \ldots \lambda\left(\alpha_n+\theta\right) \cdot \lambda\left(\alpha_n-\theta\right),
\]
où l'on a fait pour abréger
\[
b=\lambda^2 \alpha_1 \cdot \lambda^2 \alpha_2 \cdot \lambda^2 \alpha_3 \ldots \lambda^2 \alpha_n .
\]
%417
En faisant \(\theta=+\frac{\omega}{2}, \theta=+\frac{\omega^{\prime}}{2}\), les valeurs correspondantes de \(y\) seront \(\frac{1}{c_1}\) et \(\frac{1}{e_1}\), donc:
(47) \(\left\{\begin{array}{l}\frac{1}{c_1}=(-1)^n \frac{b}{k} e^{2 n} \cdot c^{2 n-1} \cdot\left[\lambda\left(\frac{\omega}{2}-\alpha_1\right) \cdot \lambda\left(\frac{\omega}{2}-\alpha_2\right) \ldots \lambda\left(\frac{\omega}{2}-\alpha_n\right)\right]^2 \\ \frac{1}{e_1}=(-1)^n \frac{b}{k} e^{2 n-1} \cdot c^{2 n} \cdot\left[\lambda\left(\frac{\omega^{\prime}}{2}-\alpha_1\right) \cdot \lambda\left(\frac{\omega^{\prime}}{2}-\alpha_2\right) \ldots \lambda\left(\frac{\omega^{\prime}}{2}-\alpha_n\right)\right]^2 .\end{array}\right.\)

Si donc les quantités \(c_1, e_1, a, y\) ont les valeurs exprimées par les équations (41), (43), (45), (47), l'équation (1) sera satisfaite en déterminant convenablement le signe du second membre. Il faut remarquer que ce signe n'est pas le même pour toutes les valeurs de \(x\); mais il sera toujours le même pour des valeurs de \(x\) comprises entre certaines limites. On doit prendre le signe + si \(x\) est très petit; et alors on doit conserver le même signe jusqu'à une certaine limite. Dans tous les cas le signe qu'il faut prendre se détermine par l'équation (36).

Le théorème de M. Jacobi est contenu comme cas particulier dans ce qui précède. En effet on l'obtiendra en faisant \(\alpha_1=\frac{2 \omega}{2 n+1}, c=1, c_1=1\). Alors on trouvera \(\alpha_2=\frac{4 \omega}{2 n+1}, \alpha_3=\frac{6 \omega}{2 n+1}, \cdots \alpha_n=\frac{2 n \omega}{2 n+1}\),
\[
\left\{\begin{array}{l}
k=b \cdot e^{2 n}\left[\lambda\left(\frac{1}{2 n+1} \frac{\omega}{2}\right) \cdot \lambda\left(\frac{3}{2 n+1} \frac{\omega}{2}\right) \cdots \lambda\left(\frac{2 n-1}{2 n+1} \frac{\omega}{2}\right)\right]^2 \\
e_1=e^{2 n+1} \cdot\left[\lambda\left(\frac{1}{2 n+1} \frac{\omega}{2}\right) \cdot \lambda\left(\frac{3}{2 n+1} \frac{\omega}{2}\right) \cdots \lambda\left(\frac{2 n-1}{2 n+1} \frac{\omega}{2}\right)\right]^4 \\
a=\left\{\left.\frac{\left.\lambda\left(\frac{\omega}{2 n+1}\right) \cdot \lambda\left(\frac{2 \omega}{2 n+1}\right) \cdot \lambda\left(\frac{3 \omega}{2 n+1}\right) \cdots \lambda\left(\frac{n \omega}{2 n+1}\right)\right|^2}{\lambda\left(\frac{1}{2 n+1} \frac{\omega}{2}\right) \cdot \lambda\left(\frac{3}{2 n+1} \frac{\omega}{2}\right) \cdots \lambda\left(\frac{2 n-1}{2 n+1} \frac{\omega}{2}\right)}\right|^2,\right. \\
y=\frac{\lambda \theta \cdot \lambda\left(\frac{2 \omega}{2 n+1}+\theta\right) \cdot \lambda\left(\frac{2 \omega}{2 n+1}-\theta\right) \cdots \lambda\left(\frac{2 n \omega}{2 n+1}+\theta\right) \cdot \lambda\left(\frac{2 n \omega}{2 n+1}-\theta\right)}{\left.\lambda\left(\frac{1}{2 n+1} \frac{\omega}{2}\right) \cdot \lambda\left(\frac{3}{2 n+1} \frac{\omega}{2}\right) \cdots \lambda\left(\frac{2 n-1}{2 n+1} \frac{\omega}{2}\right)\right]^2} \\
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-e_1^2 y^2\right)}}= \pm a \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-e^2 x^2\right)}}= \pm a d \theta
\end{array}\right.
\]

Il faut prendre le signe supérieur si \(x\) est compris entre les limites 53
%418
\(+\lambda\left(\frac{4 m+1}{2 n+1} \frac{\omega}{2}\right)\) et \(+\lambda\left(\frac{4 m+3}{2 n+1} \frac{\omega}{2}\right)\) et le signe inférieur si \(x\) est compris entre les limites \(\lambda\left(\frac{4 m+3}{2 n+1} \frac{\omega}{2}\right)\) et \(\lambda\left(\frac{4 m+5}{2 n+1} \frac{\omega}{2}\right)\).

En faisant dans notre formule générale \(\alpha_1=\frac{m \omega+m^{\prime} \omega^{\prime}}{2 n+1}\), où \(m+m^{\prime}\) est un nombre pair et où les trois nombres \(m, m^{\prime}, 2 n+1\) ne sont pas divisibles par un même facteur, on aura une formule plus générale que celle de M. Jacobi, savoir celle que j’ai demontrée dans les "Recherches sur les fonctions elliptiques." On aura dans ce cas, en faisant \(\alpha=\frac{m \omega+m^{\prime} \omega^{\prime}}{2 n+1}, \alpha_1=\alpha\), \(\alpha_2=2 \alpha, \alpha_3=3 \alpha, \ldots \alpha_n=n \alpha\), ce qui suffit pour déterminer les quantités \(c_1, e_1, a\) et \(y\).

Dans ce qui précède nous avons démontré qu’on aura une valeur convenable de la fonction \(y\), en prenant, dans l'expression générale de cette fonction \(y=\frac{f^{\prime}+f \cdot \varphi^\theta}{g^{\prime}+g \cdot \varphi^\theta}, f^{\prime}=g=0\). On peut aisément trouver toutes les autres solutions possibles à l'aide des formules (10), (11), (12). Soit
\[
y_1=\frac{f^{\prime}+f \cdot \varphi^\theta}{g^{\prime}+g \cdot \varphi^\theta}
\]
et désignons par \(c_2, e_2\), les valeurs correspondantes de \(c_1\) et \(e_1\), on doit avoir
\[
\frac{d y_1}{\sqrt{\left(1-c_2^2 y_1^2\right)\left(1-e_2^2 y_1^2\right)}}= \pm a_1 \frac{d x}{\sqrt{\left(1-e^2 x^2\right)\left(1-c^2 x^2\right)}}
\]
mais en faisant \(y=\frac{1}{k} \varphi \theta\), le second membre sera, d'après ce qui précède, égal à \(\pm \frac{a_1}{a} \frac{d y}{\sqrt{\left(1-c_1^2 y^2\right)\left(1-e_1^2 y^2\right)}}\), donc on doit avoir
\[
\frac{d y_1}{\sqrt{\left(1-c_2^2 y_1^2\right)\left(1-e_2^2 y_1^2\right)}}= \pm \frac{a_1}{a} \frac{d y}{\sqrt{\left(1-c_1^2 y^2\right)\left(1-e_1^2 y^2\right)}},
\]
où
\[
y_1=\frac{f^{\prime}+f y}{g^{\prime}+g y}
\]

D'après les équations (10), (11), (12) on satisfait de la manière la plus générale à ces équations en prenant
%419
a. \(y_1= \pm \frac{a_1}{a} y, \quad c_2^2=\frac{c_1^2 a^2}{a_1^2}, \quad e_2^2=\frac{e_1^2 a^2}{a_1^2}\),
c.
\[
\begin{aligned}
& y_1=m \frac{1-y \sqrt{ \pm e_1 c_1}}{1+y \sqrt{ \pm e_1 c_1}}, c_2=\frac{1}{m}\left(\frac{\sqrt{c_1}-\sqrt{ \pm e_1}}{\sqrt{c_1}+\sqrt{ \pm e_1}}\right)^2, \\
& \frac{a_1}{a}=\frac{m \sqrt{-1}}{2}\left(c_1 \mp e_1\right), \quad e_2=\frac{1}{m}\left(\frac{\sqrt{c_1}+\sqrt{ \pm e_1}}{\sqrt{c_1}-\sqrt{ \pm e_1}}\right)^2,
\end{aligned}
\]

Ces trois formules, en \(\mathrm{y}\) faisant \(y=\frac{1}{k} \varphi \theta\), contiendront donc toutes les manières possibles de satisfaire à l'équation (50).

On peut sans nuire à la généralité faire \(k=1\). La première de ces formules est la même que celle qui résulte de \(y=\frac{1}{k} \varphi \theta\). La seconde en résulte en mettant \(\frac{1}{e_1 c_1} \frac{1}{y}\) au lieu de \(y\). Les modules restent par cette substitution les mêmes. La troisième est en général différente des deux premières.
Deuxième cas. Si \(k\) est égal à zéro, et l'une des quantités \(k\) ', \(k\) " égale à l'unité.
Si, \(k\) étant égal à zéro, l'une des quantités \(k^{\prime}, k^{\prime \prime}\) est égale à l'unité, il faut nécessairement que l'autre soit égale à zéro. En effet si l'on avait \(k^{\prime}=k^{\prime \prime}=1\), les racines \(\lambda\left(\theta+\frac{\omega+\omega^{\prime}}{2}\right), \lambda\left(\theta+\frac{3 \omega+\omega^{\prime}}{2}\right)\) donneraient celle-ci \(\lambda\left(\theta+\frac{3 \omega+\omega^{\prime}}{2}-\frac{\omega+\omega^{\prime}}{2}\right)=\lambda(\theta+\omega)\), done \(k\) ne serait pas égal à zéro comme nous l'avons supposé. Désignons done par \(\beta\) l'une des quantités \(\frac{\omega+\omega^{\prime}}{2}, \frac{3 \omega+\omega^{\prime}}{2}\), l'expression de \(\rho \theta\) deviendra
\[
\begin{array}{r}
\varphi \theta=\lambda \theta+\lambda(\theta+\beta)+\lambda\left(\theta+\alpha_1\right)+\lambda\left(\theta-\alpha_1\right)+\cdots \\
+\lambda\left(\theta+\alpha_n\right)+\lambda\left(\theta-\alpha_n\right)
\end{array}
\]
ou, en l'exprimant en fonction de \(x\),
\[
\uparrow \theta=x \pm \frac{1}{e c} \frac{1}{x}+2 x \Sigma_{1-e^2 c^2 \lambda^2 \alpha \cdot x^2} .
\]

Soit comme dans le premier cas \(1-c_1 y=0\) pour \(x=\frac{1}{c}\), on aura \(53 *\)
%420
\[
\begin{gathered}
1 \pm c_1 y=\frac{g^{\prime} \pm c_1 f^{\prime}}{r}\left(1 \pm \frac{\varphi^\theta}{\varphi\left(\frac{\omega}{2}\right)}\right) \\
1-c_1^2 y^2=\frac{g^{\prime 2}-c_1^2 f^{\prime 2}}{r^2}\left[1-\left(\frac{\varphi^\theta}{\varphi\left(\frac{\omega}{2}\right)}\right)^2\right]
\end{gathered}
\]

Maintenant, de la même manière qu'on a démontré précédemment la formule (28), on établira la suivante:
\[
\begin{array}{r}
1-\frac{\tau^\theta}{q \delta}=-\frac{1}{\psi^\delta \cdot \varrho} \cdot\left(1-\frac{x}{\lambda \delta}\right)\left(1-\frac{x}{\lambda(\delta+\beta)}\right)\left(1-\frac{x}{\lambda\left(\delta+\alpha_1\right)}\right)\left(1-\frac{x}{\lambda\left(\delta-\alpha_1\right)}\right) \cdots \\
\cdots\left(1-\frac{x}{\lambda\left(\delta+\alpha_n\right)}\right)\left(1-\frac{x}{\lambda\left(\delta-\alpha_n\right)}\right)
\end{array}
\]
où l'on a fait pour abréger:
(57) \(\varrho= \pm e c x\left(1-e^2 c^2 \lambda^2 \alpha_1 \cdot x^2\right)\left(1-e^2 c^2 \lambda^2 \alpha_2 \cdot x^2\right) \ldots\left(1-e^2 c^2 \lambda^2 \alpha_n \cdot x^2\right)\).

En faisant \(\delta= \pm \frac{\omega}{2}\), on aura les valeurs de \(1+\frac{\varphi \theta}{\varphi\left(\frac{\omega}{2}\right)}\) et \(1-\frac{\varphi \theta}{\varphi\left(\frac{\omega}{2}\right)}\), qui multipliées entre elles donneront celle de \(1-\left(\frac{\varphi \theta}{\varphi\left(\frac{\omega}{2}\right)}\right)^2\). Cette valeur substituée dans l'expression de \(1-c_1^2 y^2\) (55) donnera
\[
\begin{array}{r}
1-c_1^2 y^2=\frac{c_1^2 f^{\prime 2}-g^{\prime 2}}{\varphi^2\left(\frac{\omega}{2}\right) \cdot r^2 \varrho^2}\left(1-c^2 x^2\right)\left(1-e^2 x^2\right)\left(1-\frac{x^2}{\lambda^2\left(\frac{\omega}{2}-\alpha_1\right)}\right)^2 \cdots \\
\cdots\left(1-\frac{x^2}{\lambda^2\left(\frac{\omega}{2}-\alpha_n\right)}\right)^2,
\end{array}
\]
et par conséquent, si l’on fait
(58) \(\quad t=\left(1-\frac{x^2}{\lambda^2\left(\frac{\omega}{2}-\alpha_1\right)}\right)\left(1-\frac{x^2}{\lambda^2\left(\frac{\omega}{2}-\alpha_2\right)}\right) \cdots\left(1-\frac{x^2}{\lambda^2\left(\frac{\omega}{2}-\alpha_n\right)}\right)\), on aura
\[
\sqrt{1-c_1^2 y^8}=\frac{\sqrt{c_1^2 f^{\prime 2}-g^{\prime 2}}}{\varphi\left(\frac{\omega}{2}\right) \cdot r \varrho} t \sqrt{\left(1-c^2 x^2\right)\left(1-e^2 x^2\right)}
\]

Cette valeur, mise dans l'équation (29), donne
\[
\sqrt{1-e_1^2 y^2}=\frac{\varphi\left(\frac{\omega}{2}\right)}{a \sqrt{c_1^3 f^{\prime 2}-g^{\prime 2}}} \frac{r \varrho}{t} \frac{d y}{d x} .
\]

On voit donc que \(\sqrt{1-a_1^2 y^2}\) doit être une fonction rationnelle de \(x\).
%421
Il n'est pas difficile de démontrer qu'on satisfera à cette condition, en supposant que \(1-e_1^8 y^8\) s'évanonit pour \(x= \pm \lambda\left(\frac{\omega-\beta}{2}\right)\); on aura alors
\[
\begin{aligned}
& \sqrt{1-e_1^8 y^8}=\frac{\sqrt{e_1^2 f^{\prime 2}-g^{\prime 8}}}{\varphi\left(\frac{\omega-\beta}{2}\right) \cdot r \varrho}\left(1-\frac{x^8}{\lambda^2\left(\frac{\omega-\beta}{2}\right)}\right)\left(1-\frac{x^8}{\lambda^2\left(\frac{\omega-\beta}{2}-\alpha_1\right)}\right) \cdots \\
& \cdots\left(1-\frac{x^2}{\lambda^2\left(\frac{(1)-\beta}{2}-\alpha_n\right)}\right) \text {. } \\
&
\end{aligned}
\]

Les équations (24) domneront dans ce cas
\[
\begin{aligned}
& g^{\prime}=c_1 f \varphi\left(\frac{\omega}{2}\right)=e_1 f \varphi\left(\frac{\omega-\beta}{2}\right), \\
& f^{\prime}=\frac{g}{c_1} \varphi\left(\frac{\omega}{2}\right)=\frac{g}{e_1} \varphi\left(\frac{\omega-\beta}{2}\right),
\end{aligned}
\]
auxquelles on satisfera en prenant
\[
\begin{gathered}
f=g^{\prime}=0 \\
\frac{f^{\prime}}{g}=\frac{\varphi\left(\frac{\omega}{2}\right)}{c_1}=\frac{\varphi\left(\frac{\omega-\beta}{2}\right)}{e_1} .
\end{gathered}
\]

De la il résulte:
\[
\begin{array}{cl}
c_1=k \cdot \varphi\left(\frac{\omega}{2}\right) ; \quad e_1=k \cdot \varphi\left(\frac{\omega-\beta}{2}\right) \\
y=\frac{1}{k \varphi^\theta}, \quad a= \pm \frac{e c}{k} .
\end{array}
\]

Connaissant ainsi une solution de l'équation proposée, on aura toutes les autres à l'aide des formules \((10),(11),(12)\). Le cas le plus simple est celui où \(n=0\). Alors on aura, en faisant \(c_1=c=1, \beta=\frac{3 \omega}{2}+\frac{\omega^{\prime}}{2}\),
\[
\varphi \theta=\lambda \theta+\lambda(\theta+\beta)=x+\frac{1}{e x},
\]
(63) \(\left\{\begin{array}{l}y=(1+e) \frac{x}{1+e x^2}, \quad e_1=\frac{2 \sqrt{e}}{1+e}, \\ \frac{d y}{\sqrt{\left(1-y^2\right)\left(1-e_1^8 y^2\right)}}=(1+e) \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-e^2 x^2\right)}} \text {. }\end{array}\right.\)
%422
Troisième cas. Si \(k=1\).
Daus ce cas l'expression (15) de \(\varphi \theta\) deviendra,
\[
\varphi \theta=\lambda \theta+\lambda(\theta+\omega)+\lambda\left(\theta+\alpha_1\right)+\lambda\left(\theta-\alpha_1\right)+\cdots+\lambda\left(\theta+\alpha_n\right)+\lambda\left(\theta-\alpha_n\right) .
\]

Or cètte quantité se réduit à zéro pour une valeur quelconque de \(\boldsymbol{\theta}\), ce dont on pourra se convaincre aisément, en remarquant que \(\varphi \boldsymbol{\theta}\) doit rester le même en changeant \(\boldsymbol{\theta}\) en \(\boldsymbol{\theta}+\boldsymbol{\omega}\).

La fonction \(\varphi \theta\) étant égale à zéro, si l'on désigne par \(\frac{1}{2}\left(f^{\prime}-g^{\prime} y\right)\) le coefficient de \(x^{m-2}\) dans le premier membre de l'équation (9), on aura, en faisant pour abréger
\[
\begin{gathered}
F \theta=\lambda^2 \theta+\lambda^2(\theta+\alpha)+\cdots+\lambda^2\left(\theta+\alpha_{m-1}\right): \\
f^{\prime}-g^{\prime} y=-(f-g y) F \theta
\end{gathered}
\]
d'où l'on tire,
\[
y=\frac{f^{\prime}+f \cdot F \theta}{g^{\prime}+g \cdot F^{\prime} \theta} \text {. }
\]

Maintenant il n'est pas difficile de trouver toutes les solutions relatives à ce troisième cas en se servant de l'expression (64). Je ne m'arrêterai pas ici à développer les formules mêmes; je vais seulement faire connaître un théorème plus général que celui exprimé par les formules (48).
Théorème. On aura
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-e_1^2 y^2\right)}}= \pm \frac{a d x}{\sqrt{\left(1-x^2\right)\left(1-e^2 x^2\right)}}= \pm a d \theta
\]
où
\[
\begin{aligned}
& a=k \cdot \lambda \frac{\omega}{n} \cdot \lambda \frac{2 \omega}{n} \cdots \lambda \frac{(n-1) \omega}{n}, \quad e_1=e^n\left(\lambda \frac{\omega}{2 n} \cdot \lambda \frac{3 \omega}{2 n} \cdots \lambda\left(n-\frac{1}{2}\right) \frac{\omega}{n}\right)^2, \\
& 1=k \cdot \lambda \frac{\omega}{2 n} \cdot \lambda \frac{3 \omega}{2 n} \cdots \lambda\left(n-\frac{1}{2}\right) \frac{\omega}{n}, \\
& y=k \cdot \lambda \theta \cdot \lambda\left(\theta+\frac{\omega}{n}\right) \lambda\left(\theta+\frac{2 \omega}{n}\right) \cdots \lambda\left(\theta+\frac{(n-1) \omega}{n}\right), \\
& n \text { étant un nombre entier quelconque, } \frac{\omega}{2}=\int_0^1 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-e^2 x^2\right)}} .
\end{aligned}
\]

En supposant \(n\) impair, la formule (65) est la même que celle que nous avons trouvée (48).
Si l'on fait \(x=\sin \varphi, y=\sin \psi\), on obtiendra
%423
\[
\frac{d \psi}{\sqrt{1-e_1^2 \sin ^2 \psi}}=a \frac{d \varphi}{\sqrt{1-e^2 \sin ^2 \varphi}},
\]
où l'on pourra exprimer la quantité \(\psi\) comme il suit:
\[
\begin{aligned}
& \psi=\varphi+\operatorname{arctang}\left\{\operatorname{tang} \varphi \cdot \sqrt{1-e^2 \lambda^2\left(\frac{\omega}{n}\right)}\right\} \\
& +\operatorname{arctang}\left\{\operatorname{tang} \varphi \cdot \sqrt{1-e^2 \lambda^2\left(\frac{2 \omega}{n}\right)}\right\} \\
& +\ldots \ldots \ldots \ldots \ldots \\
& +\operatorname{arctang}\left\{\operatorname{tang} \varphi \cdot \sqrt{1-e^2 \lambda^2\left(\frac{n-1}{n} \omega\right)}\right\} . \\
&
\end{aligned}
\]

En supposant \(n=2\) on aura
ou bien
\[
\psi=\varphi+\operatorname{arctang}\left(\operatorname{tang} \varphi \cdot \sqrt{1-e^z}\right),
\]
\[
\operatorname{tang}(\psi-\varphi)=\operatorname{tang} \varphi \cdot \sqrt{1-e^2} .
\]
(Voyez Legendie Exercices t. I, p. 84).
Si l'on suppose \(n\) très grand, on aura à peu près \(e_1=0\), donc
\[
\psi=a \int_0^{\varphi} \frac{d \varphi}{\sqrt{1-e^2 \sin ^2 \varphi}}=\sum_0^{n-1} \operatorname{arctang}\left\{\operatorname{tang} \varphi \cdot \sqrt{1-e^2 \lambda^2\left(\frac{m \omega}{n}\right)}\right\} .
\]

Soit \(\varphi=\frac{\pi}{2}\), on aura \(\psi=n \frac{\pi}{2}\), donc \(n \frac{\pi}{2}=a \frac{\omega}{2}\), donc \(\frac{1}{a}=\frac{1}{\pi} \frac{\omega}{n}\). De là il résulte, en faisant \(n\) infini,
\[
\int_0^\omega \frac{d \varphi}{\sqrt{1-e^2 \sin ^2 \varphi}}=\frac{1}{\pi} \int_0^\omega \operatorname{arctang}\left(\operatorname{tang} \varphi \cdot \sqrt{1-e^2 \lambda^y x}\right) d x .
\]

Nous avons vu précédemment que le nombre des valeurs inégales de l'expression \(\lambda\left(\theta+k_1 \alpha_1+k_2 \alpha_2+\cdots+k_\nu \alpha_\nu\right)\) est toujours fini. On peut dans tous les cas trouver ces valeurs comme il suit.
Soient
\[
\left\{\begin{array}{l}
\lambda\left(\theta+n_1 \alpha_1\right)=\lambda \theta \\
\lambda\left(\theta+n_2 \alpha_2\right)=\lambda\left(\theta+m_1 \alpha_1\right) \\
\lambda\left(\theta+n_3 \alpha_3\right)=\lambda\left(\theta+m_1 \alpha_1+m_2 \alpha_2\right) \\
\cdots \cdots \cdots \\
\lambda\left(\theta+n_\nu \alpha_\nu\right)=\lambda\left(\theta+m_1 \alpha_1+m_2 \alpha_2+\cdots\right.
\end{array}\right.
\]
%424
où \(n_1, n_2, n_3, \ldots n_v\) sont les nombres entiers les plus petits possibles qui puissent satisfaire à des équations de cette forme, \(m_1, m_2, \ldots m_{\nu-1}\) étant des nombres entiers, qui pourront être différens dans les différentes équations. Cela posé, je dis qu'on aura toutes les valeurs inégales de l'expression \(\lambda\left(\theta+k_1 \alpha_1+k_3 \alpha_2+\cdots+k_\nu \alpha_\nu\right)\) en attribuant à \(k_1, k_2, \ldots k_\nu\) toutes les valeurs entières et positives respectivement moindres que \(n_1, n_2, \ldots n_\nu\). En effet, si l'on avait
\[
\lambda\left(\theta+k_1{ }^{\prime} \alpha_1+k_2{ }^{\prime} \alpha_2+\cdots+k_v{ }^{\prime} \alpha_v\right)=\lambda\left(\theta+k_1 \alpha_1+k_2 \alpha_2+\cdots+k_v \alpha_v\right),
\]
salls avoir à la fois
\[
k_1^{\prime}=k_1, k_2^{\prime}=k_2, \ldots k_\nu^{\prime}=k_v,
\]
en mettant \(\theta-k_1 \alpha_1-k_2 \alpha_2-\cdots-k_{m-1} \alpha_{m-1}-k_m{ }^{\prime} \alpha_m-k_{m+1} \alpha_{m+1}-\cdots-k_\nu \alpha_\nu\) au lieu de \(\boldsymbol{\theta}\), on en tirera
\[
\lambda\left[\theta+\left(k_m-k_m{ }^{\prime}\right) \alpha_m\right]=\lambda\left[\theta+\left(k_1{ }^{\prime}-k_1\right) \alpha_1+\cdots+\left(k_{m-1}^{\prime}-k_{m-1}\right) \alpha_{m-1}\right],
\]
où l'on a supposé que \(k_m-k_m{ }^{\prime}\) est la première des quantités \(k_\nu-k_\nu{ }^{\prime}, k_{v-1}\) - \(k_{r^{\prime}-1}, \ldots q\) qui soit différente de zéro. Or en supposant, ce qui est permis, que \(k_m-k_m{ }^{\prime}\) ' soit positif, ce nombre sera en même temps moindre que \(n_m\), ce qui est contre l'hypothèse. Le nombre total des valeurs inégales de l'expression \(\lambda\left(\theta+k_1 \alpha_1+k_{z_2} \alpha_2+\cdots+k_\nu \alpha_\nu\right)\) sera donc égal à
\[
n_1 n_2 n_3 \ldots n_\nu
\]
car il est clair qu'on n'aura pas de valeurs nouvelles, en attribuant à \(k_1\), \(k_2, \ldots k_v\) des valeurs respectivement plus grandes que \(n_1, n_2, \ldots n_v\).
Le degré de l'équation \(p-q y=0\) est donc
\[
n=n_1 n_2 n_3 \ldots n_\nu \text {. }
\]

Si donc ce degré doit être un nombre premier, on doit avoir \(v=1\) et \(m=n_1\). Les racines de l'équation \(p-q y=0\) deviendront done dans ce cas
\[
\begin{gathered}
\lambda \theta, \lambda(\theta+\alpha), \lambda(\theta+2 \alpha), \ldots \lambda[\theta+(n-1) \alpha] \\
\lambda(\theta+n \alpha)=\lambda \theta, \text { et } \alpha=\frac{m \omega+m^{\prime} \omega^{\prime}}{n},
\end{gathered}
\]
\(m\) et \(m^{\prime}\) étant deux nombres entiers dont la somme est un nombre pair et qui n'ont pas un même diviseur commun avec \(n\).

On doit remarquer qu'à la même valeur de \(m\) répondent toujours plusieurs solutions différentes du problème général. Le nombre total de ces solutions est en général égal à \(3 m\).
%425
On peut de ce qui précède déduire un grand nombre de théorèmes remarquables sul les fonctions elliptiques. Parmi ceux-ei on doit distinguer les suivans.
a. Si l'èquation (1) peut être satisfaite en supposant \(y=\psi(x)=\frac{p}{q}\) où le degré des fonctions entières \(p\) et \(q\) est égal à un nombre composé \(m n\), on pourra toujours trouver des fonctions rationnelles \(q\) et \(f\) telles qu'en faisant
\[
\left\{\begin{array}{l}
x_1=\rho x=\frac{p^{\prime}}{q^{\prime}}, \text { on ait } y=f\left(x_1\right)=\frac{p_1}{q_1}, \\
\frac{d x_1}{\sqrt{\left(1-c_2^2 x_1^2\right)\left(1-e_2^2 x_1^2\right)}}=a_1 \frac{d x}{\sqrt{\left(1-c^2 x^2\right)\left(1-e^2 x_1^2\right)}}, \\
\frac{d y_1}{\sqrt{\left(1-c_1^2 y^2\right)\left(1-e_1^2 y^2\right)}}=a_2 \frac{d x_1}{\sqrt{\left(1-c_2^2 x_1^2\right)\left(1-e_2^2 x_1^2\right)}},
\end{array}\right.
\]
le degré des fonctions entières \(p^{\prime}\) et \(q^{\prime}\) étant égaal à l'un des facteurs \(m, n\), et le degré de \(p_1\) et \(q_1\) étant égal à l'autre.
b. Quel que soit le degré de l'équation \(p-q y=0\), on en pourra toujours tirer la valeur de \(x\) en \(y\) à l'aide d'opérations algébriques. Voilà donc une classe d'équations qui sont résolubles algébriquement. Les racines auront la forme suivante:
\[
x=\text { fonct. ration. }\left(y, r_1^{\frac{1}{n_1}}, r_2^{\frac{1}{n_2}}, r_3^{\frac{1}{n_2}} \ldots r_v^{\frac{1}{n_\nu}}\right),
\]
\(n_1, n_z, \ldots n_v\) étant des nombres premiers entre eux dont le produit est égal au degré de l'équation en question, et les \(r_1, r_2, \ldots r_\nu\) étant de la forme
\[
\zeta+t \sqrt{\left(1-c_1^y y^2\right)\left(1-e_1^y y^2\right)}
\]
oì \(\zeta\) et \(t\) sont des fonctions entières de \(y\).
c. Il y a un cas remarquable du problème général; c'est celui où l'on demande toutes les solutions possibles de l'équation
\[
\frac{d y}{\sqrt{\left(1-e^2 y^2\right)\left(1-e^2 y^2\right)}}=a \frac{d x}{\sqrt{\left(1-c^2 x^2\right)\left(1-e^2 x^2\right)}} .
\]

On aura à cet égard le théorème suivant:
%426
Si l'équation précédente admet une solution algébrique en \(x\) et \(y, y\) étant rationnel en \(x\) ou non, la quantité constante \(a\) doit nécessairement avoir la forme
\[
\mu^{\prime}+\sqrt{-\mu},
\]
où \(\|^{\prime}\) et \(" \boldsymbol{l}\) désignent deux nombres rationnels, le dernier étant essentiellement positif. Si l'on attribue à \(a\) une telle valeur on pourra trouver une infinité de valeurs différentes pour \(e\) et \(c\), qui rendent le problème possible. Toutes ces valeurs sont exprimables par des radicaux.

Si donc on suppose que a soit une quantité réelle il faut qu'elle soit en même temps rationnelle. Dans ce cas on sait d'ailleurs qu'on pourra satisfaire à l'équation différentielle dont il s'agit, quelles que soient les valeurs des quantités \(c\) et \(e\).
d. Du théorème précédent, on peut par un simple changement de variables déduire celui-ci:
Si l'équation
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-b^2 y^2\right)}}=a \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}
\]
où \(b^2=1-c^2\), admet une solution algébrique entre \(x\) et \(y\), le coefficient \(a\) doit avoir la forme suivante:
\[
\sqrt{\mu}+\mu^{\prime} \sqrt{-1}
\]
\(\mu^{\prime}\) et \(\boldsymbol{\mu}\) ayant la même signification que précédemment. Si donc on veut que \(a\) soit réel il faut qu'il soit égal à la racine carrée d'une quantité rationnelle. Cette condition remplie, le problème a une infinité de solutions. Comme cas particulier on en déduit ce théorème:

Si en supposant \(\varphi\) et \(\psi\) réels et le module \(c\) noindre que l'unite, l'équation
\[
\frac{d \psi}{\sqrt{1-b^2 \sin ^2 \psi}}=a \frac{d \varphi}{\sqrt{1-c^2 \sin ^2 \varphi}},
\]
a une intégrale algébrique en \(\sin \varphi\) et \(\sin \psi\), il faut nécessairement que \(a\) soit égal à la racine carrée d'une quantité rationnelle et positive.

Ainsi par exemple, si dans la formule (65) on suppose \(e_1^2=1-e^2\), on aura \(a=\sqrt{n}\) comme nous allons voir. En faisant \(\theta=\frac{\omega}{2 n}\) dans l'ex-
%427
pression de \(y\), on trouvera, en vertu de la valeur de \(k, y=1\), done
\[
\int_0^1 \frac{d y}{\sqrt{\left(1-y^2\right)\left(1-e_1^2 y^2\right)}}=a \int_0^{\lambda\left(\frac{\omega}{2 n}\right)} \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-e^2 x^2\right)}}=\frac{a \omega}{2 n},
\]
en remarquant qu'on doit, dans le second membre de l'équation (65), prendre le signe supérieur depuis \(x=0\) jusqu'à \(x=\lambda\left(\frac{\omega}{2 n}\right)\). Cela posé, en remarquant que \(\lambda\left(\theta+\frac{m \omega}{n}\right)=\lambda\left(\frac{(n-m) \omega}{n}-\theta\right)\), il est clair qu'on aura
\[
y=k \cdot \lambda \theta \cdot \lambda\left(\frac{\omega}{n}-\theta\right) \cdot \lambda\left(\frac{2 \omega}{n}-\theta\right) \ldots \lambda\left(\frac{(n-1) \omega}{n}-\theta\right)
\]
en multipliant cette valeur par celle que donne la formule (65), on aura, en faisant usage de la formule
\[
\lambda(\alpha+\theta) \cdot \lambda(\alpha-\theta)=\frac{\lambda^2 \alpha-\lambda^2 \theta}{1-e^2 \lambda^2 \alpha \cdot \lambda^2 \theta}=\frac{\lambda^2 \alpha-x^2}{1-e^2 \lambda^2 \alpha \cdot x^2}
\]
qu'on obtiendra -à l'aide du théorème 1 :
\[
y^2=k^2 x^2 \frac{\lambda^2 \frac{\omega}{n}-x^2}{1-e^2 \lambda^2 \frac{\omega}{n} \cdot x^2} \cdots \frac{\lambda^2 \frac{(n-1) \omega}{n}-x^2}{1-e^2 \lambda^2 \frac{(n-1) \omega}{n} \cdot x^2} .
\]

En faisant maintenant \(x=p \sqrt{-1}, y=z \sqrt{-1}\), on aura, en supposant \(p\) réel, pour toutes les valeurs de cette quantité,
\[
\int_0^z \frac{d z}{\sqrt{\left(1+z^2\right)\left(1+e_1^2 z^2\right)}}=a \int_0^p \frac{d p}{\sqrt{\left(1+p^2\right)\left(1+e^2 p^2\right)}},
\]
mais si l'on fait \(p=\frac{1}{0}\), on aura de même \(z=\frac{1}{0}\), done
\[
\int_0^{\frac{1}{b}} \frac{d z}{\sqrt{\left(1+z^2\right)\left(1+e_1^2 z^2\right)}}=a \int_0^{\frac{1}{b}} \frac{d p}{\sqrt{\left(1+p^2\right)\left(1+e^2 p^2\right)}} .
\]

Le premier membre de cette équation est la même chose que \(\frac{\omega}{2}\), et le second la même chose que \(a \int_0^1 \frac{d y}{\sqrt{\left(1-y^2\right)\left(1-e_1^2 y^2\right)}}\), ce qui est facile à prouver; done
%428
\[
\frac{\omega}{2}=a \int_0^1 \frac{d y}{\sqrt{\left(1-y^2\right)\left(1-e_1^2 y^2\right)}}
\]

Cette équation combinée avec (73) donne
\[
\frac{\omega}{2}=a \frac{a \omega}{2 n},
\]
c'est-à-dire
\[
a=\sqrt{n}
\]

Christiania le 27 mai 1828.
%429
XX.

ADDITION AU MÉMOIRE PRÉCÉDENT.

Astronomische Nachrichten, herausgegeben von Schumacher, Bd. 7, n \(\mathrm{n}^n\) 147. Altona 1829.

Dans le numéro 138 de ce journal j’ai fait voir comment on pourra trouver tontes les transformations possibles, réelles on imaginaires, d'une fonction elliptique proposée. Les modules \(c, e, c_1, e_1\) pourront être des quantités quelconques. Le cas le plus remarquable est celui où l'on suppose les modules réels. Dans ce cas le problème général pourra se résoudre par une méthode particulière, entièrement différente de celle que nous avons donnée dans le mémoire cité. Puisque cette nouvelle méthode est remarquable par sa grande simplicité je vais l'indiquer ici en pen de mots.

Le problème général que nous allons complètement résoudre est le suivant:
"Throuver tous les cas possibles ò l'on pourra satisfaire à l'équation "différentielle:
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-e_1^2 y^2\right)}}=a \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}
\]
"par une équation algébrique entre les variables \(x\) et \(y\), en supposant "les modules \(c\) et \(c_1\) moindres que l'unité et le coefficient a réel ou "imaginaire."
En désignant par \(\lambda \theta\) la fonction inverse de celle-ci:
\[
\theta=\int_0 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^3 x^2\right)}}
\]
%430
de sorte que \(x=\dot{\lambda} \theta\), on aura, en vertu de la formule (4) du numéro 138 ,
\[
\lambda\left[(-1)^{m+m^{\prime}} \theta+m \omega+m^{\prime} \omega^{\prime}\right]=\dot{\lambda} \theta,
\]
oì les quantités constantes \(\omega, \omega^{\prime}\) sont déterminées par les formules
\[
\begin{aligned}
& \frac{\omega}{2}=\int_0^1 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}, \\
& \frac{\omega^{\prime}}{2}=\int_0^{\frac{1}{c}} \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}} .
\end{aligned}
\]

Dans le cas que nous considérons, la quantité \(\omega\) est réelle, mais \(\omega^{\prime}\) est imaginaire. On aura en effet
\[
\frac{\omega^{\prime}}{2}=\int_0^1 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}+\int_1^{\frac{1}{c}} \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}},
\]
c'est-à-dire:
\[
\frac{\omega^{\prime}}{2}=\frac{\omega}{2}+\sqrt{-1} \cdot \int_1^{\frac{1}{c}} \frac{d x}{\sqrt{\left(x^2-1\right)\left(1-c^2 x^2\right)}},
\]
où il est clair que le coefficient de \(\sqrt{-1}\) est une quantité réelle. En faisant \(x=\frac{1}{\sqrt{1-b^2 y^2}}\), où \(b=\sqrt{1-c^2}\), on trouve
\[
\frac{\omega^{\prime}}{2}=\frac{\omega}{2}+\sqrt{-1} \cdot \frac{\tilde{\omega}}{2},
\]
où
\[
\frac{\tilde{\omega}}{2}=\int_0^1 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-b^2 x^2\right)}} .
\]

Le théorème II du numéro 138 donnera donc celui-ci: "On satisfera de la manière la plus générale à l'équation
\[
\lambda \theta^{\prime}=\dot{\lambda} \theta
\]
"en prenant
\[
\theta^{\prime}=(-1)^m \theta+m \omega+m^{\prime} \widetilde{\omega} \sqrt{-1},
\]
\({ }^\eta\) où \(m\) et \(m^{\prime}\) sont des nombres entiers quelconques, et \(\omega\) et \(\widetilde{\omega}\) deux "quantités réelles données par les formules (2) et (3).“
Cela posé, soit
(5)
\[
f(y, x)=0
\]
l'équation algébrique entre \(y\) et \(x\) qui doit satisfaire à l'équation différentielle
%431
(1). Si l'on fait \(x=\lambda \theta\) et \(y=\lambda_1 \theta^{\prime}\), où \(\theta\) et \(\theta^{\prime}\) sont deux nouvelles ra riables, et \(\lambda_1\) la fonction elliptique qui répond an module \(c_1\), de sorte quo
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c_1^2 y^2\right)}}=d \theta^{\prime} \text { pour } y=\lambda_1 \theta^{\prime},
\]
l'équation (1) deviendra
\[
d \theta^{\prime}= \pm a d \theta
\]
d'où l'on tire en intégrant: \(\boldsymbol{\theta}^{\prime}=\varepsilon \pm a \theta\), où \(\varepsilon\) est une constante. On a done
\[
y=\lambda_1(\varepsilon \pm \alpha \theta)
\]
ou bien, en mettant \(+a\) pour \(\pm a\)
\[
y=\lambda_1(\varepsilon+a \theta) \text {. }
\]

L'équation (5) entre \(x\) et \(y\) donnera donc celle-ci
\[
f\left[\lambda_1(\varepsilon+a \theta), \lambda \theta\right]=0
\]
qui ne contient que la seule variable \(\theta\), et qui aura lieu quelle que soit la valeur de cette quantité.

Il né serait pas difficile à l'aide de la formule (8) de trouver la fonction \(f(y, x)\); mais pour notre objet il suffit de connaître le coefficient \(a\) et une certaine relation entre les fonctions completes. Voici comment on \(y\) parviendra. En mettant \(\boldsymbol{\theta}+2 m \boldsymbol{\omega}\) au lieu de \(\theta\), et en remarquant qu'en vertu de l'équation (4)
\[
\lambda(\theta+2 m \omega)=\lambda \theta
\]
on obtiendra cette autre équation
\[
f\left[\lambda_1(\varepsilon+2 m a \omega+a \theta), \lambda \theta\right]=0 .
\]

On aura de même, en mettant \(\theta+m \widetilde{w} i\) pour \(\theta\), où \(i=\sqrt{-1}\),
\[
f\left[\lambda_1(\varepsilon+m a \tilde{\omega} i+a \theta), \lambda \theta\right]=0 .
\]

Dans ces deux équations \(m\) pourra être un nombre entier quelconque. En faisant \(x=\lambda \theta\) on voit done que l'équation algébrique
\[
f(y, x)=0
\]
est satisfaite en mettant pour \(y\) une quantité queleonque de l'une des deux formes :
\[
\lambda_1(\varepsilon+2 m a(i)+a \theta), \lambda_1(\varepsilon+m a \tilde{\omega} i+a \theta) ;
\]
mais \(m\) peut avoir une infinité de valuurs, tandis que l'équation dont il
%432
s'agit n'a qu'un nombre limité de racines; il faut done qu'on puisse trouver deux nombres entiers \(k\) et \(k^{\prime}\) tels que
\[
\lambda_1\left(\varepsilon+2 k^{\prime} a \omega+a \theta\right)=\lambda_1(\varepsilon+2 k a \omega+a \theta),
\]
et deux autres \(\nu\) et \(\nu^{\prime}\) tels que
\[
\lambda_1\left(\varepsilon+\nu^{\prime} a \widetilde{\omega} i+a \theta\right)=\lambda_1(\varepsilon+\nu a \widetilde{\omega} i+a \theta) .
\]

En vertu de la formule (4) ces deux équations donneront respectivement
\[
\left\{\begin{array}{l}
2 k^{\prime} a()=2 k a \omega+2 m \omega_1+m^{\prime} \widetilde{\omega}_1 \sqrt{-1}, \\
\nu^{\prime} a \widetilde{\omega} i=v^{\prime} \alpha \widetilde{\omega} i+2 u \omega_1+u^{\prime} \widetilde{\omega}_1 \sqrt{-1},
\end{array}\right.
\]
où \(\omega_1\) et \(\widetilde{\omega}_1\) désignent les valeurs de \(\omega\) et \(\widetilde{\omega}\) qui répondent au module \(c_1\), c'est-à-dire qu'on a
\[
\left\{\begin{array}{l}
\frac{\omega_1}{2}=\int_0^1 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c_1^2 x^2\right)}} \\
\frac{\hat{\omega}_1}{2}=\int_0^1 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-b_1^2 x^2\right)}}, \text { où } b_1=\sqrt{1-c_1^8} .
\end{array}\right.
\]

Cela posé, les équations (13) domneront, en y mettant \(\nu\) pour \(k^{\prime}-k\) et \(\boldsymbol{\nu}^{\prime}\) pour \(\nu^{\prime}-\nu\),
\[
\left\{\begin{array}{l}
a=\frac{m}{\nu} \frac{\omega_1}{\omega}+\frac{m^{\prime}}{2 \nu} \frac{\omega_1}{\omega} \sqrt{-1}, \\
a=\frac{\mu^{\prime}}{\nu^{\prime}} \frac{\tilde{\omega}_1}{\tilde{\omega}}-\frac{2 \mu}{\nu^{\prime}} \frac{\omega_1}{\tilde{\omega}} \sqrt{-1},
\end{array}\right.
\]
d'où, en comparant les parties réelles et imaginaires,
\[
\frac{m}{\nu} \frac{\omega_1}{\omega}=\frac{\mu^{\prime}}{\nu^{\prime}} \frac{\hat{\omega}_1}{\omega} ; \frac{m^{\prime}}{2 \nu} \frac{\hat{\omega}_1}{\omega}=-\frac{2 \mu}{\nu^{\prime}} \frac{\omega_1}{\hat{\omega}} .
\]

Ces deux équations donneront celles-ci:
\[
\frac{\omega^2}{\tilde{\omega}^2}=-\frac{1}{4} \frac{m m^{\prime}}{\mu \mu^{\prime}} \frac{\nu^{\prime 8}}{v^2}, \frac{\omega_1^2}{\tilde{\omega}_1^2}=-\frac{1}{4} \frac{m^{\prime} \mu^{\prime}}{m \mu} .
\]

Maintenant \(\frac{\omega^2}{\omega^3}\) est une fonction continue de \(c\), donc les équations (17) ne sauraient avoir lieu que pour des valeurs particulieres des modules \(c\) et \(c_1\). Si donc on suppose \(c\) indéterminé il faut que l'une des équations
\[
m^{\prime}=\mu=0 \text {, }
\]
%433
\[
m=\mu^{\prime}=0
\]
ait lieu. Les équations (15) et (16) se réduiront dans le premier cas à
\[
\left\{\begin{array}{l}
a=\frac{m}{\nu} \frac{\omega_1}{\omega}=\frac{\mu^{\prime}}{\nu^{\prime}} \frac{\tilde{v}_1}{\omega} \\
\frac{\omega_1}{\tilde{\omega}_1}=\frac{v^{\prime} \mu^{\prime}}{v^{\prime} m} \frac{\omega}{\omega}
\end{array}\right.
\]
et dans le second cas à
\[
\left\{\begin{array}{l}
a=\frac{m^{\prime}}{2 v} \frac{\hat{\omega}_1}{(1)} V-1=-\frac{2 \mu}{v^{\prime}} \frac{\omega_1}{\hat{\omega}} \sqrt{-1} \\
\frac{\omega_1}{\hat{\omega}_1}=-\frac{1}{4} \frac{m^{\prime} v^{\prime}}{\mu \nu} \frac{\hat{\theta}}{\omega} .
\end{array}\right.
\]

Mais si la valeur du module \(c\) est telle que la prenière des équations (17) ait lieu, on doit avoir en même temps
\[
\frac{\omega}{\hat{\omega}}=\frac{1}{2} \frac{\nu^{\prime}}{\nu} \sqrt{-\frac{m m^{\prime}}{\mu \mu^{\prime}}}, \frac{\omega_1}{\tilde{\omega}_1}=\frac{1}{2} \sqrt{-\frac{m^{\prime} \mu^{\prime}}{m \mu}},
\]
et alors \(a\) est donné par l'une des équations (15).
Quant aux nombres \(m, m^{\prime}, ", \mu^{\prime}, \nu, \nu^{\prime}\) il faut les prendre tels que \((1)\), \(\omega_1, \widetilde{\omega}, \widetilde{\omega}_1\) soient, selon leur nature, des quantités positives. Si donc on suppose, ce qui est permis, \(v\) et \(\nu^{\prime}\) positifs, il faut que \(m\) et " \(\prime^{\prime}\) soient de même signe et \(m^{\prime}\) et "l de signe contraire. On pourra d'ailleurs sans diminuer la généralité supposer \(m^{\prime}, m\) et \(\mu^{\prime}\) positifs et " négatif.
De ce qu'on vient de voir on déduit immédiatement ce théorème:
Théorème I. Pour que l'équation (1) ait une intégrale algélbrique en \(x\) et \(y\), il faut nécessairement que les modules \(c_1\) et \(c\) soient liés entre eux de telle sorte que l'une des deux quantités \(\frac{\omega_1}{\hat{\omega}_1}\) et \(\frac{\tilde{\omega}_1}{\omega_1}\) soit dans un rapport rationnel avec \(\frac{\omega}{\tilde{\omega}}\); c'est-à-dire qu'on doit avoir l'une des équations
\[
\frac{\omega_1}{\tilde{\omega}_1}=k \frac{\omega}{\tilde{\omega}} ; \frac{\widetilde{\omega}_1}{\omega_1}=k^{\prime} \frac{\omega}{\hat{\omega}}
\]
où \(k\) et \(k^{\prime}\) sont des nombres rationnels. Si la première de ces équations a lieu, mais non la seconde, on aura en même temps
\[
a=\delta \frac{\omega_1}{\omega}
\]
%434
où \(\delta\) est un nombre rationnel. Si la seconde équation a lieu mais non la première, on aura en même temps
\[
a=\delta \frac{\tilde{\omega}_1}{\omega} \sqrt{-1}
\]

Enfin si les deux équations (23) ont lieu en même temps, les modules \(c\) et \(c_1\) seront tous deux déterminés, savoir respectivement par les équations
\[
\frac{\tilde{\omega}}{\omega}=\sqrt{k k^{\prime}}, \frac{\tilde{\omega}_1}{\omega_1}=\sqrt{\frac{k^{\prime}}{k}}
\]
et alors le coefficient \(a\) doit avoir la forme
\[
a=\delta \frac{\omega_1}{\omega}+\delta^{\prime} \frac{\tilde{\omega}_1}{\omega} \sqrt{-1},
\]
où \(\delta\) et \(\delta^{\prime}\) sont des nombres rationnels.
Les conditions indiquées dans ce théorème doivent donc nécessairement être remplies pour que l'équation (1) ait une intégrale algébrique. Il reste encore le point le plus important, savoir de déterminer si ces conditions sont suffisantes. Or c'est ce que nous allons faire voir à l'aide de la formule (65) du numéro 138. Cette formule peut facilement être démontrée en faisant effectivement la substitution de \(y\); mais il existe une autre démonstration, tirée de considérations entièrement différentes et que nous allons donner ici, en nous servant d'une formule démontrée dans les "Recherches sur les fonctions elliptiques." Il s'agit de la formule (185) de ce mémoire (Crelle's Journal für die reine und angewandte Mathematik, Bd. 2, p. 176), savoir
\[
f \alpha=\Pi_0^{\infty} \frac{1-\left(\frac{\varrho-\varrho^{-1}}{r^{m+\frac{1}{1}}-r^{-m-\frac{1}{2}}}\right)^2}{1+\left(\frac{\varrho-\varrho^{-1}}{r^{m+\frac{1}{2}}+r^{-m-\frac{1}{2}}}\right)^2}
\]
où
\[
\varrho=e^{\frac{\alpha \pi}{\bar{\omega}^{\prime}}}, r=e^{\frac{\omega^{\prime} \pi}{\bar{\omega}^{\prime}}}
\]
les quantités \(\omega^{\prime}\) et \(\widetilde{\omega}^{\prime}\) étant données par les équations
\[
\begin{aligned}
& \frac{\omega^{\prime}}{2}=\int_0^1 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1+e^2 x^2\right)}} \\
& \frac{\tilde{\omega}^{\prime}}{2}=\int_0^{\frac{1}{e}} \frac{d x}{\sqrt{\left(1-e^2 x^2\right)\left(1+x^2\right)}} .
\end{aligned}
\]

On a de plus
%435
\((31)\)
\[
f \alpha=\sqrt{1-x^2}
\]
où \(x\) est lié à \(\alpha\) par l'équation
\[
\alpha=\int_0 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1+e^2 x^2\right)}}
\]

Si l'on fait \(e=\frac{c}{\sqrt{1-c^2}}=\frac{c}{b}, x=\sqrt{1-y^2}\), on trouvera
\[
\begin{gathered}
\frac{\omega^{\prime}}{2}=b \frac{\omega}{2} ; \frac{\tilde{\omega}^{\prime}}{2}=b \frac{\tilde{\omega}}{2} ; \frac{\omega^{\prime}}{\widetilde{\omega}^{\prime}}=\frac{\omega}{\tilde{\omega}}, \\
d \alpha=-b \frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^2 y^2\right)}},
\end{gathered}
\]
d'où
\[
y=\lambda\left(\frac{\omega}{2}-\frac{\alpha}{b}\right)
\]
maintenant l'équation \(x=\sqrt{1-y^2}\) dònne \(y=\sqrt{1-x^2}=f \alpha\), done
\[
f \alpha=\lambda\left(\frac{\omega}{2}-\frac{\alpha}{b}\right)
\]
d'où, en mettant \(b \frac{\omega}{2}-b \alpha\) à la place de \(\alpha\),
\[
\lambda \alpha=f\left(b \frac{\omega}{2}-b \alpha\right) \text {. }
\]

Cela posé, si l'on pose dans la formule (28) \(b \frac{\omega}{2}-b \alpha\) au lieu de \(\alpha\), on trouvera, après quelques réductions faciles,
\[
\lambda \alpha=A \frac{\left(1-t^2\right)\left(1-t^2 r^2\right)\left(1-t^{-2} r^2\right)\left(1-t^2 r^4\right)\left(1-t^{-2} r^4\right) \ldots}{\left(1+t^2\right)\left(1+t^2 r^2\right)\left(1+t^{-2} r^2\right)\left(1+t^3 r^4\right)\left(1+t^{-2} r^4\right) \ldots}
\]
où
\[
t=e^{-\frac{\alpha \pi}{\omega}}, r=e^{-\frac{\omega}{\omega} \pi}
\]
et \(A\) une quantité indépendante de \(\alpha\). Si l'on fait pour abréger
\[
\frac{1-e^{-8 x}}{1+e^{-2 x}}=\psi(x)
\]
on aura done
(36) \(\lambda \alpha=A \cdot \psi\left(\alpha \frac{\pi}{\tilde{\omega}}\right) \cdot \psi(\omega+\alpha) \frac{\pi}{\omega} \cdot \psi(\omega-\alpha) \frac{\pi}{\omega} \cdot \psi(2 \omega+\alpha) \frac{\pi}{\omega} \cdot \psi(2 \omega-\alpha) \frac{\pi}{\tilde{\omega}} \cdots\)
Si l'on fait maintenant suecessivement
%436
\[
\alpha=\theta, \theta+\frac{\omega}{n}, \theta+\frac{2 \omega}{n}, \cdots \theta+\frac{n-1}{n} \omega
\]
on aura les valeurs de \(\lambda \boldsymbol{\theta}, \lambda\left(\theta+\frac{\omega}{\dot{n}}\right) \cdots \lambda\left(\theta+\frac{n-1}{n} \omega\right)\), qui multipliées ensemble donneront sur le champ
\[
\begin{aligned}
\lambda \theta \cdot \lambda(\theta & \left.+\frac{\omega}{n}\right) \cdot \lambda\left(\theta+\frac{2 \omega}{n}\right) \cdots \lambda\left(\theta+\frac{n-1}{n} \omega\right) \\
& =A^n \cdot \psi \delta \frac{\pi}{\tilde{\omega}_1} \cdot \psi\left(\omega_1+\delta\right) \frac{\pi}{\tilde{\omega}_1} \cdot \psi\left(\omega_1-\delta\right) \frac{\pi}{\tilde{\omega}_1} \cdot \psi\left(2 \omega_1+\delta\right) \frac{\pi}{\tilde{\omega}_1} \cdots,
\end{aligned}
\]
où l'on a fait pour abréger
\[
\delta=\frac{\tilde{\omega}_1}{\tilde{\omega}} \theta, \frac{\omega_1}{\tilde{\omega}_1}=\frac{1}{n} \frac{\omega}{\tilde{\omega}}
\]
or si l'on pose dans la formule (36) le module \(c_1\) au lieu de \(c\), et si l'on désigne les valeurs correspondantes de
\[
\lambda \theta, \omega, \widetilde{\omega}, A
\]
respectivement par
\[
\lambda_1 \theta, \omega_1, \widetilde{\omega}_1, A_1
\]
il viendra
\[
\lambda_1 \alpha=A_1 \cdot \psi \alpha \frac{\pi}{\tilde{\omega}_1} \cdot \psi\left(\omega_1+\alpha\right) \frac{\pi}{\tilde{\omega}_1} \cdot \psi\left(\omega_1-\alpha\right) \frac{\pi}{\tilde{\omega}_1} \cdots
\]

Le second membre de la formule (37) est done la même chose que \(\frac{A^u}{A_1} \lambda_1 \delta\) \(=\frac{A^n}{A_1} \lambda_1\left(\frac{\tilde{\omega}_1}{\omega} \theta\right)\), et par conséquent on aura la formule suivante:
\[
\text { (39) } \quad \lambda_1\left(\frac{\tilde{\omega}_1}{\tilde{\omega}} \theta\right)=\frac{\Lambda_1}{A^n} \cdot \lambda \theta \cdot \lambda\left(\theta+\frac{\omega}{n}\right) \cdot \lambda\left(\theta+\frac{2 \omega}{n}\right) \ldots \lambda\left(\theta+\frac{n-1}{n} \omega\right) \text {, }
\]
cette équation a donc toujours lieu si le module \(c_1\) est tel que
\[
\frac{\omega_1}{\tilde{\omega}_1}=\frac{1}{n} \frac{\omega}{\widetilde{\omega}}
\]
quel que soit d'ailleurs le nombre entier \(n\).
Si l'on fait \(\lambda \theta=x, \lambda_1\left(\frac{\tilde{\sigma}_1}{\tilde{\omega}} \theta\right)=y\), on aura l'équation
\[
\frac{\tilde{\omega} d y}{\sqrt{\left(1-y^2\right)\left(1-c_1^2 y^2\right)}}=\frac{\tilde{\omega}_1 d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}=\widetilde{\omega}_1 d \theta
\]
qui par conséquent est satisfaite par l'expression algébrique
%437
\[
y=\frac{A_1}{A^n} \cdot \lambda \theta \cdot \lambda\left(\theta+\frac{\omega}{n}\right) \ldots \lambda\left(\theta+\frac{n-1}{n} \omega\right) .
\]

La valeur de \(y\) est toujours une fonction algébrique de \(x\). En effet, si \(n\) est un nombre impair, on a
\[
y=\frac{A_1}{A^n} \cdot x \cdot \frac{\lambda^2\left(\frac{\omega}{n}\right)-x^2}{1-c^2 \cdot \lambda^2\left(\frac{\omega}{n}\right) \cdot x^2} \cdots \frac{\lambda^2\left(\frac{n-1}{2} \frac{\omega}{n}\right)-x^2}{1-c^2 \lambda^2\left(\frac{n-1}{2} \frac{\omega}{n}\right) \cdot x^2},
\]
et si \(n\) est un nombre pair
\[
y=\frac{A_1}{A^n} \cdot x \cdot \frac{\lambda^2\left(\frac{\omega}{n}\right)-x^2}{1-c^2 \lambda^2\left(\frac{\omega}{n}\right) x^2} \cdots \frac{\lambda^2\left(\frac{n-2}{2} \frac{\omega}{n}\right)-x^2}{1-c^2 \lambda^2\left(\frac{n-2}{2} \frac{\omega}{n}\right) x^2} \cdot \frac{\sqrt{1-x^2}}{\sqrt{1-c^2 x^2}} .
\]

Considérons maintenant les trois cas de notre problème général.
Premier cas. Si a est réel.
Dans ce cas on doit avoir, comme nous l'avons vu, \(a=\delta \frac{\tilde{\omega}_1}{\tilde{\omega}}==\frac{\mu}{\nu} \frac{\tilde{\omega}_1}{\tilde{\omega}}\), où "l et \(v\) sont des nombres entiers; l'équation proposée deviendra
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c_1^2 y^2\right)}}=\frac{\mu}{v} \frac{\tilde{\omega}_1}{\tilde{\omega}} \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}} .
\]

On doit avoir de plus \(\frac{\omega_1}{\tilde{\omega}_1}=k \frac{\omega}{\tilde{\omega}}=\frac{m}{n} \frac{\omega}{\tilde{\omega}}, m\) et \(n\) étant entiers. Si l'on fait \(x=\lambda(\nu \widetilde{\omega} \theta)\) et \(y=\lambda_1\left(\mu \widetilde{\omega}_1 \theta\right), \theta\) étant une nouvelle variable, l'équation (45) sera satisfaite, car les deux membres se réduiront ì \(\mu \widetilde{\omega}_1 d \theta\). Pour avoir une intégrale en \(x\) et \(y\) il faut done éliminer \(\theta\) des deux équations
\[
x=\lambda(\nu \bar{\omega} \theta) ; y=\lambda_1\left(\mu \widetilde{\omega}_1 \theta\right) .
\]

Nous allons voir que le résultat de l'élimination sera une équation algélbrique en \(x\) et \(y\).
Soit \(c^{\prime}\) un nouveau module et désignons par
\[
\lambda^{\prime} \theta, \omega^{\prime}, \widetilde{\omega}^{\prime}, A^{\prime}
\]
les valeurs correspondantes de
\[
\lambda \theta, \omega, \bar{\omega}, A
\]

Cela posé, si l'on suppose le module \(c^{\prime}\) tel que \(\frac{\omega^{\prime}}{\omega^{\prime}}=\frac{1}{n} \frac{\omega}{\widetilde{\sigma}}\), on anra en vertu de la formule (39), en mettant \(\mu \nu \theta \bar{\omega}\) an lieu de \(\theta\)
%438
\[
\lambda^{\prime}\left(\mu \nu \widetilde{\omega}^{\prime} \theta\right)=\frac{A^{\prime}}{A^n} \lambda(\mu \nu \widetilde{\omega} \theta) \cdot \lambda\left(\mu \nu \widetilde{\omega} \theta+\frac{\omega}{n}\right) \ldots \lambda\left(\mu \nu \widetilde{\omega} \theta+\frac{n-1}{n} \omega\right)
\]
maintenant, ayant \(\frac{\omega^{\prime}}{\tilde{\omega}^{\prime}}=\frac{1}{n} \frac{\omega}{\tilde{\omega}}\) et \(\frac{\omega_1}{\tilde{\omega}_1^{\circ}}=\frac{m}{n} \frac{\omega}{\tilde{\omega}}\), on en tire \(\frac{\omega^{\prime}}{\tilde{\omega}^{\prime}}=\frac{1}{m} \frac{\omega_1^{\prime}}{\tilde{\omega}_1}\); donc la même formule donnera
\[
\lambda^{\prime}\left(\mu \widetilde{\omega}^{\prime} \theta\right)=\frac{A^{\prime}}{A_1^m} \lambda_1\left(\mu, \widetilde{\omega}_1 \theta\right) \cdot \lambda_1\left(\mu \nu \widetilde{\omega}_1 \theta+\frac{\omega_1}{m}\right) \ldots \lambda_1\left(\mu \widetilde{\omega}_1 \theta+\frac{m-1}{m} \omega_1\right) .
\]

En égalant entre elles ces deux expressions de \(\hat{\lambda}^{\prime}\left(\boldsymbol{\mu} \boldsymbol{\nu}^{\prime} \boldsymbol{\theta}\right)\) et faisant pour abréger
\[
\nu \widetilde{\omega} \theta=\delta, \quad, \widetilde{\omega}_1 \theta=\delta_1
\]
il viendra
\[
\left\{\begin{array}{c}
\frac{1}{A^n} \lambda(\mu \delta) \cdot \lambda\left(\mu \delta+\frac{\omega}{n}\right) \ldots \lambda\left(\mu \delta+\frac{n-1}{n} \omega\right) \\
=\frac{1}{A_1^m} \lambda_1\left(\nu \delta_1\right) \cdot \lambda_1\left(\nu \delta_1+\frac{\omega_1}{m}\right) \ldots \lambda_1\left(\nu \delta_1+\frac{m-1}{m} \omega_1\right) .
\end{array}\right.
\]

Le premier membre de cette équation est une fonction algébrique de \(\lambda\left(\prime \prime \delta^{\prime}\right)\) et le second une fonction algébrique de \(\lambda_1\left(\nu \delta_1\right)\); mais \(\lambda(\mu \delta)\) est at son tour une fonction algébrique de \(\lambda \delta=x\), et \(\lambda_1\left(\nu \delta_1\right)\) une fonction algébrique de \(\lambda_1 \delta_1=y\). Done enfin les deux membres de l'équation (50) sont respectivement des fonctions algébriques de \(x\) et de \(y\). Donc cette équation exprime l'intégrale cherchée en \(x\) et \(y\) de l'équation différentielle (45). Pour en avoir l'intégrale complète il suffit d'ajouter à \(\delta\) ou à \(\delta_1\) une quantité constante arbitraire. Quant aux quantités \(A\) et \(A_1\) on doit remarquer qu'on a
\[
A=\frac{1}{\sqrt{c}}, A_1=\frac{1}{\sqrt{c_1}} \text {. }
\]

Pour domner un exemple, supposons qu’on démande une intégrale algébrique de l'équation,
\[
\frac{-d y}{\sqrt{\left(1-y^2\right)\left(1-c_1^2 y^2\right)}}=\frac{\tilde{\omega}_1}{\tilde{\omega}} \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}
\]
dans le cas où \(\frac{\omega_1}{\tilde{\omega}_1}=\frac{2}{3} \frac{\omega}{\tilde{\omega}}\). On aura alors \(\mu=\nu=1, m=2, n=3\). L'équation (50) deviendra donc
\[
c \sqrt{c} \cdot \lambda \delta \cdot \lambda\left(\delta+\frac{\omega}{3}\right) \cdot \lambda\left(\delta+\frac{2 \omega}{3}\right)=c_1 \cdot \lambda_1 \delta_1 \cdot \lambda_1\left(\delta_1+\frac{\omega_1}{2}\right),
\]
%439
c'est-è-dire :
\[
y \frac{\sqrt{1-y^2}}{\sqrt{1-c_1^2 y^2}}=\frac{c \sqrt{c}}{c_1} x \frac{\lambda^2 \frac{\omega}{3}-x^2}{1-c^2 \lambda^y \frac{\omega}{3} \cdot x^2} .
\]

Second cas. Si a \(\sqrt{-1}\) est reel.
Dans ce cas on doit avoir, d'après l'équation (25), \(a=\frac{\mu}{\nu} \frac{\tilde{\omega}_1}{\omega} \sqrt{-1}, "\), et \(v\) étant entiers. On doit avoir de même \(\frac{\omega_1}{\tilde{\omega}_1}=\frac{m}{n} \frac{\tilde{\omega}}{(1)}\). L'équation proposée (1) deviendra
\[
\frac{\nu}{\mu} \frac{\omega}{\tilde{\omega}_1} \sqrt{-1} \cdot \frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c_1^2 y^2\right)}}=\frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}} .
\]

Pour réduire ce cas au précédent, il suffit de faire \(x=\frac{z \sqrt{-1}}{\sqrt{1-z^2}}, z\) étant une nouvelle variable; on aura alors \(\frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}=\sqrt{-1} \cdot \frac{d z}{\sqrt{\left(1-z^2\right)\left(1-b^2 z^2\right)}}\), \(b\) étant égal à \(\sqrt{1-c^2}\), et par suite l'équation (52) deviendra
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c_1^2 y^2\right)}}=\frac{\mu}{\nu} \frac{\tilde{\omega}_1}{\omega} \frac{d z}{\sqrt{\left(1-z^2\right)\left(1-l^2 z^2\right)}},
\]
dont l'intégrale algébrique est exprimé par la formule (50) en y faisant \(z=\lambda \delta=\frac{x}{\sqrt{x^2-1}}\) et mettant \(\widetilde{\omega}\) an lieu de \(\boldsymbol{\omega}\).

Supposons par exemple qu'il s'agisse de trouver une intégrale algélbrique de l'équation
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c_1^2 y^2\right)}}=\frac{\tilde{o}_1}{\omega} \sqrt{-1} \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}},
\]
dans le cas où \(\frac{\omega_1}{\tilde{\omega}_1}=2 \cdot \frac{\hat{\omega}}{\omega}\). Ayant \(\mu=\nu=1\) et \(m=2, n=1\), l'équation (50) deviendra
\[
\sqrt{b} \cdot \lambda \delta=c_1 \cdot \lambda_1\left(\delta_1\right) \cdot \lambda_1\left(\delta_1+\frac{\omega_1}{2}\right)
\]
ou, en remettant les valeurs de \(\lambda \delta\) et \(\lambda_1 \delta_1\),
\[
y \frac{\sqrt{1-y^3}}{\sqrt{1-c_1^3 y^3}}=\frac{\sqrt{b}}{c_1} \frac{x}{\sqrt{x^3-1}} .
\]
%440
Troisième cas. Si \(\frac{\varpi}{\omega}=\sqrt{k k^{\prime}}, \frac{\omega_1}{\varpi_1}=\sqrt{\frac{k}{k^{\prime}}}\).
Dans ce cas on doit avoir, en vertn du théorème \(\mathrm{I}, a=\frac{\mu}{\nu} \frac{\hat{\omega}_1}{\tilde{\omega}}+\frac{\mu^{\prime}}{\nu^{\prime}} \frac{\tilde{\omega}_1}{\omega} \sqrt{-1}\), ı, \(\nu^{\prime}, \iota^{\prime}, \nu^{\prime}\) étant des nombres entiers. L'équation proposée deviendra donc
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c_1^2 y^2\right)}}=\left(\frac{\mu}{\nu} \frac{\tilde{\sigma}_1}{\omega}+\frac{\mu^{\prime}}{\nu^{\prime}} \frac{\tilde{\omega}_1}{\omega} \sqrt{-1}\right) \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}},
\]
et cette équation sera toujours intégrable algébriquement. En effet comme on a
\[
\frac{\omega_1}{\hat{\omega}_1}=k \frac{\omega}{\omega} \text { et } \frac{\omega_1}{\hat{\omega}_1}=\frac{1}{k^{\prime}} \frac{\omega}{\omega}
\]
\(k^{\prime}\) et \(k\) étant des nombres rationnels, on pourra, en vertu de ce que nous venons de voir dans les deux premiers cas, satisfaire algébriquement aux équations
\[
\begin{gathered}
\frac{d z}{\sqrt{\left(1-z^2\right)\left(1-c_1^2 z^2\right)}}=\frac{\mu}{v} \frac{\omega_1}{\hat{\omega}} \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}, \\
\frac{d v}{\sqrt{\left(1-v^2\right)\left(1-c_1^2 v^2\right)}}=\mu^{\prime}{ }^{\prime}{ }_\omega{ }_1 \sqrt{-1} \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}} .
\end{gathered}
\]

Par là l'équation (53) deviendra
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c_1^2 y^2\right)}}=\frac{d z}{\sqrt{\left(1-z^2\right)\left(1-c_1^2 z^2\right)}}+\frac{d v}{\sqrt{\left(1-v^2\right)\left(1-c_x^2 v^2\right)}}
\]
on \(y\) satisfera, comme on sait, en prenant
\[
y=\frac{z \sqrt{\left(1-v^2\right)\left(1-c_1^8 v^2\right)}+v \sqrt{\left(1-z^2\right)\left(1-c_1^2 z^2\right)}}{1-c_1^2 z^2 v^2} .
\]

En substituant les valeurs de \(v\) et \(z\) en \(x\), on aura une intégrale de l'équation, algébrique en \(x\) et \(y\).

Nous avons ainsi démontré que les conditions nécessaires exposées dans le théorème I sont en même temps suffisantes.

D’après ce qui a été exposé dans le premier cas, on a immédiatement ce théorème:

Pour que deux fonctions elliptiques réelles \(F\left(c^{\prime}, \theta^{\prime}\right), F(c, \theta)\) puissent être réduites l'une à l'autre, il est nécessaire et il suffit qu'on ait entre les fonctions completes \(F^1(c), F^1(b), F^1\left(c^{\prime}\right), F^1\left(b^{\prime}\right)\) cette relation :
%441
\[
n \cdot F^1\left(c^{\prime}\right) \cdot F^1(b)=m \cdot F^1\left(b^{\prime}\right) \cdot F^1(c)
\]
où \(m\) et \(n\) sont des nombres entiers. Si cette condition est remplie, on pourra établir une relation algébrique entre \(\sin \theta^{\prime}\) et \(\sin \theta\) telle que
\[
F\left(c^{\prime}, \theta^{\prime}\right)=k \frac{F^1\left(b^{\prime}\right)}{F^1(b)} F(c, \theta),
\]
où \(k\) est un nombre rationnel. On pourra ajouter que dans le cas où \(k=1\), \(\theta^{\prime}\) est lié à \(\theta\) par l'équation:
(57) \(\left\{\begin{array}{r}\boldsymbol{\theta}^{\prime}+\operatorname{arctang}\left(a_1^{\prime} \operatorname{tang} \theta^{\prime}\right)+\cdots+\operatorname{arctang}\left(a_{m-1}^{\prime} \operatorname{tang} \theta^{\prime}\right) \\ =\boldsymbol{\theta}+\operatorname{arctang}\left(a_1 \operatorname{tang} \theta\right)+\cdots+\operatorname{arctang}\left(a_{n-1} \operatorname{tang} \theta\right),\end{array}\right.\)
où \(a_1, a_2 \ldots a_1^{\prime}, a_2^{\prime} \ldots\) sont des quantités constantes données par les formules
\[
\left\{\begin{array}{l}
a_\mu=\sqrt{1-c^2 \sin ^2 \theta_\mu}, \\
a_\mu{ }^{\prime}=\sqrt{1-c^{\prime 2} \sin ^2 \theta_\mu{ }^{\prime}},
\end{array}\right.
\]
après avoir déterminé \(\theta_\mu\) et \(\theta_\mu{ }^{\prime}\) de telle sorte que
\[
\left\{\begin{array}{l}
F\left(c, \theta_\mu\right)=\frac{2 \mu}{n} F^1(c)=\frac{\mu}{n} \int_0^\pi \frac{d \theta}{\sqrt{1-c^8 \sin ^8 \theta}}, \\
F\left(c^{\prime}, \theta_\mu{ }^{\prime}\right)=\frac{2 \mu}{m} F^1\left(c^{\prime}\right)=\frac{\mu}{m} \int_0^\pi \frac{d \theta}{\sqrt{1-c^{\prime 2} \sin ^2 \theta}} .
\end{array}\right.
\]

En prenant \(n=1\) on aura la formule (67) du numéro 138.
Il y a un cas du problème général qui mérite d'être remarqué; e'est celui où l'on suppose les deux modules égaux entre eux, en d'autres termes, où l'on demande tous les cas dans lesquels il sera possible d'intégrer algébriquement l'équation différentielle
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^2 y^2\right)}}=a \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}} .
\]

On a dans ce cas \(\omega^{\prime}=\omega, \widetilde{\omega}^{\prime}=\widetilde{\omega}\), et par conséquent les équations (15) deviendront
\[
a=\frac{m}{\nu}+\frac{m^{\prime}}{2 \nu} \frac{\tilde{o}}{\omega} \sqrt{-1}=\frac{\mu^{\prime}}{v^{\prime}}-\frac{2 \mu}{\nu^{\prime}} \frac{\omega}{\omega} \sqrt{-1},
\]
et de là
\[
\frac{m}{\nu}=\frac{\mu^{\prime}}{\nu^{\prime}}, \frac{m^{\prime}}{2 \nu} \cdot \frac{\sigma}{\omega}=-\frac{2 \mu}{\nu^{\prime}} \cdot \frac{\omega}{\sigma} .
\]
%442
Si l'on veut que \(a\) soit réel, on a \(a=\frac{m}{\nu}, m^{\prime}=\mu=0 ;\) dans ce . cas on n'aura aucune condition pour la valeur de \(c\), qui peut être quelconque, mais on voit que \(a\) doit être un nombre rationnel. Si au contraire on admet des valeurs imaginaires de \(a\), le module \(c\) doit être tel que \(\frac{m^{\prime}}{2 \nu} \cdot \frac{\omega}{\omega}=-\frac{2 \mu}{\nu^{\prime}} \cdot \frac{\omega}{\omega}\); on tire de là
\[
\frac{(\prime)}{\omega}=\frac{1}{2} \sqrt{-\frac{m^{\prime} v^{\prime}}{\mu \nu}} .
\]

En vertu de cette expression la valeur de \(a\) deviendra
\[
a=\frac{\mu^{\prime}}{\nu^{\prime}}-\frac{\mu}{\nu^{\prime}} \sqrt{-\frac{m^{\prime} \nu^{\prime}}{\mu \nu}} \cdot \sqrt{-1} .
\]

Soit \(\frac{\omega}{\omega}=\sqrt{k}\), on aura
\[
a=\delta+\delta_{\cdot}^{\prime} \sqrt{k} \cdot \sqrt{-1}
\]
\(k, \delta, \delta^{\prime}\) pouvant désigner des nombres ratiomnels quelconques. On voit que pour que l'équation \((60)\) soit intégrable algébriquement en supposant \(a\) imaginaire, il est nécessaire et il suffit que l'on ait
\[
\frac{\omega}{\tilde{\omega}}=\sqrt{k}, \quad a=\delta+\delta^{\prime} \sqrt{k} \cdot \sqrt{-1}
\]
\(k\) est essentiellement positif.
On pourra exprimer le module \(c\) en produits infinis comme il suit:
\[
\sqrt[4]{c}=\frac{1-e^{-\pi \sqrt{k}}}{1+e^{-\pi \sqrt{k}}} \cdot \frac{1-e^{-3 \pi \sqrt{k}}}{1+e^{-3 \pi} \sqrt{k}} \cdot \frac{1-e^{-5 \pi \sqrt{k}}}{1+e^{-5 \pi \sqrt{k}}} \cdots
\]

On tire cette expression de la formule (34), en y faisant \(\alpha=\frac{\omega}{2}\) et remarquant que \(\frac{\omega}{\tilde{\omega}}=\sqrt{k}\), let \(A=\frac{1}{\sqrt{c}}\). On aura en même temps le module \(b\) par cette formule
\[
\sqrt[4]{b}=\frac{1-e^{-\frac{\pi}{\sqrt{k}}}}{1+e^{-\frac{\pi}{\sqrt{k}}}} \cdot \frac{1-e^{-\frac{3 \pi}{\sqrt{k}}}}{1+e^{-\frac{3 \pi}{\sqrt{k}}}} \cdot \frac{1-e^{-\frac{5 \pi}{\sqrt{k}}}}{1+e^{-\frac{5 \pi}{\sqrt{k}}}} \cdots
\]

Il suit encore de ce qui précède que si le module \(c\) a la valeur ci-dessus, l'équation
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-b^2 y^2\right)}}=k^{\prime} \sqrt{k} \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}},
\]
%443
sera toujours intégrable algébriquement, quels que soient les nombres rationnels \(k\) et \(k k^{\prime}\), pourvu que \(k\) soit positif.

Il y a encore beancoup de choses à dire sur la transformation des fonctions elliptiques. On trouvera des développemens ultérieurs sur cette matière, ainsi que sur la théorie des fonctions elliptiques en général, dans un mémoire qui va paraître dans le Journal de M. Crelle.
Christiania le 25 septembre 1828.
%444
XXI.

REMARQUES SUR QUELQUES PROPRIÉTÉS GÉNÉRALES D'UNE CERTAINE SORTE DE FONCTIONS TRANSCENDANTES.
Journal fiir die reine und angewandte Mithematik, herausgegeben von Crelle, Bd. 3, Berlin 1828.
1.
Si \(\psi x\) désigone la fonction elliptique la plus générale, c'est-à-dire si
\[
\psi x=\int \frac{r d x}{\sqrt{R}},
\]
où \(r\) est une fonction rationnelle quelconque de \(x\), et \(R\) une fonction entière de la même variable, qui ne passe pas le quatrième degré, cette fonction a, comme on sait, la propriété très remarquable, que la somme d'un nombre quelconque de ces fonctions peut être exprimée par une seule fonction de la même forme, en y ajoutant une certaine expression algébrique et logarithmique.

Il semble que dans la théorie des fonctions trancendantes les géomètres se sont bornés aux fonctions de cette forme. Cependant il existe encore pour une classe très étendue d'autres fonctions une propriété analogue ì celle des fonctions elliptiques.

Je veux parler des fonctions qui peuvent être regardées comme intégrales de différentielles algébriques quelconques. Si l'on ne peut pas exprimer la somme d'un nombre quelconque de fonctions données par une seule fonction de la même espèce, comme dans le cas des fonctions elliptiques, an moins on pourra exprimer dans tous les cas une pareille somme par la somme d'un nombre déterminé d'autres fonctions de la même nature que
%445
les premières, en y ajoutant une certaine expression algébrique et logarithmique*). Nous démontrerons cette propriété dans liun des cahiers suivans de ce journal. Pour le moment je vais considérer un cas particulier, qui embrasse les fonctions elliptiques, savoir celui des fonctions contenues dans la formule
\[
\psi x=\int \frac{r d x}{\sqrt{R}}
\]
\(R\) étant une fonction rationnelle et entière quelconque, et \(r\) une fonction rationnelle.
2.
Nous allons d'abord établir le théorème suivant:
Théorème I. Soit \(\varphi x\) une fonction entière de \(x\), décomposée d'une manière quelconque en deux facteurs entiers \(\varphi_1 x\) et \(\varphi_z x\), de sorte que \(\varphi x=\) \(\varphi_1 x \cdot \varphi_z x\). Soit \(f x\) une autre fonction entière quelconque, et
\[
\psi x=\int \frac{f x \cdot d x}{(x-\alpha) \sqrt{\varphi x}}
\]
où \(\alpha\) est une quantité constante quelconque. Désignons par \(a_0, a_1, a_z \ldots\) \(c_0, c_1, c_2, \ldots\) des quantités quelconques, dont l'une au moins soit variable. Cela posé, si l'on fait
\[
\text { (3) }\left\{\begin{array}{r}
\left(a_0+a_1 x+\cdots+a_n x^n\right)^2 \varphi_1 x-\left(c_0+c_1 x+\cdots+c_m x^m\right)^2 \varphi_2 x \\
=A\left(x-x_1\right)\left(x-x_2\right)\left(x-x_3\right) \cdots\left(x-x_\mu\right),
\end{array}\right.
\]
où \(A\) ne dépend pas de \(x\), je dis qu'on aura
\[
\text { (4) } \varepsilon_1 \psi x_1+\varepsilon_2 \psi x_2+\varepsilon_3 \psi x_3+\cdots+\varepsilon_\mu \psi x_\mu
\]
\[
=-\frac{f \alpha}{\sqrt{\varphi \alpha}} \log \frac{\left(a_0+a_1 \alpha+\cdots+a_n \alpha^n\right) \sqrt{\varphi_1 \alpha}+\left(c_0+c_1 \alpha+\cdots+c_m \alpha^m\right) \sqrt{\varphi_{\mathrm{a}} \alpha}}{\left(a_0+a_1 \alpha+\cdots+a_n \alpha^n\right) \sqrt{\varphi_1 \alpha}-\left(c_0+c_1 \alpha+\cdots+c_m \alpha^m\right) \sqrt{\varphi_{\mathrm{a}} \alpha}}+r+C,
\]
où \(C\) est une quantité constante, et \(r\) le coefficient de \(\frac{1}{x}\) dans le développement de la fonction
\[
\frac{f x}{(x-\alpha) \sqrt{\varphi^x}} \cdot \log \frac{\left(a_0+a_1 x+\cdots+a_n x^n\right) \sqrt{\varphi_1 x}+\left(c_0+c_1 x+\cdots+c_m x^m\right) \sqrt{\varphi_2 x}}{\left(a_0+a_1 x+\cdots+a_n x^n\right) \sqrt{\varphi_1 x}-\left(c_0+c_1 x+\cdots+c_m x^m\right) \sqrt{\varphi_2 x}}
\]
suivant les puissances descendantes de \(x\). Les quantités \(\varepsilon_1, \varepsilon_2, \ldots \varepsilon_\mu\) sont
*) J'ai présenté un mémoire sur ces fonctions à l'académie royale des sciences de Paris vers la fin de l'unnée 1826.
%446
égales à +1 ou à -1, et leurs valeurs dépendent de celles des quantiiés \(x_1, x_2, \ldots x_\mu\).

Désignons le premier membre de l'équation (3) par \(F x\), et faisons pour abréger
\[
\left\{\begin{array}{l}
\theta x=a_0+a_1 x+a_2 x^2+\cdots+a_n x^n, \\
\theta_1 x=c_0+c_1 x+c_2 x^2+\cdots+c_m x^m
\end{array}\right.
\]
nous aurons
\[
F x=(\theta x)^2 \varphi_1 x-\left(\theta_1 x\right)^2 \varphi_2 x .
\]

Cela posé, soit \(x\) l'une quelconque des quantités \(x_1, x_2, \ldots x_\mu\), on aura l'équation
\[
F x=0
\]

De lì, en différentiant, on tire
\[
F^{\prime} x \cdot d x+\delta F x=0
\]
en désignant par \(F^{\prime} x\) la dérivée de \(F x\) par rapport à \(x\), et par \(\delta F x\) la différentielle de la même fonction par rapport aux quantités \(a_0, a_1, a_2, \ldots\) \(c_0, c_1, c_2, \ldots \mathrm{Or}\), en remarquant que \(\varphi_1 x\) et \(\varphi_2 x\) sont indépendans de ces dernières variables, l'équation (6) donnera
\[
\delta F x=2 \theta x \cdot \varphi_1 x \cdot \delta \theta x-2 \theta_1 x \cdot \varphi_2 x \cdot \delta \theta_1 x
\]
donc en vertu de (8)
\[
F^{\prime} x \cdot d x=2 \theta_1 x \cdot \varphi_2 x \cdot \delta \theta_1 x-2 \theta x \cdot \varphi_1 x \cdot \delta \theta x .
\]

Maintenant, ayant \(F x=0=(\theta x)^2 \varphi_1 x-\left(\theta_1 x\right)^2 \varphi_2 x\), on en tire
\[
\theta x \sqrt{\varphi_1 x}=\varepsilon \theta_1 x \sqrt{\varphi_2 x}
\]
où \(\varepsilon= \pm 1\). De là il vient
\[
\begin{gathered}
\theta x \cdot \varphi_1 x=\varepsilon \theta_1 x \sqrt{\varphi_1 x \cdot \varphi_2 x}=\varepsilon \theta_1 x \sqrt{\varphi x} \\
\theta_1 x \cdot \varphi_2 x=\varepsilon \theta x \sqrt{\varphi_2 x \cdot \varphi_1 x}=\varepsilon \theta x \sqrt{\varphi x}
\end{gathered}
\]
done l'expression de \(F^{\prime} x\). dx pourra être mise sous la forme
\[
F^{\prime} x \cdot d x=2 \varepsilon\left(\theta x \cdot \delta \theta_1 x-\theta_1 x \cdot \delta \theta x\right) \sqrt{\varphi x} .
\]

Cela donne, en multipliant par \(\varepsilon \frac{f x}{\sqrt{\rho x}} \frac{1}{F^{\prime} x} \frac{1}{x-a}\),
\[
\varepsilon \frac{f x \cdot d x}{(x-\alpha) \sqrt{q x}}=\frac{2 f x\left(\theta x \cdot \delta \theta_1 x-\theta_1 x \cdot \delta A_x x\right)}{(x-\alpha) f^{\prime \prime} x}
\]
%447
En faisant pour abréger
il viendra
\[
\lambda(x)=2 f x\left(\theta x \cdot \delta \theta_1 x-\theta_1 x \cdot \delta \theta x\right)
\]
\[
\varepsilon \frac{f x \cdot d x}{(x-\alpha) \sqrt{\rho x}}=\frac{\lambda x}{(x-\alpha) F^{\prime} x},
\]
\(\lambda x\) étant une fonction entière par rapport a \(x\).
Désignous par \(\Sigma I ' x\) la quantité
\[
I^{\prime} x_1+I^{\prime} x_2+I^{\prime} x_3+\cdots+I^{\prime} x_\mu
\]
et remarquons que l'équation (14) subsiste encore, en mettant l'une quelconque des quantités \(x_1, x_2, \ldots x_\mu\) au lieu de \(x\); cette équation donnera
\[
\Sigma \varepsilon \frac{f x \cdot d x}{(x-\alpha) \sqrt{\Phi x}}=\Sigma \frac{\lambda x}{(x-\alpha) F^{\prime \prime} x}=\delta v .
\]

Cela posé, on pourra chasser sans difficulté les quantités \(x_1, x_2, \ldots x_\mu\) du second membre.
En effet, quelle que soit la fonction entière \(\lambda x\), on peut supposer
\[
\lambda x=(x-\alpha) \lambda_1 x+\lambda \alpha,
\]
\(\lambda_1 x\) étant une fonction entière de \(x\), savoir \(\frac{\lambda x-\lambda \alpha}{x-\alpha}\). En substituant cette valeur dans (15), il viendra
\[
\delta v=\Sigma \frac{\lambda_1 x}{F^{\prime} x}+\lambda \alpha \Sigma \frac{1}{(x-\alpha) F^{\prime \prime} x} .
\]

Maintenant on aura, d'après une formule commue,
\[
\Sigma \frac{1}{(x-\alpha) F^{\prime} x}=-\frac{1}{F \alpha}
\]
en remarquant que l'on a donc
\[
F \alpha=A\left(\alpha-x_1\right)\left(\alpha-x_z\right) \ldots\left(\alpha-x_\mu\right)
\]
\[
\delta v=-\frac{\lambda \alpha}{F_\alpha}+\Sigma \frac{\lambda_1 x}{F^{\prime} x}
\]

Il reste à-trouver \(\Sigma \frac{\lambda_1 x}{F^{\prime} x}\). Or cela peut se faire à l'aide de la formule (17). En effet, en développant \(\frac{1}{\alpha-x}\) selon les puissances descendantes de \(\alpha\), il viendra
%448
\[
\frac{1}{F \alpha}=\frac{1}{\alpha} \Sigma \frac{1}{F^{\prime} x}+\frac{1}{\alpha^2} \Sigma \frac{x}{F^{\prime} x}+\cdots+\frac{1}{\alpha^{k+1}} \Sigma \frac{x^k}{F^{\prime} x}+\cdots
\]
d'où l'on voit que \(\sum \frac{x^k}{F^{\prime} x}\) est égal au coefficient de \(\frac{1}{\alpha^{k+1}}\) dans le développement de \(\frac{1}{\boldsymbol{F} \boldsymbol{\alpha}}\), ou bien à celui de \(\frac{1}{\boldsymbol{\alpha}}\) dans le développement de \(\frac{\boldsymbol{\alpha}^k}{\boldsymbol{F} \boldsymbol{\alpha}}\). De là on voit aisément que \(\Sigma \frac{\lambda_1 x}{F^{\prime} x}\), où \(\lambda_1 x\) est une fonction quelconque entière de \(x\), sera égal au coefficient de \(\frac{1}{x}\) dans le développement de la fonction \(\frac{\lambda_1 x}{F^{\prime} x}\) selon les puissances ascendantes de \(\frac{1}{x}\). Si pour abréger on désigne ce coefficient relatif à une fonction quelconque \(r\), développable de cette manière, par \(I \pi\), on aura
\[
\Sigma \frac{\lambda_1 x}{F^{\prime} x}=\Pi \frac{\lambda_1 x}{F^{\prime} x} .
\]

Or la formule (16), en divisant par \((x-\alpha) F x\), donne
\[
\Pi \frac{\lambda x}{(x-\alpha) F x}=\Pi \frac{\lambda_1 x}{F x}
\]
en remarquant que \(\Pi \frac{\lambda \alpha}{(x-\alpha) F x}\) est toujours égal à zéro. Donc l'expression \(\left(16^{\prime}\right)\) de \(\delta v\) deviendra
\[
\delta v=-\frac{\lambda \alpha}{F \alpha}+\Pi \frac{\lambda x}{(x-\alpha) F x}
\]

Maintenant on a \(\left(14^{\prime}\right)\)
\[
\lambda x=2 f x \cdot\left(\theta x \cdot \delta \theta_1 x-\theta_1 x \cdot \delta \theta x\right)
\]
donc, en mettant \(\alpha\) au lieu de \(x\),
\[
\lambda \alpha=2 f \alpha \cdot\left(\theta \alpha \cdot \delta \theta_1 \alpha-\theta_1 \alpha \cdot \delta \theta \alpha\right)
\]

En substituant ces expressions dans la valeur de \(\delta v\), et mettant pour \(F_\alpha\) sa valeur \((\theta \alpha)^2 \varphi_1 \alpha-\left(\theta_1 \alpha\right)^2 \varphi_2 \alpha\), on obtiendra
\[
\delta v=-\frac{2 f \alpha \cdot\left(\theta \alpha \cdot \delta \theta_1 \alpha-\theta_1 \alpha \cdot \delta \theta \alpha\right)}{(\theta \alpha)^2 \cdot \Upsilon_1 \alpha-\left(\theta_1 \alpha\right)^2 \cdot \varphi_2 \alpha}+\Pi \frac{2 f x}{x-\alpha} \cdot \frac{\theta \cdot x \cdot \delta \theta_1 x-\theta_1 x \cdot \delta \theta_1}{\left(\theta_1 x\right)^2 \cdot \Upsilon_1 x-\left(\theta_1 x\right)^2 \cdot \Upsilon_2 x} .
\]

On trouvera aisément l'intégrale de cette expression; car, en remarquant que \(f \alpha, \varphi_1 \alpha, \varphi_z \alpha, f x, x-\alpha, \varphi_1 x, \varphi_2 x\) sont des quantités constantes, on aura, en vertu de la formule
%449
\[
\int \frac{p d q-q d p}{p^2 m-q^2 n}=\frac{1}{2 \sqrt{m n}} \log \frac{p \sqrt{m}+q \sqrt{n}}{p \sqrt{m}-q \sqrt{n}}:
\]

Or l'équation (15) donne
\[
\Sigma \varepsilon \int \frac{f x \cdot d x}{(x-\alpha) \sqrt{\varphi x}}=v
\]
done en faisant
\[
\psi(x)=\int \frac{f x \cdot d x}{(x-\alpha) \sqrt{\varphi x}}
\]
et désignant par \(\varepsilon_1, \varepsilon_2, \ldots \varepsilon_\mu\) des quantités de la forme \(\pm 1\), on aurar la formule
qui s'accorde parfaitement avec la formule (4).
Les valeurs de \(\varepsilon_1, \varepsilon_2, \ldots \varepsilon_\mu\) ne sont pas arbitraires; elles dépendent de la grandeur de \(x_1, x_2, \ldots x_\mu\), et celle-ci est déterminée par l'équation
\[
\theta x \sqrt{\varphi_1 x}=\varepsilon \theta_1 x \sqrt{\varphi_2 x}
\]
équivalente aux équations .
\[
\begin{array}{r}
\theta x_1 \sqrt{\varphi_1 x_1}=\varepsilon_1 \theta_1 x_1 \sqrt{\varphi_2 x_1} ; \theta x_2 \sqrt{\varphi_1 x_2}=\varepsilon_2 \theta_1 x_2 \sqrt{\varphi_2 x_2} ; \ldots \\
\theta x_\mu \sqrt{\varphi_1 x_\mu}=\varepsilon_\mu \theta_1 x_\mu \sqrt{\varphi_2 x_\mu} .
\end{array}
\]

D'ailleurs les quantités \(\varepsilon_1, \varepsilon_2, \ldots \varepsilon_\mu\) conserveront les mêmes valeurs pour toutes les valeurs de \(x_1, x_2, \ldots x_\mu\), comprises entre certaines limites. Il en sera de même de la constante \(C\).
3.
La démonstration précédente suppose toutes les quantités \(x_1, x_8, \ldots x_\mu\) différentes entre elles, car dans le cas contraire \(F^{\prime} x\) serait égal à zéro pour
%450
un certain nombre de valeurs de \(x\), et alors le second membre de la furmule (14) se présenterait sous la forme \(\frac{0}{0}\). Néanmoins il est évident que la formule (25) subsistera encore dans le cas où plusieurs des quantités \(x_1\), \(x_2, \ldots x_\mu\) sont égales entre elles.
En faisant \(x_2=x_1\), on aura (26)
\[
\theta x_1 \sqrt{\varphi_1 x_1}=\varepsilon_1 \theta_1 x_1 \sqrt{\varphi_2 x_1}=\varepsilon_2 \theta_1 x_1 \sqrt{\varphi_2 x_1}
\]
et cela domne, en supposant que \(\theta_1 x \cdot \varphi_2 x\) et \(\theta x \cdot \varphi_1 x\) n'aient pas de diviseur commun,
\[
\varepsilon_2=\varepsilon_1 \text {. }
\]

En vertu de cette remarque on aura le théorème suivant:
Théorème II. Si l'on fait
\[
(\theta x)^2 \varphi_1 x-\left(\theta_1 x\right)^2 \varphi_2 x=A\left(x-x_1\right)^{m_1}\left(x-x_2\right)^{m_2} \cdots\left(x-x_\mu\right)^{m_\mu},
\]
les fonctions entieres \(\theta x \cdot \varphi_1 x\) et \(\theta_1 x \cdot \varphi_2 x\) n'ayant pas de diviseur commun, on aura
\[
\left\{\begin{array}{r}
\varepsilon_1 m_1 \psi x_1+\varepsilon_2 m_2 \psi x_2+\varepsilon_3 m_3 \psi x_3+\cdots+\varepsilon_\mu m_\mu \psi x_\mu \\
=C-\frac{f \alpha}{\sqrt{\varphi \alpha}} \log \frac{\theta \alpha \sqrt{\varphi_1 \alpha}+\theta_1 \alpha \sqrt{{\varphi_2 \alpha}_1}}{\theta \alpha \sqrt{\varphi_1 \alpha}-\theta_1 \alpha \sqrt{\varphi_2 \alpha}} \\
+\Pi \frac{f x}{(x-\alpha) \sqrt{\varphi x}} \log \frac{\theta x \sqrt{\varphi_1 x}+\theta_1 x \sqrt{\varphi_2 x}}{\theta x \sqrt{\varphi_1 x}-\theta_1 x \sqrt{\varphi_2 x}} .
\end{array}\right.
\]
4.

Si l'on suppose \(f x\) divisible par \(x-\alpha\), on aura \(f \alpha=0\), donc en mettant \((x-\alpha) f x\) au lieu de \(f x\), il viendra:

Théorème III. Les choses étant supposées les mêmes que dans le Théorème II, si l'on fait
\[
\psi x=\int \frac{f x \cdot d x}{\sqrt{\varphi \cdot x}},
\]
\(f x\) étant une fonction entière quelconque, on aura
%451
5.
Si dans la formule (28) on suppose le degré de la fonction entière \(f(x)\) moindre que la moitié de celui de \(\varphi x\), il est clair que la partie du second membre affectée du signe \(\Pi\), s'évanouira. Donc on aura ce théorème:

Théorème IV. Si le degré de la fonction entière \((f x)^2\) est moindre que celui de \(\varphi x\), et si l'on fait
\[
\psi x=\int \frac{f x \cdot d x}{(x-\alpha) \sqrt{\varphi x}}:
\]
on aura
\[
\begin{aligned}
& \varepsilon_1 m_1 \psi x_1+\varepsilon_2 m_2 \psi x_2+\cdots+\varepsilon_\mu m_\mu \psi x_\mu \\
& =C-\frac{f \alpha}{\sqrt{\varphi \alpha}} \cdot \log \frac{\theta \alpha \sqrt{\Upsilon_1 \alpha}+\theta_1 \alpha \sqrt{\uparrow_2 \alpha}}{\theta \alpha \sqrt{\Upsilon_1 \alpha}-\theta_1 \alpha \sqrt{\Upsilon_2 \alpha}} . \\
&
\end{aligned}
\]
6.

En faisant \(f \alpha=1\) dans le théorème précédent et différentiant \(k-1\) fois de suite, on aura le théorème suivant:
Théorème V. Si l'on fait
\[
\psi x=\int \frac{d x}{(x-\alpha)^k \sqrt{\varphi^x}},
\]
on aura
\[
\begin{aligned}
& \varepsilon_1 m_1 \psi x_1+\varepsilon_2 m_2 \psi x_2+\cdots+\varepsilon_\mu m_\mu \psi x_\mu \\
& =C-\frac{1}{1.2 \ldots(k-1)} \cdot \frac{d^{k-1}}{d \alpha^{k-1}}\left(\frac{1}{\sqrt{\varphi \alpha}} \cdot \log \frac{\theta \alpha \sqrt{\Upsilon_1 \alpha}+\theta_1 \alpha \sqrt{\Upsilon_2 \alpha}}{\theta \alpha \sqrt{\Upsilon_1 \alpha}-\theta_1 \alpha \sqrt{\Upsilon_2 \alpha}}\right)
\end{aligned}
\]
7.

Si dans le théorème III on suppose le degré de \((f x)^2\) moindre que celui de \(\varphi x\) diminué de deux unités, le second membre se réduit à une constante. Cela donne aisément le théorème qui suit:
Théorème VI. Si l'on désigne par \(\psi x\) la fonction
\[
\int \frac{\left(\delta_0+\delta_1 x+\delta_2 x^2+\cdots+\delta_{\nu^{\prime}} x^{\nu^{\prime}}\right) d x}{\sqrt{\beta_0+\beta_1 x+\beta_2 x^2+\cdots+\beta_\nu x^\nu}},
\]
où \(v^{\prime}=\frac{v-1}{2}-1\) si \(v\) est impair, et \(v^{\prime}=\frac{\nu}{2}-2\) si \(v\) est pair, on aura toujours
%452
\[
\varepsilon_1 m_1 \psi x_1+\varepsilon_2 m_2 \psi x_2+\cdots+\varepsilon_\mu m_\mu \psi x_\mu=\text { constante. }
\]

On voit que \(\nu^{\prime}\) a la même valeur pour \(\nu=2 m-1\) et pour \(\nu=2 m\), savoir \(\nu^{\prime}=m-2\).
8.
Soit maintenant
\[
\psi x=\int \frac{r d x}{\sqrt{\varphi x}}
\]
\(r\) étant une fonction rationnelle quelconque de \(x\). Quelle que soit la forme de \(r\), on pourra toujours faire
\[
r=f x+\frac{f_1 x}{\left(x-\alpha_1\right)^{k_1}}+\frac{f_2 x}{\left(x-\alpha_2\right)^{k_2}}+\cdots+\frac{f_\omega x}{\left(x-\alpha_\omega\right)^{k_\omega}}
\]
\(f x, f_1 x, f_2 x, \ldots f_1 x\) étant des fonctions entières. Cela posé, il est clair qu'en vertu des théorèmes III et \(\mathrm{V}\), on aura le suivant:

Théorème VII. Quelle que soit la fonction rationnelle \(r\) exprimée par la formule (32), en faisant
\[
\psi x=\int \frac{r d x}{\sqrt{\varphi_x}} \text { et } \frac{\theta x \sqrt{\varphi_1 x}+\theta_1 x \sqrt{\digamma_2 x}}{\theta x \sqrt{\varphi_1 x}-\theta_1 x \sqrt{\varphi_2 x}}=\chi x,
\]
on aura toujours
\[
\left\{\begin{aligned}
& \varepsilon_1 m_1 \psi x_1+\varepsilon_2 m_2 \psi x_2+\cdots+\varepsilon_\mu m_\mu \psi x_\mu=C+\Pi \frac{r}{\sqrt{\varphi x}} \log \chi x-\frac{1}{\Gamma k_1} \frac{d^{k_1-1}}{d \alpha_1^{k_1-1}}\left(\frac{f_1 \alpha_1}{\sqrt{\varphi \alpha_1}} \log \chi \alpha_1\right)-\frac{1}{\Gamma k_2} \frac{d^{k_2-1}}{d \alpha_2^{k_2-1}}\left(\frac{f_2 \alpha_2}{\sqrt{\varphi \alpha_2}} \log \chi \alpha_2\right)-\cdots \\
&-\frac{1}{\Gamma k_\omega} \frac{d^{k_\omega-1}}{d \alpha_\omega{ }^{k_\omega-1}}\left(\frac{f_\omega \alpha_\omega}{\sqrt{\varphi \alpha_\omega}} \log \chi \alpha_\omega\right)
\end{aligned}\right.
\]
en représentant par Tk le produit \(1.2 .3 \ldots(k-1)\).
9.
Nous avons considéré précédemment les quantités \(x_1, x_2, \ldots x_\mu\) comme des fonctions de \(a_0, a_1, a_2, \ldots c_0, c_1, c_2, \ldots\) Supposons maintenant qu'un certain nombre des quantités \(x_1, x_2, \ldots x_\mu\) soient données et regardées comme des variables indépendantes; et soient \(x_1, x_2, \ldots x_{\mu^{\prime}}\) ces quantités. Alors il faut déterminer \(a_0, a_1, \ldots c_0, c_1, \ldots\) de manière que le premier membre de l'équation (3) soit divisible par
%453
\[
\left(x-x_1\right)\left(x-x_2\right) \ldots\left(x-x_{\mu^{\prime}}\right) .
\]

Cela ce fera à l'aide des équations (26). Les “" premières équations,
\[
\left\{\begin{array}{c}
\theta x_1 \sqrt{\varphi_1 x_1}=\varepsilon_1 \cdot \theta_1 x_1 \sqrt{\varphi_2 x_1} \\
\theta x_2 \sqrt{\varphi_1 x_2}=\varepsilon_2 \cdot \theta_1 x_2 \sqrt{\varphi_2 x_2} \\
\cdots \cdots \cdots \cdots \cdots \cdots \\
\theta x_{\mu^{\prime}} \sqrt{\varphi_1 x_{\mu^{\prime}}}=\varepsilon_{\mu^{\prime}} \theta_1 x_{\mu^{\prime}} \sqrt{\varphi_2 x_{\mu^{\prime}}}
\end{array}\right.
\]
donneront \(\mu^{\prime}\) des quantités \(a_0, a_1, \ldots c_0, c_1, \ldots\) exprimées en fonction rationnelle des autres et de \(x_1, x_2, \ldots x_{\mu^{\prime}}, \sqrt{\varphi x_1}, \sqrt{\varphi x_2}, \ldots \sqrt{\varphi x_{\mu^{\prime}}}\).

Le nombre des indéterminées \(a_0, a_1, \ldots a_n, c_0, c_1, \ldots c_m\) est égal à \(m+n+2\); donc, comme il est aisé de le voir par la forme des équations (35), on pourra faire \(\mu^{\prime}=m+n+1\). Cela posé, en substituant les valeurs de \(a_0, a_1, \ldots c_0, c_1, \ldots\) dans les fonctions \(\theta x, \theta_1 x, \ldots\), la fonction entière \((\theta x)^2 \varphi_1 x-\left(\theta_1 x\right)^2 \varphi_2 x\) deviendra divisible par
\[
\left(x-x_1\right)\left(x-x_2\right) \ldots\left(x-x_{\mu^{\prime}}\right) .
\]

En désignant le quotient par \(R\), on aura
\[
R=A\left(x-x_{\mu^{\prime}+1}\right)\left(x-x_{\mu^{\prime}+2}\right) \cdots\left(x-x_\mu\right) .
\]

Donc les \(\mu-\mu^{\prime}\) quantités \(x_{\mu^{\prime}+1}, x_{\mu^{\prime}+2}, \ldots x_\mu\), seront les racines d'une équation, \(R=0\), du degré \(\mu-\mu^{\prime}\), dont tous les coefficiens sont exprimés rationnellement par les quantités \(x_1, x_2, x_3, \ldots x_{\mu^{\prime}}, \sqrt{\varphi x_1}, \sqrt{\varphi x_2}, \ldots\) \(\sqrt{\varphi x_{\mu^{\prime}}}\)
Faisons
\[
\begin{gathered}
\varepsilon_1=\varepsilon_2=\varepsilon_3=\cdots=\varepsilon_{\mu_1}=1 \\
\varepsilon_{\mu_1+1}=\varepsilon_{\mu_1+2}=\cdots=\varepsilon_{\mu^{\prime}}=-1 \\
x_{\mu_1+1}=x_1^{\prime}, \quad x_{\mu_1+2}=x_2^{\prime}, \ldots x_{\mu^{\prime}}=x_{\mu_s}^{\prime}, \\
x_{\mu^{\prime}+1}=y_1, \quad x_{\mu^{\prime}+2}=y_2, \ldots x_\mu=y_{\nu^{\prime}},
\end{gathered}
\]
on aura, en désignant par \(\psi(x)\) la fonction \(\int \frac{r d x}{\sqrt{\varphi x}}\),
\[
\left\{\begin{aligned}
\psi x_1+\psi x_2+\cdots+\psi x_{\mu_1}-\psi x_1^{\prime}-\psi x_2^{\prime}-\cdots-\psi x_{\mu_2}{ }^{\prime} & \cdots \\
& =v-\varepsilon_{\mu^{\prime}+1} \psi y_1-\varepsilon_{\mu^{\prime}+8} \psi y_2-\varepsilon_{\mu^{\prime}+3} \psi y_3-\cdots-\varepsilon_\mu \psi y_{\nu^{\prime}},
\end{aligned}\right.
\]
où \(v\) est une expression algébrique et logarithmique. Les quantités \(x_1, x_2\),
%454
\(\ldots x_{\mu_1} ; x_1{ }^{\prime}, x_2{ }^{\prime}, \ldots x_{\mu_2}{ }^{\prime}\) sont des quantités variables quelconques, et \(y_1, y_2\), .. \(y_{v^{\prime}}\) seront déterminables à l'aide d'une équation du degré \(v^{\prime}\).

Maintenant nous verrons qu'on pourra toujours rendre \(\boldsymbol{\nu}^{\prime}\) indépendant du nombre \(\mu_1+\mu_2\) des fonctions données. En effet, cherchons la plus petite valeur de \(\nu^{\prime}\). En supposant indéterminées toutes les quantités \(a_0, a_1, \ldots c_0\), \(c_1, \ldots\), il est clair que " \("\) sera égal à l'un des deux nombres \(2 n+\nu_1\) et \(2 m+\nu_2, \nu_1\) et \(\nu_2\) représentant les degrés des fonctions \(\varphi_1 x, \varphi_2 x\). Soit par exemple
\[
\mu=2 n+\nu_1
\]
on doit avoir en même temps
\[
\mu=\text { ou }>2 m+\nu_2,
\]
d'où, en ajoutant, on tire
\[
\mu=\mathrm{ou}>m+n+\frac{v_1+v_2}{2}
\]
or
done
\[
\nu^{\prime}=\mu-\mu^{\prime}=\mu-m-n-1
\]
\[
\nu^{\prime}=\text { ou }>\frac{v_1+v_2}{2}-1
\]
ou bien, en désignant le degré de \(\varphi x\) par \(\nu\),
\[
v^{\prime}=\text { ou }>\frac{v}{2}-1 \text {. }
\]

On voit par la que la plus petite valeur de \(v^{\prime}\) est \(\frac{v-1}{2}\) ou \(\frac{v}{2}-1\), selon que \(v\) est impair ou pair. Donc cette valeur est indépendante du nombre \(\mu_1+\mu_2\) des fonctions données; elle est précisément la même que le nombre total des coefficiens \(\delta_0, \delta_1, \delta_2, \ldots\) dans le sixième théorème. On aura maintenant ce théorème:

Théorème VIII. Soit \(\psi x=\int \frac{r d x}{\sqrt{\varphi x}}\), où \(r\) est une fonction rationnelle quelconque de \(x\), et \(\varphi x\) une fonction entière du degré \(2 v-1\) ou \(2 v\), et soient \(x_1, x_2, \ldots x_{\mu_1}, x_1{ }^{\prime}, x_2{ }^{\prime}, \ldots x_{\mu_3}{ }^{\prime}\) des variables données. Cela posé, quel que soit le nombre \(\mu_1+\mu_2\) des variables, on pourra toujour's trouver, au moyen d’une équation algébrique, \(v-1\) quantités \(y_1, y_2, \ldots y_{v-1}\) telles que
\[
\left\{\begin{aligned}
\psi x_1+\psi x_2+\cdots+\psi x_{\mu_1} & -\psi x_1^{\prime}-\psi x_2^{\prime}-\cdots-\psi x_{\mu_3}^{\prime} \\
& =v+\varepsilon_1 \psi y_1+\varepsilon_2 \psi y_2+\cdots+\varepsilon_{v-1} \psi y_{v-1}
\end{aligned}\right.
\]
%455
\(v\) étant algébrique et logarithmique, et \(\varepsilon_1, \varepsilon_2, \ldots \varepsilon_{v-1}\) égaux à +1 ou \(\grave{a}-1\).

On pent ajouter que les fonctions \(y_1, y_2, \ldots y_{v-1}\) restent les mêmes, quelle que soit la forme de la fonction rationnelle \(r\), et que la fonction \(v\) ne change pas de valeur en ajoutant à \(r\) une fonction entière quelconque du degré \(\boldsymbol{\nu}-2\).
10.
Les équations (35) qui déterminent les quantités \(a_0, a_1, \ldots c_0, c_1, \ldots\) deviendront

Pour déterminer \(\varepsilon_1, \varepsilon_2, \ldots \varepsilon_{\nu-1}\), on aura les équations:
\[
\left\{\begin{array}{l}
\theta y_1 \sqrt{\varphi_1 y_1}=-\varepsilon_1 \theta_1 y_1 \sqrt{\varphi_2 y_1} \\
\theta y_2 \sqrt{\varphi_1 y_2}=-\varepsilon_2 \theta_1 y_2 \sqrt{\varphi_2 y_2} \\
\ldots \ldots \ldots \ldots \ldots \\
\theta y_{v-1} \sqrt{\varphi_1 y_{v-1}}=-\varepsilon_{v-1} \theta_1 y_{v-1} \sqrt{\varphi_2 y_{v-1}} .
\end{array}\right.
\]

I ees fonctions \(y_1, y_2, \ldots y_{v-1}\) sont les racines de l'équation
\[
\frac{(\theta y)^2 \cdot \boldsymbol{\Upsilon}_1 y-\left(\theta_1 y\right)^2 \cdot \boldsymbol{\Upsilon}_2 y}{\left(y-x_1\right)\left(y-x_2\right) \cdots\left(y-x_{\mu_1}\right)\left(y-x_1\right)\left(y-x_2{ }^{\prime}\right) \cdots\left(y-x_{\left.\mu_2{ }^{\prime}\right)}\right.}=0 .
\]

Le degré de la fonction \(\theta y\) est \(n=\frac{\mu_1+\mu_2+\nu-1-\nu_1}{2}\), et celui de \(\theta_1 y\) est \(m=n+\nu_1-\nu\).
11.
La formule (39) a lieu si plusieurs des quantités \(x_1, x_2, \ldots x_1{ }^{\prime}, x_2{ }^{\prime}, \ldots\) sont égales entre elles, mais dans ce cas les équations (40) ne suffisent plus pour déterminer les quantités \(a_0, a_1, \ldots c_0, c_1, \ldots\); car si par exemple \(x_1=x_2=\cdots=x_k\), les \(k\) premières des équations \((40)\) deviendront identiques. Pour avoir les équations nécessaires dans ce cas, posons pour abréger
%456
\[
\theta x \cdot \sqrt{\varphi_1 x}-\theta_1 x \cdot \sqrt{\varphi_2 x}=\lambda x
\]

L'expression \(\frac{\lambda x}{\left(x-x_1\right)^k}\) doit avoir une valeur finie en faisant \(x=x_1\). On en déduit, d'après les principes du calcul différentiel, les \(k\) équations
\[
\lambda x_1=0, \lambda^{\prime} x_1=0, \lambda^{\prime \prime} x_1=0, \ldots \lambda^{(k-1)} x_1=0,
\]
et ce sont elles qu'il faut substituer à la place des équations
\[
\lambda x_1=0, \lambda x_2=0, \ldots \lambda x_k=0
\]
daus le cas où \(x_1=x_2=\cdots=x_k\).
%457
XXII.

SUR LE NOMBRE DES TRANSFORMATIONS DIFFÉRENTES QU'ON PEUT FAIRE SUBIR A UNE FONCTION ELLIPTIQUE PAR LA SUBSTITUTION D'UNE FONCTION RATIONNELLE DONT LE DEGRÉ EST UN NONBRE PREMIER DONNÉ.
Journal für die reine und angewandte Mathematik, herausgegeben von Crelle, Bd. 3, Berlin 1828.
Soit pour abréger
\[
\dot{A}^2=\left(1-x^2\right)\left(1-c^2 x^2\right) ; A^{\prime 2}=\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)
\]
et supposons qu'on satisfasse à l'équation différentielle
\[
\frac{d y}{d^{\prime}}=a \frac{d x}{d}
\]
en \(y\) substituant pour \(y\) une fonction rationnelle de \(x\) de la forme
\[
y=\frac{A_0+A_1 x+\cdots+A_{2 n+1} x^{2 n+1}}{B_0+B_1 x+\cdots+B_{2 n+1} x^{2 n+1}}
\]
où \(2 n+1\) est un nombre premier, et où l'un an moins des coefficiens \(A_{z n+1}\) et \(B_{2 n+1}\) est différent de zéro. En supposant, ce qui est permis, la fraction précédente réduite à sa plus simple expression, nous dirons que \(\frac{d y}{J^{\prime}}\) se transforme en \(a \frac{d x}{d}\) par la substitution d'une fonction du degré \(2 n+1\).

Il s'agit maintenant de trouver toutes les valeurs différentes de \(y\) qui répondent à la même valeur de \(2 n+1\). Si l'on fait
\[
\frac{\omega}{2}=\int_0^1 \frac{d x}{d} \text { et } \frac{\omega^{\prime}}{2}=\int_0^{\frac{1}{c}} \frac{d x}{d}
\]
%458
et qu'on désigne par \(\lambda \theta\) une fonction de \(\theta\), telle que
\[
d \theta=\frac{d x}{d} \text { pour } x=\lambda \theta
\]
et en outre
\[
\lambda(0)=0
\]
il suit immédiatement de ce que j’ai dit sur le problème général de la transformation des fonctions elliptiques dans le \(\mathrm{n}^0 138 \mathrm{du}\) journal d'astronomie de M. Schumacher*), qu'on satisfera de la manière la plus générale à l'équation \(\frac{d y}{I^{\prime}}=a \frac{d x}{d}\) dans le cas où \(B_{2 n+1}=0\), en prenant
\[
\left\{\begin{array}{l}
y=a \frac{x\left(1-\frac{x^2}{\lambda^2 \alpha}\right)\left(1-\frac{x^2}{\lambda^2 2 \alpha}\right) \cdots\left(1-\frac{x^2}{\lambda^2 n \alpha}\right)}{\left(1-c^2 \lambda^2 \alpha \cdot x^2\right)\left[1-c^2 \lambda^2(2 \alpha) \cdot x^2\right] \cdots\left[1-c^2 \lambda^2(n \alpha) \cdot x^2\right]} \\
c^{\prime}=c^{2 n+1}\left[\lambda\left(\frac{\omega}{2}+\alpha\right) \cdot \lambda\left(\frac{\omega}{2}+2 \alpha\right) \ldots \lambda\left(\frac{\omega}{2}+n \alpha\right)\right]^4 \\
a=\frac{c^{n+\frac{1}{2}}}{\sqrt{c^{\prime}}}[\lambda \alpha \cdot \lambda(2 \alpha) \ldots \lambda(n \alpha)]^2
\end{array}\right.
\]
où \(\alpha\) est une quantité de la forme
\[
\alpha=\frac{m \omega+m^{\prime} \omega^{\prime}}{2 n+1}
\]
\(m\) et \(m^{\prime}\) étant deux entiers. Maintenant, ayant trouvé cette solution, il suit encore de la formule (51) du mémoire cité que toutes les autres valeurs de \(y\) seront de la forme \(\frac{f^{\prime}+f y}{g^{\prime}+g y}, y\) étant donné par (5), \(f^{\prime}, f, g, g^{\prime}\) étant des quantités constantes qui doivent satisfaire à l'équation
(7)
\[
\begin{aligned}
\left(1+\frac{g+f}{g^{\prime}+f^{\prime}} x\right)\left(1+\frac{g-f}{g^{\prime}-f^{\prime}} x\right)\left(1+\frac{g+c^{\prime} f}{g^{\prime}+c^{\prime} f^{\prime}} x\right)\left(1+\frac{g-c^{\prime} f}{g^{\prime}-c^{\prime} f^{\prime}} x\right) & \\
& =\left(1-x^2\right)\left(1-c^{\prime 2} x^2\right)
\end{aligned}
\]

Cette équation donne vingt-quatre systèmes de valeurs différentes. On trouve ainsi qu'à chaque valeur de \(\alpha\) répondent 24 valeurs de \(y\) et douze valeurs du module \(c^{\prime}\). Mais comme les valeurs de \(y\) sont deux à deux égales, mais de signes contraires, nous n'en compterons que douze. Par la même raison nous réduirons le nombre des valeurs de \(c^{\prime}\) à six. Cela posé, si l'on fait pour abréger:
*) Mémoire XIX de cette édition.
%459
(8) \(\left\{\begin{array}{l}p=x\left(1-\frac{x^2}{\lambda^2 \alpha}\right) \ldots\left(1-\frac{x^2}{\lambda^2(n \alpha)}\right) ; v=\left(1-c^2 \lambda^2 \alpha \cdot x^2\right) \ldots\left[1-c^2 \lambda^2(n \alpha) x^2\right] \\ \varepsilon=c^{n+1}\left[\lambda\left(\frac{\omega}{2}+\alpha\right) \ldots \lambda\left(\frac{\omega}{2}+n \alpha\right)\right]^2 ; \delta=c^{n+\frac{1}{2}}[\lambda \alpha \cdot \lambda(2 \alpha) \ldots \lambda(n \alpha)]^2,\end{array}\right.\) on trouvera aisément ces valeurs correspondantes des trois quantités \(c^{\prime}, a, y\) : (9)
I. II.
III.
IV.
V.
VI.
\[
\begin{aligned}
& \text { (où } i=\sqrt{-1} \text { ). } \\
&
\end{aligned}
\]

On voit qu’a chaque valeur de \(c^{\prime}\) correspondent deux valeurs différentes de la fonction \(y\). Maintenant si l'on attribue aux nombres \(m\) et \(m^{\prime}\) des valeurs entières quelconques, on aura toutes les solutions possibles de notre problème. Or parmi ces solutions il n'y aura qu'un nombre fini qui soient différentes entre elles. Cherchons d'abord les solutions différentes qui répondent au premier cas, savoir \(c^{\prime}=\varepsilon^2\) et \(y=\frac{\delta}{\varepsilon} \cdot \frac{p}{v}\). Pour les trouver, soit \(\alpha^{\prime}\) une valeur de \(\alpha\) et désignons les valeurs correspondantes de \(y, p, v, \delta\), \& par \(y^{\prime}, p^{\prime}, v^{\prime}, \delta^{\prime}, \varepsilon^{\prime}\). Cela posé, il est évident que si \(y^{\prime}\) doit être égal à \(\pm y\), on doit avoir
\[
p^{\prime}=p, v^{\prime}=v, \frac{\delta^{\prime}}{\varepsilon^{\prime}}= \pm \frac{\delta}{\varepsilon} \text {. }
\]

Or en vertu de l'équation (8) on ne pourra avoir \(p^{\prime}=p\), al moins que les quantités \(\lambda^2 \alpha, \lambda^2(2 \alpha), \ldots \lambda^2(n \alpha)\) ne soient, quoique dans un ordre différent, égiales à celles-ci:
\[
\lambda^2 \alpha^{\prime}, \lambda^2\left(2 \alpha^{\prime}\right), \ldots \lambda^2\left(n \alpha^{\prime}\right)
\]

Soit done
\[
\lambda^2 \alpha^{\prime}=\lambda^2(\mu \alpha)
\]
où \(\mu\) est moindre que \(n\). On en tire \(\lambda \alpha^{\prime}= \pm \hat{\lambda}(\mu \alpha)\), d'où, en vertu dù théorème II du \(\mathrm{n}^0 138\) du journal d'astronomie,
%460
\[
\alpha^{\prime}=k \omega+k^{\prime} \omega^{\prime} \pm \mu \alpha
\]
où \(k\) et \(l^{\prime}\) désignent des nombres entiers quelconques. Cela donne
\[
\lambda^2\left(\mu^{\prime} \alpha^{\prime}\right)=\lambda^2\left(\mu^{\prime}, u \alpha\right)
\]
et puisque \(\lambda[\theta+(2 n+1) \alpha]=\lambda \theta\), et que \(2 n+1\) est un nombre premier, il s'ensuit que
\[
p^{\prime}=p, v^{\prime}=v, \delta^{\prime}=\delta, \varepsilon^{\prime}=\varepsilon .
\]

Donc les solutions qui répondent à \(\alpha\) et \(\alpha^{\prime}\) sont précisément égales entre elles.

Soit d'abord \(m^{\prime}=0\) en sorte que \(\alpha=\frac{m \omega}{2 n+1}\). Si l'on fait \(k^{\prime}=0\), et qu'on détermine les nombres \(k\) et "u de manière à satisfaire à l'équation
\[
k \pm \frac{\mu m}{2 n+1}=\frac{1}{2 n+1}
\]
on aura
\[
\alpha^{\prime}=\frac{\omega}{2 n+1} .
\]

On voit par là que la solution qui répond à \(\alpha=\frac{m \omega}{2 n+1}\) est la même que celle qui répond à \(\alpha=\frac{\omega}{2 n+1}\), quel que soit \(m\).
Supposons maintenant \(m^{\prime}\) différent de zéro, on aura
\[
\alpha^{\prime}=k \omega+k^{\prime} \omega^{\prime} \pm \frac{m_\mu \omega+m^{\prime} \mu \omega^{\prime}}{2 n+1} .
\]

Si l'on détermine les deux nombres entiers " \("\) et \(k^{\prime}\). par l'équation
et \(k\) par celle-ci :
\[
k^{\prime} \pm \frac{m^{\prime} \mu}{2 n+1}=\frac{1}{2 n+1}
\]
\[
k \pm \frac{\mu m}{2 n+1}=\frac{\nu}{2 n+1}
\]
où \(v\) est positif et moindre que \(2 n+1\), on aura
\[
\alpha^{\prime}=\frac{\omega^{\prime}+v \omega}{2 n+1}
\]

On voit par là, que pour obtenir toutes les valenrs différentes de \(v\) et \(p\), il suffit de donner à \(\alpha\) les valeurs:
\[
\frac{\omega}{2 n+1}, \frac{\omega^{\prime}}{2 n+1}, \frac{\omega^{\prime}+\omega}{2 n+1}, \frac{\omega^{\prime}+2 \omega}{2 n+1}, \ldots \frac{\omega^{\prime}+2 n \omega}{2 n+1} .
\]
%461
Or toutes les solutions ainsi obtenues seront effectivement différentes entre elles; car si l'on attribue ì \(\alpha\) et à \(\alpha^{\prime}\) deux valeurs différentes de la série (10), il est clair qu'on ne pourra satisfaire à l'équation
\[
\alpha^{\prime}=k \omega+k^{\prime} \omega^{\prime} \pm, 1 \alpha
\]
qui exprime une condition nécessaire de l'identité des deux solutions qui répondent ì \(\alpha\) et à \(\alpha^{\prime}\).

Done le nombre des solutions différentes qui répondent à \(y=\frac{\delta}{\varepsilon} \cdot \frac{p}{v}\) est \(2 n+2\). Maintenant si l'on attribue à \(\alpha\) toutes les valeurs (10), les formnles (9) donneront \(12(2 n+2)\) solutions, et il est évident que toutes les \(12(2 n+2)\) valeurs correspondantes de \(y\) seront nécessairement différentes entre elles. Cependant il ne répond à ces \(24(n+1)\) solutions que \(12(n+1)\) valeurs du module. Il faut observer que la conclusion précédente n'a pas lieu pour le cas particulier où \(n=0\). En effet, dans ce cas y n'aura que douze valeurs différentes, car les deux valeurs \(\alpha=\omega, \alpha=\omega^{\prime}\), auxquelles dans ce cas se réduisent les quantités (10), domneront pour \(y^{\circ}\) une même valeur, savoir \(y=x\). Il faut remarquer également que le module \(c\) ne doit pas avoir les valeurs zéro ou un. Dans ces cas la fonction \(\int \frac{d x}{d}\) n'est plus une fonction elliptique, mais circulaire ou logarithmique.

On pourra mettre les huit dernières valeurs de \(y(9)\) sous une antre forme qui est à quelques égards plus élégante. En effet on pourra démontrer qu'on a
\[
\left\{\begin{array}{r}
v-\delta p=(1-x \cdot \sqrt{c})\left(1-2 k_1 x \sqrt{c}+c \cdot x^2\right)\left(1-2 k_z x \sqrt{c}+c x^2\right) \ldots \\
\ldots\left(1-2 k_n x \sqrt{c}+c x^2\right) \\
v-\delta p \sqrt{-1}=(1-x \sqrt{-c})\left(1-2 k_1^{\prime} x \sqrt{-c}-c x^2\right)\left(1-2 k_z^{\prime} x \sqrt{-c}-c x^2\right) \ldots \\
\ldots\left(1-2 k_n^{\prime} x \sqrt{-c}-c x^2\right)
\end{array}\right.
\]

En changeant le signe de \(x\), on aura des expressions semblables pour \(v+\delta p\) et \(v+\delta p \sqrt{-1}\). Les quantités \(k_1, k_z, k_3, \ldots k_n\) sont domnées par la formule
\[
k_\mu=\frac{\lambda(\mu \alpha)}{1-c \cdot \lambda^2(\mu \alpha)}
\]

On a pareillement
\[
k_\mu^{\prime}=\frac{M(\mu \alpha)}{1+c \cdot \lambda^2(\mu \alpha)}
\]
\(\Delta(\theta)\) désignant la quantité
%462
\[
\frac{d \lambda \theta}{d \theta}= \pm \sqrt{\left(1-\lambda^2 \theta\right)\left(1-c^2 \lambda^2 \theta\right)}
\]

Donc le numérateur et le dénominateur de la fraction (3), qui exprime la valeur de \(y\), se trouvent décomposés en facteurs dans tous les cas.

Dans le cas où le module \(c\) est moindre que l'unité, les équations (9), nous font voir que généralement les modules des transformées sont imaginaires, excepté ceux qui répondent à
\[
\alpha=\frac{\omega}{2 n+1} \text { et à } \alpha=\frac{\omega^{\prime}-\omega}{2 n+1},
\]
et en même temps à l'une des solutions I, II, III, IV. Il n'y a done que huit modules réels. Si l'on ne désire que ceux qui sont moindres que l'unité, on n'en aura que quatre. Cependant il pourra arriver, \(c\) ayant des valeurs particulières, qu'un plus grand nombre des modules transformés soient réels. Je ferai voir dans une autre occasion, comment on pourra trouver toutes ces valeurs particulières. Pour le moment je ferai connaître une manière d'exprimer toutes les valeurs du module \(c^{\prime}\) à l'aide de produits infinis.

Si \(c\) est moindre que l'unité, \(\omega\) sera une quantité réelle, \(\omega^{\prime}\) au contraire sera imaginaire; car on a
\[
\omega^{\prime}=2 \cdot \int_0^{\frac{1}{c}} \frac{d x}{\Delta}=\omega+2 \sqrt{-1} \cdot \int_1^{\frac{1}{c}} \frac{d x}{\sqrt{\left(x^2-1\right)\left(1-c^2 x^2\right)}},
\]
c'est-ì-dire que, si l'on fait
\[
\frac{\omega}{2}=\int_0^1 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-b^2 x^2\right)}}
\]
où
\[
b=\sqrt{1-c^z}
\]
on aura
\[
\omega^{\prime}=\omega+\widetilde{\omega} \sqrt{-1}
\]
\(\widetilde{\omega}\) étant une quantité réelle comme \(\omega\). Cela posé, les \(2 n+2\) valeurs de \(\alpha\) deviendront:
\[
\frac{\omega}{2 n+1}, \frac{\sigma i+\omega}{2 n+1}, \ldots \frac{\varpi i+(2 n+1) \omega}{2 n+1}
\]

A la place de ces valeurs on pourra anssi mettre celles-ci:
\[
\frac{\omega}{2 n+1}, \frac{\varpi i}{2 n+1}, \frac{\sigma i+2 \omega}{2 n+1}, \frac{\omega i+4 \omega}{2 n+1}, \ldots \frac{\sigma i+4 n \omega}{2 n+1},
\]
où \(i=\sqrt{-1}\).
%463
En faisant \(c=1, e=\frac{c}{b}\) (formule 189 t. II, p. 177*), et mettant ensuite \(b \omega\) et \(b \widetilde{\omega}\) au lieu de \(\omega\) et \(\widetilde{\omega}\), et enfin \(\alpha=b\left(\frac{\omega}{2}-\theta\right)\), on trouvera \(\lambda \theta=f \alpha\), et la formule donnera après quelques réductions faciles,
(12) \(\lambda \theta=\frac{2}{\sqrt{c}} \sqrt{q} \cdot \sin \left(\frac{\pi}{\omega} \theta\right) \cdot \frac{\left[1-2 q^2 \cos \left(\frac{2 \pi}{\omega} \theta\right)+q^4\right]\left[1-2 q^4 \cos \left(\frac{2 \pi}{\omega} \theta\right)+q^8\right] \cdots}{\left[1-2 q \cdot \cos \left(\frac{2 \pi}{\omega} \theta\right)+q^2\right]\left[1-2 q^3 \cos \left(\frac{2 \pi}{\omega} \theta\right)+q^6\right] \ldots}\), où \(q=e^{-\frac{\widetilde{\omega}}{\omega} \pi}\).

Pour calculer la valeur de \(\varepsilon\) d'après l'équation (8), il suffit de chercher les valeurs de \(\lambda\left(\frac{\omega}{2}+\alpha\right), \lambda\left(\frac{\omega}{2}+2 \alpha\right), \ldots \lambda\left(\frac{\omega}{2}+n \alpha\right)\) an moyen de la formule précédente, et de les multiplier ensuite entre elles. Si l'on fait d'abord \(\alpha=\frac{\omega}{2 n+1}\) on trouvera aisément
\[
\varepsilon=2 \cdot \sqrt[4]{q^{2 n+1}} \cdot\left(\frac{1+q^{2(2 n+1)}}{1+q^{2 n+1}} \cdot \frac{1+q^{4(2 n+1)}}{1+q^{3(2 n+1)}} \cdots\right)^2 .
\]

De même si l'on fait
\[
\alpha=\frac{\tilde{\omega} i+2 \mu \omega}{2 n+1}
\]
et si l'on pose pour abréger
\[
\delta_1=\cos \frac{2 \pi}{2 n+1}+\sqrt{-1} \cdot \sin \frac{2 \pi}{2 n+1}
\]
on parviendra à cette formule:
(14) \(\varepsilon=2 \cdot \sqrt[4]{\delta_1^\mu \cdot q^{\frac{1}{2 n+1}}} \cdot\left\{\frac{1+\left(\delta_1^\mu \cdot q^{\frac{1}{2 n+1}}\right)^2}{1+\delta_1^\mu \cdot q^{\frac{1}{2 n+1}}} \cdot \frac{1+\left(\delta_1^\mu \cdot q^{\frac{1}{2 n+1}}\right)^4}{1+\left(\delta_1^\mu \cdot q^{\frac{1}{2 n+1}}\right)^3} \cdots\right\}^2\).

Donc on voit que pour avoir toutes les valeurs de \(\varepsilon\), il suffit de substituer dans l'expression
\[
2 \cdot \sqrt[4]{q} \cdot\left(\frac{1+q^2}{1+q} \cdot \frac{1+q^4}{1+q^3} \cdots \frac{1+q^{2 m}}{1+q^{2 m-1}} \cdots\right)^2
\]
au lieu de \(q\), les \(2 n+2\) valeurs \(q^{2 n+1}, q^{\frac{1}{2 n+1}}, \delta_1 q^{\frac{1}{2 n+1}}, \delta_1^2 q^{\frac{1}{2 n+1}}, \ldots \delta_1^{2 n} q^{\frac{1}{2 n+1}}\), \(1, \delta_1, \delta_1^2, \ldots\) étant les racines de l'équation \(\delta^{2 n+1}=1\). Deux seulement
") Voyez p. 347 de cette édition.
%464
des valeurs de \(\varepsilon\) sont réelles, savoir celles qui répondent à la substitution de \(q^{2 n+1}\) et \(q^{\frac{1}{2 n+1}}\), c'est-à-dire à
\[
\alpha=\frac{\omega}{2 n+1} \text { et } \alpha=\frac{\widetilde{\omega} i}{2 n+1} \text {. }
\]

Il suit encore des formules précédentes que toutes les \(2 n+2\) valeurs de \(\varepsilon\) sont nécessairement différeutes entre elles, excepté peut-être pour certaines valeurs particulières du module \(c\). Ayant trouvé les valeurs de \(\varepsilon\), on auraa celles du module \(c^{\prime}\) à l'aide des équations (9). Il est à remarquer que l'expression (15) est précisément la valeur de \(\sqrt{c}\), comme on peut le voir en faisant \(\theta=\frac{\omega}{2}\). Dans le cas où l'on suppose \(y\) de la forme \(\frac{\delta}{\varepsilon} \cdot \frac{p}{v}\), le module \(c^{\prime}\) sera égal à \(\varepsilon^2\) d'après les formules \((9)\), donc \(\sqrt{c^{\prime}}=\varepsilon\). Par conséquent dans ce cas le module \(c\) se changera successivement dans toutes les valeurs du module \(c^{\prime}\), si l'on remplace dans la formule
\[
\sqrt{c}=2 \cdot \sqrt[4]{q} \cdot\left(\frac{1+q^2}{1+q} \cdot \frac{1+q^4}{1+q^3} \cdots\right)^2
\]
\(q \operatorname{par} q^{2 n+1}, \sqrt[2 n+1]{q}, \delta_1^{2 n+1} \sqrt{q}, \delta_1^{2 n+1} \sqrt{q}, \ldots \delta_1^{2 n} \sqrt{q}\)
Ce théorème s'accorde parfaitement avec le théorème énoncé par M. Jacobi dans le tome III. p. 193 de ce journal. Seulement à l'endroit cité la fonction de \(q\), qui exprime la valeur de \(\sqrt{c}\), est présentée sous une autre forme. Donc on trouverait immédiatement le théorème de ce géomètre, si l'on pouvait parvenir à démontrer l'identité des deux fonctions
\[
\sqrt[4]{q} \cdot\left(\frac{1+q^2}{1+q} \cdot \frac{1+q^4}{1+q^3} \cdots\right)^2=\frac{q^{\frac{1}{4}}+q^{\frac{9}{4}}+q^{\frac{25}{4}}+\cdots}{1+2 q+2 q^4+2 q^9+\cdots}
\]

On pourra encore démontrer qu'on aura les \(2 n+2\) valeurs de \(c^{\prime}\), en mettant dans la formule
\[
\sqrt[4]{c}=\frac{1-r}{1+r} \cdot \frac{1-r^3}{1+r^3} \cdot \frac{1-r^5}{1+r^5} \cdots
\]
les quantités \(r^{2 n+1}, \sqrt{2 n+1}, \delta_1^{\underline{2}+1} \sqrt{r}, \delta_1^{2 n+1} \sqrt{r}, \ldots \delta_1^{2 n} \sqrt{r}\), , au lieu de \(r\), la lettre \(r\) désignant la quantité \(e^{-\frac{\omega}{\sigma \pi} \pi}\). Cette quantité est liée à \(q\) par l'équation
\[
\log \left(\frac{1}{r}\right) \cdot \log \left(\frac{1}{q}\right)=\pi^2
\]
%465
Pour avoir la valeur du coefficient \(a\) il faut connaitre celle de \(\delta(8)\). Or on pourra la déduire aisément de la formule (12), en y faisant \(\theta=\alpha\), \(2 \alpha, \ldots n \alpha\). On trouve de cette manière que les valeurs de \(\delta\) qui répondent respectivement à
\[
\alpha=\frac{\omega}{2 n+1}, \frac{\varpi i}{2 n+1}, \frac{\tilde{\omega} i+2 \omega}{2 n+1}, \ldots \frac{\varpi i+4 n \omega}{2 n+1}
\]
sont égrales à celles que prend l'expression
\[
\delta=2 \frac{\pi}{\omega} \sqrt[4]{q}\left(\frac{1-q^2}{1-q} \cdot \frac{1-q^4}{1-q^3} \cdots\right)^2
\]
en y substituant au lieu de \(q\) les valeurs \(q^{2 n+1}, \sqrt[2 n+1]{q}, \delta_1^{2 n+1} \sqrt{q}, \delta_1^{2 n+1} \sqrt{q}, \ldots \delta_1^{2 n} \sqrt{q}\).
%466
XXIII.

THÉORÈME GÉNÉRAL SUR LA TRANSFORMATION DES FONCTIONS ELLIPTIQUES DE LA SLCONDE ET DE LA TROISIÈME ESPÈCE.
Journal für die reine und angewandte Mathematik, heransgegeben von Crelle, Bd. 3, Berlin 1828.
Si une intégrale algébrique \(f(y, x)=0\) satisfait à l'équation
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)}}=a \cdot \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}
\]
on anra toujours
\[
\int \frac{A+B x^2}{1-\frac{x^2}{n^2}} \cdot \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}=\int \frac{A^{\prime}+B^{\prime} y^2}{1-\frac{y^2}{m^2}} \cdot \frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)}}+k \log p
\]
où \(A, B, n\) sont des quantités données, \(A^{\prime}, B^{\prime}, m, k\) des quantités constantes, fonctions des premières, et \(p\) une certaine fonction algébrique de \(y\) et \(x\). Il est très remarquable que les paramètres \(m\) et \(n\) sont liés entre eux par la même équation que \(y\) et \(x\), savoir \(f(m, n)=0\). Dans le cas où \(n\) est infini, le premier membre deviendra seulement une fonction de la seconde espèce, et dans ce cas on pourra démontrer que
(a) \(\int\left(A+B x^2\right) \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}=\int\left(A^{\prime}+B^{\prime} y^2\right) \frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)}}+v\), où \(v\) est une fonction algébrique des variables \(x\) et \(y\).

Au reste il est aisé de démontrer la formule \((a)\). Il n'y a qu’à différentier l'équation
\[
a \int \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}=\int \frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)}}
\]
par rapport au module \(c\). Je me réserve de donner dans un autre mémoire des développemens plus étendus sur le théorème ci-dessus.
%467
XXIV.

NOTE SUR QUELQUES FORMULES ELLIPTIQUES.

Journal für die reine und angewandte Mathematik, herausgegeben von Crelle, 13d. 4, Berlin 1829.

Dans le second tome de ce journal j'ai donné plusieurs formules poul le développement des fonctions \(\varphi \alpha, f \alpha, F \alpha\), dans le cas où les modules \(e\) et \(c\) sont réels. Il sera facile d'en déduire des formules analognes poir le cas où \(e^2\) est une quantité négative, comme nous allons voir.
Soit pour plus de simplicité \(c=1\). Cela posé, si l'on fait
\[
\lambda \alpha=f\left(\frac{\omega}{2}-b \alpha\right) \text {, où } b=\frac{1}{\sqrt{1+e^2}},
\]
on trouvera aisément, par la définition de la fonction \(f\), qu'on a
\[
\alpha=\int_0 \frac{d x}{V^{\prime}\left(1-x^2\right)\left(1-e^2 x^2\right)},
\]
en faisant
\[
x=i \alpha \text { et } c=\frac{e}{\sqrt{1+e^2}} .
\]

Donc le module \(c\) est plus petit que l'unité, et comme on a \(b=\sqrt{1-c^y}, b\) sera son complément.
On trouvera aussi.
\[
\left\{\begin{array}{l}
\frac{\theta}{2}=b \int_0^1 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}=b \int_0^{\frac{\pi}{2}} \frac{d \theta}{\sqrt{1-c^2 \sin ^2 \theta}}, \\
\frac{\pi}{2}=b \int_0^1 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-b^2 x^2\right)}}=b \int_0^{\frac{\pi}{3}} \frac{d \theta}{\sqrt{1-b^2 \sin ^2 \theta}} .
\end{array}\right.
\]
%468
Si l'on fait
\[
\dot{\lambda}^{\prime} \alpha=\sqrt{1-\lambda^2 \alpha}, \lambda^{\prime \prime} \alpha=\sqrt{1-c^2 \lambda^2 \alpha}
\]
on aura encore
\[
\lambda^{\prime} \alpha=\varphi\left(\frac{\omega}{2}-b \alpha\right), \lambda^{\prime \prime} \alpha=b F\left(\frac{\omega}{2}-b \alpha\right)
\]
et en faisant
\[
\frac{\omega^{\prime}}{2}=\int_0^{\frac{\pi}{2}} \frac{d \theta}{\sqrt{1-c^2 \sin ^2 \theta}}, \frac{\widetilde{\sigma}^{\prime}}{2}=\int_0^{\frac{\pi}{2}} \frac{d \theta}{\sqrt{1-b^2 \sin ^2 \theta}},
\]
on a, en vertu de (3)
\[
\frac{\omega^{\prime}}{\widetilde{\omega}^{\prime}}=\frac{\omega}{\widetilde{\omega}}, \omega=b \omega^{\prime}, \widetilde{\omega}=b \bar{\omega}^{\prime}
\]

Considérons maintenant d'abord la formule (185) p. 176**), qui doine la valeur de \(f \alpha\). Pour en déduire celle de la fonction \(\lambda \alpha\), il suffit de mettre \(\frac{\omega}{2}-b \alpha\) à la place de \(\alpha\). Faisons done \(\alpha=\frac{\omega}{2}-b \theta\), et posons pour abréger,
\[
\varrho=e^{-\frac{\theta t}{\bar{\omega}^{\prime}}}, r=e^{-\frac{\omega^{\prime}}{\bar{\omega}^{\prime}} \pi}:
\]
alors la formule (185) donne sur le champ
où
\[
i \boldsymbol{\theta}=A \cdot \prod_0^{\infty} \frac{\left(1-r^{2 m+1}\right)^2-\left(\varrho^m-\varrho^{-1} r^{m+1}\right)^2}{\left(1+r^{2 m+1}\right)^2+\left(\varrho^{r^m}-\varrho^{-1} \vartheta^{m+1}\right)^2},
\]
\[
A^{\frac{1}{2}}=\frac{(1+r)\left(1+r^3\right) \cdots}{(1-r)\left(1-r^3\right)}
\]

Or. on a
\[
\left(1-r^{2 m+1}\right)^2-\left(\varrho r^m-\varrho^{-1} r^{m+1}\right)^2=\left(1-\varrho^2 r^{2 m}\right)\left(1-\varrho^{-2} r^{2 m+2}\right)
\]
et
\[
\left(1+r^{2 m+1}\right)^2+\left(\rho^m-\varrho^{-1} r^{m+1}\right)^2=\left(1+\varrho^2 r^{2 m}\right)\left(1+\varrho^{-2} r^{2 m+2}\right),
\]
par conséquent l'expression de \(\boldsymbol{\lambda} \theta\) deviendra, en développant,
\[
\lambda \theta=A \cdot \frac{1-\varrho^2}{1+\varrho^2} \cdot \frac{1-\varrho^2 r^2}{1+\varrho^2 r^2} \cdot \frac{1-\varrho^{-2} r^2}{1+\varrho^{-2} r^2} \cdot \frac{1-\varrho^2 r^4}{1+\varrho^2 r^4} \cdot \frac{1-\varrho^{-2} r^4}{1+\varrho^{-2} r^4} \ldots
\]

Avec la même facilité on tirera des deux formules (184) et (186), en y faisant \(\alpha=\frac{\omega}{2}-b \theta\),
*) P. 346 de cette édition.
%469
(10) \(\quad \lambda^{\prime} \theta=A^{\prime} \cdot \frac{2 \varrho}{1+\varrho^2} \cdot\left(1-\varrho^2 r\right)\left(1-\varrho^{-2} r\right)\left(1-\varrho^2 r^3\right)\left(1-\varrho^{-2} r^3\right)\left(1+\varrho^{-2} r^2\right)\left(1+\varrho^2 r^4\right)\left(1+\varrho^{-2} r^4\right) \ldots\)
(11) \(\quad \lambda^{\prime \prime} \theta=A^{\prime \prime} \cdot \frac{2 \varrho}{1+\varrho^2} \cdot \frac{\left(1+\varrho^2 r\right)\left(1+\varrho^{-9} r\right)\left(1+\varrho^2 r^3\right)\left(1+\varrho^{-2} r^3\right) \ldots}{\left(1+\varrho^2 r^2\right)\left(1+\varrho^{-2} r^2\right)\left(1+\varrho^2 r^4\right)\left(1+\varrho^{-2} r^4\right) \ldots}\),
où \(A^{\prime}, A^{\prime \prime}\) sont donnés par les formules
\[
\begin{aligned}
\sqrt{A^{\prime}} & =\frac{\left(1+r^2\right)\left(1+r^4\right)\left(1+r^6\right) \ldots}{(1-r)\left(1-r^3\right)\left(1-r^5\right) \ldots} \\
\sqrt{A^{\prime \prime}} & =\frac{\left(1+r^2\right)\left(1+r^4\right)\left(1+r^6\right) \ldots}{(1+r)\left(1+r^3\right)\left(1+r^5\right) \ldots}
\end{aligned}
\]

On pourra trouver pour \(A, A^{\prime}, A^{\prime \prime}\) d'autres expressions beaucoup plus simples et qui donneront des formules très remarquables.
Si l'on fait, dans la formule \((9), \theta=\frac{\omega^{\prime}}{2}+\frac{\widetilde{\sigma}^{\prime}}{2} i\), on aura .
\[
\lambda \theta=f\left(\frac{\widetilde{\omega}}{2} i\right)=\frac{\sqrt{1+e^2}}{e}=\frac{1}{c}, \text { et } \rho^2=e^{-r i-\frac{\omega^{\prime}}{\widetilde{\omega}}}=-r
\]
donc en substituant,
\[
\frac{1}{c}=A\left(\frac{1+r}{1-r} \cdot \frac{1+r^3}{1-r^3} \cdot \frac{1+r^5}{1-r^5} \cdots\right)^2
\]
c'est-à-dire, en vertu de la formule \(\left(8^{\prime}\right)\),
\[
\frac{1}{6}=A^2
\]
d'où
\[
A=\frac{1}{\sqrt{c}} \text {. }
\]

En faisant, dans l'expression de \(\lambda^{\prime} \theta, \theta=\frac{\omega^{\prime}}{2}+\frac{\sigma^{\prime}}{2} i\), on a
\[
\lambda^{\prime} \theta=-\varphi\left(\frac{\tilde{\omega} i}{2}\right)=-\frac{i}{e}=-i \frac{\sqrt{1-c^2}}{c}, \text { et } \rho^2=-r
\]
donc
\[
i \cdot \frac{b}{c}=4 A^{\prime} i \sqrt{r}\left(\frac{1+r^2}{1-r} \cdot \frac{1+r^4}{1-r^3} \cdots\right)^2
\]
d'où l'on tire, en vertu de l'équation (12),
\[
A^{\prime}=\frac{1}{2 \sqrt{r}} \cdot \sqrt{\frac{b}{c}} .
\]
%470
Enfin si l'on fait dans la formule (11) \(\theta=\frac{\omega^{\prime}}{2}\), on trouvera
done
\[
\hat{\lambda}^{\prime \prime} \theta=\sqrt{1-c^2}=b, \rho^2=r
\]
\[
\zeta=4 A^{\prime \prime} \sqrt{r}\left(\frac{1+r^2}{1+r} \cdot \frac{1+r^4}{1+r^3} \cdots\right)^2=4 A^{\prime \prime} \sqrt{r} \cdot A^{\prime \prime}
\]
et par suite
\[
A^{\prime \prime}=\frac{\sqrt{b}}{2 \sqrt{r}}
\]

En comparant ces valeurs de \(A, A^{\prime}, A^{\prime \prime}\) à celles données plus hant, on en déduira ces formules:
\[
\begin{gathered}
\sqrt[4]{c}=\frac{1-r}{1+r} \cdot \frac{1-r^3}{1+r^3} \cdot \frac{1-r^5}{1+r^5} \cdots, \\
\sqrt[4]{\frac{4}{c}}=\sqrt{2} \cdot \sqrt[8]{r} \cdot \frac{1+r^2}{1-r} \cdot \frac{1+r^4}{1-r^3} \cdot \frac{1+r^6}{1-r^5} \ldots, \\
\sqrt[4]{b}=\sqrt{2} \cdot \sqrt[8]{r} \cdot \frac{1+r^2}{1+r} \cdot \frac{1+r^4}{1+r^3} \cdot \frac{1+r^6}{1+r^5} \cdots,
\end{gathered}
\]
dont l'une est une suite des deux autres.
Si dans l'expression de \(\lambda \boldsymbol{\theta}\) on fait \(\boldsymbol{\theta}=0\), après avoir divisé les deux membres par
\[
1-\varrho^2=2 \frac{\theta \pi}{\sigma^{\prime}}+\cdots,
\]
et qu'on remarque que \(\frac{\lambda \theta}{\theta}=1\), pour \(\theta=0\), on obtiendra
\[
\sqrt[4]{c} \cdot \sqrt{\frac{\sigma^{\prime}}{x}}=\frac{\left(1-r^2\right)\left(1-r^4\right)\left(1-r^6\right) \cdots}{\left(1+r^2\right)\left(1+r^4\right)\left(1+r^6\right) \cdots} .
\]

De la on tire, en substituant la valeur de \(\sqrt[4]{c}\) :
\[
\begin{aligned}
\sqrt{\frac{\sigma^{\prime}}{\pi}}= & \frac{(1+r)\left(1-r^2\right)\left(1+r^3\right)\left(1-r^4\right) \ldots}{(1-r)\left(1+r^2\right)\left(1-r^3\right)\left(1+r^4\right) \ldots} \\
= & (1+r)^2\left(1+r^3\right)^2\left(1+r^5\right)^2 \ldots \times\left(1-r^2\right)\left(1-r^4\right)\left(1-r^6\right) \ldots \\
= & {\left[(1+r)\left(1+r^3\right)\left(1+r^5\right) \ldots\right]^2 \cdot(1+r)\left(1+r^2\right)\left(1+r^3\right) \ldots } \\
& \quad \times(1-r)\left(1-r^2\right)\left(1-r^3\right) \ldots
\end{aligned}
\]

A l'aide des formules \((16,14,18)\) il est facile de trouver l'expression des produits infinis
%471
\[
(1+r)\left(1+r^2\right)\left(1+r^3\right) \ldots,(1-r)\left(1-r^2\right)\left(1-r^3\right) \ldots
\]

En effet, si l'on fait pour abréger
\[
\left\{\begin{array}{l}
P=(1+r)\left(1+r^3\right)\left(1+r^5\right) \ldots \\
P^{\prime}=\left(1+r^2\right)\left(1+r^4\right)\left(1+r^6\right) \ldots,
\end{array}\right.
\]
et qu'on ait égard à la formule
\[
\frac{1}{(1-r)\left(1-r^3\right)\left(1-r^5\right) \ldots}=(1+r)\left(1+r^2\right)\left(1+r^3\right) \ldots=P \cdot P^{\prime}
\]
les formules \((14,16)\) domneront sur le champ
\[
\sqrt[4]{c}=\frac{1}{P^2 \cdot P^{\prime}}, \quad \sqrt[4]{b}=\sqrt{2} \cdot \sqrt[8]{r} \cdot \frac{P^{\prime}}{P},
\]
d'où l'on tire
\[
P=\sqrt[6]{2} \cdot \sqrt{\frac{24}{b^2 c^2}}, \quad P^{\prime}=\frac{\sqrt[6]{b} \cdot \sqrt{r}}{3} \cdot \frac{1}{\sqrt{2} \cdot \sqrt{c}} \cdot \frac{1}{\sqrt{r}} .
\]

On comnait donc les produits \(P\) et \(P^{\prime}\). En les multipliant entre eux, il viendra
\[
(1+r)\left(1+r^2\right)\left(1+r^3\right)\left(1+r^4\right) \cdots=\frac{\sqrt[18]{b}}{\sqrt[6]{2 c} \cdot \sqrt{r}} .
\]

De même la formule (18) domne, en substituant les valeurs de \(P, P^{\prime}\),
\[
\sqrt{\frac{\widetilde{\sigma}^{\prime}}{\pi}}=P^3 \cdot P^{\prime} \cdot(1-r)\left(1-r^2\right)\left(1-r^3\right) \ldots
\]
et de là:
\[
(1-r)\left(1-r^2\right)\left(1-r^3\right) \ldots=\frac{\sqrt[12]{b} \cdot \sqrt{c}}{\sqrt{2} \cdot \sqrt{r}} \cdot \sqrt{\frac{\pi^{\prime}}{\pi}}
\]
formule due à M. Jacobi ('Tome III. p. 193, où ce géomètre en présente plusieurs autres très remarquables et très élégantes).

Des formules démontrées précédemment on pent aisément en tirer un grand nombre d'autres. En voici quelques unes des plus remarquables.
Si l'on fait pour abréger
\[
q=e^{-\frac{\omega^{\prime}}{\omega^{\prime}} \pi}
\]
on aura
%472
\[
\lambda\left(\frac{\omega^{\prime}}{\pi} x\right)=\frac{2}{\sqrt{c}} \cdot \sqrt[4]{q} \cdot \sin x \cdot \frac{1-2 q^2 \cos 2 x+q^4}{1-2 q \cos 2 x+q^2} \cdot \frac{1-2 q^4 \cos 2 x+q^8}{1-2 q^3 \cos 2 x+q^6} \ldots
\]
\[
\lambda^{\prime}\left(\frac{\omega^{\prime}}{x} x\right)=2 \sqrt{\frac{b}{c}} \cdot \sqrt[4]{q} \cdot \cos x \cdot \frac{1+2 q^2 \cos 2 x+q^4}{1-2 q \cos 2 x+q^2} \cdot \frac{1+2 q^4 \cos 2 x+q^8}{1-2 q^3 \cos 2 x+q^6} \ldots
\]
\[
\lambda^{\prime \prime}\left(\frac{\omega^{\prime}}{\pi} x\right)=\sqrt{b} \cdot \frac{1+2 q \cos 2 x+q^2}{1-2 q \cos 2 x+q^2} \cdot \frac{1+2 q^3 \cos 2 x+q^6}{1-2 q^3 \cos 2 x+q^6} \cdots
\]

Ces formules ont été déduites respectivement des formules \((11,10,9)\), en changeant \(c\) en \(b\), et en faisant ensuite
\[
\theta=\frac{\widetilde{\omega}^{\prime}}{2}+\frac{\omega^{\prime}}{2} \sqrt{-1}+\frac{\omega^{\prime}}{\pi} x \sqrt{-1} .
\]

En comparant ces valeurs à celles que M. Jacobi a données pour les mêmes fonctions à l'endroit cité, on parviendra à des résultats remarquables. Ainsi, en faisant dans la formule (3) de M. Jacobi, \(k=c\), on aura
(27) \(\left\{\begin{array}{l}\frac{1+2 q \cos 2 x+2 q^4 \cos 4 x+2 q^9 \cos 6 x+\cdots}{1-2 q \cos 2 x+2 q^4 \cos 4 x-2 q^9 \cos 6 x+\cdots} \\ =\frac{\left(1+2 q \cos 2 x+q^2\right)\left(1+2 q^3 \cos 2 x+q^6\right)\left(1+2 q^5 \cos 2 x+q^{10}\right) \cdots}{\left(1-2 q \cos 2 x+q^2\right)\left(1-2 q^3 \cos 2 x+q^6\right)\left(1-2 q^5 \cos 2 x+q^{10}\right) \cdots}\end{array}\right.\)
formule qui doit avoir lieu pour des valeurs quelconques réelles de \(x\) et \(q\), en supposant \(q\) moindre que l'unité.

En prenant les logarithmes des valeurs de \(\lambda\left(\frac{\omega^{\prime}}{\pi} x\right)\) etc., on trouvera après quelques réductions faciles:
(28)
\[
\begin{aligned}
& \log \lambda\left(\frac{\omega^{\prime}}{\pi} x\right)=\log 2-\frac{1}{2} \log c-\frac{1}{4} \frac{\pi^{\prime}}{\omega^{\prime}} \pi+\log \sin x \\
& \quad+2\left(\cos 2 x \cdot \frac{q}{1+q}+\frac{1}{2} \cos 4 x \cdot \frac{q^2}{1+q^2}+\frac{1}{3} \cos 6 x \cdot \frac{q^3}{1+q^3}+\cdots\right)
\end{aligned}
\]
(29)
\[
\begin{aligned}
\log \tilde{\lambda}^{\prime} & \left(\frac{\omega^{\prime}}{\pi} x\right)=\log 2+\frac{1}{2} \log b-\frac{1}{2} \log c-\frac{1}{4} \frac{\widetilde{\omega}^{\prime}}{\omega^{\prime}} \pi+\log \cos x \\
& +2\left(\cos 2 x \cdot \frac{q}{1-q}+\frac{1}{2} \cos 4 x \cdot \frac{q^2}{1+q^2}+\frac{1}{3} \cos 6 x \cdot \frac{q^3}{1-q^3}+\cdots\right),
\end{aligned}
\]
(30) \(\log \lambda^{\prime \prime}\left(\frac{\omega^{\prime}}{\pi} x\right)=\frac{1}{2} \log b+4\left(\cos 2 x \cdot \frac{q}{1-q^2}+\frac{1}{3} \cos 6 x \cdot \frac{q^3}{1-q^6}+\cdots\right)\).

En faisant \(x=0\), on trouvera:
\[
\log \left(\frac{1}{b}\right)=8 \cdot\left(\frac{q}{1-q^2}+\frac{1}{3} \cdot \frac{q^3}{1-q^a}+\frac{1}{5} \cdot \frac{q^5}{1-q^{10}}+\cdots\right)
\]
%473
(32)
\[
\begin{aligned}
\log \left(\frac{1}{c}\right) & =\frac{1}{2} \cdot \frac{\pi^{\prime}}{\sigma^{\prime}} \pi-2 \log 2+4\left(\frac{q}{1+q}-\frac{1}{2} \cdot \frac{q^2}{1+q^2}+\frac{1}{3} \cdot \frac{q^3}{1+q^3}-\cdots\right) \\
& =8 \cdot\left(\frac{r}{1-r^2}+\frac{1}{3} \cdot \frac{r^3}{1-r^6}+\frac{1}{5} \cdot \frac{r^5}{1-r^{10}}+\cdots\right)
\end{aligned}
\]

En posant dans les formules \((206)\) et \((207)\) t. II, p. 180*): \(\alpha=1-\frac{2 . x}{x}\), on trouvera les expressions suivantes:
(33) \(\quad \lambda\left(\frac{\omega^{\prime}}{\pi} x\right)=\frac{4 \pi}{c \omega^{\prime}} \cdot \sqrt{q} \cdot\left(\sin x \cdot \frac{1}{1-q}+\sin 3 x \cdot \frac{q}{1-q^3}+\sin 5 x \cdot \frac{q^2}{1-q^5}+\cdots\right)\),
(34) \(\lambda^{\prime}\left(\frac{\omega^{\prime}}{x} x\right)=\frac{4 \pi}{c \omega^{\prime}} \cdot \sqrt{q} \cdot\left(\cos x \cdot \frac{1}{1+q}+\cos 3 x \cdot \frac{q}{1+q^3}+\cos 5 x \cdot \frac{q^2}{1+q^5}+\cdots\right)\).

Ces formules sont peut-être les plus simples qu'on puisse trouver pour exprimer les fonctions elliptiques en quantités connues.

Voici encore deux autres formules qu'on déduira des équations (204) et \((205)\) t. II, p. \(\left.179^*\right)\), en y faisant \(\alpha=\frac{\omega}{2}-\omega x\) :
\[
\begin{aligned}
& \lambda^{\prime}\left(\omega^{\prime} x\right)=\frac{2 \pi}{c \sigma^{\prime}} \cdot\left(\frac{r^x-r^{1-x}}{1+r}-\frac{r^{3 x}-r^{3-3 x}}{1+r^3}+\frac{r^{5 x}-r^{5-5} x}{1+r^5}-\cdots\right), \\
& \lambda^{\prime \prime}\left(\omega^{\prime} x\right)=\frac{2 \pi}{\sigma^{\prime}} \cdot\left(\frac{r^x+r^{1-x}}{1-r}-\frac{r^{3 x}+r^{3-3 x}}{1-r^3}+\frac{r^{5 x}+r^{5-5 x}}{1-r^5}-\cdots\right),
\end{aligned}
\]
\(r\) désignant la même chose que précédemment.
Il est à remarquer que les quantités \(r\) et \(q\) sont liées entre elles par l'équation :
\[
\log r \cdot \log q=\pi^2
\]

A l'aide des expressions des modules \(c\) et \(b\) domnées plus haut, on pourra trouver une relation générale entre les modules de deux fonctions, elliptiques qui sont réductibles l'une à l'antre. En effet on pourra démontrer, comme je l'ai fait dans un des derniers numéros des \({ }^2\) Astronomische Nachrichten \(\left.{ }^{6 * * *}\right)\), que si deux fonctions elliptiques réelles
\[
F^{\prime}(c, \theta)=\int_0 \frac{d \theta}{\sqrt{1-c^2 \sin ^2 \theta}}, \quad F\left(c^{\prime}, \theta^{\prime}\right)=\int_0 \frac{d \theta^{\prime}}{\sqrt{1-c^{\prime 2} \sin ^2 \theta^{\prime}}},
\]
*) P. 350 de cette édition.
**) Mémoiro \(\mathrm{XX}\) de cotte ćlition.
60
%474
dont les modules \(c\) et \(c^{\prime}\) sont moindres que l'unité, sont réductibles l'une à l'autre à l'aide d'une relation algébrique entre \(\sin \theta\) et \(\sin \theta^{\prime}\), on peut trouver deux nombres entiers \(m\) et \(n\), tels que l'équation
\[
\begin{aligned}
& n \cdot \int_0^{\frac{\pi}{2}} \frac{d \theta}{\sqrt{1-c^2 \sin ^2 \theta}} \cdot \int_0^{\frac{\pi}{8}} \frac{d \theta}{\sqrt{1-b^{\prime 2} \sin ^2 \theta}} \\
& =m \cdot \int_0^{\frac{\pi}{8}} \frac{d \theta}{\sqrt{1-l^2 \sin ^2 \theta}} \cdot \int_0^{\frac{\pi}{2}} \frac{d \theta}{\sqrt{1-c^2 \sin ^2 \theta}}
\end{aligned}
\]
soit satisfaite; \(b^{\prime}\) est le complément de \(c^{\prime}\), savoir \(b^{\prime}=\sqrt{1-c^{22}}\).
Si cette condition est remplie, on pourra toujours déterminer \(\sin \theta^{\prime}\) algébriquement en \(\sin \theta\) de sorte que
\[
F^{\prime}\left(c^{\prime}, \theta^{\prime}\right)=a \cdot F(c, \theta)
\]
où \(a\) est un coefficient constant.
Cela posé, désignons par \(\omega^{\prime \prime}, \widetilde{\omega}^{\prime \prime}, r^{\prime}, q^{\prime}\) les valeurs de \(\omega^{\prime}, \widetilde{\omega}^{\prime}, r, q\) qui répondent au module \(c^{\prime}\), on aura en vertu de la formule (14)
\[
\sqrt[4]{c^{\prime}}=\frac{\left(1-r^{\prime}\right)\left(1-r^{\prime 3}\right)\left(1-r^{\prime 5}\right) \cdots}{\left(1+r^{\prime}\right)\left(1+r^{\prime 3}\right)\left(1+r^5\right) \cdots}
\]
\(r^{\prime}\) étant égal à \(e^{-\frac{\omega^*}{\omega^*} \pi}\). Mais l'équation (39) donne
\[
\frac{\omega^{\prime \prime}}{\tilde{\omega}^{\prime \prime}}=\frac{n}{m} \cdot \frac{\omega^{\prime}}{\widetilde{\omega}^{\prime}}
\]
done
\[
r^{\prime}=e^{-\frac{n}{m} \cdot \frac{\omega^{\prime}}{\omega^{\prime}} \pi}
\]
c'est-ì-dire que
\[
r^{\prime}=r^{\frac{n}{m}}
\]

Donc on a ce théorème:
Une fonction elliptique réelle étant proposée, si son module \(c\) est donné par la formule:
\[
\sqrt[4]{c}=\frac{(1-r)\left(1-r^3\right)\left(1-r^5\right) \cdots}{(1+r)\left(1+r^3\right)\left(1+r^5\right) \cdots}
\]
on aura le module de toute autre fonction elliptique réelle, réductible à la première, en mettant au lieu de \(r\) la puissance \(r^{\frac{n}{m}}\), où \(n\) et \(m\) sont deux nombres entiers et positifs quelconques; autrement dit, on aura, en désignant par \(c^{\prime}\) le module de la nouvelle fonction,
%475
\[
\sqrt[4]{c^{\prime}}=\frac{\left(1-r^{\frac{n}{m}}\right)\left(1-r^{3 \frac{n}{m}}\right)\left(1-r^{5 \frac{n}{m}}\right) \cdots}{\left(1+r^{\frac{n}{m}}\right)\left(1+r^{3 \frac{n}{m}}\right)\left(1+r^{5 \frac{n}{m}}\right)}
\]

En faisant
\[
\sqrt[4]{c}=\sqrt{2} \cdot \sqrt[8]{q} \cdot \frac{1+q^2}{1+q} \cdot \frac{1+q^4}{1+q^3} \cdot \frac{1+q^6}{1+q^5} \cdots
\]
on aura encore la formule suivante:
\[
\sqrt[4]{c^{\prime}}=\sqrt{2} \cdot(\sqrt[8]{q})^{\frac{m}{n}} \cdot \frac{1+q^{2 \frac{m}{n}}}{1+q^{\frac{m}{n}}} \cdot \frac{1+q^{4 \frac{m}{n}}}{1+q^{3 \frac{m}{n}}} \cdot \frac{1+q^{6 \frac{m}{n}}}{1+q^{5 \frac{m}{n}}} \cdots
\]

Dans le cas particulier où le module \(c\) est \(\sqrt{\frac{1}{2}}\), on a \(\widetilde{\omega}^{\prime}=\omega^{\prime}\), donc
\[
r=e^{-\pi}=q
\]

De là il suit que le module \(c\) de toute fonction elliptique réelle, qui est réductible à la fonction \(\int_0 \frac{d \theta}{\sqrt{1-\frac{1}{2} \cdot \sin ^2 \theta}}\), est donné par la formule:
\[
\begin{aligned}
\sqrt[4]{c}=\frac{1-e^{-\mu x}}{1+e^{-\mu x}} \cdot \frac{1-e^{-3 \mu \pi}}{1+e^{-3 \mu \tau}} & \cdot \frac{1-e^{-5 \mu \tau}}{1+e^{-5 \mu x}} \cdots \\
& =\sqrt{2} \cdot e^{-\frac{\pi}{8 \mu}} \frac{1+e^{-\frac{2 \pi}{\mu}}}{1+e^{-\frac{\pi}{\mu}}} \cdot \frac{1+e^{-\frac{4 \pi}{\mu}}}{1+e^{-\frac{3 \pi}{\mu}}} \cdot \frac{1+e^{-\frac{6 \pi}{\mu}}}{1+e^{-\frac{5 \pi}{\mu}}} \cdots
\end{aligned}
\]
où "" est un nombre rationnel quelconque.
D'ailleurs, dans ce cas \(c\) pourra toujours être exprimé en termes finis à l'aide de radicaux.
Si l'on suppose \(b^{\prime}=c\), on a \(c^{\prime}=b, \omega^{\prime \prime}=\widetilde{\omega}^{\prime}, \widetilde{\omega}^{\prime \prime}=\omega^{\prime}\); mais
\[
\begin{aligned}
& \frac{\omega^{\prime \prime}}{\omega^{\prime \prime}}=\frac{n}{m} \cdot \frac{\omega^{\prime}}{\widetilde{v}^{\prime}}=\frac{\widetilde{v}^{\prime}}{\omega^{\prime}}, \\
& \frac{\omega^{\prime}}{\widetilde{\omega^{\prime}}}=\sqrt{\frac{m}{n}}=\sqrt{u} .
\end{aligned}
\]
done
\[
\frac{\omega^{\prime}}{\sigma^{\prime}}=\sqrt{\frac{m}{n}}=\sqrt{1}
\]

De là nous concluons:
Si deux fonctions elliptiques réelles dont les modules sont complémens l'un de l'autre, sont reductibles entre elles, le module sera donné par la formule:
\[
\sqrt[4]{c}=\frac{1-e^{-\pi \sqrt{\mu}}}{1+e^{-\pi / \mu}} \cdot \frac{1-e^{-3 \pi \sqrt{\mu}}}{1+e^{-3 i \sqrt{\mu}}} \cdot \frac{1-e^{-5 \pi \sqrt{\mu}}}{1+e^{-5 \pi \sqrt{\mu}}} \cdots
\]
(6)*
%476
et son complément \(b\) par celle-ci :
\[
\sqrt[4]{b}=\frac{1-e^{-\frac{\pi}{\sqrt{\mu}}}}{1+e^{-\frac{\pi}{\sqrt{\mu}}}} \cdot \frac{1-e^{-\frac{3 \pi}{\sqrt{\mu}}}}{1+e^{-\frac{3 x}{\sqrt{\mu}}}} \cdot \frac{1-e^{-\frac{5 \pi}{\sqrt{\mu}}}}{1+e^{-\frac{5 x}{\sqrt{\mu}}}} \cdots,
\]
où, \(\boldsymbol{\iota}\) est un nombre rationnel quelconque.
Nous ajouterons qu'on a en même temps
\[
F\left(b, \theta^{\prime}\right)=k \sqrt{\mu} \cdot F(c, \theta),
\]
où \(k\) est un autre nombre rationnel. Cela donne immédiatement le théorème suivant:
Si l'équation différentielle
\[
\frac{d y}{\sqrt{A-B y^2+C y^4}}=a \cdot \frac{d x}{\sqrt{A+B x^2+C \cdot x^4}}
\]
est intégrable algébriquement, il faut nécessairement que le coefficient \(a\) soit égal ù la racine carrée d'un nombre rationnel et positif, en supposant que les quantités \(A, B, C, a\) soient réelles; et si \(a\) est de cette forme, on pourra tronver une infinité de valeurs convenables pour \(A, B, C\).

Nous terminerons ces remarques par la démonstration d'une formule curieuse, qu'on tire de la première des équations (20), savoir de la formule
\[
(1+r)\left(1+r^3\right)\left(1+r^5\right) \cdots=\sqrt[6]{2} \cdot \frac{\sqrt{24}}{\frac{\sqrt{r}}{\sqrt{b c}}} .
\]

En y changeant \(c\) en \(b, b\) se changera en \(c\), et \(r\) en \(q\), donc:
\[
(1+q)\left(1+q^3\right)\left(1+q^5\right) \cdots=\sqrt[6]{2} \cdot \frac{\sqrt[24]{q}}{\sqrt{b c}}
\]

En comparant ces formules, on voit que l'équation
\[
\frac{1}{\sqrt{r}} \cdot(1+r)\left(1+r^3\right)\left(1+r^5\right) \cdots=\frac{1}{\sqrt{q}}(1+q)\left(1+q^3\right)\left(1+q^5\right) \ldots,
\]
a lieu toutes les fois que les quantités \(r\) et \(q\) sont moindres que l'unité et liées entre elles par l'équation
\[
\log r \cdot \log q=\pi^2
\]
%477
Il existe un grand nombre de relations semblables entre \(q\) et \(r\), par exemple la suivante:
\[
\sqrt[4]{\log \frac{1}{r}} \cdot\left(\frac{1}{2}+r+r^4+r^9+\ldots\right)=\sqrt[4]{\log \frac{1}{q}} \cdot\left(\frac{1}{2}+q+q^4+q^9+\ldots\right),
\]
qui est due à M. Cauchy (Exercices de mathématiques). On pourra la déduire de la formule
\[
\sqrt{\frac{\omega^{\prime}}{\pi}}=1+2 q+2 q^4+2 q^9+\cdots
\]
doinée par M. Jacobi, en y changeant \(c\) en \(b\).
%478
XXV.

MÉMOIRE SUR UNE CLASSE PARTICULIÈRE D'ÉQUATIONS RÉSOLUBLES ALGÉBRIQUEMENT.
Journal für die reine und angewandte Mathematik, herausgegeben von Crelle, Bd. 4, Berlin 1829.
Quoique la résolution algébrique des équations ne soit pas possible en général, il y a néanmoins des équations particulières de tous les degrés qui admettent une telle résolution. Telles sont par exemple les équations de la forme \(x^n-1=0\). La résolution de ces équations est fondée sur certaines relations qui existent entre les racines. J'ai cherché à généraliser cette méthode en supposant que deux racines d'une équation donnée soient tellement liées entre elles, qu'on puisse exprimer rationnellement l'une par l'autre, et je suis parvenu à ce resultat, qu'une telle équation peut toujours être résolue à l'aide d'un certain nombre d'équations moins élevées. Il y a même des eas où l'on pent résoudre algébriquement l'équation donnée elle-même. Cela arrive par exemple toutes les fois que, l'équation donnée étant irréductible, son degré est un nombre premier. La même chose a encore lieu si toutes les racines d'une équation peuvent être exprimées par
\[
x, \theta x, \theta^2 x, \theta^3 x, \ldots \theta^{n-1} x \text {, où } \theta^n x=x,
\]
\(\theta x\) étant une fonction rationnelle de \(x\), et \(\theta^2 x, \theta^3 x, \ldots\) des fonctions de la même forme que \(\theta x\), prise deux fois, trois fois, etc.

L'équation \(\frac{x^n-1}{x-1}=0\), où \(n\) est un nombre premier, est dans ce cas; car en désignant par \(\alpha\) une racine primitive pour le module \(n\), on peut, comme on sait, exprimer les \(n-1\) racines par
%479
\[
x, x^\alpha, x^{\alpha^2}, x^{\alpha^n}, \ldots x^{\alpha^{n-2}} \text {, où } x^{\alpha^{n-1}}=x \text {, }
\]
c'est-à-dire, en faisant \(x^\alpha=\theta x\), par
\[
x, \theta x, \theta^2 x, \theta^3 x, \ldots \theta^{n-2} x \text {, où } \theta^{n-1} x=x .
\]

La même propriété appartient à une certaine classe d'équations à laquelle je suis parvenu par la théorie des fonctions elliptiques.
En général j’ai démontré le théorème suivant:
"Si les racines d'une équation d'un degré quelconque sont liées entre elles de telle sorte, que toutes ces racines puissent être exprimées rationnellement au moyen de l'une d'elles, que nous désignerons par \(x\); si de plus, en désignant par \(\theta x, \theta_1 x\) deux autres racines quelconques, on a
\[
\theta \theta_1 x=\theta_1 \theta x
\]
l'équation dont il s'agit sera toujours résoluble algébriquement. De même, si l'on suppose l'équation irréductible, et son degré exprimé par
\[
\alpha_1^{\nu_1} \cdot \alpha_2^{\nu_2} \ldots \alpha_\omega^{\nu_\omega}
\]
où \(\alpha_1, \alpha_2, \ldots \alpha_\omega\) sont des nombres premiers différens, on pourra ramener la résolution de cette équation à celle de \(\nu_1\) équations du degré \(\alpha_1\), de \(v_z\) équations du degré \(\alpha_2\), de \(\nu_3\) équations du degré \(\alpha_3\) etc."“

Après avoir exposé cette théorie en général, je l'appliquerai aux fonctions circulaires et elliptiques.
\(\S 1\).
Nous allons d'abord considérer le cas où l'on suppose que deux racines d'une équation irréductible*) soient liées tellement entre elles, que l'une puisse être exprimée rationnellement par l'autre.
Soit
\[
\varphi x=0
\]
une équation du degré ", et \(x^{\prime}\) et \(x_1\) les deux racines qui sont liées entreelles par l'équation
*) Une équation \(q x=0\), dont les coefficiens sont des fonctions rationnelles d'un certain nombre de quantités connues \(a, b, c, \ldots\) s'appelle irréductible, lorsqu'il est impossible d'exprimer aucune de ses racines par une équation moins élevée, dont les coefficiens soient également des fonctions rationnelles de \(a, b, c \ldots\).
%480
(2)
\[
x^{\prime}=\theta x_1,
\]
où \(\theta x\) désigne une fonction rationnelle de \(x\) et de quantités connues. Iar quantité \(x^{\prime}\) étant racine de l'équation, on aura \(\varphi\left(x^{\prime}\right)=0\), et en vertu de l'équation (2)
\[
\varphi\left(\theta x_1\right)=0
\]

Je dis maintenant que cette équation aura encore lieu, si au lien de \(x_1\) on met une autre racine quelconque de l'équation proposée. On a effectivement le théorème suivant*).

Théorème I. "Si une des racines d'une équation irréductible \(\varphi x=0\) satisfait à une autre équation \(f x=0\), où \(f x\) désigne une fonction rationnelle de \(x\) et des quantités connues qu'on suppose contenues dans \(\varphi x\); cette dernière équation sera encore satisfaite en mettant au lieu de \(x\) une racine quelconque de l'équation \(\varphi x=0\)."

Or le premier membre de l'équation (3) est une fonction rationnelle de \(x\), donc on aura
\[
\varphi(\theta x)=0, \text { si } \varphi x=0,
\]
c'est-à-dire que si \(x\) est une racine de l'équation \(\varphi x=0\), la quantité \(\theta x\) le sera également.

Maintenant, d'après ce qui précède, \(\theta x_1\) est racine de l'équation \(\varphi x=0\), done \(\theta \theta x_1\) le sera aussi; \(\theta \theta \theta x_1\), etc. le seront également, en répétant l'opération désignée par \(\theta\) un nombre quelconque de fois.
*) Ce théorème se démontre aisément comme il suit:

Quelle que soit la fonction rationnelle \(f x\), on peut toujours faire \(f x=\frac{M}{N}\), où \(M\) et \(N\) sont des fonctions entières de \(x\), qui n'ont pas de facteur commun; mais une fonction entière de \(x\) peut toujours être nise sous la forme \(P+Q . q x\), où \(P\) et \(Q\) sont des fonctions entières, telles que le degré de \(P\) soit moindre que celui de la fonction \(\varphi x\). En faisant done \(M=P+Q \cdot \varphi^x\), on aura \(f x=\frac{P+Q \cdot q x}{N}\). Cela posé, soit \(x_1\) la racine de \(r x=0\) qui satisfait en même temps à \(f x=0 ; x_1\) sera également une racine de l'équation \(P=0\). Or si \(P\) n'est pas zéro pour une valeur quelconque de \(x\), cette équation donnera \(x_1\) comme racine d'une équation d'un degré moindre que celui de \(q x=0\), ce qui est contre l'hypothèse; donc \(P=0\) et par suite \(f x=\uparrow x \frac{Q}{N}\), d'où l'on voit que \(f x\) sera égal à zéro en même temps que \(\subsetneq x\) c. q. f. d.
%481
Soit pour abréger
\[
\theta \theta x_1=\theta^2 x_1 ; \quad \theta \theta^2 x_1=\theta^3 x_1 ; \theta \theta^3 x_1=\theta^{-1} x_1 \text { etc., }
\]
on aura une série de quantités,
\[
x_1, \theta x_1, \theta^2 x_1, \theta^3 x_1, \theta^4 x_1, \ldots,
\]
qui toutes seront des racines de l'équation \(\varphi x=0\). La série (5) anra une intinité de termes; mais l'équation \(\varphi x=0\) n'ayant qu'un nombre fini de racines différentes, il faut que plusieurs quantités de la série (5) soient égales entre elles.
Supposons donc
\[
\theta^n x_1=\theta^{m+n} x_1
\]
ou bien
\[
\theta^n\left(\theta^m \cdot x_1\right)-\theta^m \cdot x_1=0
\]
en remarquant que \(\theta^{m+n} x_1=\theta^n \theta^m x_1\).
Le premier membre de l'équation (6) est une fonction rationnelle de \(\theta^m x_1\); or cette quantité est une racine de l'équation \(\varphi x=0\), donc en vertu du théorème énoncé plus haut, on pourra mettre \(x_1\) au lieu de \(\theta^m x_1\). Cela dome
\[
\theta^n x_1=x_1
\]
où l'on peut supposer que \(n\) ait la plus petite valeur possible, de sorte que toutes les quantités
\[
x_1, \theta x_1, \theta^2 x_1, \ldots \theta^{n-1} x_1
\]
soient différentes entre elles.
L'équation (7) donnera
\[
\theta^k \theta^n x_1=\theta^k x_1 \text {, on } \theta^{n+k} x_1=\theta^k x_1 .
\]

Cette formule fait voir qu'à partir du terme \(\theta^{n-1} x_1\), les termes de lă suite (8) se reproduiront dans le même ordre. Les \(n\) quantités (8) seront donc les seules de la série (5) qui soient différentes entre elles.

Cela posé, si \(\|>n\), soit \(x_2\) une autre racine de l'équation proposée, qui n'est pas contenue dans la suite (8), il suit du théorème I que tontes les quantités
\[
x_2, \theta x_2, \theta^2 x_2, \ldots \theta^{n-1} x_2, \ldots
\]
seront également des racines de l'équation proposée. Or je dis que cette
%482
- suite ne contiendra que \(n\) quantités différentes entre elles et des quantités (8). En effet, ayant \(\theta^n x_1-x_1=0\), on aura en vertu du théorème 1 , \(\theta^n x_z=x_z\), et par suite
\[
\boldsymbol{\theta}^{n+k} x_2=\boldsymbol{\theta}^k x_2
\]

Donc les seules quantités de la série (9) qui puissent être différentes entre elles, seront.les \(n\) premières
\[
x_2, \theta x_2, \theta^2 x_2, \ldots \theta^{n-1} x_2 .
\]

Or celles-ci seront nécessairement différentes entre elles et des quantités (8). En effet, si l'on avait
\[
\theta^m x_2=\theta^v x_2
\]
où \(m\) et \(v\) sont moindres que \(n\), il en résulterait \(\theta^n x_1=\theta^{\prime} x_1\), ce qui est impossible, car toutes les quantités (8) sont différentes entre elles. Si au contraire on avait
\[
\theta^m x_z=\theta^v x_1
\]
il en résulterait
\[
\boldsymbol{\theta}^{n-m} \boldsymbol{\theta}^r x_1=\boldsymbol{\theta}^{n-m} \boldsymbol{\theta}^m x_2=\boldsymbol{\theta}^{n-m+m} x_2=\boldsymbol{\theta}^n x_2=x_z,
\]
douc
\[
x_2=\theta^{n-i n+v} x_1
\]
c'est-à-dire que la racine \(x_2\) serait contenue dans la série (8), ce qui est contre l'hypothèse.

Le nombre des racines contenues dans (8) et (10) est \(2 n\), donc "l sera ou égal à \(2 n\), ou plus grand que ce nombre.

Soit dans le dernier cas \(x_3\) une racine différente des racines \((8)\) et \((10)\), on aura une nouvelle série de racines
\[
x_3, \theta x_3, \theta^2 x_3, \ldots \theta^{n-1} x_3, \ldots,
\]
et l'on démontrera, précisément de la même manière, que les \(n\) premières de ces racines sont différentes entre elles et des racines (8) et (10).

En continuant ce procédé jusqu'à ce que toutes les racines de l'équation \(\varphi x=0\) soient épuisées, on verra que les "l racines de cette équation seront partagées en plusieurs groupes, composés de \(n\) termes; donc "l sera divisible par \(n\), et en nommant \(m\) le nombre des groupes, on aura
\[
\|=m \cdot n \text {. }
\]

Les racines elles-mêmes seront
%483
Si \(m=1\), on aura \(n=\mu\), et les \(\mu\) racines de l'équation \(r x=0\) seront exprimées par
\[
x_1, \theta x_1, \theta^2 x_1, \ldots \theta^{\mu-1} x_1 .
\]

Dans ce cas l'équation \(\varphi x=0\) est résoluble algébriquement, comme on le verra dans la suite. Mais la même chose n'aura pas toujours lieu lorsque \(m\) est plus grand que l'unité. On pourra seulement réduire la résolution de l'équation \(\varphi x=0\) à celle d'une équation du \(n^{\text {ième }}\) degré, dont les coefficiens dépendront d'une équation du \(m^{\text {ìme }}\) degré; c'est ce que nous allons démontrer dans le paragraphe suivant.
\(\S 2\).
Considérons un quelconque des groupes (12), par exemple le premier, et faisons
\[
\left\{\begin{array}{r}
\left(x-x_1\right)\left(x-\theta x_1\right)\left(x-\theta^2 x_1\right) \cdots\left(x-\theta^{n-1} x_1\right) \\
=x^n+A_1^{\prime} x^{n-1}+A_1^{\prime \prime} x^{n-2}+\cdots+A_1^{(n-1)} x+A_1^{(n)}=0 ;
\end{array}\right.
\]
les racines de cette éruation seront
\[
x_1, \theta x_1, \theta^2 x_1, \ldots \theta^{n-1} x_1,
\]
et les coefficiens \(A_1{ }^{\prime}, A_1{ }^{\prime \prime}, \ldots A_1^{(n)}\) seront des fonctions rationnelles et symétriques de ces quantités. Nous allons voir quon peut faire dépendre la détermination de ces coefficiens de la résolution d'une seule équation du legrié \(m\).

Pour le montrer, considérons en général une fonction queleonque rationnelle et symétrique de \(x_1, \theta x_1, \theta^2 x_1, \ldots \theta^{n-1} x_1\), et soit
\[
y_1=f\left(x_1, \theta x_1, \theta^2 x_1, \ldots \theta^{n-1} x_1\right)
\]
cette fonction.
En mettant an lien de \(x_1\) successivement \(x_2, x_3, \ldots x_n\), la fonction \(y_1\)
(i) *
%484
prendra \(m\) valeurs différentes, que nous désignerons par \(y_1, y_2, y_3, \ldots y_m\). Cela posé, si l'on forme une équation dı degré \(m\) :
\[
y^m+p_1 y^{m-1}+p_8 y^{m-2}+\cdots+p_{m-1} y+p_m=0
\]
dont les racines soient \(y_1, y_2, y_3, \ldots y_m\), je dis que les coefficiens de cette équation pourront être exprimés rationnellement par les quantités comnues, qu'on suppose contenues dans l'équation proposée.

Les quantités \(\theta x_1, \theta^2 x_1, \ldots \theta^{n-1} x_1\) étant des fonctions rationnelles de \(x_1\), la fonction \(y_1\) le sera également. Soit
\[
\left\{\begin{array}{c}
y_1=F x_1, \\
\text { nous aurons aussi } \\
y_2=F x_2, y_3=F x_3, \ldots y_m=F x_m .
\end{array}\right.
\]

En mettant dans l'équation (15) successivement \(\theta x_1, \theta^2 x_1, \theta^3 x_1, \ldots\) \(\theta^{n-1} x_1\) au lieu de \(x_1\), et en remarquant que \(\theta^n x_1=x_1, \theta^{n+1} x_1=\theta x_1\), \(\theta^{n+2} x_1=\theta^2 x_1\) etc., il est clair que la fonction \(y_1\) ne change pas de valeur; on aura done
\[
y_1=F x_1=F\left(\theta x_1\right)=F\left(\theta^2 x_1\right)=\cdots=F\left(\theta^{n-1} x_1\right) .
\]

De même
\[
\begin{aligned}
& y_2=F x_2=F\left(\theta x_2\right)=F\left(\theta^2 x_2\right)=\cdots=F\left(\theta^{n-1} x_2\right) \text {, } \\
& \ldots \ldots \ldots \ldots \ldots \ldots \ldots \\
& y_m=F x_m=F\left(\theta x_m\right)=F\left(\theta^2 x_m\right)=\cdots=F\left(\theta^{n-1} x_m\right) . \\
&
\end{aligned}
\]

En élevant chaque membre de ces équations à la \(\boldsymbol{v}^{\text {ième }}\) puissance, on en tire
\[
\left\{\begin{array}{c}
y_1^v=\frac{1}{n} \cdot\left[\left(F x_1\right)^v+\left(F \theta x_1\right)^v+\cdots+\left(F \theta^{n-1} x_1\right)^v\right] \\
y_2^v=\frac{1}{n} \cdot\left[\left(F x_2\right)^v+\left(F \theta x_2\right)^\nu+\cdots+\left(F \theta^{n-1} x_2\right)^v\right] \\
\cdots \cdots \cdots \cdots \\
y_m^v=\frac{1}{n} \cdot\left[\left(F x_m\right)^v+\left(F \theta x_m\right)^\nu+\cdots \cdots+\left(F \theta^{n-1} x_m\right)^v\right]
\end{array}\right.
\]

En ajoutant ces dernières équations, on aura la valeur de
\[
y_1^v+y_2^v+y_3^v+\cdots+y_m^v
\]
%485
exprimée en fonction rutionnelle et symétrique de toutes les racines de l'équation \(\varphi x=0\), savoir:
\[
y_1^v+y_2^v+y_3^v+\cdots+y_m^v=\frac{1}{n} \Sigma(F x)^\nu .
\]

Le second membre de cette équation pent être exprimé rationnellement par les coefficiens de \(\varphi x\) et \(\theta x\), c'est-ì-dire par des quantités connues. Donc en faisant
\[
r_r=y_1^v+y_2^{v^{\prime}}+y_3^v+\cdots+y_m^v
\]
on aura la valeur de \(r_\nu\), pour une valeur quelconque entière de \(\nu\). Or; connaissant \(r_1, r_z, \ldots r_n\), on en pourra tirer rationnellement la valeur de tonte fonetion symétrique des quantités \(y_1, y_2, \ldots y_m\). On pourra donc trouver de cette manière tous les coefficiens de l'équation (16), et par conséquent déterminer toute fonction rationnelle et symétrique de \(x_1, \theta x_1, \theta^2 x_1\), \(\ldots \theta^{n-1} x_1\) à l'aide d'une équation du \(m^{i \text { me }}\) degré. Donc on aura de cette manière les coefficiens de l'équation (14), dont la résolution domnera ensuite la valeur de \(x_1\) etc.

On voit par là qu'on peut ramener la résolution de l'équation \(\varphi x=0\), qui est du degré \(\boldsymbol{\mu}=m . n\), à celle d'un certain nombre d'équations du degré \(m\) et \(n\). Il suffit même, comme nous allons voir, do résoudre une seule équation du degré \(m\), et \(m\) équations du degré \(n\).
Soit \(\psi x_1\) ' l'un quelconque des coefficiens \(A_1^{\prime}, A_1^{\prime \prime}, \ldots A_1^{(n)}\); faisons
\[
t_\nu=y_1^\nu \cdot \psi x_1+y_2^\nu \cdot \psi x_2+y_3^\nu \cdot \psi x_3+\cdots+y_m^\nu \cdot \psi x_m .
\]

Puisque \(y_1^v \psi x_1\) est une fonction symétrique des quantités \(x_1, \theta x_1, \ldots \theta^{n-1} x_1\), on aura, en remarquant que \(\theta^n x_1=x_1, \theta^{n+1} x_1=\theta x_1\) etc.
\[
y_1^v \psi x_1=\left(F x_1\right)^\nu \cdot \psi x_1=\left(F \theta x_1\right)^\nu \cdot \psi \theta x_1=\cdots=\left(F \theta^{n-1} x_1\right)^\nu \cdot \psi \theta^{n-1} x_1,
\]
rone:
\[
y_1^v \psi x_1=\frac{1}{n} \cdot\left[\left(F x_1\right)^v \psi x_1+\left(F \theta x_1\right)^v \psi \theta x_1+\cdots+\left(F \theta^{n-1} x_1\right)^v \psi \theta^{n-1} x_1\right]
\]

On aura de semblables expressions pour \(y_2^v \psi x_2, y_3^v \psi x_3, \ldots y_m^v \psi x_m\), en mettant \(x_2, x_3, \ldots x_m\) à la place de \(x_1\). En substituant ces valeurs, on voit que \(t_\nu\) deviendra une fonction rationnelle et symétrique de tontes les racines de l'érpation \(p x=0\). En effet, on aura
\[
t_v=\frac{1}{n} \Sigma(F x)^v \psi x
\]
%486
Donc on peut exprimer \(t_v\) rationnellement par des quantités comues. Cela posé, en faisant \(v=0,1,2,3, \ldots m-1\), la formule (21) donnera
\[
\begin{array}{r}
\psi x_1+\psi x_9+\cdots+\psi x_m=t_0, \\
y_1 \psi x_1+y_2 \psi x_9+\cdots+y_m \psi x_m=t_1, \\
y_1^3 \psi x_1+y_2^z \psi x_3+\cdots+y_m^2 \psi x_m=t_3, \\
\cdots \cdots \cdots+y_m^{m-1} \psi x_m=t_{m-1} .
\end{array}
\]

On tirera aisément de ces équations, linéaires par rapport à \(\psi x_1, \psi x_2, \ldots\) \(\mu x_m\), les valeurs de ces quantités en fonction rationnelle de \(y_1, y_2, y_3, \ldots y_m\). En effet, en faisant
\[
\begin{aligned}
\left(y-y_2\right)\left(y-y_3\right) & \cdots\left(y-y_m\right) \\
& =y^{m-1}+R_{m-2} y^{m-2}+R_{m-3} y^{m-3}+\cdots+R_1 y+R_0,
\end{aligned}
\]
on aura
\[
\psi x_1=\frac{t_0 R_0+t_1 R_1+t_2 R_2+\cdots+t_{m-2} R_{m-2}+t_{m-1}}{R_0+R_1 y_1+R_2 y_1^2+\cdots+R_{m-2} y_1^{m-2}+y_1^{m-1}} .
\]

Les quantités \(R_0, R_1, \ldots R_{m-2}\) sont des fonctions rationnelles de \(y_2\), \(y_3, y_4, \ldots y_n\), mais on peut les exprimer par \(y_1\) seul. En effet, en multipliant l'équation (23) par \(y-y_1\), on aura
\[
\begin{aligned}
\left(y-y_1\right)\left(y-y_2\right) \cdots & \left(y-y_m\right)=y^m+p_1 y^{m-1}+p_2 y^{m-2}+\cdots+p_{m-1} y+p_m \\
& =y^m+\left(R_{m-2}-y_1\right) y^{m-1}+\left(R_{m-3}-y_1 R_{m-2}\right) y^{m-2}+\cdots,
\end{aligned}
\]
d'où l'on tirera, en comparant les puissances égales de \(y\) :

En substituant ces valeurs, l'expression de \(\psi x_1\) deviendra une fonction rationnelle de \(y_1\) et de quantités connues, et l'on voit qu’il est toujours possible de trouver \(\psi x_1\) de cette manière, à condition que le dénominateur
\[
R_0+R_1 y_1+R_2 y_1^2+\cdots+R_{m-2} y_1^{m-9}+y_1^{m-1}
\]
%487
ne sera pas zéro. Or on peut donner à la fonction \(y_1\) une infinité de formes qui rendront impossible cette équation. Par exemple en faisant
\[
y_1=\left(\alpha-x_1\right)\left(\alpha-\theta x_1\right)\left(\alpha-\theta^2 x_1\right) \cdots\left(\alpha-\theta^{n-1} x_1\right)
\]
où \(\alpha\) est une indéterminée, le dénominateur dont il s'agit ne peut pas s'évanouir. En effet ce dénominateur étant la même chose que
\[
\left(y_1-y_2\right)\left(y_1-y_3\right) \ldots\left(y_1 \div y_m\right)
\]
(in autrait, dans le cas oì il etait nul,
\[
y_1=y_k
\]
c'est-à-dire
\[
\left(\alpha-x_1\right)\left(\alpha-\theta x_1\right) \ldots\left(\alpha-\theta^{n-1} x_1\right)=\left(\alpha-x_k\right)\left(\alpha-\theta x_k\right) \ldots\left(\alpha-\theta^{n-1} x_k\right),
\]
ce qui est impossible, car toutes les racines \(x_1, \theta x_1, \theta^2 x_1, \ldots \theta^{n-1} x_1\) sont différentes de celles-ci: \(x_k, \boldsymbol{\theta} x_k, \theta^2 x_k, \ldots \boldsymbol{\theta}^{n-1} x_k\).

Les coefficiens \(A_1{ }^{\prime}, A_1{ }^{\prime \prime}, \ldots A_1^{(n)}\) penvent donc s'exprimer rationnellement par une même fonction \(y_1\), dont la détermination dépend d'une équation du degré \(m\).
Les racines de l'équation (14) sont
\[
x_1, \theta x_1, \theta^2 x_1 \ldots \theta^{n-1} x_1 .
\]

En remplaçant dans les coefficiens \(A_1{ }^{\prime}, A_1{ }^{\prime \prime}\) ete. \(y_1\) par \(y_2, y_3, \ldots y_m\), on obtiendra \(m-1\) autres équations, dont les racines seront respectivement:
\[
\begin{gathered}
x_2, \boldsymbol{\theta} x_2, \ldots \boldsymbol{\theta}^{n-1} x_2, \\
x_3, \boldsymbol{\theta} x_3, \ldots \boldsymbol{\theta}^{n-1} x_3, \\
\ldots \ldots \\
x_m, \boldsymbol{\theta} x_m, \ldots \boldsymbol{\theta}^{n-1} x_m .
\end{gathered}
\]

Théorème II. L'équation proposée \(\varphi x=0\) peut donc être décomposée en \(n\) équations du degré \(n\), dont les coefficiens sont respectivement des fonctions rationnelles d'une même racine d'une seule équation du degré \(m\).

Cette dernière équation n'est pas généralement résoluble algébriquement quand elle passe le quatrième degré, mais l'équation (14) et les autres semblables le sont toujours, en supposant commus les coefficiens \(A_1{ }^{\prime}, A_1{ }^{\prime \prime}\) ete., comme nois le verons dans le paragraphe suivant.
%488
\(\S 3\).
Dans le paragraphe précédent nous avons considéré le cas où \(m\) est plus grand que l'unité. Maintenant nous allons nous occuper du cas où \(m=1\). Dans ce cas on aura,\(\mu=n\), et les racines de l'équation \(p x=0\) seront
\[
x_1, \theta x_1, \theta^2 x_1, \ldots \theta^{n-1} x_1 .
\]

Je dis que tonte équation dont les racines peuvent être exprimées de cette manière est résoluble algébriquement.
Soit \(\alpha\) une racine quelconque de l'équation \(\alpha^\mu-1=0\), et faisons
\[
\psi x=\left(x+\alpha \theta x+\alpha^2 \theta^2 x+\alpha^3 \theta^3 x+\cdots+\alpha^{\mu-1} \theta^{\mu-1} x\right)^\mu,
\]
\(\psi x\) sera une fonction rationnelle de \(x\). Or cette fonction pent s'exprimer rationnellement par les coefficiens de \(\varphi x\) et \(\theta x\). En mettant \(\theta^m x\) au lieu de \(x\), on aura
\[
\psi \theta^m x=\left(\theta^m x+\boldsymbol{\alpha} \theta^{m+1} x+\cdots+\boldsymbol{\alpha}^{\mu-m} \theta^\mu x+\boldsymbol{\alpha}^{\mu-m+1} \theta^{\mu+1} x+\cdots+\boldsymbol{\alpha}^{\mu-1} \theta^{\mu+m-1} x\right)^\mu ;
\]
maintenant on a
\[
\theta^\mu x=x, \theta^{\mu+1} x=\theta x, \ldots \theta^{\mu+m-1} x=\theta^{m-1} x
\]
donc
\(\psi \theta^m x=\)
\[
\left(\alpha^{\mu-n} x+\alpha^{\mu-m+1} \theta x+\cdots+\alpha^{\mu-1} \theta^{m-1} x+\theta^m x+\alpha \dot{\theta}^{m+1} x+\cdots+\alpha^{\mu-m-1} \theta^{\mu-1} x\right)^\mu .
\]

Or \(\boldsymbol{a}^\mu=1\), done
\[
\begin{aligned}
\psi \theta^m x=\left[\alpha^{\mu-m}\left(x+\alpha \theta x+\alpha^2 \theta^2 x+\cdots+\alpha^{\mu-1} \theta^{\mu-1} x\right)\right]^\mu & \\
& =\alpha^{\mu(\mu-m)}\left(x+\alpha \theta x+\cdots+\alpha^{\mu-1} \theta^{\mu-1} x\right)^\mu
\end{aligned}
\]
donc, puisque \(a^{\mu(\mu-m)}=1\), on voit que
\[
\psi \theta^m x=\psi x \text {. }
\]

En faisant \(m=0,1,2,3, \ldots, i-1\), et en ajoutant ensuite, on trouvera
\[
\psi x=\frac{1}{\mu}\left(\psi x+\psi \theta x+\psi \theta^2 x+\cdots+\psi \theta^{u-1} x\right) .
\]
\(\psi x\) sera donc une fonction rationnclle et symétrique de toutes les racines de l'équation \(\varphi x=0\), et par conséquent on pourra l'exprimer rationnellement par des quantités commues.
%489
Soit \(\psi x=v\), on tire de l'équation (28)
\[
\sqrt[\mu]{v}=x+\alpha \theta x+\alpha^2 \theta^2 x+\cdots+\alpha^{\mu-1} \theta^{\mu-1} x .
\]

Cela posé, désignons les \(\mu\) racines de l'équation par
\[
\begin{gathered}
\alpha^\mu-1=0 \\
\cdot 1, \alpha_1, \alpha_2, \alpha_3, \ldots \alpha_{\mu-1},
\end{gathered}
\]
et les valeurs correspondantes de \(v\) par
\[
v_0, v_1, v_2, v_3, \ldots v_{\mu-1},
\]
l'équation (30) donnera, en mettant à la place de \(\alpha\) successivement \(1, \alpha_1\), \(\alpha_2, \alpha_3, \ldots \alpha_{\mu-1}:\)
\[
\left\{\begin{array}{l}
\sqrt[\mu]{v_0}=x+\theta x+\theta^2 x+\cdots+\theta^{\mu-1} x \\
\sqrt[\mu]{v_1}=x+\alpha_1 \theta x+\alpha_1^2 \theta^2 x+\cdots+\alpha_1^{\mu-1} \theta^{\mu-1} x \\
\sqrt[\mu]{v_2}=x+\alpha_2 \theta x+\alpha_2^2 \theta^2 x+\cdots+\alpha_2^{\mu-1} \theta^{\mu-1} x \\
\cdots \cdots \cdots \cdots \\
\sqrt[\mu]{v_{\mu-1}}=x+\alpha_{\mu-1} \theta x+\alpha_{\mu-1}^2 \theta^2 x+\cdots \cdots+\alpha_{\mu-1}^{\mu-1} \theta^{\mu-1} x .
\end{array}\right.
\]

En ajoutant ces équations on aura
\[
x=\frac{1}{\mu}\left[-A+\sqrt[\mu]{v_1}+\ddot{\nu}_{v_2}+\sqrt[\mu]{v_3}+\cdots+\sqrt[\mu]{v_{\mu-1}}\right]
\]
où l'on a remplacé \(\stackrel{\mu}{v}_0\), qui est une quantité constante, par \(-A\).
On comnait par là la racine \(x\). Généralement on trouve la racine \(\theta^{\prime \prime} x\) en multipliant la première des équations (33) par 1 , la seconde par \(\alpha_1^{-m}\), la troisième par \(\alpha_8^{-m}\) etc., et en ajoutant; il viendra alors
\[
\theta^m x=\frac{1}{\mu}\left[-A+\alpha_1^{-m} \cdot \sqrt[\mu]{v_1}+\alpha_2^{-m} \cdot \sqrt[\mu]{v_2}+\cdots+\alpha_{\mu-1}^{-m} \cdot \sqrt{\nu}_{\nu_{\mu-1}}\right] .
\]

En donnant à \(m\) les valeurs \(0,1,2, \ldots, \iota-1\), on aura la valeur de toutes les racines de l'équation.
L'expression précédente des racines contient généralement \(\mu-1\) radi-
%490
racine de l'équation \(\varphi x=0\) n'en a que \(\mu\). Mais on peut donner à l'expression des racines une autre forme, qui n'est pas sujette à cette difficulté. En effet, lorsque la valeur de \(\sqrt[\mu]{v_1}\) est fixée, celle des autres radicaux le sera également, comme nous allons le voir.

Quel que soit le nombre \("\), , premier on non, on pent toujours trouver une racine \(\alpha\) de l'équation \(\alpha^\mu-1=0\), telle que les racines
\[
\alpha_1, \alpha_2, \alpha_3, \ldots \alpha_{\mu-1}
\]
puissent être représentées par
\[
\alpha, \alpha^2, \alpha^3, \ldots \alpha^{\mu-1} \text {. }
\]

Cela posé, on aura
\[
\left\{\begin{array}{l}
\stackrel{\mu}{v_k}=x+\alpha^k \cdot \theta x+\alpha^{2 k} \theta^2 x+\cdots+\alpha^{(\mu-1) k} \cdot \theta^{\mu-1} x \\
\sqrt[\mu]{v_1}=x+\alpha \cdot \theta x+\alpha^2 \theta^2 x+\cdots+\alpha^{\mu-1} \cdot \theta^{\mu-1} x
\end{array}\right.
\]
d'où l'on tire
\[
\left\{\begin{aligned}
\sqrt[\mu]{v_k} \cdot\left(\sqrt[\mu]{v_1}\right)^{\mu-k} & =\left(x+\alpha^k \theta x+\alpha^{2 k} \theta^2 x+\cdots+\alpha^{(\mu-1) k} \theta^{\mu-1} x\right) \\
& \times\left(x+\alpha \theta x+\alpha^2 \theta^2 x+\cdots+\alpha^{\mu-1} \theta^{\mu-1} x\right)^{\mu-k} .
\end{aligned}\right.
\]

Le second membre de cette équation est une fonction rationnelle de \(x\), qui ne changera pas de valeur en mettant au lieu de \(x\) une autre racine quelconque \(\theta^m x\), comme on le verra aisément, en faisant cette substitution et en ayant égard à l'équation \(\theta^{\mu+\nu} x=\theta^\nu x\). En désignant donc la fonction dont il s'agit par \(\psi x\), on aura
d'où
\[
\sqrt[\mu]{v_k} \cdot\left(\sqrt[\mu]{v_1}\right)^{\mu-k}=\psi x=\psi \theta x=\psi \theta^2 x=\cdots=\psi \theta^{\mu-1} x
\]
\[
\sqrt[\mu]{v_k} \cdot\left(\sqrt[\mu]{v_1}\right)^{\mu-k}=\frac{1}{\mu}\left(\psi x+\psi \theta x+\psi \theta^2 x+\cdots+\psi \theta^{\mu-1} x\right) .
\]

Le second membre de cette équation est une fonction rationnelle et symétrique des racines, donc on peut l'exprimer en quantités connues. En le désignant par \(a_k\), on aura
\[
\stackrel{\mu}{\mu}_{v_k}\left(\sqrt[\mu]{v_1}\right)^{\mu-k}=a_k
\]
d'où
%491
\[
\sqrt[\mu]{v_k}=\frac{a_k}{v_1}\left(\stackrel{\mu}{v_1}\right)^k
\]

A l'aide de cette formule l'expression de la racine \(x\) deviendra
\[
x=\frac{1}{\mu}\left(-A+\sqrt[\mu]{v_1}+\frac{a_2}{v_1}\left(\sqrt[\mu]{v_1}\right)^2+\frac{a_3}{v_1}\left(\sqrt[\mu]{v_1}\right)^3+\cdots+\frac{a_{\mu-1}}{v_1}\left(\sqrt[\mu]{v_1}\right)^{\mu-1}\right)
\]

Cette expression de \(x\) n'a que \(\boldsymbol{\iota}\) valeurs différentes, qu'on obtiendra en mettant au lieu de \(\sqrt[\mu]{v_1}\) les,\(\mu\) valeurs:
\[
\sqrt[\mu]{v_1}, \alpha \sqrt[\mu]{v_1}, \alpha^2 \sqrt[\mu]{v_1}, \ldots \alpha^{\mu-1} \sqrt[\mu]{v_1} \text {. }
\]

La méthode que nous avons suivie précédemment pour résoudre l'équation \(\varphi x=0\) est au fond la même que celle dont s'est servi M. Gauss dans ses "Disquisitiones arithmeticae" art. 359 et suiv. pour résoudre une certaine classe d'équations, auxquelles il était parvenu dans ses recherches sur l'équation \(x^n-1=0\). Ces équations ont la même propriété que notre équation \(\varphi x=0\); savoir que toutes ses racines peuvent être représentées par
\[
x, \theta x, \theta^2 x, \ldots \theta^{\mu-1} x
\]
\(\theta x\) étant une fonction rationnelle.
En vertu de ce qui précède nous pourrons énoncer le théorème suivant:
Théorème III. Si les racines d'une équation algébrique peuvent être représentées par
\[
x, \theta x, \theta^2 x, \ldots \theta^{u-1} x
\]
où \(\theta^\mu x=x\), et où \(\theta x\) désigne une fonction rationnelle de \(x\) et de quantités connues, cette équation sera toujours résoluble algébriquement.
On en tire le suivant, comme corollaire:
Théorème IV. Si deux racines d'une équation irréductible, dont le degré est un nombre premier, sont tellement liées entre elles, qu'on puisse exprimer l'une rationnellement par l'autre, cette équation sera résoluble algébriquement.
En effet cela suit immédiatement de l'équation (11)
\[
\mu=m \cdot n
\]
car on doit avoir \(m=1\), si \(\mu\) est un nombre premier; et par conséquent les racines s'expriment par \(x, \theta x, \theta^2, \ldots, \ldots \theta^{n-1} x\).
%492
Dans le cas où toutes les quantités connues de \(\varphi x\) et \(\theta x\) sont réelles, les racines de l'équation \(\varphi x=0\) jouiront d'ine propriété remarquable, que nous allons démontrer.

Par ce qui précède on voit que \(a_{\mu-1}\) pent être exprimée rationnellement par les coefficiens de \(\varphi x\) et \(\theta x\), et par \(\alpha\). Donc si ces coefficiens sont réels, \(a_{\mu-1}\) doit avoir la forme
\[
a_{\mu-1}=a+b \sqrt{-1}
\]
où \(\sqrt{-1}\) n'entre qu’à cause de la quantité \(\alpha\), qui en général est imaginaire, et qui geénéralement peut avoir la valeur
\[
\alpha=\cos \frac{2 \pi}{\mu}+\sqrt{-1} \cdot \sin \frac{2 \pi}{\mu} .
\]

En changeant donc dans \(\alpha\) le signe de \(\sqrt{-1}\) et désignant par \(a_{\mu-1}^{\prime}\) la valeur correspondante de \(a_{\mu-1}\), on aura
\[
a_{\mu-1}^{\prime}=a-b \sqrt{-1}
\]

Or d'après la formule (40), il est évident que \(a_{\mu-1}^{\prime}=a_{\mu-1}\); donc \(b=0\) et
\[
a_{\mu-1}=a \text {. }
\]

Donc \(a_{\mu-1}\) a toujours une valeur réelle. On démontrera de la même manière que
\[
v_1=c+d \sqrt{-1} \text { et } v_{\mu-1}=c-d \sqrt{\prime-1}
\]
où \(c\) et \(d\) sont réels.
Done
\[
\begin{array}{r}
v_1+v_{\mu-1}=2 c \\
v_1 v_{\mu-1}=a^\mu
\end{array}
\]

De là on tire
\[
v_1=c+\sqrt{-1} \cdot \sqrt{a^\mu-c^2}
\]
et par suite \(\sqrt{a^\mu-c^2}=d\); d'où l'on voit que \(\sqrt{a^\mu-c^2}\) a toujours une valeur réelle.
Cela posé, on peut faire
\[
c=(\sqrt{\varphi})^\mu \cos \delta, \sqrt{a^\mu-c^2}=(\sqrt{\varrho})^\mu \sin \delta,
\]
où \(@\) est une quantité positive.
On en tire
\[
c^2+\left(\sqrt{a^\mu-c^2}\right)^2=(\sqrt{\varrho})^{2 \mu}
\]
%493
c'est-à-dire:
\[
a^\mu=\omega^\mu
\]
par conséquent \(\varrho\) sera égal à la valeur numérique de \(a\). On voit en outre que \(a\) est toujours positif, si \(\boldsymbol{\mu}\) est \(u\) nombre impair.
Connaissant \(\rho\) et \(\delta\), on aura
\[
v_1=(\sqrt{\varrho})^\mu \cdot(\cos \delta+\sqrt{-1} \cdot \sin \delta)
\]
et par suite
\[
\sqrt[\mu]{v_1}=\sqrt{\varrho} \cdot\left[\cos \left(\frac{\delta+2 m \pi}{\mu}\right)+\sqrt{-1} \cdot \sin \left(\frac{\delta+2 m \pi}{\mu}\right)\right] .
\]

En substituant cette valeur de \(\sqrt[\mu]{v_1}\) dans l'expression de \(x\) (42), elle prendra la forme:
\[
\begin{aligned}
x=\frac{1}{\mu}[- & +\sqrt{\varrho} \cdot\left(\cos \frac{\delta+2 m \pi}{\mu}+\sqrt{-1} \cdot \sin \frac{\delta+2 m \pi}{\mu}\right) \\
& +(f+g \sqrt{-1})\left(\cos \frac{2(\delta+2 m \pi)}{\mu}+\sqrt{-1} \cdot \sin \frac{2(\delta+2 m \pi)}{\mu}\right) \\
+ & (F+G \sqrt{-1}) \sqrt{\varrho} \cdot\left(\cos \frac{3(\delta+2 m \pi)}{\mu}+\sqrt{-1} \cdot \sin \frac{3(\delta+2 m \pi)}{\mu}\right) \\
& +\left(f_1+g_1 \sqrt{-1}\right)\left(\cos \frac{4(\delta+2 m \pi)}{\mu}+\sqrt{-1} \cdot \sin \frac{4(\delta+2 m \pi)}{\mu}\right) \\
& +\cdots \ldots \ldots \ldots]
\end{aligned}
\]
où \(\varphi, A, f, g, F, G\) etc., sont des fonctions rationnelles de \(\cos \frac{2 \pi}{\mu}, \sin \frac{2 \pi}{\mu}\) et des coefficiens de \(\varphi x\) et \(\theta x\). On aura toutes les racines, en donnant a \(m\) les valeurs \(0,1,2,3, \ldots, u-1\).
L'expression précédente de \(x\) fournit ce résultat:
Théorème V. Pour résoudre l'équation \(\varphi x=0\), il suffit:
1) de diviser la circonférence entière du cercle en "
2) de diviser un angle \(\delta\), qu'on peut construire ensuite, en "“ parties égales,
3) d'extraire la racine carrée d'une seule quantité @.

Ce théorème n'est que l'extension d'un théorème semblable, que M. Gauss donne sans démonstration dans l'ouvrage cité plus haut, art. 360 .
Il est encore à remarquer que les racines de l'équation \(\varphi x=0\) sont
%494
ou toutes réelles ou toutes imaginaires. En effet si une racine \(x\) est réelle, les autres le sont également, comme le font voir les expressions
\[
\theta x, \theta^2 x, \ldots \theta^{\mu-1} x
\]
qui ne contiennent que des quantités réelles. Si au contraire \(x\) est imaginaire, les autres racines le sont aussi, car si par exemple \(\theta^n x\) était réelle, \(\boldsymbol{\theta}^{\mu-m}\left(\boldsymbol{\theta}^m x\right)=\boldsymbol{\theta}^\mu x=x\), le serait également, contre l'hypothèse. Dans le premier cas \(a\) sera positif et dans le second négatif. Si " est un nombre impair, toutes les racines seront réelles.

La méthode que nous avons donnée dans ce paragraphe, pour résoudre l'équation \(\varphi x=0\), est applicable dans tous les cas, le nombre \(\boldsymbol{\mu}\) étant premier ou non; mais si \(\boldsymbol{\mu}\) est un nombre composé, il existe encore une autre méthode qui donne lieu à quelques simplifications et que nous allons exposer en peu de mots.
Soit \(\boldsymbol{\mu}=m . n\), les racines
\[
x, \theta x, \theta^2 x, \ldots \theta^{\mu-1} x
\]
pourront être groupées de la manière suivante:
\[
\begin{aligned}
& x, \quad \theta^m x, \quad \theta^{2 m} x, \ldots \theta^{(n-1) m} x, \\
& \theta x, \quad \theta^{m+1} x, \quad \theta^{2 m+1} x, \ldots \theta^{(n-1) m+1} x, \\
& \theta^2 x, \quad \theta^{m+2} x, \theta^{2 m+2} x, \ldots \theta^{(n-1) m+2} x, \\
& \ldots \ldots \ldots \ldots \ldots \\
& \theta^{m-1} x, \theta^{2 m-1} x, \theta^{3 m-1} x, \ldots \theta^{m n-1} x . \\
&
\end{aligned}
\]

En faisant pour abréger:
\[
\begin{aligned}
\theta^m x & =\theta_1 x, \\
x=x_1, \theta x & =x_2, \theta^2 x=x_3, \ldots \theta^{m-1} x=x_m,
\end{aligned}
\]
on peut écrire les racines comme il suit:
\[
\left\{\begin{array}{r}
\left.1^{\prime}\right) x_1, \theta_1 x_1, \theta_1^2 x_1, \ldots \theta_1^{n-1} x_1 \\
\left.2^{\prime}\right) x_2, \theta_1 x_2, \theta_1^2 x_2, \ldots \theta_1^{n-1} x_2 \\
\ldots \ldots \ldots \cdot \ldots \\
\left.m^{\prime}\right) x_m, \theta_1 x_m, \theta_1^2 x_m, \ldots \theta_1^{n-1} x_m,
\end{array}\right.
\]

Donc en vertu de ce qu’on a vu (\$ 2) on pent décomposer l'équation \(\varphi x=0\), qui est du degré \(m\). \(n\), en \(m\) équations du degré \(n\), dont les coef-
%495
ficiens dépendront d'une équation du degré \(m\). Les racines de ces \(m\) équations seront respectivement les racines \(1^{\prime}, 2^{\prime}, \ldots m^{\prime}\).

Si \(n\) est un nombre composé \(m_1 n_1\), on peut décomposer de la même manière chacune des équations du degré \(n\) en \(m_1\) équations du degré \(n_1\), dont les coefficiens dépendront d'une équation du degré \(m_1\). Si \(n_1\) est encore un nombre composé, on peut continuer la décomposition de la même manière.
Théorème VI. En général, si l'on suppose
\[
\boldsymbol{\mu}=m_1 \cdot m_2 \cdot m_3 \ldots m_n,
\]
la résolution de l'équation proposée \(\varphi x=0\) sera ramenée à celle de \(n\) équations des degrés
\[
m_1, m_2, m_3, \ldots m_n \text {. }
\]

Il suffit même de comnaître une seule racine de chacune de ces équations, car si l'on connaît une racine de l'équation proposée, on aura toutes les autres racines, exprimées en fonctions rationnelles de celle-ci.

La méthode précédente est au fond la même que celle domnée par M. Giauss pour la réduction de l'équation à deux termes, \(x^\mu-1=0\).

Pour faire voir plus clairement la décomposition précédente de l'équation \(\varphi x=0\) en d'autres de degrés moins élevés, supposons par exemple \(\mu=30=5.3 .2\).
Dans ce cas les racines seront
\[
x, \theta x, \theta^2 x, \ldots \theta^{29} x \text {. }
\]

Nous formerons d'abord une équation du \(6^{\text {ìme }}\) degré, dont les racines seront
\[
x, \theta^5 x, \theta^{10} x, \theta^{15} x, \theta^{20} x, \theta^{25} x .
\]

Soit \(R=0\) cette équation, on peut déterminer ses coefficiens, ratiomnellement, par une même quantité \(y\), qui sera racine d'une équation du cinquième degré: \(P=0\).
Le degré de l'équation \(R=0\) étant lui-même un nombre composé, nous
\[
x, \theta^{10} x, \theta^{20} x
\]
et dont les coefficiens sont des fonctions rationnelles de \(y\), et d'une même quantité \(z\), qui est racine d'une équation du second degré \(P_1=0\), dans laquelle les coefficiens sont exprimés rationnellement par \(y\).
%496
Voici le tableau des opérations:
\[
\begin{aligned}
& x^3+f(y, z) \cdot x^2+f_1(y, z) \cdot x+f_2(y, z)=0, \\
& z^2+f y \cdot z+f_1 y=0 \\
& y^5+A_1 \cdot y^4+A_2 \cdot y^3+A_3 \cdot y^2+A_4 \cdot y+A_5=0 .
\end{aligned}
\]

On peut aussi commencer par une équation du \(2^{\text {ième }}\) degré en \(x\), ou bien par une équation du 5 ième degré.

Reprenons l'équation générale \(\varphi x=0\). En supposant \(\mu=m . n\), on peut faire
\[
x^n+f y \cdot x^{n-1}+f_1 y \cdot x^{n-2}+\cdots=0
\]
où \(y\) est déterminé par une équation du \(m^{\text{ième}}\) degré:
\[
y^m+A \cdot y^{m-1}+\cdots=0
\]
dont tous les coefficiens sont exprimés ratiomellement en quantités connues. Cela posé, soient
plusieurs manières de décomposer le nombre \(\boldsymbol{\mu}\) en deux facteurs, on pourra décomposer l'équation proposée \(\varphi x=0\) en deux autres des \(\omega\) manières suivantes:
(1) \(\left\{\begin{array}{l}F_1\left(x, y_1\right)=0, \text { dont les racines seront } x, \theta^{m_1} x, \theta^{2 m_1} x, \ldots \theta^{\left(n_1-1\right) m_1} x \\ \text { et les coefficiens des fonctions rationnelles d'une quantité } y_1 \text {, ra- } \\ \text { cine d'une équation }\end{array}\right.\) cine d'une équation \(f_1 y_1=0\), du degré \(m_1\).
(2) \(\left\{\begin{array}{l}F_2\left(x, y_2\right)=0 \text {, dont les racines seront } x, \theta^{m_2} x, \theta^{2 m_2} x, \ldots \theta^{\left(n_2-1\right) m_2} x \\ \text { et les coefficiens des fonctions rationnelles d'une même quantité } \\ y_2, \text { racine d'une équation } f_2 y_2=0, \text { du degré } m_2 .\end{array}\right.\)
(w) \(\left\{\begin{array}{l}F_\omega\left(x, y_\omega\right)=0, \text { dont les racines seront } x, \theta^{m \omega} x, \theta^{2 m_\omega} x, \ldots \theta^{\left(n_\omega-1\right) m_\omega} x \\ \text { et les coefficiens des fonctions rationnelles d'une même quantité } \\ y_\omega, \text { racine d'une équation } f_\omega y_\omega=0, \text { du degré } m_\omega .\end{array}\right.\)
Supposons maintenant que \(m_1, m_2, \ldots m_\omega\) pris deux à deux, soient premiers entre eux, je dis qu'on pourra exprimer la valeur de \(x\) rationnelle-
%497
ment par les quantités \(y_1, y_2, y_3, \ldots y_\omega\). En effet, si \(m_1, m_2, \ldots m_\omega\) sont premiers entre eux, il est clair qu'il n'y a qu'une seule racine qui satisfasse à la fois à toutes les équations
\[
F_1\left(x, y_1\right)=0, F_2\left(x, y_2\right)=0, \ldots F_\omega\left(x, y_\omega\right)=0
\]
savoir la racine \(x\). Done, suivant un théorème connu, on peut exprimer \(x\) rationnellement par les coefficiens de ces équations et conséquemment par les quantités \(y_1, y_2, \ldots y_\omega\).

La résolution de l'équation proposée est donc ramenée à celle de \(\omega\) équations: \(f_1 y_1=0 ; f_2 y_2=0 ; \ldots f_\omega y_\omega=0\), qui sont respectivement des degrés: \(m_1, m_2, \ldots m_{t v}\), et dont les coefficiens sont des fonctions rationnelles des coefficiens de \(\varphi x\) et \(\theta x\).
Si l'on veut que les équations
\[
f_1 y_1=0, f_2 y_2=0, \ldots f_\omega y_\omega=0
\]
soient les moins élevées possibles, il faut choisir \(m_1, m_2, \ldots m_w\) tels, que ces nombres soient des puissances de nombres premiers. Par exemple si l'équation proposée \(\varphi x=0\) est du degré
\[
\boldsymbol{\iota}=\varepsilon_1^{\nu_1} \cdot \varepsilon_2^{\nu_2} \ldots \varepsilon_\omega^{\nu_\omega}
\]
où \(\varepsilon_1, \varepsilon_2, \ldots \varepsilon_\omega\) sont des nombres premiers différens, on aura
\[
m_1=\varepsilon_1^{\nu_1}, m_2=\varepsilon_2^{\nu_3}, \ldots m_\omega=\varepsilon_\omega^{\nu_\omega} .
\]

L'équation proposée étant résoluble algébriquement, les équations (56) le seront aussi; car les racines de ces équations sont des fonctions rationnelles de \(x\). On peut aisément les résoudre de la manière suivante.

La quantité \(y\) est une fonction rationnelle et symétrique des racines de l'équation (52), c'est-à-dire de
\[
x, \theta^m x, \theta^{2 m} x, \ldots \theta^{(n-1) m} x \text {. }
\]

Soit
\[
y=F x=f\left(x, \theta^m x, \theta^{2 m} x, \ldots \theta^{(n-1) m} x\right)
\]
les racines de l'équation (53) seront
\[
F x ; F(\theta x) ; F\left(\theta^2 x\right) ; \ldots F\left(\theta^{m-1} x\right)
\]
or je dis que l'on peut exprimer ces racines de la manière suivante:
\[
y, \lambda y, \lambda^2 y, \ldots \lambda^{m-1} y
\]
%498
où \(\lambda y\) est une fonction rationnelle de \(y\) et de quantités comnues.
On aura
\[
\boldsymbol{F}(\boldsymbol{\theta} x)=f\left[\theta x, \boldsymbol{\theta}\left(\boldsymbol{\theta}^m x\right), \boldsymbol{\theta}\left(\boldsymbol{\theta}^{2 n} x\right), \ldots \theta\left(\theta^{(n-1) m} x\right)\right]
\]
donc \(F(\theta x)\) sera, ainsi que \(F x\), une fonction rationnelle et symétrique des racines \(x, \theta^m x, \ldots \theta^{(n-1) m} x\), donc on peut, par le procédé trouvé \((24)\) exprimer \(F(\theta x)\) rationuellement par \(F x\). Soit donc
\[
F \theta x=\lambda F x=\lambda y, .
\]
on aura, en remplaçant (en vertu du théorème I) \(x\) par \(\theta x, \theta^2 x, \ldots \theta^{n-1} x\),
\[
\begin{gathered}
F \theta^2 x=\lambda F \theta x=\lambda^2 y, \\
F \theta^3 x=\lambda F \theta^2 x=\lambda^3 y, \\
\cdots \cdots \cdots \cdot \cdots \cdot \cdots \cdot \cdots \theta^{m-2} x=\lambda^{m-1} y,
\end{gathered}
\]
c. q. f. d.
Maintenant les racines de l'équation (53) pouvant être représentées par
\[
y, \lambda y, \lambda^2 y, \ldots \lambda^{m-1} y
\]
on peut résoudre algébriquement cette équation de la même manière que l'équation \(\varphi x=0\). (Voyez le théorème III).

Si \(m\) est une puissance d'un nombre premier, \(m=\varepsilon^\nu\), on peut encore déterminer \(y\) à l'aide de \(\nu\) équations du degré \(\varepsilon\). (Voyez le théorème VI).

Si daus le théorème VI on suppose que "u soit une puissance de 2 , on aura, comme corollaire, le théorème suivant:

Théorème VII. Si les racines d'une équation du degré \(2^\omega\) peuvent être représentées par
\[
x, \theta x, \theta^2 x, \ldots \theta^{2^{\omega 0}-1} x \text {, où } \theta^{2^\omega} x=x
\]
cette équation pourra être résolue à l'aide de l'extraction de \(\omega\) racines carrées.

Ce théorème, appliqué à l'équation \(\frac{x^{1+2^\omega}-1}{x-1}=0\), où \(1+2^\omega\) est un . nombre premier, donne le théorème de M. Gauss pour le cercle.
%499
\(\S 4\).
Des équations dont toutes les racines peuvent étre exprimées ratiomellement par l'une d'entre elles.

Nous avons vu précédemment (théorème III) qu'une équation d'um degré quelconque, dont les racines peuvent être exprimées par
\[
x, \theta x, \theta^2 x, \ldots \theta^{\mu-1} x
\]
est toujours résoluble algébriquement. Dans ce cas toutes les racines sont exprimées ratiomnellement par l'une d'entre elles; mais une équation dont les racines ont cette propriété, n'est pas toujours résoluble algébriquement; néanmoins, hors le cas considéré précédemment, il y a encore un autre, dans lequel cela a lieu. On aura le théorème suivant:

Théorème VIII. Soit \(\chi x=0\) une équation algébrique quelconque dont toutes les racines peuvent être exprimées rationnellement par l'une d'entre elles, que nous désignerons par \(x\). Soient \(\theta x\) et \(\theta_1 x\) deux autres racines quelconques, l'équation proposée séra résoluble algébriquement, si l'on a \(\theta \theta_1 x=\theta_1 \theta x\).

La démonstration de ce théorème peut être réduite sur le champ à la théorie exposée \(\S 2\), comme nous allons le voir.

Si l'on comnaît la racine \(x\), on en aura en même temps toutes les autres; il suffit donc de chercher la valeur de \(x\).
Si l'équation
\[
\chi x=0
\]
n'est pas irréductible, soit
\[
\varphi x=0
\]
l'équation la moins élevée à laquelle puisse satisfaire la racine \(x\), les coefficiens de cette équation ne contenant que des quantités connues. Alors les racines de l'équation \(\varphi x=0\) se trouveront parmi celles de l'équation \(\chi x=0\) (voyez le premier théorème), et par conséquent elles pourront s'exprimer rationnellement par l'une d'entre elles.

Cela posé, soit \(\theta x\) une racine différente de \(x\); en vertu de ce qu'on a vu dans le premier paragraphe, les racines de l'équation \(\varphi x=0\) pourront être exprimées comme il suit:
%500
\[
\begin{aligned}
& x, \quad \theta x, \quad \theta^2 x, \ldots \theta^{n-1} x \\
& x_1, \quad \theta x_1, \quad \theta^2 x_1, \ldots \theta^{n-1} x_1, \\
& \ldots \ldots \cdot \ldots \cdot \theta^{n-1} x_{m-1},
\end{aligned}
\]
et en formant l'équation
\[
x^n+A^{\prime} x^{n-1}+A^{\prime \prime} x^{n-2}+A^{\prime \prime \prime} x^{n-3}+\cdots+A^{(n-1)} x+A^{(n)}=0,
\]
dont les racines sont \(x, \theta x, \theta^2 x, \ldots \theta^{n-1} x\), les coefficiens \(A^{\prime}, A^{\prime \prime}, \ldots A^{(n)}\) pourront être exprimés rationnellement par une même quantité \(y\), qui sera racine d'une équation irréductible*):
\[
y^m+p_1 y^{m-1}+p_2 y^{m-2}+\cdots+p_{m-1} y+p_m=0
\]
dont les coefficiens sont des quantités comnues (voyez § 2).
La détermination de \(x\) pent s'effectuer à l'aide des deux équations (66) et (67). La première de ces équations est résoluble algébriquement, en supposant comnus les coefficiens, c'est-ì-dire la quantité \(y\) (voyez le théorème III). Quant à l'équation en \(y\), nous allons démontrer que ses racines ont la même propriété que celles de l'équation proposée \(\varphi x=0\), savoir d'être exprimables rationnellement par l'une d'entre elles.

La quantité \(y\) est (voy. 15) une certaine fonction rationnelle et symétrique des racines \(x, \theta x, \theta^2 x, \ldots \theta^{n-1} x\). En faisant
\[
y=f\left(x, \theta x, \theta^2 x, \ldots \theta^{n-1} x\right)
\]
les autres racines de l'équation (67) seront
\[
\begin{gathered}
y_1=f\left(x_1, \theta x_1, \theta^2 x_1, \ldots \theta^{n-1} x_1\right) \\
\ldots \ldots \ldots \\
y_{m-1}=f\left(x_{m-1}, \theta x_{m-1}, \theta^2 x_{m-1}, \ldots \theta^{n-1} x_{m-1}\right) .
\end{gathered}
\]
*) On démontrera aisément que cette équation ne pourra être réductible. Soit \(R=0\) l'équation irréductible en \(y\), et \(\nu\) son degré. En éliminant \(y\), on aura une équation en \(x\) du degré \(n \nu\); donc \(n \nu>\mu\). Mais on a
done
\[
\begin{gathered}
\mu=m \cdot n, \\
\nu \equiv m,
\end{gathered}
\]
ce qui est impossible, car \(v\) est moindre que \(m\).
%501
Maintenant, dans le cas que nous considérons, \(x_1, \ldots x_{m-1}\) sont des fonctions ratiomnelles de la racine \(x\). Faisons par conséquent
\[
x_1=\theta_1 x, x_2=\theta_2 x, \ldots x_{m-1}=\theta_{s-1} x,
\]
les racines de l'équation (67) auront la forme:
\[
y_1=f\left(\theta_1 x, \theta \theta_1 x, \theta^2 \theta_1 x, \ldots \theta^{n-1} \theta_1 x\right) .
\]
1)'après l'hypothèse les fonctions \(\theta\) et \(\theta_1\) ont la propriété que
\[
\theta \theta_1 x=\theta_1 \theta x
\]
équation qui, en vertu du théorème I, aura lieu en substituant à la place de \(x\) une autre racine quelconque de l'équation \(\varphi x=0\). On en tire successivement
\[
\begin{gathered}
\theta^2 \theta_1 x=\theta \theta_1 \theta x=\theta_1 \theta^2 x \\
\theta^3 \theta_1 x=\theta \theta_1 \theta^2 x=\theta_1 \theta^3 x \\
\cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \\
\theta^{n-1} \theta_1 x=\theta \theta_1 \theta^{n-2} x=\theta_1 \theta^{n-1} x
\end{gathered}
\]

L'expression de \(y_1\) deviendra par là
\[
y_1=f\left(\theta_1 x, \theta_1 \theta x, \theta_1 \theta^3 x, \ldots \theta_1 \theta^{n-1} x\right)
\]
et l'on voit que \(y_1\), comme \(y\), est une fonction rationnelle et symétrique des racines
\[
x, \theta x, \theta^2 x ; \ldots \theta^{n-1} x .
\]

Done ( \(§ 2\) ) on peut exprimer \(y_1\) rationnellement par \(y\) et des quantités connues. Le même raisonnement s'applique à toute autre racine de l'équation \((67)\).
Soient maintenant \(\lambda y, \lambda_1 y\) deux racines quelconques, je dis qu'on aura
\[
\lambda \lambda_1 y=\lambda_1 \lambda y \text {. }
\]

En effet, ayant par exemple
si
\[
\lambda y=f\left(\theta_1 x, \theta \theta_1 x, \ldots \theta^{n-1} \theta_1 x\right)
\]
\[
y=f\left(x, \theta x, \ldots \theta^{n-1} x\right)
\]
on aura, en mettant \(\theta_2 x\) au lieu de \(x\),
\[
\lambda y_2=f\left(\theta_1 \theta_2 x, \theta \theta_1 \theta_2 x, \ldots \theta^{n-1} \theta_1 \theta_2 x\right),
\]
où
%502
done
\[
y_2=f\left(\theta_2 x, \theta \theta_2 x, \ldots \theta^{n-1} \theta_2 x\right)=\lambda_1 y
\]
\[
\lambda \lambda_1 y=f\left(\theta_1 \theta_2 x, \theta \theta_1 \theta_2 x, \ldots \theta^{n-1} \theta_1 \theta_2 x\right)
\]
et également
\[
\lambda_1 \lambda y=f\left(\theta_2 \theta_1 x, \theta \theta_2 \theta_1 x, \ldots \theta^{n-1} \theta_2 \theta_1 x\right),
\]
donc, puisque \(\theta_1 \theta_2 x=\theta_2 \theta_1 x\),
\[
\lambda \lambda_1 y=\lambda_1 \lambda y
\]

Les racines de l'équation (67) auront donc précisément la même propriété que celles de l'équation \(\varphi x=0\).

Cela posé, on peut appliquer à l'équation (67) le même procédé qu’à l'équation \(\varphi x=0\); c'est-à-dire que la détermination de \(y\) peut s'effectuer à l'aide de deux équations, dont l'une sera résoluble algébriquement et l'autre aura la propriété de l'équation \(\varphi x=0\). Donc le même procédé peut encore être appliqué à cette dernière équation. En continuant, il est clair que la détermination de \(x\) pourra s'effectuer à l'aide d'un certain nombre d'équations, qui seront toutes résolubles algébriquement. Donc enfin l'équation \(\varphi x=0\) sera résoluble à l'aide d'opérations algébriques, en supposant connues les quantités qui avec \(x\) composent les fonctions
\[
\varphi x, \theta x, \theta_1 x, \theta_2 x, \ldots \theta_{m-1} x .
\]

Il est clair que le degré de chacme des équations auxquelles se réduit la détermination de \(x\), sera un facteur du nombre "u qui marque le degré de l'équation \(\varphi x=0\); et:

Théorème IX. Si l'on désigne les degrés de ces équations respectivement par
on aura
\[
n, n_1, n_z, \ldots n_t
\]
\[
\mu=n \cdot n_1 \cdot n_2, \ldots n_\omega \text {. }
\]

En rapprochant ce qui précède de ce qui a été exposé (§ 3\()\), on aura le théorème suivant:

Théorème X. En supposant le degré \(\mu\) de l'équation \(\varphi x=0\) décomposé comme il suit:
\[
\mu=\varepsilon_1^{\nu_1} \cdot \varepsilon_2^{\nu_2} \cdot \varepsilon_3^{\nu_3} \ldots \varepsilon_\alpha^{v_\alpha}
\]
où \(\varepsilon_1, \varepsilon_2, \varepsilon_3, \ldots \varepsilon_\alpha\) sont des nombres premiers, la détermination de \(x\) pourra s'effectner à l'aide de la résolution de \(\nu_1\) équations du degré \(\varepsilon_1\), de \(\nu_2\) équa-
%503
tions du degré \(\varepsilon_2\), etc., et toutes ces équations seront résolubles algébriquement.

Dans le cas où \(\mu=2^v\), on peut trouver la valeur de \(x\) à l'aide de l'extraction de \(\nu\) racines carrées.
Application aux fonctions circulaires.
En désignant par a la quantité \(\frac{2 \pi}{\mu}\), on sait qu'on peut trouver une équation algébrique du degré, \(\boldsymbol{\iota}\) dont les racines seront les \(\boldsymbol{\mu}\) quantités
\[
\cos a, \cos 2 a, \cos 3 a, \ldots \cos \mu a,
\]
et dont les coefficiens seront des nombres rationnels. Cette équation sera
\[
x^\mu-\frac{1}{4}, \mu x^{\mu-2}+\frac{1}{16} \frac{\mu(\mu-3)}{1.2} \cdot x^{\mu-4}-\cdots=0 .
\]

Nous allons voir que cette équation a la même propriété que l'équation \(\chi x=0\), considérée dans le paragraphe précédent.
Soit \(\cos a=x\), on aura d'après une formule connue, quel que soit \(a\),
\[
\cos m a=\theta(\cos a)
\]
où \(\theta\) désigne une fonction entière. Donc \(\cos m a\), qui exprime une racine quelconque de l'équation \((70)\), sera une fonction rationnelle de la racine \(x\). Soit \(\theta_1 x\) une autre racine, je dis qu'on aura
\[
\theta \theta_1 x=\theta_1 \theta x \text {. }
\]

En effet, soit \(\theta_1 x=\cos m^{\prime} a\), la formule (71) donnera, en mettant \(m^{\prime} a\) au lieu de \(a\),
\[
\cos \left(m m^{\prime} a\right)=\theta\left(\cos m^{\prime} a\right)=\theta \theta_1 x
\]

De la même manière on aura
\[
\cos \left(m^{\prime} m a\right)=\theta_1(\cos m a)=\theta_1 \theta x
\]
done
\[
\theta \theta_1 x=\theta_1 \theta x
\]

Done, suivant ce quon a vu dans le paragraphe précédent,
\[
x \text { ou } \cos a=\cos \frac{2 \pi}{\mu}
\]
poura être déterniné algébriquement. Cela est comnu.
%504
Supposons maintenant que \(\mu\) soit in nombre premier \(2 n+1\), les racines de l'équation (70) seront
\[
\cos \frac{2 \pi}{2 n+1}, \quad \cos \frac{4 \pi}{2 n+1}, \cdots \cos \frac{4 n \pi}{2 n+1}, \cos 2 \pi
\]

La dernière racine \(\cos 2 \pi\) est égale à l'unité; done l'équation (70) est divisible par \(x-1\). Les autres racines seront toujous égales entre elles par couples, car on a \(\cos \frac{2 m \pi}{2 n+1}=\cos \frac{(2 n+1-m) 2 \pi}{2 n+1}\), donc on peut trouver une équation dont les racines seront,
\[
\cos \frac{2 \pi}{2 n+1}, \cos \frac{4 \pi}{2 n+1}, \cdots \cos \frac{2 n \pi}{2 n+1} .
\]

Cette équation sera
\[
\begin{aligned}
& x^n+\frac{1}{2} x^{n-1}-\frac{1}{4}(n-1) x^{n-2}-\frac{1}{8}(n-2) x^{n-3} \\
& \quad+1 \frac{(n-2)(n-3)}{1.2} x^{n-4}+\frac{1}{32} \frac{(n-3)(n-4)}{1.2} x^{n-5}-\cdots=0 .
\end{aligned}
\]

Cela posé, soit
\[
\cos \frac{2 \pi}{2 n+1}=x=\cos a,
\]
on auraa d'après ce qui précède
\[
\cos \frac{2 m \pi}{2 n+1}=\theta x=\cos m a .
\]

L'équation (73) sera donc satisfaite par les racines
\[
x, \theta x, \theta^2 x, \theta^3 x, \ldots
\]

On a, quelle que soit la valeur de \(a\),
\[
\theta(\cos a)=\cos m a \text {. }
\]

De là on tire successivement:
\[
\begin{gathered}
\theta^2(\cos a)=\boldsymbol{\theta}(\cos m a)=\cos m^2 a \\
\theta^3(\cos a)=\theta\left(\cos m^2 a\right)=\cos m^3 a \\
\cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \\
\boldsymbol{\theta}^\mu(\cos a)=\boldsymbol{\theta}\left(\cos m^{\mu-1} a\right)=\cos m^\mu a
\end{gathered}
\]

Les racines (74) deviendront donc
\[
\cos a, \cos m a, \cos m^2 a, \cos m^3 a, \ldots \cos m^\mu a, \ldots
\]
%505
Cela posé, si \(m\) est une racine primitive pour le module \(2 n+1\) (voyez Gauss Disquis. arithm. art. 57), je dis que toutes les racines
\[
\cos a, \cos m a, \cos m^2 a, \ldots \cos m^{n-1} a
\]
seront différentes entre elles. En effet si l'on avait
\[
\cos m^\mu a=\cos m^\nu a,
\]
où \(\mu\) et \(\nu\) sont moindres que \(n\), on en tirerait
\[
m^\mu a= \pm m^v a+2 k \pi
\]
où \(k\) est entier. Cela donne, en remettant pour \(a\) sa valeur \(\frac{2 \pi}{2 n+1}\),
done
\[
m^\mu= \pm m^\nu+k(2 n+1)
\]
\[
m^\mu \mp m^\nu=m^\nu\left(m^{\mu-\nu} \mp 1\right)=k(2 n+1)
\]
et par conséquent \(m^{2(\mu-\nu)}-1\) serait divisible par \(2 n+1\), ce qui est impossible, car \(2(\mu-\nu)\) est moindre que \(2 n\), et nous avons supposé que \(m\) est une racine primitive.
On aura encore
\[
\cos m^n a=\cos a
\]
car \(m^{2 n}-1\) ou \(\left(m^n-1\right)\left(m^n+1\right)\) est divisible par \(2 n+1\), done
\[
m^n=-1+k(2 n+1)
\]
et par suite
\[
\cos m^n a=\cos (-a+k .2 \pi)=\cos a .
\]

Par la on voit que les \(n\) racines de l'équation (73) pourront s'exprimer par (76); c'est-à-dire par:
\[
x, \theta x, \theta^3 x, \theta^3 x, \ldots \theta^{n-1} x \text {, où } \theta^n x=x .
\]

Donc, en vertu du théorème III, cette équation sera résoluble algébriquement.

En faisant \(n=m_1 \cdot m_2 \ldots m_w\), on peut diviser la circonférence entière du cercle en \(2 n+1\) parties égales, à l'aide de \(\omega\) équations des degrés \(m_1\), \(m_2, m_3, \ldots m_\omega\). Si les nombres \(m_1, m_2, \ldots m_w\) sont premiers entre eux, les coefficiens de ces équations seront des nombres rationnels.

En supposant \(n=2^\omega\), on aura le théorème connu sur les polygones réguliers qui peuvent être construits géométriquenent.

En vertu dı théorème \(V\) on voit que pour diviser la circonférence entière du cercle en \(2 n+1\) parties égales, il suffit
%506
1) de diviser la circonférence entière du cercle en \(2 n\) parties égales,
2) de diviser un arc, qu'on peut construire ensuite, en \(2 n\) parties égales,
3) et d'extraire la racine carrée d'une seule quantité @.
M. Gauss a énoncé ce théorème dans ses Disquis., et il ajoute. que la quantité dont il faut extraire la racine, sera égale à \(2 n+1\). C'est ce qu’on peut démontrer aisément comme il suit.
On a vu \((40,38,46)\) que \(\varrho\) est la valeur numérique de la quantité
\[
\left(x+\alpha \theta x+\alpha^2 \theta^2 x+\cdots+\alpha^{n-1} \theta^{n-1} x\right)\left(x+\alpha^{n-1} \theta x+\alpha^{n-2} \theta^2 x+\cdots+\alpha \theta^{n-1} x\right),
\]
où \(\alpha=\cos \frac{2 \pi}{n}+\sqrt{-1} \cdot \sin \frac{2 x}{n}\). En substituant pour \(x, \theta x, \ldots\) leurs valeurs \(\cos a, \cos m a, \cos m^2 a, \ldots\) on aura
\[
\begin{aligned}
\pm \varrho & =\left(\cos a+\alpha \cos m a+\alpha^2 \cos m^2 a+\cdots+\alpha^{n-1} \cos m^{n-1} a\right) \\
& \times\left(\cos a+\alpha^{n-1} \cos m a+\alpha^{n-2} \cos m^2 a+\cdots+\alpha \cos m^{n-1} a\right) .
\end{aligned}
\]

En développant et en mettant \(\pm \varrho\) sous la forme
\[
\pm \varrho=t_0+t_1 \alpha+t_2 \alpha^2+\cdots+t_{n-1} \alpha^{n-1}
\]
on trouvera facilement
\[
\begin{aligned}
t_\mu & =\cos a \cdot \cos m^\mu a+\cos m a \cdot \cos m^{\mu+1} a+\cdots+\cos m^{n-1-\mu} a \cdot \cos m^{n-1} a \\
& +\cos m^{n-\mu} a \cdot \cos a+\cos m^{n-\mu+1} a \cdot \cos m a+\cdots+\cos m^{n-1} a \cdot \cos m^{\mu-1} a .
\end{aligned}
\]

Maintenant on a
\[
\cos m^\nu a \cdot \cos m^{\mu+v} a=\frac{1}{2} \cos \left(m^{\mu+\nu} a+m^\nu a\right)+\frac{1}{2} \cos \left(m^{\mu+v} a-m^\nu a\right),
\]
done
\[
\begin{array}{r}
t_\mu=\frac{1}{2}\left[\cos \left(m^\mu+1\right) a+\cos \left(m^\mu+1\right) m a+\cdots+\cos \left(m^\mu+1\right) m^{n-1} a\right] \\
\quad+\frac{1}{2}\left[\cos \left(m^\mu-1\right) a+\cos \left(m^\mu-1\right) m a+\cdots+\cos \left(m^\mu-1\right) m^{n-1} a\right] .
\end{array}
\]

Si l'on fait \(\left(m^\mu+1\right) a=a^{\prime},\left(m^\mu-1\right) a=a^{\prime \prime}\), on aura
\[
\begin{aligned}
t_\mu & =\frac{1}{2}\left[\cos a^{\prime}+\theta\left(\cos a^{\prime}\right)+\theta^2\left(\cos a^{\prime}\right)+\cdots+\theta^{n-1}\left(\cos a^{\prime}\right)\right] \\
& +\frac{1}{2}\left[\cos a^{\prime \prime}+\theta\left(\cos a^{\prime \prime}\right)+\theta^2\left(\cos a^{\prime \prime}\right)+\cdots+\theta^{n-1}\left(\cos a^{\prime \prime}\right)\right]
\end{aligned}
\]

Cela posé, il y a deux cas, savoir: \(\mu\) est différent de zéro ou non. Dans le premier cas il est clair que \(\cos a^{\prime}\) et \(\cos a^{\prime \prime}\) sont des racines de l'équation (73), donc \(\cos a^{\prime}=\theta^\delta x, \cos a^{\prime \prime}=\theta^{\varepsilon} x\). En substituant, il viendra, en remarquant que \(\theta^n x=x\) :
%507
\[
\begin{array}{r}
t_\mu=\frac{1}{2}\left(\theta^\delta x+\theta^{\delta+1} x+\cdots+\theta^{n-1} x+x+\theta x+\cdots+\theta^{\delta-1} x\right) \\
+\frac{1}{2}\left(\theta^\delta x+\theta^{\varepsilon+1} x+\cdots+\theta^{n-1} x+x+\theta x+\cdots+\theta^{\varepsilon-1} x\right)
\end{array}
\]
done
\[
t_\mu=x+\theta x+\theta^2 x+\cdots+\theta^{n-1} x
\]
c'est-à-dire que \(t_\mu\) est égal à la somme des racines; par suite, en vertu de l'équation (73),
\[
t_\mu=-\frac{1}{2} \text {. }
\]

Dans le cas où \(\boldsymbol{\mu}=0\), la valeur de \(t_\mu\) deviendra:
\[
t_0=\frac{1}{2}\left(\cos 2 a+\cos 2 m a+\cdots+\cos 2 m^{n-1} a\right)+\frac{1}{2} n
\]
or \(\cos 2 a\) est une racine de l'équation (73), done en faisant
\[
\cos 2 a=\theta^\delta x
\]
on aura
\[
\begin{aligned}
& \cos 2 a+\cos 2 m a+\cdots+\cos 2 m^{n-1} a \\
& \quad=\theta^\delta x+\theta^{\delta+1} x+\cdots+\theta^{n-1} x+x+\theta x+\cdots+\theta^{\delta-1} x=-\frac{1}{2},
\end{aligned}
\]
par conséquent
\[
t_0=\frac{1}{2} n-\frac{1}{4} .
\]

En vertu de ces valeurs de \(t_0\) et \(t_\mu\), la valeur de \(\pm \varrho\) deviendra:
\[
\pm \rho=\frac{1}{2} n-\frac{1}{4}-\frac{1}{2}\left(\alpha+\alpha^2+\alpha^3+\cdots+\alpha^{n-1}\right)
\]
mais \(\alpha+\alpha^2+\alpha^3+\cdots+\alpha^{n-1}=-1\), done
\[
\pm \varrho=\frac{1}{2} n+\frac{1}{4}
\]
et puisque \(\rho\) est essentiellement positif,
\[
\varrho=\frac{2 n+1}{4} .
\]

Cette valeur de o donne
\[
\sqrt{0}=\frac{1}{2} \cdot \sqrt{2 n+1}
\]
done la racine carrée qu'il faut extraire est celle du nombre \(2 n+1\), comme le dit M. Gouss*).
Christiania, le 29 mars 1828.
*) Dans le cas où \(n\) est un nombre impair, on peut même se dispenser de l'extraction de cette racine carrée.
%508
XXVI.

THÉORÈMES SUR LES FONCTIONS ELLIPTIQUES.

Journal für die reine und angewandte Mathematik, herausgegeben von Crelle, Bd. 4, Berlin 1829.

La formule donnée par M. Jacobi dans le tome III p. 86 de ce journal peut être établie facilement à l'aide d'un théorème que nous allons démontrer dans ce qui suit.

En faisant \(\varphi \theta=x\), on aura, en vertu de ce qu'on a vu dains le \(\S\) III du mémoire \(\mathrm{n}^0 12\) tome II de ce journal*)
\[
\varphi(2 n+1) \theta=R,
\]
où \(R\) est une fonction rationnelle de \(x\), le numérateur étant du degré \((2 n+1)^2\) et le dénominateur du degré \((2 n+1)^2-1\). L'équation (1) est done du degré \((2 n+1)^2\) et ses racines peuvent être exprimées par la formule:
\[
x=\varphi\left(\theta+\frac{2 m \omega+2 \mu \widetilde{\omega} i}{2 n+1}\right),
\]
en donnant à \(m\) et \(\mu\) tontes les valeurs entières depuis zéro jusqu'à \(2 n\). Soit pour abréger
\[
\frac{2 \omega}{2 n+1}=\alpha, \frac{2 \pi i}{2 n+1}=\beta,
\]
l'expression des racines sera
\[
x=\varphi(\theta+m \alpha+\mu \beta) .
\]
*) Mémnire XVI de cette édition.
%509
Cela posé, nous allons démontrer le théorème suivant:
Théorème I. Soit \(\psi \boldsymbol{\theta}\) une fonction entière quelconque des quantités \(\varphi(\theta+m \alpha+\mu \beta)\) qui reste la même en changeant \(\boldsymbol{\theta}\) en \(\boldsymbol{\theta}+\boldsymbol{\alpha}\) et en \(\boldsymbol{\theta}+\boldsymbol{\beta}\). Soit \(\nu\) le plus grand exposant de la quantité \(\varphi \boldsymbol{\theta}\) dans la fonction \(\psi \boldsymbol{\theta}\), on aura toujours
\[
\psi \boldsymbol{\theta}=p+q \cdot f(2 n+1) \boldsymbol{\theta} \cdot \boldsymbol{F}(2 n+1) \boldsymbol{\theta},
\]
\(p\) et \(q\) étant deux fonctions entières de \(\varphi(2 n+1) \theta\), la première du degré \(\boldsymbol{\nu}\) et la seconde du degré \(\boldsymbol{\nu}-2\).
Démonstration. En vertu de la formule (10) tome II p. 105*) on a
\[
\varphi(\theta+m \alpha+\mu \beta)=\frac{q \theta \cdot f(m \alpha+\mu \beta) \cdot F(m \alpha+\mu \beta)+\varphi(m \alpha+\mu \beta) \cdot f \theta \cdot F \theta}{1+e^2 c^2 \cdot \varphi^2(m \alpha+\mu \beta) \cdot \varphi^2 \theta},
\]
d'où il suit qu'on pourra exprimer \(\psi \boldsymbol{\theta}\) rationnellement en \(\varphi \boldsymbol{\theta}\) et \(\boldsymbol{f \theta} \cdot \boldsymbol{F} \boldsymbol{\theta}\). Or le carré de \(\boldsymbol{f \theta} \cdot \boldsymbol{F} \boldsymbol{\theta}\) est rationnel en \(\boldsymbol{\varphi} \boldsymbol{\theta}\), car
\[
(f \theta \cdot F \theta)^2=\left(1-c^2 \varphi^2 \theta\right)\left(1+e^2 \varphi^2 \theta\right),
\]
donc on pourra faire en sorte que l'expression de \(\psi \boldsymbol{\theta}\) ne contienne la quantité \(f \theta . F \theta\) qu'à la première puissance. On pourra donc faire
\[
\psi \theta=\psi_1(\varphi \theta)+\psi_2(\varphi \theta) \cdot f \theta \cdot F \theta
\]
où \(\psi_1(\varphi \theta)\) et \(\psi_2(\varphi \theta)\) sont des fonctions rationnelles de \(\varphi \theta\).
Si l'on met \(\omega-\boldsymbol{\theta}\) ì la place de \(\boldsymbol{\theta}\), on aura, en remarquant que \(\varphi(\omega-\theta)=\varphi \theta, f(\omega-\theta)=-f \theta, F(\omega-\theta)=F \theta\) :
\[
\psi(\omega-\theta)=\psi_1(\varphi \theta)-\psi_2(\varphi \theta) \cdot f \theta \cdot F \theta .
\]

Des équations (7) et (8) on tire
\[
\begin{gathered}
\psi_1(\varphi \theta)=\frac{1}{2} \cdot[\psi \theta+\psi(\omega-\theta)] \\
\psi_2(\varphi \theta) \cdot f \theta \cdot F \theta=\frac{1}{2} \cdot[\psi \theta-\psi(\omega-\theta)] .
\end{gathered}
\]

Considérons d'abord la fonction \(\psi_1(\varphi \theta)\). En y mettant \(\theta+\alpha\) au lieu de \(\theta\), il viendra
\[
\psi_1[\varphi(\theta+\alpha)]=\frac{1}{2} \cdot[\psi(\theta+\alpha)+\psi(\omega-\alpha-\theta)]
\]
or on a \(\psi(\theta+\alpha)=\psi \theta\), et par conséquent aussi, en mettant \(\omega-\alpha-\theta\) an lieu de \(\boldsymbol{\theta}\),
*) P. 268 de cette édition.
%510
done
\[
\psi(\omega-\theta)=\psi(\omega-\alpha-\theta)
\]
c'est-à-dire
\[
\begin{gathered}
\psi_1[\varphi(\theta+\alpha)]=\frac{1}{2}[\psi \theta+\psi(\omega-\theta)] \\
\psi_1\lfloor\varphi(\theta+\alpha)]=\psi_1(\varphi \theta)
\end{gathered}
\]

On aura de la même manière
\[
\psi_1[\varphi(\theta+\beta)]=\psi_1(\varphi \theta) .
\]

La première de ces équations donne, en mettant successivement \(\theta+\alpha\), \(\theta+2 \alpha, \ldots\) an lieu de \(\theta\)
\[
\psi_1[\varphi(\theta+m \alpha)]=\psi_1(\varphi \theta)^{-}
\]
où \(m\) est un nombre entier quelconque. De même la seconde équation donne
\[
\psi_1[\varphi(\theta+\mu \beta)]=\psi_1(\varphi \theta)
\]
d'où, en mettant \(\theta+m \alpha\) au lieu de \(\theta\), et en ayant égard à l'équation (11) on tire
\[
\psi_1[\varphi(\theta+m \alpha+\mu \beta)]=\psi_1(\varphi \theta) .
\]

Donc la fonction \(\psi_1(\varphi \theta)\) reste la même, en y substituant au lieu de \(\varphi \theta\) une autre racine quelconque de l'équation (1). En attribuant à \(m\) et " toutes les valeurs entières depuis zéro jusqu’à \(2 n\) et en ajoutant, la formule (12) donne
\[
\psi_1(\varphi \theta)=\frac{1}{(2 n+1)^2} \cdot \sum_0^{2 n} \sum_0^{2 n} \psi_1[\varphi(\theta+m \alpha+\mu \beta)]
\]

Le second membre de cette équation est une fonction rationnelle et symétrique des racines de l'équation (1), done on pourra l'exprimer rationnellement par les coefficiens de cette équation, c'est-ì-dire par \(\varphi(2 n+1) \theta\). Soit done
\[
\psi_1(\varphi \theta)=p
\]
la quantité \(p\) sera une fonction rationnelle de \(\varphi(2 n+1) \theta\). Or je dis que \(p\) sera toujours entier. En effet soit \(\varphi(2 n+1) \theta=y\) et \(p=\frac{p^{\prime}}{q^{\prime}}\), où \(p^{\prime}\) et \(q^{\prime}\) sont des fonctions entières de \(y\) sans diviseur commun. Soit \(y=\varphi(2 n+1) \delta\) une racine de l'équation \(q^{\prime}=0\) : la quantité \(p=\frac{1}{2}[\psi \theta+\psi(\omega-\theta)]\) sera infinie en faisant \(\theta=\delta\), done on aura \(\psi \delta+\psi(\omega-\delta)=\frac{1}{\delta}\); maintenant il est évident par la forme de la fonction \(\boldsymbol{\psi} \boldsymbol{\theta}\), que cette équation ne peut subsister à moins qu'une quantité de la forme
\[
\varphi(\delta+m \alpha+" 1 \beta) \text {ou} \varphi(\omega-\delta+m \alpha+" 1 \beta)
\]
%511
n'ait une valeur infinie. Soit donc \(\varphi(\delta+m \alpha+\mu \beta)=\frac{1}{0}\), on aura en vertu de l'équation (30) tome II p. \(113^*\) )
\[
\delta=\left(m^{\prime}+\frac{1}{2}\right) \omega+\left(n^{\prime}+\frac{1}{2}\right) \tilde{\omega} i-m \alpha-\mu \beta,
\]
où \(m^{\prime}\) et \(n^{\prime}\) sont des nombres entiers; or cette valeur de \(\delta\) donne
\[
\varphi(2 n+1) \delta=\varphi\left[\left[(2 n+1) m^{\prime}+n-2 m\right] \omega+\left[(2 n+1) n^{\prime}+n-2 \mu\right] \widetilde{\omega} i+\frac{\omega}{2}+\frac{\pi}{2} i\right],
\]
c'est-à-dire (26 p. \(\left.111^*\right)\) :
\[
\varphi(2 n+1) \delta=\frac{1}{0} .
\]

Mais cela est impossible, car une racine quelconque de l'équation \(q^{\prime}=0\) doit être finie. On trouvera également que \(\varphi(\omega-\delta+m \alpha+\| \beta)=\frac{1}{0}\) domme \(\varphi(2 n+1) \delta=\frac{1}{0}\). La quantité \(p\) est donc une fonction entière de \(\varphi(2 n+1) \boldsymbol{\theta}\).

Considérons maintenant l'équation (10). En divisant les deux membres par \(f(2 n+1) \theta \cdot F(2 n+1) \theta\), on aura
\[
\frac{\psi_2(\boldsymbol{\rho} \theta) \cdot f \theta \cdot F \theta}{f(2 n+1) \theta \cdot F(2 n+1) \theta}=\frac{1}{2} \cdot \frac{\psi \theta-\psi(\omega-\theta)}{f(2 n+1) \theta \cdot F(2 n+1) \theta} .
\]

En vertu de ce qu'on a vu (45) tome II p. 117*), on aura \(f(2 n+1) \theta=f \boldsymbol{\theta} . u\), \(\boldsymbol{F}(2 n+1) \boldsymbol{\theta}=\boldsymbol{F}^{\boldsymbol{\theta}} \boldsymbol{\theta} . v, u\) et \(v\) étant des fonctions rationnelles de \(\varphi \boldsymbol{\theta}\); donc le second membre de l'équation précédente sera une fonction rationnelle de \(\varphi \theta\). En la désignant par \(\chi(\varphi \theta)\), on aura
\[
\chi(\varphi \theta)=\frac{1}{2} \cdot \frac{\psi \theta-\psi(\omega-\theta)}{f(2 n+1) \theta \cdot F(2 n+1) \theta} .
\]

Fn mettant \(\theta+\alpha\) an lieu de \(\theta\), il viendra
\[
\begin{gathered}
\psi(\theta+\alpha)=\psi \theta, \psi[\omega-(\theta+\alpha)]=\psi(\omega-\theta), \\
f(2 n+1)(\theta+\alpha)=f[(2 n+1) \theta+2 m \omega+2 \mu \widetilde{\omega} i]=f(2 n+1) \theta \\
F(2 n+1)(\theta+\alpha)=F[(2 n+1) \theta+2 m \omega+2 \mu \bar{\omega} i]=F(2 n+1) \theta
\end{gathered}
\]
donc on aura
\[
\chi[\varphi(\theta+\alpha)]=\chi(\varphi \theta) .
\]

De la même manière on trouvera
\[
\chi[\varphi(\theta+\beta)]=\chi(\varphi \theta) .
\]

On en déduit, comme plus haut pour la fonction \(\psi_1(\varphi \theta)\), que \(\chi(\varphi \theta)\) peut être exprimé par une fonction entière de \(\varphi(2 n+1) \theta\). Soit donc
*) Les formules citées se trouvent p. 275-281 de cette édition.
%512
on aura
\[
\chi(\varphi \theta)=q
\]
et enfin
\[
\psi_2(\varphi \theta) \cdot f \theta \cdot F \theta=q \cdot f(2 n+1) \theta \cdot F(2 n+1) \theta
\]
\[
\psi \boldsymbol{\theta}=p+q \cdot f(2 n+1) \boldsymbol{\theta} \cdot F(2 n+1) \theta
\]
où \(p\) et \(q\) sont des fonctions entières de \(\varphi(2 n+1) \theta\).
Pour trouver les degrés de ces fonctions, soit \((\varphi \theta)^\nu . * \boldsymbol{\theta}\) le terme de \(\psi \boldsymbol{\theta}\), dans lequel \(\varphi \theta\) est élevé à la plus haute puissance, on aura, en supposant \(\varphi \theta\) infini,
\[
\psi \boldsymbol{\theta}=A \cdot(\varphi \theta)^v
\]
\(A\) étant une constante. De mênie on aura
et par suite:
\[
\psi(\boldsymbol{\omega}-\boldsymbol{\theta})=A^{\prime} \cdot(\boldsymbol{\phi})^\nu
\]
\[
p=\frac{1}{2}\left(A+A^{\prime}\right) \cdot(\varphi \theta)^v
\]
mais pour \(\varphi \theta\) infini, on a \(\varphi(2 n+1) \theta=B . \varphi \theta, B\) étant wie constante. Il suit de là que \(p\) sera du degré \(v\) par rapport à \(\varphi(2 n+1) \theta\). On démontrera de la même manière que la fonction \(q\) sera du degré \(v-2\), tout au plus.
Notre théorème est donc démontré.
Dans le cas où la quantité \(\varphi \theta\) ne monte qu’à la première puissance dans \(\psi \theta\), on a \(\nu=1\); par conséquent \(q\) sera du degré -1 , c'est-à-dire \(q=0\). Donc on a dans ce cas
\[
\psi \boldsymbol{\theta}=A+B \cdot \varphi(2 n+1) \boldsymbol{\theta}
\]
où \(A\) et \(B\) sont des quantités constantes, qu'on déterminera facilement en faisant \(\theta=0\) et \(\varphi \theta=\frac{1}{0}\).

Soit par exemple \(\boldsymbol{\lambda} \theta\) le produit d'un nombre quelconque des racines de l'équation (1), et faisons
\[
\psi \theta=\sum_0^{2 n} \sum_0^{2 n} \pi(\theta+m \alpha+\mu \beta)
\]
il est elair qu'on aura \(\psi(\theta)=\psi(\theta+\alpha)=\psi(\theta+\beta)\), en remarquant que
et
\[
\pi[\theta+(2 n+1) \alpha+\mu \beta]=\pi(\theta+\mu \beta)
\]
\[
\pi[\theta+(2 n+1) \beta+m \alpha]=\pi(\theta+m \alpha) .
\]
1)one
%513
\[
\sum_0^{2 n} \sum_0^{2 n} \pi(\theta+m \alpha+\mu \beta)=A+B \cdot \varphi(2 n+1) \theta .
\]

Il faut remarquer que l'une des quantités \(A\) et \(B\) est toujours égale à zéro. On a \(A=0\) si le nombre des facteurs de \(\boldsymbol{\pi} \theta\) est un nombre impair, et \(\boldsymbol{B}=\boldsymbol{0}\) si ce nombre est pair. Dans ce dernier cas la quantité \(\boldsymbol{\psi} \boldsymbol{\theta}\) est indépendante de la valeur de \(\theta\); par conséquent, en faisant \(\theta=0\), on a
\[
\sum_0^{2 n} \sum_0^{2 n} \pi(\theta+m \alpha+\mu \beta)=\sum_0^{2 n} \sum_0^{2 n} \sum_\mu j(m \alpha+\mu \beta) .
\]

Si l'on fait par exemple
\[
\pi \theta=\varphi \theta \cdot \varphi\left(\theta+k \alpha+k^{\prime} \beta\right)
\]
on a
\[
\left\{\begin{aligned}
& \sum_0^{2 n} \sum_0^{2 n} \varphi(\theta+m \alpha+\mu \beta) \cdot \varphi\left[\theta+(m+k) \alpha+\left(\mu+k^{\prime}\right) \beta\right] \\
= & \sum_0^{2 n} \sum_0^{2 n} \varphi(m \alpha+\mu \beta) \cdot \varphi\left[(m+k) \alpha+\left(\mu+k^{\prime}\right) \beta\right],
\end{aligned}\right.
\]
où \(k\) et \(k^{\prime}\) sont des nombres entiers quelconques, moindres que \(2 n+1\). Cependant on ne peut pas supposer à la fois \(k=0, k^{\prime}=0\). Car alors \(\pi \theta=(\varphi \theta)^2\) et par suite \(\boldsymbol{\nu}=2\), tandis qu'on doit avoir
\[
\nu=1 \text {. }
\]

De la même manière que nous avons démontré le théorème précédent on pourra encore établir les deux suivans:

Théorème II. Soit \(\psi \boldsymbol{\theta}\) une fonction quelconque entière des quantités de la forme \(f(\theta+m \alpha+\mu \beta)\), telle que
on aura
\[
\psi \theta=\psi(\theta+\alpha)=\psi(\theta+\beta)
\]
\[
\psi \boldsymbol{\theta}=p+q \cdot \varphi(2 n+1) \boldsymbol{\theta} \cdot \boldsymbol{F}(2 n+1) \boldsymbol{\theta},
\]
oì \(p\) et \(q\) sont des fonctions entières de \(f(2 n+1) \theta\), la première du degré \(v\) et la seconde du 'degré \(\nu-2\), tout au plus, en désignant par \(v\) le plus grand exposant de \(\boldsymbol{f}^{\boldsymbol{\theta}}\) ctans \(\boldsymbol{\psi} \boldsymbol{\theta}\).

Théorème III. Soit \(\boldsymbol{\psi} \boldsymbol{\theta}\) une fonction quelconque entière des quantités de la forme \(F^{\prime}(\theta+m \alpha+\mu \beta)\), telle que
on aura
\[
\begin{gathered}
\psi(\theta)=\psi(\theta+\alpha)=\psi(\theta+\beta) \\
\psi \theta=p+q \cdot \varphi(2 n+1) \theta \cdot f(2 n+1) \theta
\end{gathered}
\]
%514
où \(p\) et \(q\) sont des fonctions entières de \(F(2 n+1) \theta\), la première du degré \(\nu\) et la seconde du degré \(\nu-2\), tout au plus, en désignant par \(\nu\) le plus grand exposant de \(\boldsymbol{F} \boldsymbol{\theta}\) dans \(\psi \boldsymbol{\theta}\).

En vertu du premier théorème on voit sans difficulté que la valeur de \(\varphi\left(\frac{\theta}{2 n+1}\right)\), exprimée en fonction de \(\varphi \theta\), sera
\[
\varphi\left(\frac{\theta}{2 n+1}\right)=\frac{1}{2 n+1} \cdot \sum_0^{4 n^2+4 n} \sqrt[2 n+1]{p_m+q_m \cdot f \theta \cdot F \theta}
\]
où \(p_m\) et \(q_m\) sont deux fonctions entières de \(\varphi \theta\), la première impaire et du degré \(2 n+1\), la seconde paire et du degré \(2 n-2\). D'ailleurs ces fonctions sont déterminées par l'équation
\[
p_m^2-q_m^2(f \boldsymbol{\theta})^2 \cdot(\boldsymbol{F} \theta)^2=\left(\varphi^2 \theta-a_m^2\right)^{2 n+1},
\]
où \(a_m\) est une constante.
Christiania le 27 août 1828.
%515
XXVII.

DÉMONSTRATION D'UNE PROPRIÉTÉ GÉNÉRALE D'UNE CERTAINE CLASSE DE FONCTIONS TRANSCENDANTES.

Journal für die reine und angewandte Mathematik, herausgegeben von Crelle, Bd. 4, Berlin 1829.

Théorème. Soit \(y\) une fonction de \(x\) qui satisfait à une équation quelconque irréductible de la forme
\[
0=p_0+p_1 y+p_2 y^2+\cdots+p_{n-1} y^{n-1}+y^n
\]
où \(p_0, p_1, p_2, \ldots p_{n-1}\) sont des fonctions entières de la variable \(x\). Soit de même
\[
0=q_0+q_1 y+q_2 y^2+\cdots+q_{n-1} y^{n-1},
\]
une équation semblable, \(q_0, q_1, q_2, \ldots q_{n-1}\) étant également des fonctions entières de \(x\), et supposons variables les coefficiens des diverses puissances de \(x\) dans ces fonctions. Nons désignerons ces coefficiens par \(a, a^{\prime}, a^{\prime \prime} \ldots\) En vertu des deux équations (1) et (2) \(x\) sera une fonction de \(a, a^{\prime}, a^{\prime \prime}, \ldots\) et on en déterminera les valeurs en éliminant la quantité \(y\). Désignons par
\[
0=0
\]
le résultat de l'élimination, de sorte que ne contiendrar que les variables \(x, a, a^{\prime}, a^{\prime \prime}, \ldots\) Soit \(\mu\) le degré de cette équation par rapport à \(x\), et désignons par
\[
x_1, x_2, x_3, \ldots x_\mu
\]
%516
ses \(" \boldsymbol{u}\) racines, qui seront autant de fonctions de \(a, a^{\prime}, a^{\prime \prime}, \ldots\) Cela posé, si l'on fait
\[
\psi x=\int f(x, y) d x
\]
où \(f(x, y)\) désigne une fonction rationnelle quelconque de \(x\) et de \(y\), je dis que la fonction transcendante \(\psi x\) jouira de la propriété générale exprimée par l'équation suivante:
\[
\text { (6) } \psi x_1+\psi x_2+\cdots+\psi x_\mu=u+k_1 \log v_1+k_2 \log v_2+\cdots+k_n \log v_n \text {, }
\]
\(u, v_1, v_2, \ldots v_n\) étant des fonctions rationnelles de \(a, a^{\prime}, a^{\prime \prime}, \ldots\), et \(k_1\), \(k_2, \ldots k_n\) des constantes.

Démonstration. Pour établir ce théorème il suffit d'exprimer la différentielle du premier membre de l'équation (6) en fonction de \(a, a^{\prime}, a^{\prime \prime}, \ldots\); car il se réduira par là à une différentielle rationnelle, comme on va voir. D'abord les deux équations (1) et (2) donneront y en fonction rationnelle de \(x, a, a^{\prime}, a^{\prime \prime}, \ldots\) De même l'équation (3) \(\varrho=0\) donnera pour \(d x\) une expression de la forme
\[
d x=\alpha \cdot d a+\alpha^{\prime} \cdot d a^{\prime}+\alpha^{\prime \prime} \cdot d a^{\prime \prime}+\cdots \cdot
\]
où \(\alpha, \alpha^{\prime}, \alpha^{\prime \prime}, \ldots\) sont des fonctions rationnelles de \(x, a, a^{\prime}, a^{\prime \prime}, \ldots\) De là il suit qu'on pourra mettre la différentielle \(f(x, y) d x\) sous la forme
\[
f(x, y) d x=\varphi x \cdot d a+\varphi_1 x \cdot d a^{\prime}+\varphi_2 x \cdot d a^{\prime \prime}+\cdots,
\]
où \(\varphi x, \varphi_1 x, \ldots\) sont des fonctions rationnelles de \(x, a, a^{\prime}, a^{\prime \prime}, \ldots\) En intégrant, il viendra
\[
\psi x=\int\left(\varphi x \cdot d a+\varphi_1 x \cdot d a^{\prime}+\cdots\right)
\]
et de là on tire, en remarquant que cette équation aura lieu en mettant pour \(x\) les \(\mu\) valeurs de cette quantité,
\[
\begin{gathered}
\psi x_1+\psi x_2+\cdots+\psi x_\mu \\
=\int\left[\left(\varphi x_1+\varphi x_2+\cdots+\varphi x_\mu\right) d a+\left(\varphi_1 x_1+\varphi_1 x_2+\cdots+\varphi_1 x_\mu\right) d a^{\prime}+\cdots\right] .
\end{gathered}
\]

Dans cette équation les coefficiens des différentielles \(d a, d a^{\prime}, \ldots\) sont des fonctions rationnelles de \(a, a^{\prime}, \alpha^{\prime \prime}, \ldots\) et de \(x_1, x_2, \ldots x_\mu\), mais en outre ils sont symétriques par rapport à \(x_1, x_2, \ldots x_\mu\); donc, en vertu d'un théorème connu, on pourra exprimer ces fonctions rationnellement par \(a, a^{\prime}\), \(a^{\prime \prime}, \ldots\) et par les coefficiens de l'équation \(\varrho=0\); mais ceux-ci sont eux-
%517
mêmes des fonctions rationnelles des variables \(a, a^{\prime}, a^{\prime \prime}, \ldots\), donc enfin les coefficiens de \(d a, d a^{\prime}, d a^{\prime \prime}, \ldots\) de l'équation (7) le seront également. Donc, en intégrant, on aura une équation de la forme (6).

Je me réserve de développer dans une autre occasion les nombreuses applications de ce théorème, qui jetteront du jour sur la nature des fonctions transcendantes dont il s'agit.
Christiania le 6 janvier 1829.
%518
XXVIII.

PRECIS D'UNE THÉORIE DES FONCTIONS ELLIPTIQUES.

Journal für die reine und angewandte Mathematik, herausgegeben von Crelle, Bd. 4, Berlin 1829.
Introduction.

La théorie des fonctions elliptiques, créée par M. Legendre, forme une partie des plus intéressantes de l'analyse. Ayant cherché de mon côté à donner de nouveaux développemens à cette théorie, je suis, si je ne me trompe, parvenu à plusieurs résultats qui me paraissent mériter quelque attention. J'ai cherché surtout à donner de la généralité à mes recherches, en me proposant des problèmes d'une vaste étendue. Si je n'ai pas été assez heureux pour les résoudre complètement, au moins j'ai donné des moyens pour y parvenir. L'ensemble de mes recherches sur ce sujet formera un ouvrage de quelque étendue, mais que les circonstances ne m'ont pas encore permis de publier. C'est pourquoi je vais donner ici un précis de la méthode que j’ai suivie, avec les résultats généraux auxquelles elle m’a conduit. Ce mémoire sera divisé en deux parties.

Dans la première je considère les fonctions elliptiques comme intégrales indéfinies, sans rien y ajouter sur la nature des quantités réelles ou imaginaires qui les composent. Je me servirai des notations suivantes:
\[
\begin{aligned}
\Lambda(x, c) & = \pm \sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}, \\
\widetilde{\omega}(x, c) & =\int \frac{d x}{\Delta(x, c)}, \\
\widetilde{\omega}_0(x, c) & =\int \frac{x^2 d x}{\Delta(x, c)},
\end{aligned}
\]
%519
\[
\Pi(x, c, a)=\int \frac{d x}{\left(1-\frac{x^2}{a^2}\right) \Delta(x, c)}
\]
de sorte que
\[
\widetilde{\omega}(x, c), \widetilde{\omega}_0(x, c), \Pi(x, c, a)
\]
remplacent respectivement les fonctions de première, de seconde et de troisième espèce.

Cela posé, je me suis proposé ce problème général: "Trouver tous les cas possibles dans lesquels on peut satisfaire à une équation de la forme:
(a)
\[
\left\{\begin{array}{l}
\alpha_1 \widetilde{\omega}\left(x_1, c_1\right)+\alpha_2 \widetilde{\omega}\left(x_2, c_2\right)+\cdots+\alpha_n \widetilde{\omega}\left(x_n, c_n\right) \\
+\alpha_1^{\prime} \widetilde{\omega}_0\left(x_1^{\prime}, c_1{ }^{\prime}\right)+\alpha_2{ }^{\prime} \widetilde{\omega}_0\left(x_2{ }^{\prime}, c_2{ }^{\prime}\right)+\cdots+\alpha_m{ }^{\prime} \widetilde{\omega}_0\left(x_m{ }^{\prime}, c_m{ }^{\prime}\right) \\
+\alpha_1{ }^{\prime \prime} \Pi\left(x_1{ }^{\prime \prime}, c_1{ }^{\prime \prime}, a_1\right)+\alpha_2{ }^{\prime \prime} \Pi\left(x_2{ }^{\prime \prime}, c_2{ }^{\prime \prime}, a_2\right)+\cdots+\alpha_\mu{ }^{\prime \prime} \Pi\left(x_\mu{ }^{\prime \prime}, c_\mu{ }^{\prime \prime}, a_\mu\right) \\
=u+A_1 \log v_1+A_2 \log v_2+\cdots+\cdots+A_\nu \log v_\nu
\end{array}\right.
\]
où
\[
\begin{gathered}
\alpha_1, \alpha_2, \ldots \alpha_n ; \alpha_1{ }^{\prime}, \alpha_2{ }^{\prime}, \ldots \alpha_m{ }^{\prime} ; \\
\alpha_1{ }^{\prime \prime}, \alpha_2{ }^{\prime \prime}, \ldots \alpha_\mu{ }^{\prime \prime} ; A_1, A_2, \ldots A_\nu
\end{gathered}
\]
sont des quantités constantes, \(x_1, x_2, \ldots x_n ; x_1{ }^{\prime}, x_2{ }^{\prime}, \ldots x_m{ }^{\prime} ; x_1{ }^{\prime \prime}, x_2{ }^{\prime \prime}, \ldots x_\mu{ }^{\prime \prime}\) des variables liées entre elles par des équations algébriques, et \(u, v_1, v_2, \ldots v_v\) des fonctions algébriques de ces variables."

J'établis d'abord les propriétés fondamentales des fonctions elliptiques, ou ce qui concerne leur sommation, en employant une méthode particulière, qui est applicable avec la même facilité à une infinité d'autres transcendantes plus compliquées. En m'appuyant sur ces propriétés fondamentales, je considère ensuite l'équation dans toute sa généralité, et je fais le premier pas en démontrant un théorème général sur la forme qu'on pourra donner à l'intégrale d'une fonction algébrique quelconque, en supposant cette intégrale exprimable par des fonctions algébriques, logarithmiques et elliptiques, théorème qui est d'un grand usage dans tout le calcul intégral, à cause de sa grande généralité.
J'en déduis, comme corollaire, le théorème suivant:
\({ }_{\text {"Si }} \int \frac{r d x}{I(x, c)}\), où \(r\) est ume fonction rationnelle quelconque de \(x\), est exprimable par des fonctions algébriques et logarithmiques et par des fonctions elliptiques \(\psi, \psi_1, \psi_2, \ldots\), on pourra toujours supposer
(b)
\[
\begin{aligned}
& \int \frac{r d x}{I(x, c)}=p J(x, c)+\alpha \psi(y)+\alpha^{\prime} \psi_1\left(y_1\right)+\alpha^{\prime \prime} \psi_2\left(y_2\right)+\cdots \\
& \cdots+A_1 \log \frac{q_1+q_1^{\prime} \lambda(x, c)}{q_1-q_1^{\prime} \lambda(x, c)}+A_2 \log \frac{q_2+q_2^{\prime} \lambda(x, c)}{q_2-q_2^{\prime} \Lambda(x, c)}+\cdots \\
&
\end{aligned}
\]
%520
où toutes les quantités \(p, q_1, q_2, \ldots q_1{ }^{\prime}, q_2{ }^{\prime}, \ldots y, y_1, y_2, \ldots\) sont des fonctions rationnelles de \(x^{\text {(*) }}\).
De ce théorème je tire ensuite celui-ci:
"Si une équation quelconque de la forme (a) a lieu, et qu'on désigne par \(c\) l'un quelconque des modules qui y entrent, parmi les autres modules il y en aura au moins un, \(c^{\prime}\), tel qu'on puisse satisfaire à l'équation différentielle:
\[
\frac{d y}{\Delta\left(y, c^{\prime}\right)}=\varepsilon \frac{d x}{d(x, c)}
\]
en mettant pour \(y\) une fonction rationnelle de \(x\), et vice versa."
Ces théorèmes sont très importans dans la théorie des fonctions elliptiques. Ils ramènent la solution du problème général à la détermination de la solution la plus générale de l'équation
\[
\frac{d y}{d\left(y, c^{\prime}\right)}=\varepsilon \frac{d x}{d(x, c)}
\]
ou à la transformation des fonctions de première espèce. Je donne la solution complète de ce problème, et j'en déduis ensuite la transformation générale des fonctions de prenière espèce. Je fais voir que les modules doivent nécessairement être liés entre eux par une équation algébrique. On peut se contenter de considérer le cas où le dégré de la fonction y est un nombre premier, y compris l'unité. Si ce degré est désigné par \(\mu, c^{\prime}\) pourra avoir \(6(\mu+1)\) valeurs différentes, excepté pour \(\mu=1\), où ce nombre se réduit à 6 .

La seconde partie traite des fonctions à modules réels et moindres que l'unité. Au lieu des fonctions \(\widetilde{\omega}(x, c), \widetilde{\omega}_0(x, c), \Pi(x, c, a)\) j'en introduis trois antres, savoir d'abord la fonction \(\lambda(\theta)\), déterminée par l'équation
\[
\theta=\int_0^{\lambda \theta} \frac{d x}{\Delta(x, c)},
\]

C'est la fonction inverse de la première espèce. En mettant \(x=\hat{\lambda} \theta\) dans les expressions de \(\widehat{\boldsymbol{\omega}}_0(x, c), \boldsymbol{\Pi}(x, c, a)\), elles deviendrońt de la forme:
\[
\begin{aligned}
\widetilde{\omega}_0(x, c) & =\int \lambda^2 \theta \cdot d \theta \\
\Pi(x, c, a) & =\int \frac{d \theta}{1-\frac{\lambda^2 \theta}{a^2}} .
\end{aligned}
\]
*) Ce théorème a également lieu, si \(\mathcal{A}(x, c)\) est la racine carrée d'une fonction entière d'un degré quelconque.
%521
Sous cette forme, les fonctions elliptiques offrent des propriétés très remarquables, et sont beaucoup plus faciles à traiter. C'est surtout la fonction i, \(\boldsymbol{\theta}\) qui mérite une attention particulière. Cette fonction a été l'objet d'un mémoire qui est inséré dans les tomes II et III de ce journal*), où j’en ai démontré le premier quelques-unes des propriétés fondamentales. On en trouvera davantage dans ce mémoire. Je vais indiquer rapidement quelques-uns des résultats auxquels je suis parvenu:
1. La fonction \(\lambda \theta\) jouit de la propriété remarquable d'être périodique de deux manières différentes, savoir non seulement pour des valeurs réelles de la variable, mais encore pour des valeurs imaginaires. En effet si l'on fait pour abréger
\[
\frac{\widetilde{\omega}}{2}=\int_0^1 \frac{d x}{\Delta(x, c)}, \frac{\omega}{2}=\int_0^1 \frac{d x}{\Delta(x, b)},
\]
où \(b=\sqrt{1-c^2}\) et \(\sqrt{-1}=i\), on aura
\[
\lambda(\theta+2 \widetilde{\omega})=\lambda \theta ; \lambda(\theta+\omega i)=\lambda \theta .
\]
2. La fonction \(\lambda \theta\) devient égale à zéro et à l'infini, pour une infinité de valeurs réelles et imaginaires de \(\boldsymbol{\theta}\)
(c)
\[
\lambda(m \widetilde{\omega}+n \omega i)=0, \lambda\left[m \widetilde{\omega}+\left(n+\frac{1}{2}\right) \omega i\right]=\frac{1}{0},
\]
où \(m\) et \(n\) sont des nombres entiers quelconques, positifs ou négatifs. De même on a
\[
\begin{gathered}
\lambda \theta^{\prime}=\lambda \theta \\
\boldsymbol{\theta}^{\prime}=(-1)^m \theta+m \tilde{\omega}+n \omega i
\end{gathered}
\]
si
cette relation est nécessaire.
3. I áa propriété fondamentale de \(\lambda \boldsymbol{\theta}\) est exprimée par l'équation
\[
\lambda\left(\theta^{\prime}+\theta\right) \cdot \lambda\left(\theta^{\prime}-\theta\right)=\frac{\lambda^2 \theta^{\prime}-\lambda^2 \theta}{1-c^2 \lambda^2 \theta \cdot \lambda^2 \theta^{\prime}},
\]
où \(\theta^{\prime}\) et \(\theta\) sont des variables quelconques, réelles on imaginaires.
4. La fonction \(\lambda \theta\) pourra se développer en facteurs et en fractions de beancoup de manières; par exemple si l'on fait pour abréger
\[
q=e^{-\frac{\omega}{\omega} \pi}, p=e^{-\frac{\omega}{\omega} \pi}
\]
*) Mímoire XVI de cette édition.
%522
on a
\[
\begin{aligned}
\lambda(\theta \bar{\omega}) & =\frac{2}{\sqrt{c}} \sqrt{q} \cdot \sin (\pi \theta) \frac{\left[1-2 q^2 \cos (2 \theta \pi)+q^4\right]\left[1-2 q^4 \cos (2 \theta \pi)+q^8\right] \ldots}{\left[1-2 q \cos (2 \theta \pi)+q^2\right]\left[1-2 q^3 \cos (2 \theta \pi)+q^6\right] \ldots} \\
& =\frac{4 \sqrt{q}}{c} \cdot \frac{\pi}{\widetilde{\omega}} \cdot\left(\frac{1}{1-q} \sin (\theta \pi)+\frac{q}{1-q^3} \sin (3 \theta \pi)+\frac{q^2}{1-q^5} \sin (5 \theta \pi)+\cdots\right), \\
& \lambda\left(\frac{\tilde{\omega}}{2}-\theta \omega\right)=\frac{1}{\sqrt{c}} \cdot \frac{\left(1-p e^{-2 \pi \theta}\right)\left(1-p e^{2 \pi \theta}\right)\left(1-p^3 e^{-2 \pi \theta}\right)\left(1-p^3 e^{2 \pi \theta}\right) \ldots}{\left(1+p e^{-2 \pi \theta}\right)\left(1+p e^{2 \pi \theta}\right)\left(1+p^3 e^{-2 \pi \theta}\right)\left(1+p^3 e^{2 \pi \theta}\right) \ldots} .
\end{aligned}
\]

On pourra exprimer d'une manière analogue les fonctions, de seconde et de troisième espèce. Les deux formules précédentes sont au fond les mêmes que les formules \((c)\).
5. Une des propriétés les plus fécondes de la fonction \(\boldsymbol{\lambda} \boldsymbol{\theta}\) est la suivante: [On a fait pour abréger: \(\Delta \theta= \pm \sqrt{\left(1-\lambda^2 \theta\right)\left(1-c^2 \lambda^2 \theta\right)}\) ].
,Si l'équation
\[
(\lambda \theta)^{2 n}+a_{n-1}(\dot{\lambda} \theta)^{2 n-2}+\cdots+a_1(\lambda \theta)^2+a_0=\left[b_0 \lambda \theta+b_1(\lambda \theta)^3+\cdots+b_{n-2}(\dot{\lambda} \theta)^{2 n-3}\right] \boldsymbol{A} \theta
\]
est satisfaite, en mettant pour \(\theta 2 n\) quantités \(\theta_1, \theta_2, \ldots \theta_{2 n}\), telles que \(\lambda^2 \boldsymbol{\theta}_1, \lambda^2 \boldsymbol{\theta}_2, \ldots \lambda^2 \boldsymbol{\theta}_{2 n}\) soient différentes entre elles, on aura toujours
\[
\begin{aligned}
\lambda\left(\theta_1+\theta_2+\cdots+\theta_{2 n}\right) & =0, \\
-\lambda\left(\theta_{2 n}\right)=+\lambda\left(\theta_1+\theta_2+\cdots+\theta_{2 n-1}\right) & =\frac{-a_0}{\lambda \theta_1 \cdot \lambda \theta_2 \ldots \lambda \theta_{2 n-1}}
\end{aligned}
\]
les coefficiens \(a_0, a_1, \ldots, b_0, b_1, \ldots\) pourront être quelconques, et il est facile de voir qu'on pourra les déterminer de sorte que \(\boldsymbol{\theta}_1, \boldsymbol{\theta}_2, \ldots \boldsymbol{\theta}_{2 n-1}\) soient donnés."
Voici une antre propriété plus générale:
"Si l'on fait
\[
p^2-q^2\left(1-x^2\right)\left(1-c^2 x^2\right)=A\left(x-\lambda \theta_1\right)\left(x-\lambda \theta_2\right) \ldots\left(x-\lambda \theta_\mu\right),
\]
où \(p\) et \(q\) sont des fonctions entières quelconques de l'indéterminée \(x\), on pourra toujours prendre les quantités \(\theta_1, \theta_2, \ldots \theta_\mu\) telles que l'expression
\[
\lambda\left(\theta_1+\theta_2+\theta_3+\cdots+\theta_\mu\right)
\]
soit égale à zéro ou à l'infini."
Ainsi par exemple, si
\[
p^2--q^2\left(1-x^2\right)\left(1-c^2 x^2\right)=A\left(x^2-\lambda^2 \theta\right)^\mu,
\]
%523
l'une des fonctions \(p\) et \(q\) étant paire et l'autre impaire, on aura
1) si \(p\) est pair:
\(\hat{\lambda}(\mu \theta)=0\), si \(\mu\) est pair et
\(\lambda(\mu \theta)=\frac{1}{0}\), si \(\mu\) est impair;
2) si \(p\) est impair:
\(\hat{\lambda}(\boldsymbol{\mu} \theta)=0\), si \(\boldsymbol{\mu}\) est impair et
\(\lambda(\mu \theta)=\frac{1}{0}\), si \(\mu\) est pair.
De la il suit "encore que, si l'équation \((d)\) a lieu, on aura toujours
\[
\hat{\boldsymbol{\theta}} \boldsymbol{\theta}=\boldsymbol{\lambda}\left(\frac{m \widetilde{\omega}+\frac{1}{2} n \omega i}{\boldsymbol{\mu}}\right),
\]
où \(m\) et \(n\) sont entiers et moindres que \(\mu\).
6. Il existe entre les quantités \(\lambda\left(\frac{m \tilde{\omega}+n \omega i}{2 \mu+1}\right)\) et les racines \((2 u+1)^{i \text { ìmes }}\) de l'unité des relations bien remarquables, savoir si l'on fait pour abréger
\[
\delta=\cos \frac{2 \pi}{2 \mu+1}+\sqrt{-1} \cdot \sin \frac{2 \pi}{2 \mu+1},
\]
on aura, quels que soient les nombres entiers \(m\) et \(\mu\) :
\[
\begin{array}{r}
0=\lambda\left(\frac{2 m \tilde{\omega}}{2 \mu+1}\right)+\delta^k \cdot \lambda\left(\frac{2 m \tilde{\omega}+\omega i}{2 \mu+1}\right)+\delta^{2 k} \cdot \lambda\left(\frac{2 m \tilde{\omega}+2 \omega i}{2 \mu+1}\right)+\delta^{3 k} \cdot \lambda\left(\frac{2 m \omega+3 \omega i}{2 \mu+1}\right) \\
+\cdots+\delta^{2 \mu k}: \lambda\left(\frac{2 m \tilde{\omega}+2 \mu \omega i}{2 \mu+1}\right) \\
0=\lambda\left(\frac{m \omega i}{2 \mu+1}\right)+\delta^{k^{\prime}} \cdot \lambda\left(\frac{2 \sigma+m \omega i}{2 \mu+1}\right)+\delta^{2 k^{\prime}} \cdot \lambda\left(\frac{4 \omega+m \omega i}{2 \mu+1}\right)+\delta^{3 k^{\prime}} \cdot \lambda\left(\frac{6 \tilde{\omega}+m \omega i}{2 \mu+1}\right) \\
+\cdots+\delta^{2 \mu k^{\prime}} \cdot \lambda\left(\frac{4 \mu \tilde{\omega}+m \omega i}{2 \mu+1}\right) .
\end{array}
\]

D'ailleurs toutes les quantités \(\lambda\left(\frac{m \omega+n \omega i}{2 \mu+1}\right)\) sont les racines d'une même équation du degré \((2 \mu+1)^2\), dont les coefficiens sont des fonctions rationnelles de \(c^2\).
7. Si la fonction
\[
\int \frac{d x}{d(x, c)},
\]
dont le module \(c\) est réel et moindre que l'unité, pent être transformée dans ine autre
\[
\varepsilon \frac{d y}{I\left(y, c^{\prime}\right)}, 
\]
%524
dont le module \(c^{\prime}\) est réel ou imaginaire, en mettant pour \(y\) une fonction algébrique quelconque de \(x\), il faut nécessairement que le module \(c^{\prime}\) soit déterminé par l'une des deux équations
\[
\begin{aligned}
& \sqrt[4]{c^{\prime}}=\sqrt{2} \cdot \sqrt[8]{q_1} \cdot \frac{\left(1+q_1^2\right)\left(1+q_1^4\right)\left(1+q_1^6\right) \ldots}{\left(1+q_1\right)\left(1+q_1^8\right)\left(1+q_1^5\right) \ldots} \\
& \sqrt[4]{c^{\prime}}=\frac{1-q_1}{1+q_1} \cdot \frac{1-q_1^8}{1+q_1^8} \cdot \frac{1-q_1^5}{1+q_1^5} \cdots
\end{aligned}
\]
où \(q_1=q^\mu, \boldsymbol{\mu}\) étant rationnel; ou, ce qui revient au même,
\[
q_1=e^{\left(-\mu \frac{\omega}{\omega}+\mu^{\prime} i\right) \pi}
\]
“ et " \({ }^{\prime}\) étant des nombres rationnels quelconques.
8. La théorie de la transformation devient très facile à l'aide des propriétés les plus simples de la fonction \(\boldsymbol{\lambda} \theta\). Pour en donner un exemple, soit proposé le problène: satisfaire de la manière la plus générale à l'équation
\[
\frac{d y}{\Delta\left(y, c^{\prime}\right)}=\varepsilon \frac{d x}{\Delta(x, c)}
\]
en supposant \(c\) et \(c^{\prime}\) moindres que l'unité et \(y\) fonction rationnelle, réelle ou imaginaire, de \(x\).

Soit \(x=\hat{\theta} \theta, y=\lambda^{\prime} \theta^{\prime}\), en désignant par \(\lambda^{\prime}\) la fonction qui répond au module \(c^{\prime}\). l'équation différentielle se changera dans ce cas en \(d \boldsymbol{\theta}^{\prime}=\varepsilon d \boldsymbol{\theta}\), d'où
\[
\theta^{\prime}=\varepsilon \theta+a
\]
\(a\) étant une constante. Cela posé, soit
\[
y=\frac{\varphi x}{f x}
\]
on aura
\[
\lambda^{\prime}(\varepsilon \theta+a)=\frac{\varphi(\lambda \theta)}{f(\lambda \theta)} .
\]

En mettant \(\boldsymbol{\theta}+2 \widetilde{\boldsymbol{\omega}}, \boldsymbol{\theta}+\boldsymbol{\omega} \boldsymbol{i}\) au lieu de \(\boldsymbol{\theta}, \lambda \boldsymbol{\theta}\) ne change pas de valeur et par conséquent on doit avoir
\[
\begin{aligned}
& \lambda^{\prime}(\varepsilon \theta+2 \varepsilon \widetilde{\omega}+a)=\lambda^{\prime}(\varepsilon \theta+a), \\
& \lambda^{\prime}(\varepsilon \theta+\varepsilon \omega i+a)=\lambda^{\prime}(\varepsilon \theta+a) .
\end{aligned}
\]

Done, si l'on désigne par \(\widehat{\omega}^{\prime}\) et \(\omega^{\prime}\) les valeurs de \(\widetilde{\omega}\) et \(\omega\) qui répondent au module \(c^{\prime}\), on aura en vertu de l'équation (2):
%525
\[
\begin{aligned}
& 2 \varepsilon \tilde{\omega}=2 m \widetilde{\omega}^{\prime}+n \omega^{\prime} i, \\
& \varepsilon \omega \dot{=}=2 m^{\prime} \widetilde{\omega}^{\prime}+n^{\prime} \omega^{\prime} i,
\end{aligned}
\]
ce qui donne
\[
\varepsilon=m \cdot \frac{\widetilde{\omega}^{\prime}}{\widetilde{\omega}}+\frac{n}{2} \cdot \frac{\omega^{\prime}}{\widetilde{\omega}} i=n^{\prime} \frac{\omega^{\prime}}{\omega}-2 m^{\prime} \frac{\widetilde{\omega}^{\prime}}{\omega} i
\]
done
\[
m \frac{\sigma^{\prime}}{\sigma}=n^{\prime} \frac{\omega^{\prime}}{\omega}, \frac{n}{2} \cdot \frac{\omega^{\prime}}{\sigma}=-2 m^{\prime} \frac{\sigma^{\prime}}{\omega}
\]
on bien
\[
\frac{\widetilde{\omega}^{\prime}}{\omega^{\prime}}=\frac{n^{\prime}}{m} \cdot \frac{\widetilde{\omega}}{\omega}=-\frac{n}{4 m^{\prime}} \cdot \frac{\omega}{\widetilde{\omega}} .
\]

Maintenant, si \(c\) est indéterminé, cette équation ne pourra subsister à moins qu'on n'ait ou \(n=0, m^{\prime}=0\), ou \(n^{\prime}=0, m=0\). Dans le premier cas \(\varepsilon\) est réel et égal à
\[
m \frac{\sigma^{\prime}}{\sigma}=n^{\prime} \frac{\omega^{\prime}}{\omega}
\]
et dans le second cas \(\varepsilon\) est imaginaire et égal à
\[
\frac{n}{2} \cdot \frac{\omega^{\prime}}{\widetilde{\omega}} i=-2 m^{\prime} \frac{\widetilde{\omega}^{\prime}}{\omega} i .
\]

Supposons \(\varepsilon\) réel. Alors on aura ce théorème:
\({ }^n \mathrm{Si}\) deux fonctions réelles peuvent être transformées l'une dans l'antre, il faut qu'on ait entre les fonctions completes \(\widetilde{\omega}, \omega, \widetilde{\omega}^{\prime}, \omega^{\prime}\) cette relation:
\[
\frac{\widetilde{\omega}^{\prime}}{\omega^{\prime}}=\frac{n^{\prime}}{m} \cdot \frac{\widetilde{\omega}}{\omega}
\]
où \(n^{\prime}\) et \(m\) sont des nombres entiers."
On pourra démontrer que si cette condition est remplie, on pourra effectivement satisfaire à l'équation
\[
\int \frac{d y}{\Delta\left(y, c^{\prime}\right)}=m \frac{\widetilde{\omega}^{\prime}}{\widetilde{\omega}} \int \frac{d x}{\Delta(x, c)} .
\]

Rien n'est plus simple que de trouver l'expression de \(y\). Il suffit pour cela de chercher les racines des deux équations \(\varphi x=0, f x=0\).

Désignons par \(\lambda \delta\) et \(\lambda \delta^{\prime}\) deux racines quelconques appartenant respectivement à ces deux équations, on aura, pour déterminer \(\delta\) et \(\delta^{\prime}\), ces deux équations :
\[
\lambda^{\prime}(\varepsilon \delta+a)=0, \lambda^{\prime}\left(\varepsilon \delta^{\prime}+a\right)=\frac{1}{0},
\]
ce qui donne
%526
\[
\delta=-\frac{a}{\varepsilon}+\frac{k}{\varepsilon} \widetilde{\omega}^{\prime}+\frac{k^{\prime}}{\varepsilon} \omega^{\prime} i ; \quad \delta^{\prime}=-\frac{a}{\varepsilon}+\frac{k}{\varepsilon} \widetilde{\omega}^{\prime}+\left(k^{\prime}+\frac{1}{2}\right) \frac{\omega^{\prime}}{\varepsilon} i,
\]
c'est-ì-dire:
\[
\delta=-\frac{a}{\varepsilon}+\frac{k}{m} \widetilde{\omega}+\frac{k^{\prime}}{n^{\prime}} \omega i ; \quad \delta^{\prime}=-\frac{a}{\varepsilon}+\frac{k}{m} \widetilde{\omega}+\left(k^{\prime}+\frac{1}{2}\right) \frac{\omega}{n^{\prime}} i,
\]
\(k\) et \(k^{\prime}\) étant des nombres entiers. Pour déterminer \(a\), il suffit de remarquer que \(\lambda \boldsymbol{\theta}\) ne change pas de valeur en mettant \(\widetilde{\omega}-\boldsymbol{\theta}\) au lieu de \(\boldsymbol{\theta}\). On aura done
\[
\lambda^{\prime}(\varepsilon \widetilde{\omega}-\varepsilon \theta+a)=\lambda^{\prime}(\varepsilon \theta+a),
\]
ce qui donne
\[
a=\frac{1}{2}\left[(2 \mu+1-m) \widetilde{\omega}^{\prime}+\mu^{\prime} \omega^{\prime} i\right)
\]

Dans le cas où \(m\) est impair, on pourra toujours faire \(a=0\).
Commaissant les valeurs de \(\delta\) et \(\delta\), on aura immédiatement les racines des deux équations \(\varphi x=0, f x=0\), et par suite l'expression des fonctions \(\varphi x\) et \(f x\) en produits de facteurs. Les formules les plus simples répondent aux cas de \(m=1\) ou \(n^{\prime}=1\), et elles sont les seules nécessaires, comme il est aisé de le voir par l'équation \(\frac{\sigma^{\prime}}{\omega^{\prime}}=\frac{n^{\prime}}{m} \cdot \frac{\widetilde{\omega}}{\omega}\). On pourra aussi se servir des expressions de la fonction \(\boldsymbol{\lambda} \theta\) en produits infinis rapportées plus haut. Je l'ai fait voir dans un mémoire qui a été envoyé à M. Schumacher pour être inséré dans son journal*).
9. Le cas où un module \(c\) peut être transformé en son complément \(\sqrt{1-c^2}=b\), mérite une attention particulière. En vertu de l'équation \(\frac{\tilde{\omega}^{\prime}}{\omega^{\prime}}=\frac{n}{m} \cdot \frac{\tilde{\omega}}{\omega}\), on aura alors
\[
\frac{\omega}{\omega}=\sqrt{\frac{m}{n}} \text { et } \frac{d y}{\Delta(y, b)}=\sqrt{m n} \frac{d x}{\Lambda(x, c)} .
\]

Le module \(c\) sera déterminé par une équation algébrique, qui paraît être résoluble par des radicaux; au moins cela aura lieu si \(\frac{m}{n}\) est un carré parfait. Dans tous les cas il est facile d'exprimer \(c\) par des produits infinis. En effet, si \(\frac{\sigma}{\omega}=\sqrt{\frac{m}{n}}\), on a
") Mémoire \(\mathbf{X X}\) de cette édition.
%527
\[
\begin{aligned}
\sqrt[4]{c}=\sqrt{2} \cdot e^{-\frac{1}{8} \pi \sqrt{\frac{m}{n}}} & \cdot \frac{\left(1+e^{-2 \pi \sqrt{\frac{m}{n}}}\right)\left(1+e^{-4 \pi \sqrt{\frac{m}{n}}}\right) \ldots}{\left(1+e^{-\pi} \sqrt{\frac{m}{n}}\right)\left(1+e^{-3 \pi \sqrt{\frac{m}{n}}}\right) \ldots} \\
= & \frac{\left(1-e^{-\pi \sqrt{\frac{n}{m}}}\right)\left(1-e^{-3 \pi \sqrt{\frac{n}{m}}}\right) \ldots}{\left(1+e^{-\pi \sqrt{\frac{n}{m}}}\right)\left(1+e^{-3 \pi \sqrt{\frac{n}{m}}}\right) \ldots}
\end{aligned}
\]

Si deux modules \(c^{\prime}\) et \(c\) peuvent être transformés l'un dans l'autre, ils auront entre eux une relation algébrique. Il ne paraît pas possible en général d'en tirer la valeur de \(c^{\prime}\) en \(c\) à l'aide de radicaux*), mais il est remarquable, que cela est toujours possible si \(c\) peut être transformé en son complément, par exemple si \(c^2=\frac{1}{2}\).

Les équations modulaires jouissent d'ailleurs de la propriété remarquable, que toutes leurs racines peuvent être exprimées rationnellement par deux d'entre elles. De même on pourra exprimer toutes les racines par l'une d'elles à l'aide de radicaux.
10. On pourra développer la fonction \(\lambda \theta\) de la manière suivante:
\[
\lambda \theta=\frac{\theta+a \theta^3+a^{\prime} \theta^5+\cdots}{1+b^{\prime} \theta^4+b^{\prime \prime} \theta^6+\cdots},
\]
où le numérateur et le dénominateur sont des séries toujours convergentes. En faisant
\[
\begin{aligned}
& \varphi \theta=\theta+a \theta^3+a^{\prime} \theta^5+\cdots \\
& f \theta=1+b^{\prime} \theta^4+b^{\prime \prime} \theta^6+\cdots
\end{aligned}
\]
ces deux fonctions auront la propriété exprimée par les deux équations
*) Dans le cas par exemple où \(y\) est de la forme:
\[
y=\sqrt{\frac{c^5}{c^{\prime}}} \cdot \frac{x\left(a^2-x^8\right)\left(a_1^3-x^3\right)}{\left(1-c^3 a^2 x^3\right)\left(1-c^2 a_1^3 x^3\right)}
\]
l'équation entre \(c^{\prime}\) et \(c\) est du sixième degré. Or je suis parvenu à démontrer rigoureusement, que si une équation du sixième degré est résoluble ì l'aide de roulicurr, il doit arriver l'un de deux, ou cette équation sera décomposable en deux autres du troisième degré, dont les coefficiens dépendent d'une équation du second degré, ou elle sera décomposable en trois équations du second degré, dont les coefticiens sont déterminés par une équation du troisième degré. L'équation entre \(c^{\prime}\) et \(c\) ne paraît guère être déconiposable de cette manière.
%528
\[
\begin{aligned}
& \varphi\left(\theta^{\prime}+\theta\right) \cdot \varphi\left(\theta^{\prime}-\theta\right)=\left(\varphi \theta \cdot f \theta^{\prime}\right)^2-\left(\varphi \theta^{\prime} \cdot f \theta\right)^2 \\
& f\left(\theta^{\prime}+\theta\right) \cdot f\left(\theta^{\prime}-\theta\right)=\left(f \theta \cdot f \theta^{\prime}\right)^2-c^2\left(\varphi \theta \cdot \varphi \theta^{\prime}\right)^2
\end{aligned}
\]
où \(\theta^{\prime}\) et \(\theta\) sont deux variables indépendantes. Ainsi par exemple si l'on fait \(\theta^{\prime}=\theta\), on a
\[
f(2 \theta)=(f \theta)^4-c^2(\varphi \theta)^4
\]

Ces fonctions jouissent de beancoup de propriétés remarquables.
11. I Les formules présentées dans ce qui précède ont lieu avec quelques restrictions, si le module \(c\) est quelconque, réel ou imaginaire.
PREMIÈRE PARTIE.
DES FONCTIONS ELLIPTIQUES EN GÉNÉRAL.
CHAPITRE I.
Propriétés générales des fonctions elliptiques.
Les fonctions elliptiques jouissent comme on sait de cette propriété remarquable, que la somme d'un nombre quelconque de fonctions peut être exprimée par une seule fonction de la même espèce, en y ajoutant une certaine expression algébrique et logarithmique. La découverte de cette propriété est due, si je ne me trompe, à M. Legendre. La démonstration que cet illustre géomètre en a donnée, est fondée sur l'intégration algébrique de l'équation différentielle
\[
\frac{d y}{\sqrt{\alpha+\beta y+\gamma y^2+\delta y^3+\varepsilon y^4}}=\frac{d x}{\sqrt{\alpha+\beta x+\gamma x^2+\delta x^3+\varepsilon x^4}} .
\]

L’objet de ce chapitre sera de démontrer cette propriété des fonctions elliptiques, mais en nous appuyant sur des considérations différentes de celles de M. Legendre.
\(\S 1\).
Démonstration dun théorème fondamental.
Nous allons commencer par établir un théorème général qui servira de
%529
fondement de tout ce qui va être exposé dans ce mémoire, et qui en même temps exprime une propriété très remarquable des fonctions elliptiques.

Théorème I. Soient \(f x\) et \(\varphi x\) deux fonctions quelconques entrères de \(x\), l'une paire, l'autre impaire, et dont les coefficiens soient supposés variables. Cela posé, si l'on décompose la fonction entière paire
\[
(f x)^2-(\varphi x)^2(\Delta x)^2
\]
en facteurs de la forme \(x^2-x_1^2\), de sorte qu'on ait
(1) \((f x)^2-(\varphi x)^2(\Delta x)^2=A\left(x^2-x_1^2\right)\left(x^2-x_2^2\right)\left(x^2-x_3^y\right) \ldots\left(x^2-x_\mu^2\right)\), où \(A\) est indépendant de l'indéterminée \(x\), je dis qu'on aura
\[
\Pi x_1+\Pi x_2+\Pi x_3+\cdots+\Pi x_\mu=C-\frac{a}{2 \Delta a} \log \frac{f a+\varphi a \cdot \Delta a}{f a-\varphi a \cdot \Delta a},
\]
\(a\) désiguant le paramètre de la fonction \(\Pi x\), de sorte que
\[
\Pi x=\int \frac{d x}{\left(1-\frac{x^8}{a^2}\right) \Delta x} .
\]

Lá quantité \(C\) est la coustante d'intégration.
Dérnonstration. Supposons d'abord que tous les coefficiens des diverses puissances de \(x\) dans les fonctions \(f x\) et \(\varphi x\) soient les variables indépendantes. Alors toutes les quantités \(x_1, x_2, \ldots x_\mu\) seront évidemment inégales et fonctions de ces variables. En désignant par \(x\) l'une quelconque d'entre elles, l'équation (1) donnera
\[
(f x)^2-(\varphi x)^2(A x)^2=0
\]
d'où
\[
f x+\varphi x \cdot d x=0 .
\]

Cela posé, faisons pour abréger
\[
\psi x=(f x)^2-(\varphi x)^2(\Delta x)^2
\]
et désignons par \(\psi^{\prime} x\) la dérivée de cette fonction par rapport à \(x\) seul. De même désignons par la caractéristique \& la différentiation qui se rapporte aux seules variables indépendantes. Alors on tire de l'équation (4) en différentiant
\[
\psi^{\prime} x \cdot d x+2 f x \cdot \delta f x-2 \varphi x \cdot \delta \varphi x \cdot(I x)^2=0
\]
mais en vertu de l'équation (5) on a
%530
\[
\begin{gathered}
f x=-\varphi x \cdot \Delta x \\
\varphi x(\Delta x)^2=-f x \cdot \Delta x
\end{gathered}
\]
donc, en substituant,
\[
\psi^{\prime} x \cdot d x-2 \Delta x(\varphi x . \delta f x-f x \cdot \delta \varphi x)=0 .
\]

De là on tire, en divisant par \(\left(1-\frac{x^2}{a^2}\right) 1 x\),
\[
\frac{d x}{\left(1-\frac{x^2}{a^2}\right) d x}=\frac{2(\varphi x \cdot \delta f x-f x \cdot \delta \varphi x)}{\left(1-\frac{x^2}{a^2}\right) \psi^{\prime} x}
\]
et en intégrant
\[
\Pi x=\int \frac{2(\varphi x \cdot \delta f x-f x \cdot \delta \varphi x)}{\left(1-\frac{x^2}{a^2}\right) \psi^{\prime} x}
\]

En faisant maintenant \(x=x_1, x_2, \ldots x_\mu\), en ajoutant les résultats et en faisant pour abréger
\[
2(\varphi x \cdot \delta f x-f x \cdot \delta \varphi x)=\theta x
\]
on obtiendra
\[
\begin{aligned}
& \Pi x_1+\Pi x_2+\cdots+\Pi x_\mu \\
& =\int\left(\frac{\theta x_1}{\left(1-\frac{x_1^2}{a^2}\right) \psi^{\prime} x_1}+\frac{\theta x_2}{\left(1-\frac{x_2^2}{a^2}\right) \psi^{\prime} x_2}+\cdots+\frac{\theta x_\mu}{\left(1-\frac{x_\mu^2}{a^2}\right) \psi^{\prime} x_\mu}\right) .
\end{aligned}
\]

Maintenant \(\boldsymbol{\theta} x\) étant une fonction entière de \(x\) dont le degré est évidemment inférieur à celui de la fonction \(\psi x\), le second membre, d'après un théorème connu sur la décomposition des fonctions fractionnaires, se réduit à
\[
\int \frac{a \theta a}{2 \psi a}
\]
ou, en substituant la valeur de \(\theta a\) et celle de \(\psi a\), à
\[
a \int \frac{\varphi p a \cdot \delta f a-f a \cdot \delta, f a}{(f a)^2-(\varphi a)^2(d a)^2} \text {. }
\]

Cette intégrale se trouvera facilement; en effet, \(\boldsymbol{I} a\) étant constant, on aura en intégrant d'après les règles commes,
\[
C-\frac{a}{2 \Delta a} \log \frac{f a+\varphi a \cdot A a}{f a-\varphi a \cdot \Delta a}
\]
\(C\) étant la constante d'intégration. Cette fonction mise à la place du second membre de l'équation (6), donne précisément la formule (2) qu'il s'agissait de démontrer.
%531
La propriété de la fonction \(\Pi(x)\), exprimée par la formule (2), est d'autant plus remarquable, qu'elle aura lieu en supposant la fonction \(\Delta x\) racine carrée d'une fonction quelconquc entière et paire de \(x\). En effet la démonstration précédente est fondée sur cette seule propriété de la fonction 1x. On a ainsi une propriété générale d'une classe très étendue de fonctions transcendantes*).

La formule (2) étant démontrée pour le cas où les quantités \(x_1, x_2\), \(\ldots x_\mu\) sont inégales, il est évident qu'elle aura encore lieu en établissant entre les variables indépendantes des relations quelconques qui pourront rendre égales plusieurs des quantités \(x_1, x_2, \ldots x_\mu\).

Il faut observer que les signes des radicaux \(1 x_1, 1 x_2, \ldots 1 x_\mu\) ne sont pas arbitraires. Ils doivent être pris tels qu'ils satisfassent aux équations
(7) \(f x_1+\varphi x_1 \cdot \Delta x_1=0, f x_2+\varphi x_2 \cdot \Delta x_2=0, \ldots f x_\mu+\varphi x_\mu \cdot \Delta x_\mu=0\),
qu'on tire de l'équation (5), en mettant pour \(x\) les valeurs \(x_1, x_2, \ldots x_\mu\).
La formule (2) exprime une propriété de la fonction de la troisième espèce \(\Pi(x)\). Or rien n'est plus facile que d'en déduire des propriétés semblables des fonctions:
\[
\widetilde{\omega} x=\int \frac{d x}{d x} \text { et } \widetilde{\omega}_0 x=\int \frac{x^2 d x}{d x} .
\]

D'abord si l'on fait \(a\) infini, on a \(\Pi x=\widetilde{\omega} x\); mais il est clair que la partie logarithmique de la formule (2) s'évanouira dans ce cas; le second membre se réduira donc à une constante, et par conséquent on aur'a
\[
\widetilde{\omega} x_1+\widetilde{\omega} x_2+\cdots+\widetilde{\omega} x_\mu=C .
\]

De même si l'on développe les deux membres de l'équation (2) suivant les puissances ascendantes de \(\frac{1}{a}\), on aura, en comparant les coefficiens de \(\frac{1}{a^2}\) dans les deux membres,
\[
\widetilde{\omega}_0 x_1+\widetilde{\omega}_0 x_2+\cdots+\widetilde{\omega}_0 x_\mu \doteq C-p
\]
où \(p\) est une fonction algébrique des variables, savoir le coefticient de \(\frac{1}{a^2}\) dans le développement de la fonction
*) Voyez sur ce sujet un mémoire inséré dans le tome III, p. 313, de ce journal. On trouve un théorème beancoup plus général \(t\). IV, p. 200).
%532
\[
\frac{a}{2 \Delta a} \log \frac{f a+r a \cdot \Delta a}{f a-r a \cdot \Delta a}
\]
suivant les puissances ascendantes de \(\frac{1}{a}\).
En vertu des formules \((2,9,10)\) il est clair, qu'en désignant par \(\psi x\) une fonction quelconque de la forme:
\[
(11)\left\{\begin{array}{c}
\psi x=\int\left\{+B x^2+\frac{\alpha}{1-\frac{x^2}{a^2}}+\frac{\alpha_1}{1-\frac{x^2}{a_1^2}}+\cdots+\frac{\alpha_\nu}{1-\frac{x^2}{a_\nu^2}}\right\} \frac{d x}{\Delta x}, \\
\psi x_1+\psi x_2+\cdots+\psi x_\mu=C-B \cdot p-\frac{\alpha a}{2 \Delta a} \log \frac{f a+\varphi a_A \Delta a}{f a-\varphi a \Delta a} \\
\quad-\frac{\alpha_1 a_1}{2 \Delta a_1} \log \frac{f a_1+\varphi a_1 \Delta a_1}{f a_1-\varphi a_1 \Delta a_1}-\cdots-\frac{\alpha_\nu a_\nu}{2 \Delta a_\nu} \log \frac{f a_\nu+\varphi a_\nu \Delta a_\nu}{f a_\nu-\varphi a_\nu \Delta a_\nu} .
\end{array}\right.
\]
\[
\begin{aligned}
& \psi x_1+\psi x_2+\cdots+\psi x_\mu=C-B \cdot p-\frac{\alpha a}{2 \Delta a} \log \frac{f a+\varphi a \Delta a}{f a-\varphi a \Delta a} \\
& \quad-\frac{\alpha_1 a_1}{2 \Delta a_1} \log \frac{f a_1+\varphi a_1 \Delta a_1}{f a_1-\varphi a_1 \Delta a_1}-\cdots-\frac{\alpha_\nu a_\nu}{2 \Delta a_\nu} \log \frac{f a_\nu+\varphi a_\nu \Delta a_\nu}{f a_\nu-\varphi a_\nu \Delta a_\nu}
\end{aligned}
\]

On voit que cette équation a lieu quelle que soit la constante \(A\).
\(\S 2\).
Propriété fondamentale des fonctions elliptiques, tivée des formules précédentes.
Dans ce qui précède les quantités \(x_1, x_2, x_3, \ldots x_\mu\) sont regardées comme fonctions des coefficiens variables dans \(f x\) et \(\varphi x\). Supposons maintenant qu'on détermine ces coefficiens de manière qu'un certain nombre des quantités \(x_1, x_2, \ldots x_\mu\) prennent des valeurs données mais variables. Soient
\[
x_1, x_2, \ldots x_m
\]
des variables indépendantes. Alors les coefficiens dans \(f x, \varphi x\) deviendront des fonctions de ces quartités. En les substituant dans l'équation
\[
(f x)^2-(\varphi x)^2(\Lambda x)^2=0
\]
le premier membre sera divisible par le produit
\[
\left(x^2-x_1^2\right)\left(x^2-x_2^2\right) \cdots\left(x^2-x_m^2\right),
\]
et le quotient, égalé à zéro, donnera une équation du degré \(\mu-m\) par rapport à \(x^2\), dont les racines seront les \(\mu-m\) quantités.
\[
x_{m+1}^2, x_{m+2}^2, \ldots x_\mu^2,
\]
qui par suite sont des fonctions algébriques de \(\dot{x}_1, x_2, \ldots x_m\).
%533
Le cas le plus simple et le plus important est celui où le nombre \(\boldsymbol{\mu}-m\) a la moindre valeur possible. Pour avoir ce minimum, il faut donner aux fonctions \(f x\) et \(\varphi x\) la forme la plus générale pour laquelle le degré de l'équation \((f x)^2-(\varphi x)^2(\mathcal{A} x)^2=0\) est égal à \(2 \mu\).

Il est facile de voir que le plus grand nombre de coefficiens qu'il soit possible à introduire dans \(f x\) et \(\varphi x\), est \(\boldsymbol{\mu}\). Mais, puisqu'en vertu de la forme des équations (7) on peut supposer un de ces coefficiens égal à lunité, sans diminuer la généralité, on n'aura réellement que \(\mu-1\) indéterminées. On pourra done faire \(m=\mu-1\), en sorte que toutes les quantités \(x_1, x_2\), ... \(x_\mu\), excepté une seule, seront des variables indépendantes. Par la on aura immédiatement la propriété fondamentale des fonctions elliptiques dont il a été question au commencement du chapitre.
Il y a deux cas différens à considérer, savoir \(\mu\) pair ou impair.
Premier cas, si \(\mu\) est pair et égal à \(2 n\).
A. Si la fonction \(f x\) est paire et \(\varphi x\) impaire, il est clair que \(f x\) doit être du degré \(2 n\), et \(\varphi x\) du degré \(2 n-3\). Faisons donc
\[
\left\{\begin{array}{l}
f x=a_0+a_1 x^2+a_2 x^4+\cdots+a_{n-1} x^{8 n-2}+x^{8 n} \\
\varphi x=\left(b_0+b_1 x^8+b_2 x^4+\cdots+b_{n-8} x^{8 n-4}\right) x
\end{array}\right.
\]
et
(13) \((f x)^2-(\varphi x)^2\left(1-x^2\right)\left(1-c^2 x^2\right)=\left(x^2-x_1^2\right)\left(x^2-x_2^2\right) \ldots\left(x^2-x_{2 n-1}^8\right)\left(x^2-y^2\right)\), où nous avons mis \(y\) au lieu de \(x_{2 n}\), qui sera une fonction des variables \(x_1\), \(x_8, \ldots x_{2 n-1}\). Les coefficiens \(a_0, a_1, a_2, \ldots a_{n-1}, b_0, b_1, \ldots b_{n-2}\) sont déterminés en fonction de \(x_1, x_2, \ldots\) d l'aide des, \(\boldsymbol{l}-1\) équations (7), savoir:
\[
\text { (13') } f x_1+\varphi x_1 \cdot \Lambda x_1=0, f x_2+\varphi x_2 \cdot \Lambda x_2=0, \ldots f x_{2 n-1}+\varphi x_{2 n-1} \cdot \Lambda x_{2 n-1}=0
\]

Ces équations, étant linéaires par rapport aux inconnues, domneront celles-ci en fonction rationnelle des quantités
\[
x_1, x_2, \ldots x_{2 n-1}, \Delta x_1, \Lambda x_8, \ldots \Delta x_{2 n-1} .
\]

Il est clair qu'on pourra donner aux radicaux \(\Delta x_1, \Delta x_8, \ldots A x_{3 n-1}\) des signes arbitraires.

Pour avoir la valeur de \(y\), faisons dans l'équation (13) \(x=0\). Cela donne
\[
a_0^2=x_1^2 x_3^2 \ldots x_{2 n-1}^2 \cdot y^2,
\]
d'où l'on tire
%534
\[
y=-\frac{a_0}{x_1 \cdot x_2 \ldots x_{2 n-1}}
\]

La quantité \(y\) est done une fonction rationnelle des variables \(x_1, x_2, \ldots\) et des radicaux correspondans. Si maintenant \(y\) a cette valeur et si l'on fait de plus
\[
\Delta x_{2 n}=-\Delta y
\]
les formules \((2,9,10)\) donneront
\[
\left\{\begin{array}{l}
\widetilde{\omega} x_1+\widetilde{\omega} x_2+\cdots+\widetilde{\omega} x_{2 n-1}=\widetilde{\omega} y+C \\
\widetilde{\omega}_0 x_1+\widetilde{\omega}_0 x_2+\cdots+\widetilde{\omega}_0 x_{2 n-1}=\widetilde{\omega}_0 y-b_{n-2}+C \\
\Pi x_1+\Pi x_2+\cdots+\Pi x_{2 n-1}=\Pi y-\frac{a}{2 \Delta a} \log \frac{f a+\varphi a \cdot \Delta a}{f a-\varphi a \cdot \Delta a}+C .
\end{array}\right.
\]

Quant aux fonctions \(\widetilde{\varpi} y, \widetilde{\varpi}_0 y, \Pi y\), il faut bien observer que le signe du radical \(1 y\) n'est pas toujours le même. Il est dans tous les cas déterminé par la dernière des équations (7) qui, en mettant pour \(x_{2 n}\) et \(\boldsymbol{A} x_{2 n}\) leurs valeurs \(y\) et \(-\Delta y\), deviendra
\[
f y-\varphi y \cdot \Delta y=0 .
\]

On en tire
\[
\Delta y=\frac{f y}{\varphi y}
\]
ce qui fait voir que le radical \(\Delta y\), comme \(y\), est une fonction rationnelle des quantités \(x_1, x_2, \ldots \Delta x_1, \Delta x_2 \ldots\)

La fonction \(y\) a la propriété d'être zéro en même temps que les variables \(x_1, x_2, \ldots x_{2 n-1}\). En effet si l'on fait
\[
x_1=x_2=\cdots=x_{2 n-1}=0,
\]
l'équation (13) ne pourra subsister à moins que tous les coefficiens \(a_0, a_1\), \(\ldots a_{n-1}, b_0, b_1, \ldots b_{n-2}\) ne soient égaux à zéro, done cette équation se réduit à
\[
x^{4 n}=x^{4 n-2}\left(x^2-y^2\right)
\]
done on aura \(y=0\).
On pourrait donner le signe contraire au second membre de l'équation (14). Celui que nous avons choisi est tel que le radical \(\Delta y\) se réduit à +1 , en supposant \(x_1=x_2=x_3=\cdots=x_{2 n-1}=0\), et en même temps \(\Lambda x_1=\Lambda x_2=\cdots=\Lambda x_{2 n-1}=+1\). Pour démontrer cela, supposons \(x_1, x_2\), \(\ldots x_{2 n-1}\) infiniment petits; on aura alors
%535
\[
d x_1=\lambda x_2=\cdots=\Lambda x_{2 n-1}=1
\]
et par conséquent les équations \(\left(13^{\prime}\right)\) font voir que \(x_1, x_2, \ldots x_{2 n-1}\) satisfont à l'équation
\[
x^{2 n}+a_{n-1} x^{2 n-2}+b_{n-2} x^{2 n-3}+\cdots+b_0 x+a_0=0 .
\]

Cette équation étant du degré \(2 n\), doit avoir encore une racine. En la désignant par \(z\), on aura
\[
a_0=z \cdot x_1 \cdot x_2 \cdots x_{2 n-1}
\]
done en vertu de l'équation (14),
\[
z=-y
\]

L'équation est done satisfaite en faisant \(x=-y\). Or cela donne
\[
y^{2 n}+a_{n-1} y^{2 n-2}+\cdots+a_1 y^2+a_0=\left(b_0+b_1 y^2+\cdots+b_{n-2} y^{2 n-4}\right) y
\]
done en vertu de l'équation (16):
\[
\Delta y=+1
\]

On pourra encore remarquer que \(y\) se réduit pour des valeurs infiniment petites de \(x_1, x_2, \ldots x_{2 n-1}\) à \(x_1+x_2+\cdots+x_{2 n-1}\). On le voit par l'équation (17), qui, n'ayant pas de second terme, domnera la somme des racines égale à zéro, c'est-à-dire
\[
x_1+x_2+\cdots+x_{2 n-1}-y=0
\]
donc
\[
y=x_1+x_2+\cdots+x_{2 n-1} \text {. }
\]
B. Si \(f x\) est impair et \(\varphi x\) pair, \(f x\) doit être du degré \(2 n-1\) et \(\varphi x\) du degré \(2 n-2\). Donc on aura dans ce cas \(2 n-1\) coefficiens indéterminés, et on parviendra ì des formules semblables aux formules (15); mais la fonction \(y\) aura une valeur différente. Il sera facile de démontrer qu'elle sera égale à \(\frac{1}{c y}\), la valeur de \(y\) étant déterminée par l'équation (14).
Second cas, si "u est un nombre impair et égal à \(2 n+1\).
A. Si \(f x\) est impair et \(\varphi x\) pair, on aura
\[
\left\{\begin{array}{l}
f x=\left(a_0+a_1 x^2+a_2 x^4+\cdots+a_{n-1} x^{2 n-8}+x^{2 n}\right) x \\
\varphi x=b_0+b_1 x^2+b_2 x^4+\cdots+b_{n-1} x^{2 n-2}
\end{array}\right.
\]
(21) \((f x)^2-(\varphi x)^2\left(1-x^2\right)\left(1-c^2 x^2\right)=\left(x^2-x_1^2\right)\left(x^2-x_2^2\right) \ldots\left(x^2-x_{2 n}^2\right)\left(x^2-y^2\right)\).
%536
Les coefficiens \(a_0, a_1, \ldots a_{n-1}, b_0, b_1, \ldots b_{n-1}\) sont déterminés par les \(2 n\) équations linéaires
(22) \(f x_1+\varphi x_1 \cdot \Delta x_1=0, f x_2+\varphi x_z \cdot \Delta x_2=0, \ldots f x_{2 n}+\varphi x_{2 n} \cdot \Delta x_{2 n}=0\).

La fonction \(y\) le sera par l'équation
\[
y=\frac{b_0}{x_1 \cdot x_2 \cdots x_{2 n}},
\]
qu'on obtiendra, en faisaut dans \((21) x=0\). Enfin le radical \(d y\) est déterminé par
\[
\boldsymbol{I} y=\frac{f y}{\varphi y} .
\]

Cela posé on aura
\[
\left\{\begin{array}{l}
\widetilde{\omega} x_1+\widetilde{\omega} x_2+\cdots+\widetilde{\omega} x_{2 n}=\widetilde{\omega} y+C \\
\widetilde{\omega}_0 x_1+\widetilde{\omega}_0 x_2+\cdots+\widetilde{\omega}_0 x_{2 n}=\widetilde{\omega}_0 y-b_{n-1}+C \\
\Pi x_1+\Pi x_2+\cdots+\Pi x_{2 n}=\Pi y-\frac{a}{2 \Delta a} \log \frac{f a+\boldsymbol{f a} \cdot \Delta a}{f a-\Phi a \cdot \Delta a}+C
\end{array}\right.
\]

Les fonctions \(y\) et \(1 y\) sont, comme dans le cas précédent, des fonctions rationnelles des variables \(x_1, x_2, \ldots x_{2 n}\) et des radicaux \(\Delta x_1, \Delta x_2, \ldots \Delta x_{2 n}\), et on démontrera de la même manière, qu'on aura pour des valeurs infiniment petites de \(x_1, x_2, \ldots x_{2 n}\),
\[
y=x_1+x_2+\cdots+x_{2 n}, \quad d y=+1
\]
si l'on suppose en même temps que les radicaux \(\lambda x_1, \boldsymbol{A} x_2, \ldots \lambda x_{2 n}\) se réduisent \(\grave{a}+1\); donc \(y\) s'évanouira simultanément avec les variables.

Les formules (25) pourront d'ailleurs être déduites sur le champ de celles du premier cas, en \(\mathrm{y}\) faisant \(x_{2 n-1}=0\), et changeant ensuite \(n\) en \(n+1\).
B. Si \(f x\) est pair et \(\varphi x\) impair, on parviendra à des formules semblables. La valeur qui en résultera pour la fonction \(y\), sera égale à \(\frac{1}{c y}\), où \(y\) est déterminé par la formule (23).

On voit par les formules \((15,25)\), qu'on pourra toujours exprimer la somme d'un nombre domné de fonctions par une seule fonction de la même espèce, en y ajoutant, pour les fonctions de la première espèce, une constante, pour celles de la seconde espèce une certaine fonction algébrique, et pour celles de la troisième espèce une fonction logarithmique.
%537
En remarquant qu'une intégrale quelconque de la forme
\[
\int \frac{\theta x \cdot d x}{d \cdot x}
\]
peut être réduite aux fonctions \(\bar{\omega} x\) et \(\widetilde{\omega}_0 x\) et à un certain nombre de fonctions de la troisième espèce, en y ajoutant une expression algébrique et logarithnique, il est clair qu'en faisant
\[
\psi x=\int \frac{\theta x \cdot d x}{A x},
\]
on aura la relation
\[
\psi x_1+\psi x_2+\psi x_3+\cdots=\psi y+v+C
\]
oì \(v\) est exprimable par des fonctions algébriques et logarithmiques.
En vertu des formules \((15,25)\) il est clair que la fonction \(v\) ne change pas de valeur, si l'on ajoute à la fonction rationnelle \(\theta x\) une quantité constante quelconque, de sorte qu'on pent supposer également
\[
\psi x=\int(A+\theta x) \frac{d x}{d x} .
\]

Je dis maintenant que la fonction \(\psi\) est la seule qui puisse satisfaire à l'équation (27). En effet si l'on différentie cette équation par rapport à l'une des variables indépendantes \(x_1, x_2, \ldots\), par exemple à \(x_1\), on aura
\[
\psi^{\prime} x_1 \cdot d x_1=\psi^{\prime} y \frac{d y}{d x_1} d x_1+\frac{d v}{d x_1} d x_1 .
\]

Cela posé, si l'on suppose toutes les quantités \(x_3, x_1, \ldots y\) égales à des constantes déterminées, on aura, en mettant \(x\) pour \(x_1\), et en faisant
\[
\begin{gathered}
\psi^{\prime} y=A, \quad \frac{d v}{d x_1}=p, \quad \frac{d y}{d x_1}=q: \\
\psi^{\prime} x \cdot d x=A q d x+\mu d x,
\end{gathered}
\]
d'où l'on tire
\[
\psi x=\int(A q+p) d x .
\]

La fonction \(\psi x\) ne pourra donc contenir qu'une senle constante indéterminée \(A\), et par conséquent
\[
\psi x=\int(A+\theta x) \frac{d x}{d x}
\]
est son expression générale.
Les propriétés exprimées par les formules de ce paragraphe appartien-
%538
nent donc aux seules fonctions elliptiques. C'est pourquoi je les ai nummées fondamentales.

Dans les formules que nous avons domnées, y a une valeur unique, mais on pourra satisfaire aux mêmes formules, en mettant pour y une expression algébrique contenant une constante arbitraire. En effet, pour avoil une telle expression, il suffit de supposer une des variables \(x_1, x_2, x_3, \ldots\) égale à une constante arbitraire, et la valeur de \(y\) qu'on obtiendra ainsi, serar la plus générale possible, comme on sait par la théorie de l'intégration des équations différentielles du premier ordre, dont l'intégrale complète ne contient qu'une seule constante arbitraire.

A l'aide des formules \((15,25)\) on pourra exprimer la somme d'un nombre quelconque de fonctions par une seule fonction. Il est facile d'en tirer les formules suivantes:
\[
(28)\left\{\begin{array}{l}
\frac{\mu_1}{\mu} \widetilde{\omega} x_1+\frac{\mu_2}{\mu} \widetilde{\omega} x_2+\cdots+\frac{\mu_n}{\mu} \widetilde{\omega} x_n=C+\widetilde{\varpi} y \\
\frac{\mu_1}{\mu} \widetilde{\omega}_0 x_1+\frac{\mu_2}{\mu} \widetilde{\omega}_0 x_2+\cdots+\frac{\mu_n}{\mu} \widetilde{\omega}_0 x_n=\widetilde{\omega}_0 y-p+C \\
\frac{\mu_1}{\mu} \Pi x_1+\frac{\mu_2}{\mu} \Pi x_2+\cdots+\frac{\mu_n}{\mu} \Pi x_n=\Pi y-\frac{a}{2 \operatorname{Ia} a} \log \frac{f a+\boldsymbol{f} a \cdot d a}{f a-\Phi a \cdot d a}+C
\end{array}\right.
\]
où \(\mu_1, \mu_2, \ldots, \mu_n, \mu\) désignent des nombres entiers quelconques, et où \(y\) est une fonction algébrique des variables \(x_1, x_2, \ldots x_n\), de même que les coefticiens de \(f a\) et \(\varphi a\). Pour avoir ces formules, il suffit de supposer dans (13) et (21) un certain nombre des quantités \(x_1, x_2, \ldots y\) égales entre elles.
Pour déterminer \(y, f x, \varphi x\), on aura cette équation
\[
\begin{aligned}
(f x)^2-(\varphi x)^2\left(1-x^2\right) & \left(1-c^2 x^2\right) \\
= & \left(x^2-x_1^2\right)^{\mu_1}\left(x^2-x_2^2\right)^{\mu_2} \ldots\left(x^2-x_n^2\right)^{\mu_n}\left(x^2-y^2\right)^\mu,
\end{aligned}
\]
qui doit avoir lieu pour une valeur quelconque de \(x\).
\(\S 3\).
Application au cas vì deux fonctions sont données.
Pour réduire deux fonctions à une seule, il suffit de supposer, dans les formules (25), \(n=1\). On aura alors
\[
f x=a_0 x+x^3, \varphi x=b_0,
\]
%539
et pour détemniner les deux constantes \(a_0\) et \(b_0\), on aura les deux équations
\[
a_0 x_1+x_1^3+b_0 1 x_1=0, a_0 x_2+x_2^3+b_0 1 x_2=0,
\]
qui donnent
\[
a_0=\frac{x_2^8 \Delta x_1-x_1^8 \Delta x_2}{x_1 \Delta x_2-x_2 \Delta x_1}, \quad b_0=\frac{x_2 x_1^8-x_1 x_2^8}{x_1 \Delta x_2-x_8 \Delta x_1} .
\]

Connaissant \(b_0\), on aura la valeur de \(y\) par la formule (23), savoir pour \(n=1\)
\[
y=\frac{b_0}{x_1 x_2}
\]
done
\[
y=\frac{x_1^2-x_2^2}{x_1 \Delta x_2-x_2 \Delta x_1}
\]
ou bien, en multipliant haut et bas par \(x_1 A x_2+x_2 A x_1\),
\[
y=\frac{x_1 A x_2+x_2 A x_1}{1-c^2 x_1^2 x_2^2}
\]

Si l'on exprime \(a_0\) et \(b_0\) en \(x_1, x_2, y\), on aura ces expressions très simples:
\[
b_0=x_1 x_2 y, \quad a_0=\frac{1}{2}\left(c^2 x_1^2 x_2^2 y^2-x_1^2-x_2^2-y^2\right) \text {. }
\]

L'expression de \(a_0\) se tire de l'équation
\[
\left(a_0 x+x^3\right)^2-b_0^2\left(1-x^2\right)\left(1-c^2 x^2\right)=\left(x^2-x_1^2\right)\left(x^2-x_2^2\right)\left(x^2-y^2\right),
\]
en égalant entre eux les coefficiens de \(x^4\) dans les deux membres.
Les fonctions \(a_0\) et \(y\) étant déterminées comme on vient de le voir, les formules (25) donneront, en faisant \(n=1\),
\[
\left\{\begin{array}{l}
\widetilde{\omega} x_1+\widetilde{\omega} x_2=\widetilde{\omega} y+C \\
\widetilde{\omega}_0 x_1+\widetilde{\omega}_0 x_2=\widetilde{\omega}_0 y-x_1 x_2 y+C, \\
\Pi x_1+\Pi x_2=\Pi y-\frac{a}{2 A a} \log \frac{a_0 a+a^3+x_1 x_2 y}{a_0 a+a^3-x_1 x_2 y}+C
\end{array}\right.
\]

Quant à la valeur du radical \(\boldsymbol{X} y\), elle est domnée par l'équation (24)
\[
\Delta y=\frac{f y}{\varphi^y}=\frac{a_0 y+y^3}{b_0}
\]
c'est-à-dire
\[
\Delta y=\frac{a_0+y^2}{x_1 x_2}
\]

Pour réduire la différence de deux fonctions à une senle, il suffit de chan(is*
%540
ger le signe de \(x_8\) dans les formules précédentes. La valeur de \(y\) deviendra alors
\[
y=\frac{x_1 d x_2-x_2 \Delta x_1}{1-c^2 x_1^2 x_2^2}=\frac{x_1^2-x_2^2}{x_1 A x_8+x_8 d x_1} .
\]

Si dans les formules (33) on fait \(x_2\) égal à une constante arbitraire, on aura la relation qui doit avoir lieu entre les variables de deux fonctions pour qu'elles soient réductibles l'une à l'autre. En faisant \(x_2=e, x_1=x\), on aura
\[
y=\frac{x d e+e \Lambda x}{1-c^2 e^2 x^2} \text { et } \widetilde{\omega} x=\widetilde{\omega} y+C .
\]

En différentiant, il viendra
\[
\frac{d y}{d y}=\frac{d x}{d x} .
\]

L’intégrale complète de cette équation est donc exprimée par l'équation algébrique (36), e étant la constante arbitraire. Parmi les intégrales particulieres on doit remarquer les suivantes:
1) \(y=x\), qui répond à \(e=0, \boldsymbol{I} y=\Delta x\),
2) \(y= \pm \frac{1}{c x}\), qui répond à \(e=\frac{1}{0}, \quad y y=\mp \frac{d x}{c x^2}\),
3) \(y=\sqrt{\frac{1-x^2}{1-c^2 x^2}}\), qui répond à \(e=1,1 y=\frac{\left(c^2-1\right) x}{1-c^2 x^2}\),
4) \(y \doteq \frac{1}{c} \sqrt{\frac{1-c^2 x^2}{1-x^2}}\), qui répond à \(e=\frac{1}{c}, \quad 1 y=\frac{\left(1-c^2\right) x}{\left(1-x^2\right) c}\).
\(\S 4\).
Application au cas où tontes les fonctions domuées sont égales
Si l'on fait dans les formules \((15,25)\).
\[
x_1=x_8=x_3=\cdots=x, \Lambda x_1=\Lambda x_2=\Lambda x_3=\cdots=\Lambda x
\]
on aura celles-ci :
%541
où
\[
(f z)^2-(\varphi z)^2\left(1-z^2\right)\left(1-c^2 z^2\right)=\left(z^2-x^2\right)^\mu\left(z^2-y^2\right),
\]
\(z\) étant indéterminé.
Ia fonction \(y\) est déterminée par les équations \((14,23)\) :
\[
y=-\frac{a_0}{x^\mu}, y=\frac{b_0}{x^\mu} \text {. }
\]

La première a lieu si \(\boldsymbol{\mu}=2 n-1\), la seconde si \(\boldsymbol{\mu}=2 n\). Les équations \(\left(13^{\prime}, 22\right)\), qui doivent déterminer les coefficiens \(a_0, a_1, a_2, \ldots, b_0, b_1, b_2, \ldots\), se réduiront dans le cas que nous considérons à une seule, savoir
\[
f x+\varphi x \cdot \Delta x=0,
\]
mais d'après les principes du calcul différentiel, cette équation doit encore avoir lieu, en la différentiant par rapport à \(x\) seul un nombre quelconque de fois moindre que \(\mu\). On aura donc en tout " équations linéaires entre les " incomnues; on en tire leurs valeurs en fouction rationnelle de la variable \(x\) et du radical \(\Delta x\). Connaissant \(a_0, a_1, a_2, \ldots, b_0, b_1, b_2, \ldots\), on aura ensuite la valeur de \(\boldsymbol{A} y\) par l'équation
\[
\Delta y=\frac{f y}{\uparrow y} .
\]

On pourrait ainsi déterminer toutes les quantités nécessaires, mais pour mieux approfondir les propriétés de la fonction \(y\), nous allons traiter le problème d'une autre manière, qui conduira successivement aux valeurs de y qui répondent aux valeurs \(1,2,3\), etc. de, .
Désignons par \(x_\mu\) la valeur de \(y\) qui répond à \(\mu\). On aura
\[
\widetilde{\omega} x_\mu=C+\mu \widetilde{\omega} x
\]
done
\[
\widetilde{\omega}\left(x_{\mu+m}\right)=C+\widetilde{\omega} x_\mu+\widetilde{\omega} x_m
\]
mais si l'on fait
\[
y=\frac{x_m d x_\mu+x_\mu d x_m}{1-c^2 x_m^2 x_\mu^2}
\]
on aura, en vertu des équations \((31,33)\)
\[
\widetilde{\omega} x_m+\widetilde{\omega} x_\mu=\widetilde{\omega} y,
\]
done
\[
\widetilde{\omega} x_{\mu+m}=C+\widetilde{\omega} y .
\]

La valeur la plus générale de \(\dot{x}_{\mu+m}\), qui satisfera à cette équation est
%542
\[
x_{\mu+m}=\frac{y \Delta e+e \Delta y}{1-c^2 e^2 y^2},
\]
où \(e\) est une constante. Pour la déterminer, soit \(x\) infiniment petit; on aura alors
done
\[
x_m=m x, x_\mu=\mu x, x_{\mu+m}=(m+\mu) x, \Delta x_m=\Lambda x_\mu=1
\]
\[
y=(m+\mu) x, \Delta y=1
\]

L'équation \(\left(41^{\prime}\right)\) domnera done
\[
(m+\mu) x=(m+\mu) x \Delta e+e,
\]
donc \(e=0, \wedge e=1\) et par suite \(x_{m+\mu}=y\), c'est-à-dire que
\[
x_{\mu+m}=\frac{x_\mu \Delta x_m+x_m \Delta x_\mu}{1-c^2 x_m^2 x_\mu^2} .
\]

On aura de la même manière
\[
x_{\mu-m}=\frac{x_\mu \Delta x_m-x_m \Delta x_\mu}{1-c^2 x_m^2 x_\mu^2} .
\]

La première de ces formules servira à trouver \(x_{\mu+m}\), lorsqu'on connaît \(x_m\) et \(x_\mu\); on pourra donc former successivement les fonctions
\[
x_2, x_3, x_4, x_5, \ldots
\]
en remarquant que \(x_1=x, \Delta x_1=\Delta x\).
Si l'on fait \(m=1\), on trouvera
\[
x_{\mu+1}=-x_{\mu-1}+\frac{2 x_\mu \Delta x}{1-c^2 x^2 x_\mu^2} \text {. }
\]

En remarquant que
\[
x_0=0, x_1=x,
\]
cette formule fait voir que \(x_\mu\) est une fonction rationnelle de \(x\), si \(\mu\) est un nombre impair, et que \(x_\mu\) est de la forme \(p / x\), où \(p\) est rationnel, si " est un nombre pair. Dans le premier cas \(\frac{\boldsymbol{A}_\mu}{\boldsymbol{A} x}\) est rationnel, et dans le second \(1 x_\mu\) le sera. On voit également que \(x_\mu\) s'évanouira en même temps que \(\Delta x\), si "u est un nombre pair. Les quantités
\[
x_{2 \mu+1}, \frac{\Delta x_{2 \mu+1}}{\Delta x}, \frac{x_{2 \mu}}{d x}, \Lambda x_{2 \mu}
\]
sont donc des fonctions rationnelles de \(x\).
Si l'on multiplie entre elles les deux formules \((42,43)\), il viendra
%543
\[
x_{\mu+m}, x_{\mu-m}=\frac{x_\mu^2-x_m^2}{1-c^2 x_\mu^2 x_m^2},
\]
équation qui paraît être la relation la plus simple qu'on puisse établir entre les fonctions \(x_\mu\). En y faisant \(m=\mu-1\), on aura
\[
x_{2 \mu-1}=\frac{1}{x} \frac{x_\mu^2-x_{\mu-1}^2}{1-c^2 x_\mu^2 x_{\mu-1}^2} \text {. }
\]

De même si daus la formule (42) on fait \(m=\mu\), on aura
\[
x_{2 \mu}=\frac{2 x_\mu \cdot I_1 x_\mu}{1-c^2 x_\mu^4}
\]

Ces deux formules paraissent être les plus commodes pour calculer successivement les fonctions \(x_2, x_3, x_4, \ldots\)
Pour trouver les expressions les plus simples de \(x_\mu\), supposons
\[
x_\mu=\frac{p_\mu}{q_\mu}, \Delta x_\mu=\frac{r_\mu}{q_\mu^2}
\]
où \(p_\mu^2, q_\mu\) sont des fonctions entières de \(x\) sans diviseur commun. En mettant ces valeurs dans l'équation (46), on aura
\[
\frac{p_{2 \mu}}{q_{2 \mu}}=\frac{2 p_\mu q_\mu{ }^2 \mu}{q_\mu^4-c^2 p_\mu^4}
\]

Or il est évident que la fraction du second membre est réduite à sa plus simple expression; done on aura séparément
\[
p_{2 \mu}=2 p_\mu q_\mu r_\mu, q_{2 \mu}=q_\mu^4-c^2 p_\mu^4 \cdot
\]

En faisant les mêmes substitutions dans l'équation (45), on obtiendra
\[
\frac{d \cdot p_{z \mu-1}}{q_{2 \mu-1}}=\frac{p_\mu^2 q_{\mu-1}^2-q_\mu^2 p_{\mu-1}^2}{q_\mu^2 q_{\mu-1}^2-c^2 p_\mu^2 p_{\mu-1}^2} .
\]

Or je dis que la fraction du second membre est nécessairement réduite à sal plus simple expression. En effet si l'on avait pour une même valeur de \(x\)
\[
p_\mu^2 q_{\mu-1}^2-q_\mu^2 \mu_{\mu-1}^2=0, q_\mu^8 q_{\mu-1}^2-c^2 p_\mu^3 p_{\mu-1}^8=0
\]
on aurait encore
\[
x_\mu^2=x_{\mu-1}^2, 1-c^2 x_\mu^2 x_{\mu-1}^2=0 .
\]

Mais on a en général
\[
x_{2 \mu-1}=\frac{x_\mu \cdot x_{\mu-1}+x_{\mu-1} I \cdot x_\mu}{1-c^2 x_\mu^2 x_{\mu-1}^{\mathrm{g}}}=\frac{x_{\mu-1}^2-x_{\mu-1}^2}{x_\mu \cdot x_{\mu-1}-x_{\mu-1} / x_\mu},
\]
done aussi
\[
x_\mu / x_{\mu-1}=x_{\mu-1} / x_\mu=0
\]
%544
ou bien
\[
x_\mu^2\left(1-x_{\mu-1}^2\right)\left(1-c^2 x_{\mu-1}^2\right)=0=-x_{\mu-1}^2\left(1-x_\mu^2\right)\left(1-c^2 x_\mu^2\right)
\]
ce qui est impossible, car il fallait
\[
x_\mu^2= \pm \frac{1}{c} \text {. }
\]

Cela posé, l'équation (49) domnera
\[
p_{2 \mu-1}=\frac{1}{x}\left(p_\mu^2 q_{\mu-1}^2-q_\mu^2 p_{\mu-1}^2\right), \quad q_{2 \mu-1}=q_\mu^2 q_{\mu-1}^2-c^2 p_\mu^2 p_{\mu-1}^2 \cdot
\]

Si donc on détermine successivement les fonctions
\[
p_2, q_2, p_3, q_3, p_4, q_4, \ldots
\]
par les équations \((48,50), \frac{p_\mu}{q_\mu}\) sera toujours réduit à sa plus simple expression.

On pourra faire \(p_1=x, q_1=1\). D'après la forme des expressions \((48,50)\) il est clair que
1) \(p_{2 \mu-1}\) est une fonction entière et impaire de \(x\) du degré \((2 \mu-1)^2\),
2) \(p_{2 \mu}=p^{\prime} \cdot d x\), où \(p^{\prime}\) est ume fonction entière et impaire du degré \((2 u)^2-3\),
3) \(q_\mu\) est une fonction entière et paire du degré \(\boldsymbol{\mu}^2-1\) ou \(\mu^2\), selon que \(\boldsymbol{\mu}\) est impair ou pair.

Les fonctions \(x_{2 \mu-1}\) et \(x_{2 \mu}\) auront done la forme suivante:
\[
\begin{aligned}
x_{2 \mu-1} & =\frac{x\left(A_0+A_2 x^2+A_4 x^4+\cdots+A_{(2 \mu-1)^2-1} x^{(2 \mu-1)^3-1}\right)}{1+A_2^1 x^2+A_4^1 x^4+\cdots+A_{(2 \mu-1)^2-1}^1 x^{(2 \mu-1)^2-1}}, \\
x_{2 \mu} & =\frac{x d x\left(B_0+B_2 x^2+B_4 x^4+\cdots+B_{4 \mu^2-4} x^{(2 \mu)^2-4}\right)}{1+B_2^1 x^2+B_4^1 x^4+\cdots+B_{4 \mu^2}^1 x^{(2 \mu)^2}} .
\end{aligned}
\]

On aura par exemple
\[
x_2=\frac{2 x d x}{1-c^2 x^4}, \quad x_3=x \frac{3-4\left(1+c^2\right) x^2+6 c^2 x^4-c^4 x^8}{1-6 c^2 x^4+4 c^2\left(1+c^2\right) x^6-3 c^4 x^8} .
\]

Il est facile de voir que les coefficiens \(A_0, A_2, \ldots A_2^1, A_4^1, \ldots B_0\), \(B_2, \ldots B_2^1, B_4^1, \ldots\) seront des fonctions entières de \(c^2\). On a toujours
\[
A_0=2 \mu-1, B_0=2, \text { et } A_2^1=B_2^1=0 .
\]

La fonction \(x_{2 \mu}\) est, comme on le voit, irrationnelle; or on pent facilement trouver une fonction rationnelle \(y\) qui satisfasse à l'équation
\[
\frac{d y}{d y}=2 \mu \frac{d x}{d x} .
\]
%545
Une telle fonction est la suivante
\[
y=\sqrt{\frac{1-x_{2 \mu}^2}{1-c^2 x_{2 \mu}^2}}=\frac{d x_{2 \mu}}{1-c^2 x_{2 \mu}^2},
\]
car on a, en vertu de la relation (37),
\[
\frac{d y}{\Delta y}=\frac{d x_{2 \mu}}{d x_{2 \mu}}
\]
et \(y\) est rationnel, puisque les fonctions \(\mathcal{A}_{2 \mu}\) et \(x_{2 \mu}^2\) le sont. On se convaincra aisément que cette fonction \(y\) aura la forme
\[
y=\frac{1+\alpha x^2+\cdots+\beta x^{(2 \mu)^{\mathrm{a}}}}{1+\alpha^{\prime} x^2+\cdots+\beta^{\prime} x^{(2 \mu)^2}} .
\]

Pour,\(\iota=1\), on aura
\[
y=\frac{1-2 x^2+c^2 x^4}{1-2 c^2 x^2+c^2 x^4} .
\]

Nous verrons dans la suite comment on pourra décomposer les fonctions \(x_\mu\) et \(y\) en facteurs et en fractions partielles.

Nous montrerons de même que les équations précédentes sont toujours résolubles algébriquement par rapport à \(x\), de sorte qu'on peut exprimer \(x\) en \(x_\mu\) à l'aide de radicaux.
CHAPITRE II.
Sur la relation la plus générale possible entre un nombre quelconque de fonctions elliptiques.
Après avoir établi dans le chapitre précédent les propriétés fondamentales des fonctions elliptiques, nous allons maintenant en faire l'application au problème général que nous nous sommes proposé. Nous ferons voir qu'on pourra en ramener la solution à celle de quelques autres problèmes plus simples.
\(\S 1\).

Sur lu forme qu'on pourra donner à lintégrale d'une différentielle quelconque algébrique, en supposant cette intégrale exprimable par des fonctions algébriques, logarithmiques et elliptiques.
Soient \(x_1, x_2, x_3, \ldots x_\mu\) des variables en nombre quelconque, liées entre elles par des équations algébriques dont le nombre est moindre que 69 .
%546
celui des variables. Soient \(y_1, y_2, \ldots y_\mu\) des fonctions algébriques quelconques de ces variables et supposons que la différentielle
\[
y_1 d x_1+y_2 d x_2+\cdots+y_\mu d x_\mu
\]
soit complète et que son intégrale soit exprimable à l'aide de fonctions algébriques, logarithmiques et elliptiques, de sorte que l'on ait
\[
\begin{aligned}
\int\left(y_1 d x_1+y_2 d x_2+\cdots\right. & \left.+y_\mu d x_\mu\right) \\
=u & +A_1 \log v_1+A_2 \log v_2+\cdots+A_v \log v_v \\
& +\alpha_1 \cdot \psi_1 t_1+\alpha_2 \cdot \psi_2 t_2+\cdots+\alpha_n \cdot \psi_n t_n
\end{aligned}
\]
\(A_1, A_2, \ldots A_v, \alpha_1, \alpha_z, \ldots \alpha_n\) étant des quantités constantes, \(u, v_1, v_z\), \(\ldots v_\nu, t_1, t_2, \ldots t_n\) des fonctions algébriques des variables \(x_1, x_2, \ldots x_\mu\), et \(\psi_1, \psi_2, \psi_3, \ldots \psi_n\) des fonctions elliptiques quelconques des trois espèces avec des modules et des paramètres quelconques. Désignons respectivement par \(c_1, c_8, \ldots c_n\) les modules de ces fonctions, et faisons pour abréger
\[
\pm \sqrt{\left(1-x^2\right)\left(1-c_m^8 x^2\right)}=\dot{d_m x}
\]
de sorte qu'on ait en général
\[
\psi_m x=\int \frac{\theta^{\prime} d x}{I_m x},
\]
\(\theta^{\prime}\) étant une fonction ratiomnelle de \(x^2\) de l'une des trois formes
\[
\text { 1, } x^2, \frac{1}{1-\frac{x^2}{a^2}},
\]
selon que \(\psi_n x\) est une fonction de la première, de la seconde on de la troisième espèce. Nous pourrons même supposer que \(\theta^{\prime}\) soit une fonction rationnelle quelconque de \(x\).

On poura regarder un certain nombre des quantités \(x_1, x_2, \ldots x_\mu\) comme des variables indépendantes. Soient celles-ci les \(m\) premières:
\[
x_1, x_2, x_3, \ldots x_m
\]
alors toutes les quantités
\[
x_{m+1}, x_{m+2}, \ldots x_\mu ; t_1, t_2, \ldots t_n ; u ; v_1, v_2, \ldots v_\nu ; y_1, y_2, \ldots y_\mu
\]
seront des fonctions algébriques de \(x_1, x_2, \ldots x_n\).
Cela posé, imaginons une fonction algébrique \(\theta\) telle qu'on puisse exprimer toutes les fonctions
\[
u, v_1, v_2, \ldots v_v ; t_1, t_2, \ldots t_n, \Delta_1\left(t_1\right), \Delta_2\left(t_2\right), \ldots \Delta_n\left(t_n\right)
\]
%547
rationnellement en
\[
\theta, x_1, x_2, x_3, \ldots x_\mu, y_1, y_2, y_3, \ldots y_\mu \text {. }
\]

Il existe une infinité de fonctions \(\theta\) qui jouissent de cette propriété. Une telle fonction sera par exemple la somme de toutes les fonctions (62), multipliées chacune par un coefficient indéterminé et constant. C'est ce qui est facile à démontrer par la théorie des équations algébriques. La quantité \(\boldsymbol{\theta}\), étant une fonction algébrique des variables \(x_1, x_2, \ldots\), pourra donc satisfaire à une équation algébrique, dans laquelle tous les coefficiens sont des fonctions rationnelles de \(x_1, x_2, \ldots\) Or au lieu de supposer ces coefficiens rationnels en \(x_1, x_2, \ldots\), nous les supposerons rationnels en
\[
x_1, x_2, x_3, \ldots x_\mu, y_1, y_2, y_3, \ldots y_\mu
\]
car cette supposition permise simplifiera beaucoup le raisonnement. Soit donc
\[
V=0
\]
l'équation en \(\boldsymbol{\theta}\); désignons son degré par \(\delta\) et supposons, ce qui est permis, qu'il soit impossible que la fonction \(\theta\) puisse être racine d'une autre équation de la même forme, mais dont le degré soit moindre que \(\delta\).

Imaginons maintenant qu'on différentie l'équation (57) par rapport aux variables indépendantes \(x_1, x_2, \ldots x_m\). Il est facile de voir que la differentielle qu'on trouve sera de la forme
\[
p_1 d x_1+p_z d x_2+\cdots+p_m d x_m=0
\]
où \(p_1, p_2, \ldots p_m\) seront des fonctions rationnelles des quantités
\[
\begin{gathered}
x_1, x_2, \ldots x_m, x_{m+1}, \ldots x_\mu, y_1, y_2, \ldots y_\mu, u, v_1, v_2, v_3, \ldots v_v, \\
t_1, t_2, \ldots t_n, \Lambda_1\left(t_1\right), \Lambda_2\left(t_2\right), \ldots \Lambda_n\left(t_n\right) .
\end{gathered}
\]

Done en introduisant la fonction \(\theta, p_1, p_2, \ldots p_m\) deviendront des fonctions rationnelles de
\[
\theta, x_1, x_2, \ldots x_\mu, y_1, y_2, \ldots y_\mu .
\]

Cela posé, l'équation (66) domnera séparément
\[
p_1=0, p_2=0, p_3=0, \ldots p_m=0
\]
et il est clair que si ces équations sont satisfaites, l'équation proposée (57) le: sera également. Maintenant les équations (68) sont autant d'équations en \(\theta\) de la même forme que \(V=0\), on pruront aisément être réduites à cette
%548
forme; mais, d'après l'hypothèse, \(V=0\) est une équation irréductible en- \(\theta\), done il suit d'un théorème connu, que toutes les équations (68) seront encore satisfaites, en mettant pour \(\theta\) une quelconque des racines de l'équation \(V=0\). Done l'équation (57) aura lieu quelle que soit la valeur de \(\boldsymbol{\theta}\), pourvu qu'elle satisfasse à l'équation \(V=0\).
Désignons par
\[
\theta_1, \theta_2, \ldots \theta_\delta
\]
les racines de l'écuation \(V=0\), et par
\[
u^{\prime}, u^{\prime \prime}, \ldots u^{(\delta)} ; v_m{ }^{\prime}, v_m{ }^{\prime \prime}, \ldots v_m^{(\delta)} ; t_m{ }^{\prime}, t_m{ }^{\prime \prime}, \ldots t_m^{(\delta)}
\]
les valeurs correspondantes des fonctions \(u, v_m, t_m\). Alors l'équation (57) donnera, en substituant dans le second membre d'abord les expressions des quantités \(u, v_1, v_2, \ldots t_1, t_2, \ldots, A_1\left(t_1\right), A_2\left(t_2\right), \ldots\) en fonction rationnelle de \(\theta, x_1, x_2, \ldots x_\mu, y_1, y_2, \ldots y_\mu\), et ensuite au lieu de \(\theta\) successivement les \(\delta\) valeurs \(\boldsymbol{\theta}_1, \boldsymbol{\theta}_2, \ldots \boldsymbol{\theta}_\delta\), l'équation (57) donnera, dis-je, \(\delta\) équations semblables qui, ajoutées ensemble, conduiront à celle-ci:
(71) \(\left\{\begin{array}{c}\delta \int\left(y_1 d x_1+y_2 d x_2+\cdots+y_\mu d x_\mu\right)=u^{\prime}+u^{\prime \prime}+\cdots+u^{(\delta)} \\ +A_1\left(\log v_1{ }^{\prime}+\log v_1{ }^{\prime \prime}+\cdots+\log v_1^{(\delta)}\right)+\cdots+A_\nu\left(\log v_\nu{ }^{\prime}+\log v_\nu{ }^{\prime \prime}+\cdots+\log v_\nu^{(\delta)}\right) \\ +\alpha_1\left(\psi_1 t_1{ }^{\prime}+\psi_1 t_1{ }^{\prime \prime}+\cdots+\psi_1 t_1^{(\delta)}\right)+\cdots+\alpha_n\left(\psi_n t_n{ }^{\prime}+\psi_n t_n^{\prime \prime}+\cdots+\psi_n t_n^{(\delta)}\right) .\end{array}\right.\)

Le second membre de cette équation pourra être réduit à une forme beancoup plus simple. Considérons d'abord la partie algébrique
\[
u^{\prime}+u^{\prime \prime}+\cdots+u^{(\delta)}=U
\]

Cette fonction est exprimée rationnellement en
\[
x_1, x_2, \ldots x_\mu, y_1, y_2, \ldots y_\mu, \theta_1, \theta_2, \ldots \theta_\delta
\]
mais elle est en même temps symétrique par rapport ì \(\boldsymbol{\theta}_1, \boldsymbol{\theta}_2, \ldots \boldsymbol{\theta}_\delta\), donc en vertu d'un théorème connu sur les fonctions symétriques et rationnelles, on pourra exprimer la fonction \(U\) rationnellement en fonction de
\[
x_1, x_2, \ldots x_\mu, y_1, y_2, \ldots y_\mu
\]
et des coefficiens de l'équation \(V=0\); mais cenx-ci sont eux-mêmes des fonctions rationnelles des quantités (73), done la fonction \(U\) le sera également.
Soit maintenant
\[
\log V_m=\log v_m^{\prime}+\log v_m^{\prime \prime}+\cdots+\log v_m^{(\delta)}
\]
%549
on aura
\[
V_m=v_m^{\prime} v_m^{\prime \prime} \ldots v_m^{(\delta)},
\]
done la fonction \(V_m\) est aussi une fonction rationnelle des quantités (73, 69) et symétrique par rapport à \(\theta_1, \theta_2, \ldots \theta_\delta\); donc on démontrera de la même manière que \(V_m\) pourra s'exprimer rationmellement par les quantités (73) seules.

Il reste à considérer la partie elliptique de l'équation (71): or d'après les formules du chapitre précédent, on pourra toujours faire
\[
\left\{\begin{array}{l}
\psi_m t_m{ }^{\prime}+\psi_n t_m{ }^{\prime \prime}+\cdots+\psi_m t_m^{(\delta)} \\
=\psi_m T_m+p+B_1 \log q_1+B_2 \log q_2+\cdots+B_v \log q_v
\end{array}\right.
\]
oì toutes les quantités
\[
T_m, A_m\left(T_m\right), p, q_1, q_2, \ldots q_v
\]
sont des fonctions rationnelles des fonctions
\[
t_m{ }^{\prime}, t_m{ }^{\prime \prime}, \ldots t_m^{(\delta)}, \mathbb{1}_m\left(t_m{ }^{\prime}\right), \mathbb{1}_m\left(t_m{ }^{\prime \prime}\right), \ldots A_m\left(t_m^{(\delta)}\right)
\]
or celles-ci sont des fonctions rationnelles des quantités \((69,73)\), et il est clair qu'elles seront symétriques par rapport ì \(\theta_1, \theta_2, \ldots \theta_\delta\), donc enfin on pourra exprimer les fonctious (76) ratiomnellement par les quantités \(x_1\), \(x_2, \ldots x_\mu ; y_1, y_z, \ldots y_\mu\).

En vertu de ce que nous venons de voir, on pourra done mettre le second membre de l'équation (71) sous la forme:
\[
\begin{gathered}
r+A^{\prime} \log \varrho^{\prime}+A^{\prime \prime} \log \varrho^{\prime \prime}+\cdots+A^{(k)} \log \varrho^{(k)} \\
+\alpha_1 \cdot \psi_1 T_1+\alpha_2 \cdot \psi_2 T_2+\cdots+\alpha_n \cdot \psi_n T_n^{\prime} .
\end{gathered}
\]

Nous sommes ainsi parvenus à ce théorème géméral:
Théorème II. Si une intégrale quelconque de la forme
\[
\int\left(y_1 d x_1+y_2 d x_2+\cdots+y_\mu d x_\mu\right)
\]
où \(y_1, y_2, \ldots y_\mu\) sont des fonctions algébriques de \(x_1, x_2, \ldots x_\mu\), ces derniers étant liés entre eux par un nombre quelconque d'équations algélriques, peut être exprimée par des fonctions algébriques, logarithmiques et elliptiques de sorte qu'on ait
\[
\begin{array}{r}
\int\left(y_1 d x_1+y_2 d x_2+\cdots+y_\mu d x_\mu\right)=u+A_1 \log v_1+A_2 \log v_z+\cdots+A_v \log v_v \\
+\alpha_1 \cdot \psi_1 t_1+\alpha_g \cdot \psi_2 t_2+\cdots+\alpha_n \cdot \psi_n t_n,
\end{array}
\]
%550
où \(A_1, A_2, \ldots \alpha_1, \alpha_2, \ldots\) sont des constantes, \(u, v_1, v_2, \ldots t_1, t_2, \ldots\) des fonctions algébriques de \(x_1, x_2, \ldots\), et \(\psi_1, \psi_2, \ldots\) des fonctions elliptiques quelconques, alors je dis qu'on pourra toujours exprimer la même intégrale de la manière suivante:
\[
\begin{aligned}
\delta \int\left(y_1 d x_1+y_2 d x_2\right. & \left.+\cdots+y_\mu d x_\mu\right)=r+A^{\prime} \log \varrho^{\prime}+A^{\prime \prime} \log \varrho^{\prime \prime}+\cdots \\
& +A^{(k)} \log \varphi^{(k)}+\alpha_1 \cdot \psi_1 \theta_1+\alpha_2 \cdot \psi_2 \theta_2+\cdots+\alpha_n \cdot \psi_n \theta_u,
\end{aligned}
\]
\(\delta\) étant un nombre entier; \(\alpha_1, \alpha_2, \ldots \alpha_n\) les mêmes que dans l'équation domnée; \(A^{\prime}, A^{\prime \prime}, \ldots\) des constantes, et
\[
\theta_1, \Lambda_1\left(\theta_1\right), \theta_2, \Lambda_2\left(\theta_2\right), \ldots \theta_n, \Delta_n\left(\theta_n\right), r, \varrho^{\prime}, \varrho^{\prime \prime}, \ldots \varphi^{(k)}
\]
des fonctions rationnelles des quantités
\[
x_1, x_2, \ldots x_\mu ; y_1, y_2, \ldots y_\mu \text {. }
\]

Ce théorème est non seulement d'une grande importance pour la solution de notre problème général, mais il est encore le fondement de tout ce qui concerne l'application des fonctions algébriques, logarithmiques et elliptiques à la théorie de l'intégration des formules différentielles algébriques. J'en ai déduit un grand nombre de résultats nouveaux et généraux que je soumettrai au jugement des géomètres dans une autre occasion.
Comme corollaire de ce théorème on doit remarquer le suivant:
Théorème III. Si une intégrale de la forme
\[
\int\left(y_1 d x_1+y_2 d x_2+\cdots+y_\mu d x_\mu\right)
\]
peut être exprimée par une fonction algébrique et logarithmique de la forme
\[
u+A_1 \log v_1+A_9 \log v_2+\cdots+A_v \log v_v,
\]
on pourra toujours supposer que \(u, v_1, v_2, \ldots v_v\) soient des fonctions \(r a\) tionnelles de \(x_1, x_2, \ldots x_\mu, y_1, y_2, \ldots y_\mu\). Si done on a l'intégrale \(\int y d x\), où y est liée à \(x\) par une équation algébrique quelconqiue, on pourra supposer que \(u, v_1, v_2\) etc. soient des fonctions rationnelles de \(y\) et \(x^*\) ).
*) J'ai fondé sur ce théorème une nouvelle théorie de l'intégration des formules différentielles algébriques, mais que les circonstances ne m'ont pas permis de publier jusqu’à présent. Cette théorie dépasse de beaucoup les résultats connus, elle a pour but d'opérer tontes les réductions possibles des intégrales des formules algébriques, à l'aide des fonctions algébriques et logarithmiques. On parviendra aiusi à réduire au plus petit nombre possible les intégrales nécessaires pour représenter sous forme finie toutes les intégrales qui appartiennent à une même classe.
%551
\(\S 2\).
Applicution du théorème du paragraplee précédent à la relation générale entré des fonctions algébriques, logarithmiques et elliptiques.
Du théorème geénéral démontré dans le paragraphe précédent on peut déduire immédiatement plusieurs propositions importantes, relatives à la théorie des fonctions elliptiques.
Soit
(77) \(\alpha_1 \psi_1 x_1+\alpha_2 \psi_2 x_2+\cdots+\alpha_\mu \psi_\mu x_\mu=u+A_1 \log v_1+A_2 \log v_2+\cdots+A_\nu \log v_\nu\), une relation quelconque entre les fonctions elliptiques
\[
\psi_1 x_1, \psi_2 x_2, \ldots \psi_\mu x_\mu
\]
dont les modules sont respectivement \(c_1, c_2, \ldots c_\mu\). Si pour abréger on fait \(\pm \sqrt{\left(1-x^2\right)\left(1-c_n^2 x^2\right)}=\Delta_n x\), le premier membre sera la même chose que
\[
\int\left(\frac{\alpha_1 r_1}{J_1 x_1} d x_1+\frac{\alpha_2 r_2}{J_2 x_2} d x_2+\cdots+\frac{\alpha_\mu r_\mu}{J_\mu x_\mu} d x_\mu\right)
\]
où \(r_1, r_2, \ldots r_\mu\) seront respectivement des fonctions rationnelles de \(x_1, x_2\), ... \(x_\mu\) : Donc en vertu du théorème III on pourra énoncer le suivant:

Théorème IV. Si l'équation (77) a lieu en supposant que \(u, v_1, v_2\), \(\ldots v_\nu\) soient des fonctions algébriques des quantités \(x_1, x_2, \ldots x_\mu\), on pourra toujours, sans diminuer la généralité, supposer que \(u, v_1, v_2, \ldots v_v\) soient exprimées rationnellement en \(x_1, x_2, \ldots x_\mu, I_1 x_1, d_2 x_2, \ldots I_\mu x_\mu\).
En écrivant l'équation générale (77) de cette manière:
(78) \(\int\left(\frac{\alpha_1 r_1 d \cdot x_1}{I_1 \cdot x_1}+\frac{\alpha_2 r_2 d x_2}{I_2 \cdot c_2}+\cdots+\frac{\alpha_m v_m d x_m}{J_m x_m}\right)\)
\[
=u+A_1 \log v_1+A_2 \log v_2+\cdots+A_\nu \log v_\nu-\alpha_{m+1} \psi_{m+1} x_{m+1}-\cdots-\alpha_\mu \psi_\mu x_\mu \text {, }
\]
on aura, en vertu du théorème 11 , le suivant:
Théorème V. Si l'équation (77) a lieu, on en pourra toujours tirer une autre de la forme:
\[
\begin{aligned}
\delta \alpha_1 \psi_1 x_1+\delta \alpha_2 \psi_2 x_2+\cdots & +\delta \alpha_m \psi_m x_m+\alpha_{m+1} \psi_{m+1} \theta_1+\cdots+\alpha_\mu \psi_\mu \theta_{\mu-m} \\
& =r+A^{\prime} \log \varphi^{\prime}+A^{\prime \prime} \log \varphi^{\prime \prime}+\cdots+A^{(k)} \log \varphi^{(k)}
\end{aligned}
\]
d) étant un nombre entier et les quantités
%552
\[
\theta_1, \mathcal{A}_{m+1} \theta_1, \theta_2, \mathcal{A}_{m+2} \theta_2, \ldots \theta_{\mu-m}, \mathbb{A}_\mu \theta_{\mu-m}, r, \varrho^{\prime}, \varphi^{\prime \prime}, \ldots \varphi^{(k)}
\]
des fonctions rationnelles de
\[
x_1, x_8, \ldots x_m, \Lambda_1 x_1, \Lambda_2 x_2, \ldots \Delta_m x_m .
\]

On aura encore comme corollaire:
Théorèmè VI. Si une relation quelconque entre les fonctions elliptiques \(\psi_1 x_1, \psi_2 x_2, \ldots \psi_\mu x_\mu\) des trois espèces a la forme exprimée par l'équation (77), on en tirera une autre de la forme:
\[
\begin{aligned}
\delta \alpha_m \cdot \psi_m x=-\alpha_1 \cdot \psi_1 \theta_1 & -\alpha_2 \cdot \psi_2 \theta_2-\cdots-\alpha_{m-1} \cdot \psi_{m-1} \theta_{m-1} \\
& -\alpha_{m+1} \cdot \psi_{m+1} \theta_{m+1}-\cdots-\alpha_\mu \cdot \psi_\mu \theta_\mu \\
& +r+A^{\prime} \log \varphi^{\prime}+A^{\prime \prime} \log \varphi^{\prime \prime}+\cdots+A^{(k)} \log \varrho^{(k)}
\end{aligned}
\]

\(\delta\) étant un nombre entier et toutes les quantités
\[
\theta_1, \Lambda_1 \theta_1, \theta_2, \Lambda_2 \theta_2, \ldots r, \varrho^{\prime}, \rho^{\prime \prime}, \ldots
\]
des fonctions rationnelles de la variable \(x\) et du radical correspondant \(\boldsymbol{A}_m x\). 'Toutes ces fonctions pourront donc se mettre sous la forme:
\[
p+q \cdot \Delta_m x
\]
où \(\psi\) et \(q\) sont des fonctions rationnelles de \(x\) seul.
Voilà le théorème qui nous conduira, comme nous le verrons plus bas, à la solution de notre problème.

Si l'on suppose que toutes les variables \(x_1, x_2, \ldots x_\mu\) soient égales entre elles et à \(x\), et en outre que les fonctions \(\psi_1, \psi_2, \ldots \psi_\mu\) aient le même module, que nous désignerons par \(c\), alors le premier membre de l'équation (77) sera la même chose que \(\int \frac{r d x}{I x}\), où \(r\) est une fonction rationnelle de \(x\); donc en vertu du théorème III on pourra énoncer le snivant:

T'éorème VII. Si entre les fonctions \(\bar{\omega} x, \widetilde{\omega}_0 x, \Pi_1 x, \Pi_2 x, \ldots \Pi_\mu x\), où \(\Pi_1, \Pi_2, \ldots \Pi_\mu\) désignent des fonctions de la troisième espèce, avec des paramètres quelconques, mais avec le même module \(c\) que les deux fonctions de la première et de la seconde espèce \(\widetilde{\omega} x\) et \(\widetilde{\omega}_0 x\), on a une relation quelconque de la forme:
(81) \(\left\{\begin{array}{r}\alpha \widetilde{\omega} x+\alpha_0 \widetilde{\omega}_0 x+\alpha_1 I_1 x+\alpha_2 I_2 x+\cdots+\alpha_\mu I_\mu x \\ =u+A_1 \log v_1+A_2 \log v_2+\cdots+A_\nu \log v_v,\end{array}\right.\)
on pourra toujours supposer que les quantités
%553
\[
u, v_1, v_2, \ldots v_v
\]
soient de la forme \(p+q \mathcal{A}\), où \(p\) et \(q\) sont des fonctions rationnelles de \(x\) seul.

Ce théorème est aussi d'une grande importance dans la théorie des fonctions elliptiques. Nous en développerons dans le chapitre IV les conséquences les plus importantes pour notre objet.
\(\S 3\).
Réduction du problème général.
Reprenons la formule du théorème VI. En la différentiant, le résultat sera de la forme
\[
P+Q \Delta_m x=0
\]
où \(P\) et \((\) ) sont des fonctions rationnelles de \(x\); donc on doit avoir séparément \(P=0, Q=0\), et par suite \(P-Q \cdot \Delta_m x=0\), donc la formule \((80)\) aura encore lieu en changeant le signe du radical \(\Delta_m x\). Or en faisant ce changement et en désignant par \(\theta_1{ }^{\prime}, \theta_2{ }^{\prime}, \theta_3{ }^{\prime}\) etc. les valeurs correspondantes de \(\theta_1, \theta_2, \ldots\), on aura
\[
-\delta \alpha_m \psi_m x=-\Sigma \alpha \psi \theta^{\prime}+v^{\prime}
\]
où pour abréger nous avons mis le signe de sommation \(\Sigma, v^{\prime}\) étant la partie algébrique et logarithmique. En retranchant cette équation de l'équation \((80)\), on obtiendra
\[
2 \delta \alpha_m \psi_m x=\Sigma \dot{\alpha}\left(\psi \theta^{\prime}-\psi \theta\right)+v-v^{\prime}
\]

Cela posé, désignons par \(c\) le module de la fonction \(\psi\) et par \(\Delta x\) la fonction \(\pm \sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}\); alors on aura, d'après ce qu'on a vu dans le chapitre I (35)
\[
\psi \theta^{\prime}-\psi \theta=\psi y-v^{\prime \prime},
\]
en faisant
\[
y=\frac{\theta^{\prime} \Delta \theta-\theta \cdot \Delta \theta^{\prime}}{1-e^2 \theta^2 \theta^{\prime 2}}
\]
\(v^{\prime \prime}\) étant une expression algébrique et logarithmique.
Soient maintenant
\[
\theta=p+q A_m x, \quad \boldsymbol{\theta}=r+0 \cdot J_m x
\]
où \(p, q, r, \rho\) sont des fonctions rationnelles de \(x\). En changeant le signe du radical \(\boldsymbol{d}_n x\), on aurar les valeurs de \(\theta^{\prime}\) et \(\boldsymbol{1} \theta^{\prime}\), savoir
70)
%554
\[
\theta^{\prime}=p-q \mathbb{A}_m x, \quad \mathcal{A} \theta^{\prime}=r-\varrho \mathbb{I}_m x .
\]

En substituant ces valeurs dans l'expression de \(y\), il est clair que cette fonction prendra la forme
\[
y=t \Delta_n x
\]
où \(t\) est rationnel en \(x\). En vertu de la formule (34) on voit de même que \(\boldsymbol{A} y\) sera rationnel en \(x\).
Si l'on fait maintenant
\[
z=\frac{y d e+e d y}{1-c^2 e^2 y^2}
\]
où \(e\) est constant, on aura encore
done
\[
\psi y=\psi z+v^{\prime \prime \prime}
\]
\[
\psi \boldsymbol{\theta}^{\prime}-\psi \boldsymbol{\theta}=\psi z+v_1 .
\]

Or je dis qu'on pourra faire en sorte que \(z\) soit une fonction rationnelle de \(x\). En effet il suffit pour cela d'attribuer à la constante \(e\) une valeur qui ammule \(\mathcal{A} e\).
Soit par exemple \(e=1\), on aura
\[
z=\frac{\Delta y}{1-c^2 y^2} \text { d'où } \Delta z=\frac{c^2-1}{1-c^2 y^2} y,
\]
mais, comme nous venons de le voir, \(y^2\) et \(\Delta y\) sont des fonctions rationmelles de \(x\), done \(z\) le sera de même.
La formule (82) prendra done la forme suivante:
\[
2 \delta \alpha_m \psi_m x=\Sigma \alpha \cdot \psi z+V
\]
où \(V\) est une fonction algébrique et logarithmique, qui en vertu du théorème II pourra se mettre sons la forme
\[
u+A_1 \log v_1+A_2 \log v_2+\cdots,
\]
toutes les quantités \(u, v_1, v_2, \ldots\) étant de la forme \(p+q I_n x\).
En développant le second membre de l'équation (85), on aura aussi la formule
(86) \(\left\{\begin{array}{r}2 \delta \alpha_m \cdot \psi_m x=\alpha_1 \cdot \psi_1 z_1+\alpha_2 \cdot \psi_2 z_2+\cdots+\alpha_{m-1} \cdot \psi_{m-1} z_{m-1} \\ +\alpha_{m+1} \cdot \psi_{m+1} z_{m+1}+\cdots+\alpha_\mu \cdot \psi_\mu z_\mu+V,\end{array}\right.\)
où en vertu des deux équations \((84,83)\) toutes les quantités
\[
z_1, \frac{I_1 z_1}{I_m x}, z_2, \frac{I_2 z_2}{I_m x}, z_3, \frac{I_3 z_3}{I_m x}, \ldots z_\mu, \frac{I_\mu z_\mu}{I_m x}
\]
%555
sont des fonctions rationnelles de la variable \(x\). Cette formule est done une suite nécessaire de la formule générale (77). Il faut faire attention que \(\delta\) est un nombre entier et que les coefficiens \(\alpha_1, \alpha_2, \ldots \alpha_\mu\) sont précisément les mêmes dans les deux formules. C'est une remarque essentielle.

A l'aide de la formule \((86)\) on pourra maintenant réduire la formule générale (77) à une autre plus simple. En effet, en éliminant la fonction \(\psi_m x\) entre ces deux équations, on trouvera une équation de la même forme que la proposée, mais qui contiendra un nombre moindre de fonctions elliptiques. Faisons \(m=\mu\) et mettons \(x_\mu\) pour \(x\) dans la formule \((86)\). On aura
\[
2 \delta \alpha_\mu \cdot \psi_\mu x_\mu=\alpha_1 \cdot \psi_1 z_1+\alpha_2 \cdot \psi_2 z_2+\cdots+\alpha_{\mu-1} \cdot \psi_{\mu-1} z_{\mu-1}+V .
\]

En éliminant la fonction \(\psi_\mu x_\mu\) entre les deux équations il viendra
\[
\alpha_1\left(2 \delta \psi_1 x_1-\psi_1 z_1\right)+\cdots+\alpha_{\mu-1}\left(2 \delta \psi_{\mu-1} x_{\mu-1}-\psi_{\mu-1} z_{\mu-1}\right)=V^{\prime \prime}
\]

Mais \(2 \delta\) étant un nombre entier, on pourra, en vertu de ce que nous avons vu dans le chapitre précédent, trouver des fonctions algébriques \(x_1{ }^{\prime}, x_2{ }^{\prime}, \ldots\) \(x_{\mu-1}^{\prime}\) telles que
\[
\begin{aligned}
& 2 \delta \psi_1 x_1-\psi_1 z_1=\psi_1 x_1{ }^{\prime}+V_1 \\
& 2 \delta \psi_2 x_2-\psi_2 z_2=\psi_2 x_2{ }^{\prime}+V_2
\end{aligned}
\]
etc.
donc la formule (87) donnera celle-ci
\[
\left\{\begin{array}{r}
\alpha_1 \cdot \psi_1^{\prime} x_1{ }^{\prime}+\alpha_2 \cdot \psi_2 x_2{ }^{\prime}+\cdots+\alpha_{\mu-1} \cdot \psi_{\mu-1} x^{\prime}{ }_{\mu-1} \\
=u^{\prime}+A_1{ }^{\prime} \log v_1{ }^{\prime}+A_2{ }^{\prime} \log v_z{ }^{\prime}+\cdots+A_{v^{\prime}}{ }^{\prime} \log v_{r^{\prime}}{ }^{\prime}
\end{array}\right.
\]

Cette équation est précisément de la même forme que l'équation proposée; seulement elle ne contient plus la fonction \(\psi_\mu\). On pourra la traiter de la même manière et en chasser une autre fonction, par exemple \(\psi_{\mu-1}\). En continuant ainsi, on parviendra enfin à une équation qui ne contiendra quo des fonctions algébriques et logarithmiques, et qui ne n'aura pas de difficulté.
On voit done que le problème général pourra être rédnit à celui-ci: Satisfaire de la manière la plus générale ì l'équation
\[
\left\{\begin{aligned}
\psi x=\beta_1 \cdot \psi_1 y_1+\beta_z \cdot \psi_2 y_2+\cdots+\beta_n \cdot \psi_n y_n & \\
& +u+A_1 \log v_1+A_z \log v_z+\cdots+A_v \log v_v,
\end{aligned}\right.
\]
oì \(\psi, \psi_1, \psi_z, \ldots \psi_n\) désignent des fonctions elliptiques des trois espèces, en supposant que
%556
\[
y_1, y_2, \ldots y_n
\]
soient des fonctions rationnelles de \(x\); et que \(\Lambda_1 y_1, \Lambda_z y_2, \ldots A_n y_n\) soient de la forme p1x, où \(p\) est rationnel en \(x\), et où \(1 x\) désigne le radical qui figure dans la fonction \(\psi x\).
Soient
\[
\Lambda_1 y_1=p_1 \Delta x, \Lambda_2 y_2=p_2 \Delta x, \ldots \Lambda_n y_n=p_n \Delta x
\]

Supposons que ces équations soient satisfaites, et soit
\[
\psi x=\int \frac{\theta x \cdot d x}{d x}, \psi_1 x=\int \frac{\theta_1 x \cdot d x}{A_1 x}, \ldots \psi_n x=\int \frac{\theta_n x \cdot d x}{A_n x},
\]
\(\theta x, \theta_1 x, \ldots \theta_n x\) étant toujours des fonctions rationnelles suivant la nature des fonctions \(\psi, \psi_1, \ldots \psi_n\), on aura
\[
\psi_m y_m=\int \frac{\theta_m y_m}{p_m} \cdot \frac{d y_m}{d x} \cdot \frac{d x}{d x}
\]
or \(\frac{\theta_m y_m}{p_m} \cdot \frac{d y_m}{d x}\) est une fonction rationnelle de \(x\), donc l'intégrale du second membre pourra être réduite à la forme
\[
\psi_m y_m=r+A \widetilde{\omega} x+A_0 \widetilde{\boldsymbol{\omega}}_0 x+A^{\prime} \Pi\left(x, a^{\prime}\right)+A^{\prime \prime} \Pi\left(x, a^{\prime \prime}\right)+\cdots,
\]
où \(r\) est une expression algébrique et logarithmique. En transformant toutes les fonctions \(\psi x, \psi_1 y_1, \psi_2 y_2, \ldots\) de cette manière, l'équation (89) prendra cette forme
\[
\left\{\begin{array}{r}
\alpha \widetilde{\omega} x+\alpha_0 \widetilde{\omega}_0 x+\alpha_1 \Pi\left(x, a_1\right)+\alpha_2 \Pi\left(x, a_2\right)+\cdots+\alpha_\mu \Pi\left(x, a_\mu\right) \\
=u+A_1 \log v_1+A_2 \log v_2+\cdots
\end{array}\right.
\]

En vertu de ce que nous venons de voir il est clair que la solution du problème (89) pourra être réduite à celle des problèmes suivans:

Problème A. Trouver tous les cas possibles où l'on peut satisfaire à l'équation
\[
\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)=p^2\left(1-x^2\right)\left(1-c^2 x^2\right),
\]
en supposant \(y\) et \(p\) fonctions rationnelles de l'indéterminée \(x, c\) et \(c^{\prime}\) étant des constantes.
Problème B. L'équation (91) étant satisfaite, réduire les trois fonctions
à la forme
\[
\widetilde{\omega}\left(y, c^{\prime}\right), \widetilde{\varpi}_0\left(y, c^{\prime}\right), \Pi\left(y, c^{\prime}, a\right)
\]
\[
r+A \widetilde{\omega} x+A_0 \widetilde{\omega}_0 x+A^{\prime} \Pi\left(x, a^{\prime}\right)+A^{\prime \prime} \Pi\left(x, a^{\prime \prime}\right)+\cdots
\]
%557
où \(r\) est une expression algébrique et logarithmique.
Problème C. Trouver la relation la plus générale entre les fonctions qui ont le même module et la même variable, c'est-à-dire: trouver les conditions nécessaires et suffisantes pour qu'on puisse exprimer une fonction de la forme
\[
\alpha \widetilde{\omega} x+\alpha_0 \widetilde{\omega}_0 x+\alpha_1 \Pi\left(x, a_1\right)+\alpha_z \Pi\left(x, a_2\right)+\cdots,
\]
par des fonctions algébriques et des logarithmes.
La solution complète de ces trois problèmes sera l'objet principal de nos recherches ultérieures. Nous allons commencer par le dernier qui est le plus simple.
CIIAPITRE III.

Détermination de la relation la plus générale possible entre un nombre quelconque de fonctions elliptiques de la même variable et du même module; on solution du problime C.
Soit comme précédemment
\[
\Lambda x= \pm \sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}
\]
\(\widetilde{\omega} x, \widetilde{\omega}_0 x\) les fonctions des deux premières espèces et \(\Pi \alpha_1, \Pi \alpha_2, \ldots \Pi \alpha_\mu\) des fonctions de la troisième espèce, ayant pour paramètres \(\alpha_1, \alpha_2, \ldots \alpha_\mu\), de sorte que
\[
\widetilde{\omega} x=\int \frac{d x}{d x}, \widetilde{\varpi}_0 x=\int \frac{x^2 d x}{d x}, \quad \Pi \alpha_n=\int \frac{d x}{\left(1-\frac{x^2}{\alpha_m^2}\right) d x} .
\]

Cela posé, il s'agit de satisfaire de la manière la plus générale à l'équation
\[
\left\{\begin{array}{r}
\beta \widetilde{\omega} x+\beta_0 \widetilde{\omega}_0 x+\beta_1 \Pi \alpha_1+\beta_z I \alpha_2+\cdots+\beta_n \Pi \alpha_n \\
=u+A_1 \log v_1+A_z \log v_2+\cdots+A_\nu \log v_v .
\end{array}\right.
\]

En vertu du théorème VI on peut supposer que \(u, v_1, v_2, \ldots v_\nu\) soient de la forme \(p+q 1 x\), où \(p\) et \(q\) sont rationnels en \(x\).

Nous supposons, ce qui est permis, qu'il soit impossible de trouver une relation semblable, qui ne contienne pas toutes les fonctions \(I \alpha_1, \Pi \alpha_2\), \(\ldots \Pi \alpha_n\). Nous supposons encore qu'aucun des paramètres \(\kappa_1, \alpha_2, \ldots{\Omega_n}^{\prime}\) ne soit égal à \(\pm 1\) ou à \(\pm \frac{1}{c}\); car dans ce cas on pourrait, comme on sait, réduire la fonction correspondante de la troisième espèce anx fonctions âx et \(\widetilde{w}_0 x\).
%558
Cela posé, désignons le premier membre de l'équation (92) par \(\psi x\) et le second par \(u+\Sigma A \log v\). On aura
\[
\psi x=u+\Sigma A \log v
\]

Il est clair que cette équation aura encore lieu si le radical \(1 x\) change de signe. Donc en désignant par \(u^{\prime}\) et \(v^{\prime}\) les valeurs correspondantes de \(u\) et \(v\), on aura
\[
-\psi x=u^{\prime}+\Sigma A \log v^{\prime}
\]

Cela donne
\[
2 \psi x=u-u^{\prime}+\Sigma A \log \frac{v}{v^{\prime}} .
\]

Mettons ici \(-x\) au lieu de \(+x\), on pourra supposer que \(\Delta x\) reste invariable; la fonction \(\psi x\) changera de signe, et par conséquent on aura, en désignant par \(u^{\prime \prime}, u^{\prime \prime \prime}, v^{\prime \prime}, v^{\prime \prime \prime}\) les valeurs correspondantes de \(u, u^{\prime}, v, v^{\prime}\) :
\[
-2 \psi x=u^{\prime \prime}-u^{\prime \prime \prime}+\sum A \log \frac{v^{\prime \prime}}{v^{\prime \prime \prime}} \text {. }
\]

De là on tire
\[
\psi x=\frac{1}{4}\left(u-u^{\prime}-u^{\prime \prime}+u^{\prime \prime \prime}\right)+\frac{1}{4} \Sigma A \log \frac{v v^{\prime \prime \prime}}{v^{\prime} v^{\prime \prime}} .
\]

Soit
\[
v=p+q x+\left(p^{\prime}+q^{\prime} x\right) \wedge x
\]
\(p, q, p^{\prime}, q^{\prime}\) étant des fonctions paires, on aura
\[
\begin{aligned}
v^{\prime} & =p+q x-\left(p^{\prime}+q^{\prime} x\right) \Delta x \\
v^{\prime \prime} & =p-q x+\left(p^{\prime}-q^{\prime} x\right) d x \\
v^{\prime \prime \prime} & =p-q x-\left(p^{\prime}-q^{\prime} x\right) d x
\end{aligned}
\]
done:
\[
\begin{aligned}
& v v^{\prime \prime \prime}=p^2-q^2 x^2-\left(p^{\prime 2}-q^{\prime 2} x^2\right)(1 x)^2+2 x\left(\mu q^{\prime}-q p^{\prime}\right) / x, \\
& v^{\prime} v^{\prime \prime}=p^2-q^2 x^2-\left(p^{\prime 2}-q^{\prime 2} x^2\right)(1 x)^2-2 x\left(\mu q^{\prime}-q p^{\prime}\right) / x,
\end{aligned}
\]
par conséquent on aura
\[
\frac{v v^{\prime \prime \prime}}{v^{\prime} v^{\prime \prime}}=\frac{f x+\uparrow x \cdot A x}{f x-\tau x \cdot I x},
\]
\(f x\) et if \(x\) étant des fonctions entières, dont l'une est paire et l'antre imparie. Nous les supposerons, ce qui est permis, sans diviseur commun.

La partie algébrique \(\frac{1}{4}\left(u-u^{\prime}+u^{\prime \prime \prime}-u^{\prime \prime}\right)\) est évidemment de la forme \(r A x\), où \(r\) est mo fonction impaire de \(x\). En écrivant \(A\) an lieu de \(1 A\), l'expression de ipx prendra la forme suivante:
%559
\[
\psi x=r d x+\Sigma A \log \frac{f x+\rho x \cdot I x}{f x-\varphi x \cdot d x} .
\]

Quant aux coefficiens \(A_1, A_2, \ldots A_\nu\), nous pourrons supposer qu’il soit impossible d'avoir entre eux une relation de cette forme
\[
m_1 A_1+m_2 A_2+\cdots+m_\nu A_\nu=0,
\]
où \(m_1, m_2, \ldots m_v\) sont des nombres entiers. En effet, si cette équation avait lieu, on aurait
\[
\Sigma A \log v=\frac{1}{m_\nu}\left\{A_1 \log \frac{v_1^{m_\nu}}{v_\nu^{m_1}}+A_2 \log \frac{v_2^{m_\nu}}{v_\nu^{m_3}}+\cdots+A_{\nu-1} \log \frac{v^{m_\nu}}{v_{\nu-1}^{m_{\nu-1}}}\right\}
\]
c'est-ì-dire :
\[
\Sigma A \log v=A_1{ }^{\prime} \log v_1{ }^{\prime}+A_2{ }^{\prime} \log v_2{ }^{\prime}+\cdots+A^{\prime}{ }_{\nu-1} \log v^{\prime}{ }_{\nu-1},
\]
équation dont le second membre contient un nombre moindre de logarithmes que le premier: On pourra répéter cette réduction jusqu’à ce qu’une équation telle que (95) soit impossible. Cela posé, il faut prendre la différentielle des deux membres et comparer entre elles les fonctions algébriques qui en résultent.

Considérons d'abord la partie logarithmique du second membre de la formule (94). Soit pour abréger
\[
\varrho=\log \frac{f x+\varphi x \cdot A x}{f x-\varphi x \cdot A \cdot x}
\]
on aura, en différentiant, un résultat de la forme
\[
d \varrho=\frac{v \cdot d x}{\left[(f \cdot x)^2-(\varsigma \cdot x)^2(1 \cdot x)^2\right] J x}
\]
où \(v\) est une fonction paire et entière de \(x\), savoir
\[
v=2\left(f x \cdot \varphi^{\prime} x-\varphi x \cdot f^{\prime} x\right)(1 x)^2-2 f x \cdot \varphi x \cdot\left[\left(1+c^2\right) x-2 c^2 x^3\right]
\]

En faisant
\[
\theta x=(f x)^2-(\varphi x)^2(1 x)^2
\]
on pourra alussi mettre \(v\) sous cette forme:
\[
v \psi x=2 f^{\prime} x \cdot \theta x-f x \cdot \theta^{\prime} x
\]
équation facile à vérifier.
Cela posé, décomposons la fonction entière o.x en facteurs de la forme \(\left(x^2-a^2\right)^m\), et faisons en conséquence:
\[
(f x)^2-(\boldsymbol{\rho} x)^2(1 x)^2=\left(x^2-a_1^2\right)^{m_1}\left(x^2-a_2^2\right)^{m_2} \cdots\left(x^2-a_\mu^2\right)^{m_\mu}=\theta x .
\]
%560
Maintenant l'équation (100) fait voir que si \(\theta x\) a le facteur \(\left(x^2-a^2\right)^m, v\) aura nécessairement le facteur \(\left(x^8-a^2\right)^{m-1}\); donc la fonction fractionnaire \(\frac{v}{\theta x}\) pourra être décomposée de la manière suivante:
\[
\frac{v}{\theta x}=t+\frac{\beta_1^{\prime}}{a_1^2-x^2}+\frac{\beta_2^{\prime}}{a_2^2-x^2}+\cdots+\frac{\beta_\mu^{\prime}}{a_\mu^2-x^2},
\]
où \(t\) est la partie entière, \(\beta_1{ }^{\prime}, \beta_2{ }^{\prime}, \ldots \beta_\mu{ }^{\prime}\) des constantes. D'abord je dis que \(t\) est une constante. En effet l'expression (98) de \(v\) fait voir que le degré de cette fonction ne pourra jamais surpasser celui de \(\theta x\). Pour trouver les coefficiens \(\beta_1{ }^{\prime}, \beta_2{ }^{\prime}, \ldots\), appelons \(\beta^{\prime}\) l'un quelconque d'entre eux, correspondant au facteur \(\left(x^2-a^2\right)^m\) de \(\theta x\). On aura
\[
\beta^{\prime}=\frac{v\left(a^2-x^2\right)}{\theta x} \text { pour } x=a,
\]
mais si l'on fait
\[
\theta x=R\left(a^2-x^2\right)^m
\]
on aura en vertu de l'équation (100)
\[
\frac{v\left(a^2-x^2\right)}{\theta x}=\frac{2 f^{\prime} x}{f^{\prime} x}\left(a^2-x^2\right)-\frac{f x}{\varphi x} \frac{d R}{R \cdot d x}\left(a^2-x^2\right)+2 m x \frac{f x}{\varphi x},
\]
donc en faisant \(x=a\)
\[
\beta^{\prime}=2 m a \frac{f a}{\varphi a} .
\]

Or on a \((f a)^2-(\varphi a)^2(\Delta a)^2=0\), done
\[
f a+\varphi a \cdot \Delta a=0
\]
et par suite
\[
\beta^{\prime}=-2 m a d a
\]

On a done
\[
\frac{v}{\theta \cdot c}=k-\frac{2 m_1 a_1 d a_1}{a_1^2-x^2}-\frac{2 m_2 a_2 d a_8}{a_2^2-x^2}-\cdots-\frac{2 m_\mu a_\mu d a_\mu}{a_\mu^2-x^2} .
\]

En multipliant par \(\frac{d x}{d x}\) on aura la valeur de \(d \varrho\). La formule (94) domnera donc, en différentiant,
\[
\begin{aligned}
\beta+\beta_0 x^2+\frac{\alpha_1^2 \beta_1}{\alpha_1^2-x^2}+\frac{\alpha_2^2 \beta_2}{\alpha_2^2-x^2}+\cdots & +\frac{\alpha_n^2 \beta_n}{\alpha_n^2-x^2}=\frac{d r}{d x}(\Lambda x)^2-r\left[\left(1+c^2\right) x-2 c^2 x^3\right] \\
& +A_1\left(k_1-\frac{2 m_1 a_1 / a_1}{a_1^8-x^2}-\frac{2 m_2 a_2 A a_2}{a_2^2-x^2}-\cdots\right) \\
& +A_2\left(k_2-\frac{2 m_1^{\prime} a_1^{\prime} A a_1^{\prime}}{a_1^{\prime}-x^2}-\frac{2 m_2^{\prime} a_2^{\prime} A a_2^{\prime}}{a_2^{\prime 2}-x^2}-\cdots\right) \\
& + \text { etc. }
\end{aligned}
\]
%561
En substituant pour \(r\) une fonction rationnelle quelconque de \(x\), on voit sans peine qu'il sera impossible de satisfaire à cette équation, à moins que r ne soit égal à zéro. En se rappelant que nous avons supposé qu’il soit impossible de tronver une relation entre un nombre moindre des fonctions \(\Pi \alpha_1, \Pi \alpha_8, \ldots I I \alpha_n\), et en ayant égard à l'impossibilité d'une équation de la forme (95), on se convaincra aisément que tous les coefficiens \(A_1, A_2\), \(\ldots A_\nu\) doivent être nuls excepté un seul. Soit done
\[
A_y=A_3=\cdots=A_\nu=0 \text { et } A_1=1
\]

On aura
\[
\begin{aligned}
\beta+\beta_0 x^2+\frac{\alpha_1^2 \beta_1}{\alpha_1^2-x^2}+ & \frac{\alpha_2^2 \beta_2}{\alpha_2^2-x^2}+\cdots+\frac{\alpha_n^2 \beta_n}{\alpha_n^2-x^2} \\
& =k_1-\frac{2 m_1 a_1 d u_1}{a_1^2-x^2}-\frac{2 m_2 a_2 A a_2}{a_2^2-x^2}-\cdots-\frac{2 m_\mu a_\mu \cdot d a_\mu}{a_\mu^2-x^2}
\end{aligned}
\]
done
\[
\begin{aligned}
& \beta=k_1, \quad \beta_0=0, \quad \alpha_1=a_1, \alpha_2=a_2, \ldots \\
& \beta_1=-\frac{2 m_1 \perp a_1}{a_1}, \quad \beta_2=-\frac{\left.2 m_2\right\lrcorner a_2}{a_2}, \ldots
\end{aligned}
\]

Cela posé, la formule générale (94) prendra la forme
\[
\beta . \widetilde{w} x-\frac{2 m_1 J c_1}{\alpha_1} \Pi \alpha_1-\cdots-\frac{2 m_n d \alpha_n}{\alpha_n} \Pi \alpha_n=\log \frac{f x+q \cdot x \cdot d x}{f x-\boldsymbol{q} x \cdot d \cdot x}+C
\]
où les paramètres \(\alpha_1, \alpha_2, \ldots \alpha_n\) doivent satisfaire à l'équation
\[
(f x)^2-(\varphi x)^2\left(1-x^2\right)\left(1-c^2 x^2\right)=\left(x^2-\alpha_1^2\right)^{m_1}\left(x^2-\alpha_2^2\right)^{m_3} \ldots\left(x^2-\alpha_n^2\right)^{m_n}
\]
l'une des fonctions \(f x, \varphi x\) étant paire et l'autre impaire.
T'elle est donc la relation la plus générale entre des fonctions rapportées au même module et à la même variable. Il est remarquable que la fonction de la seconde espèce n'entre point dans cette relation. Quant à la quantité constante \(\beta\) qui multiplie la fonction de la première espèce \(\bar{\varpi} x\), elle pourra dans certaines circonstances se réduire à zéro.

L'équation (105) qui domne les relations nécessaires entre les paramètres \(a_1, a_2, \ldots \alpha_n\) est précisément de la même forme que cehe que nous avons considéré dans le chapitre I. En regardant \(\alpha_1, \alpha_2, \ldots \alpha_n\) comme des variables, elle donmera en vertu du théorème I,
\[
\left\{\begin{array}{l}
m_1 I^{\prime} \alpha_1+m_2 I^{\prime} \alpha_2+\cdots+m_n I^{\prime} \alpha_n=C-\frac{u}{2 A a} \log \frac{f a+q a \cdot A a}{f a-m a \cdot d a} \\
m_1 \bar{\omega} \alpha_1+m_2 \bar{\omega} \alpha_2+\cdots+m_n \bar{\omega} \alpha_n=C
\end{array}\right.
\]
%562
\[
\text { où } \Pi^{\prime} \alpha=\int \frac{d \alpha}{\left(1-\frac{\alpha^2}{a^2}\right) \Delta \alpha} \text {. }
\]

Les paramètres \(\alpha_1, \alpha_2, \ldots \alpha_n\) satisfont donc à l'équation différentielle
\[
\frac{m_1 d \alpha_1}{\Delta \alpha_1}+\frac{m_2 d \alpha_2}{\Delta \alpha_2}+\cdots+\frac{m_n d \alpha_n}{\Delta \alpha_n}=0
\]

Pour avoir toutes les fonctions de la troisième espèce qui soient réductibles indéfiniment à la première espèce, il faut faire \(n=1\). En posant \(\alpha_1=\alpha\), \(m_1=m\), on a
\[
\Pi \alpha=\frac{\beta \alpha}{2 m \Delta \alpha} \widetilde{\omega} x-\frac{\alpha}{2 m \cdot d \alpha} \log \frac{f x+\boldsymbol{f} x \cdot \Delta x}{f x-\varphi x \cdot \Delta x} .
\]

Pour déterminer le paramètre \(\alpha\), on aura dans ce cas l'équation
\[
(f x)^2-(\varphi x)^2\left(1-x^2\right)\left(1-c^2 x^2\right)=\left(x^2-\alpha^2\right)^m,
\]
ce qui fait dépendre \(\alpha\) d'une équation qui est généralement du degré \(m^2\). Le cas le plus simple est celui où \(m=2\). On aura dans ce cas
\[
\varphi x=\frac{1}{c} \sqrt{-1}, f x=a x
\]
done
\[
\left(x^2-\alpha^2\right)^2=x^4-\left(\frac{1+c^2}{c^2}-\alpha^2\right) x^2+\frac{1}{c^2}=\left(x^2 \pm \frac{1}{c}\right)^2
\]
donc \(\alpha\) pourra avoir les deux valems \(\frac{1}{\sqrt{c}}, \frac{1}{\sqrt{-c}}\); Les valeurs correspondantes de \(a\) sont \(1-\frac{1}{c}, 1+\frac{1}{c}\). On aura ainsi
\[
\Pi\left(\frac{1}{\sqrt{c}}\right)=\int \frac{d x}{\left(1-c x^2\right) \cdot x}=k \widetilde{0} x+\frac{1}{4} \frac{\sqrt{-1}}{c-1} \log \frac{(c-1) x+\sqrt{-1} \cdot d x}{(c-1) \cdot c-\sqrt{-1} \cdot d x}
\]
où l'on pourra changer le signe de \(c\).
Si \(m=3\), on aura dans le cas où \(f x\) est impair,
\[
f x=x^3+a x, \varphi x=b
\]
done
\[
\left(x^3+a x\right)^2-b^2\left(1-x^2\right)\left(1-c^2 x^2\right)=\left(x^2-\alpha^2\right)^3
\]

De là on tire
\[
\alpha^3=b, \alpha^3+a \alpha+b d \alpha=0,2 a-c^2 b^2=-3 \alpha^2, a^2+\left(1+c^2\right) b^2=3 \alpha^4
\]
donc en éliminant \(a\) et \(b\) on trouvera
\[
a=\frac{1}{2}\left(c^2 \alpha^6-3 \alpha^2\right),
\]
%563
\[
\Delta \alpha=\frac{1}{2}\left(1-c^2 \alpha^4\right)
\]

Si donc \(\alpha\) est une racine de cette équation, on aura
\[
\Pi \alpha=\int \frac{d x}{\left(1-\frac{x^2}{\alpha^2}\right) d x}=\ln \widetilde{\varpi} x-\frac{1}{3} \frac{\alpha}{1-e^2 \alpha^4} \log \frac{x^3+\frac{1}{2}\left(c^2 \alpha^6-3 \alpha^2\right) x+\alpha^3 \cdot A x}{x^3+\frac{1}{2}\left(c^2 \alpha^6-3 \alpha^2\right) \cdot x-\alpha^3 \cdot A x} .
\]

Généralement la quantité \(\alpha\) sera, pour un \(m\) quelconque, racine de l'ume des deux équations
\[
x_m=0, x_m=\frac{1}{0},
\]
où \(x_m\) est la fonction de \(x\) que nous avons considéré dans le paragraphe 4 du chapitre I, et qui est telle qu'on ait
\[
\frac{d x_m}{d x_m}=m \frac{d x}{\Delta x}
\]
et en même temps
\[
x_m=0 \text { pour } x=0 .
\]

On pourra encore remarquer que si l'on désigne par \(\alpha\) une racine de \(x_m=0\), \(\frac{1}{c \alpha}\) sera racine de l'équation \(x_m=\frac{1}{0}\). Pour prouver que \(\alpha\) satisfait à l'une des équations (110), il suffit de remarquer qu'on a (39):
\[
p^2-q^2(\Lambda x)^2=\left(x^2-\alpha^2\right)^m\left(x^2-\alpha_m^2\right)
\]
où \(\alpha_m\) désigne la même fonction de \(\alpha\), que \(x_m\) de \(x\). En multipliant les denx équations \((109,111)\) membre à membre, il viendra
\[
\text { (111') }\left[p f x \pm q \varphi x(A x)^2\right]^2-(p \varphi x \pm q f x)^2(1 x)^2=\left(x^2-\alpha^2\right)^{2 m}\left(x^2-\alpha_m^2\right) \text {. }
\]

Or on tire des mêmes équations
\[
p^2(f x)^2-q^2(\varphi x)^2(\Lambda x)^4=\left(x^2-\alpha^2\right)^m \cdot R,
\]
li étant une fonction entière. De lì il suit que l'une des deux fonctions
\[
p f x+q \varphi x(\Lambda x)^2, p f x-q \varphi x(\Lambda x)^2
\]
sera divisible par \(\left(x^2-\alpha^2\right)^m\); done en divisant l'équation \(\left(111^{\prime}\right)\) par \(\left(x^2-\alpha^2\right)^{2 m}\), on aura un résultat de la forme
\[
r^2-\rho^2(\Lambda x)^2=x^2-\alpha_m^2,
\]
où l'une des fonctions \(r\) et \(@\) sera paire et l'autre impaire. On doit donc avoir d'abord \(\varrho=0\), et ensuite \(r^2=x^2-\alpha_m^2\), d'où \(\alpha_m=0\), on \(\alpha_m=1\). Réciproquement, si l'une de ces équations a lieu, il est clair par la forme de 71*
%564
l'équation (111) qu'on pourra satisfaire à l'équation (109). Il est à remarquer que dans le cas que nous considérons, \(\beta\) ne pourra jamais être zéro. Donc il n'existe pas de fonction de la troisième espèce, exprimable par des fonctions algébriques et logarithmiques.

I se cas particulier le plus remarquable de la formule générale (104) est celui où \(n=3\) et \(m_1=m_2=m_3=1\). Dans ce cas, en faisant \(\alpha_3=\alpha\), \(\Lambda \alpha_3=-\Delta \alpha\), on aura
\[
\frac{\Delta \alpha_1}{\alpha_1} \Pi \alpha_1+\frac{\Delta \alpha_2}{\alpha_2} \Pi \alpha_2=\frac{\Delta \alpha}{\alpha} \Pi \alpha+\beta . \widetilde{\omega} x-\frac{1}{2} \log \frac{f x+\varphi x \cdot A x}{f \cdot x-\varphi \cdot x \cdot \Delta x},
\]
où
\[
\left\{\begin{array}{l}
f x=x^3+a x, \varphi x=b, \\
\text { de sorte que } \\
\left(x^3+a x\right)^2-b^2\left(1-x^2\right)\left(1-c^4 x^2\right)=\left(x^2-\alpha^2\right)\left(x^2-\alpha_1^2\right)\left(x^2-\alpha_2^2\right),
\end{array}\right.
\]
d'où l'on tire, comme dans le paragraphe 3 du chapitre I,
\[
\left\{\begin{array}{l}
\alpha=\frac{\alpha_1 \Delta \alpha_2+\alpha_2 \Delta \alpha_1}{1-c^2 \alpha_1^2 \alpha_2^2} \\
b=\alpha \alpha_1 \alpha_2 ; a=\frac{1}{2}\left(c^2 \alpha^2 \alpha_1^2 \alpha_2^2-\alpha^2-\alpha_1^2-\alpha_2^2\right) \\
\frac{d \alpha}{\alpha}=\frac{\alpha^2+a}{\alpha \alpha_1 \alpha_2} ; \beta=-c^2 \alpha \alpha_1 \alpha_2
\end{array}\right.
\]

Les deux paramètres \(\alpha_1, \alpha_2\) sont donc arbitraires.
Comme cas particulier on doit remarquer celui où \(\alpha_2\) est infini. On aura dans ce cas
\[
\alpha= \pm \frac{1}{c \alpha_1} \text {. }
\]

On pourra done réduire l'une à l'autre deux fonctions, dont les paramètres sont respectivement \(\alpha, \frac{1}{c \alpha}\). La formule correspondante pour effectuer cette réduction est:
\[
\Pi \alpha+\Pi\left(\frac{1}{c \alpha}\right)=\widetilde{\omega} x+\frac{1}{2} \frac{\alpha}{\Delta \alpha} \log \frac{x \Delta \alpha+\alpha \Delta x}{x \Delta \alpha-\alpha \Delta x} .
\]

Pour trouver toutes les fonctions réductibles l'une à l'autre, il suffit de faire dans la formule (104), \(n=2\). Cela donne
\[
m_1 \frac{\Delta \alpha_1}{\alpha_1} \Pi \alpha_1+m_2 \frac{\Delta \alpha_2}{\alpha_2} \Pi \alpha_2=\beta . \widetilde{\omega} x-\frac{1}{2} \log \frac{f x+\varphi x \cdot d x}{f x-4 x \cdot \Delta x},
\]
où les paramètres \(\alpha_1\) et \(\alpha_2\) sont liés entre eux par l'équation
%565
(117)
\[
(f x)^2-(\varphi x)^2\left(1-x^3\right)\left(1-c^2 x^2\right)=\left(x^2-\alpha_1^2\right)^{m_1}\left(x^8-\alpha_2^2\right)^{m_2}
\]
ce qui domnera une senle équation entre \(\alpha_1\) et \(\alpha_2\).
CHAPITRE IV.
De l'équation \(\left(1-y^2\right)\left(1-c^2 y^2\right)=r^2\left(1-x^2\right)\left(1-c^8 x^2\right)\).
Considérons maintenant le problème \((A)\), savoir de satisfaire de la manière la plus générale à l'équation
\[
\left(1-y^8\right)\left(1-c^{\prime 2} y^2\right)=r^8\left(1-x^2\right)\left(1-c^2 x^2\right),
\]
\(y\) et \(r\) étant des fonctions rationnelles de \(x\). La méthode qui s'offre d'abord pour résoudre ce problème est celle des coefticiens indéterminés, mais cette méthode ne paraît guère applicable si le degré de la fonction y est un peu élevé; du moins son application serait très pénible. Je vais en indiquer une autre qui conduit assez simplement à la solution de ce problème, qui est, ce me semble, le plus important dans la théorie des fonctions elliptiques.
\(\S 1\).
Réduction du problème ì celui de satisfaire à l'équation:
\[
\frac{d y}{\Delta\left(y, c^{\prime}\right)}=\varepsilon \frac{d x}{\Delta(x, c)} .
\]

Nous allons voir d'abord que si l'équation (118) a lieu, on doit avoir nécessairement
\[
r=\frac{1}{\varepsilon} \frac{d y}{d i r}
\]
où \& est constant.
Il est facile de voir que les deux facteurs \(1-y^2, 1-c^{\prime 8} y^2\) ne peuvent s'évanouir en même temps, car cela domnerait \(e^{\prime z}=1\), mais ce cas est exclu. On doit donc avoir séparément
\[
1-y^2=r_1^3 \varrho, 1-c^{\prime 2} y^2=r_2^2 \varrho^{\prime},
\]
\(r_1\) et \(r_2\) étant des fonctions rationnelles dont le produit est égal à \(r\). On aura également
\[
\varphi \varrho^{\prime}=\left(1-x^2\right)\left(1-c^2 x^2\right) \text {. }
\]
(Or; en différentiant les deux équations (119), on en tirerå
\[
\left\{\begin{array}{r}
-2 y d y=r_1\left(r_1 d \varphi+20 d r_1\right), \\
-2 e^2 y d y=r_2\left(r_2 d \varphi^{\prime}+2 u^{\prime} d r_2\right),
\end{array}\right.
\]
%566
Mais il est clair que \(y\) ne pourra avoir aucun facteur commun, ni avec \(r_1\) ni avec \(r_2\), donc il faut que le numérateur de la fraction rationnelle \(\frac{d y}{d x}\) soit divisible par \(r_1\) et par \(r_2\); mais ces deux fonctions ne pourront s'évanouir en même temps, donc on doit avoir
\[
\frac{d y}{d x}=r_1 r_2 v=r v
\]
\(v\) étant une fonction rationnelle de \(x\), qui ne devient pas infinie en attribuant à \(x\) une valeur qui donne \(r=0\). Soit \(y=\frac{p}{q}\), où \(p\) et \(q\) sont deux fonctions entières de \(x\) sans diviseur commun, on aura évidemment
\[
\begin{cases}r=\frac{\theta}{q^2} \\ \text { donc } \\ & q^2 \frac{d y}{d x}=\theta v=\frac{q d p-p d q}{d x} .\end{cases}
\]

Cela fait voir que \(v\) est une fonction entière. Or je dis que \(v\) se réduira a une constante. Désignons par \(m\) et \(n\) les degrés des fonctions \(p\) et \(q\), et par \(" \boldsymbol{l}\) et \(\boldsymbol{v}\) ceux de \(\theta\) et \(v\). Cela posé, il \(\mathrm{y}\) a trois cas à considérer:
1) Si \(m>n\). Dans ce cas l'équation
\[
\left(q^2-p^2\right)\left(q^2-c^2 p^2\right)=\theta^2\left(1-x^2\right)\left(1-c^2 x^2\right)
\]
fait voir qu'on doit avoir
\[
4 m=2 \mu+4
\]
mais comme on a
\[
\theta v=\frac{q d p-p d q}{d x}
\]
il s'ensuit que
\[
\begin{gathered}
\mu+v=m+n-1 \\
v<2 m-\mu-1
\end{gathered}
\]
done
\[
v<2 m-\mu-1
\]
on, puisque \(2 m-\mu=2\),
\[
v<1
\]
done
\[
v=0
\]
et par conséquént \(v\) constant.
2) Si \(n>m\). On auraa de la même manière
%567
\[
\begin{gathered}
4 n=2 u+4,2 n-\mu=2 \\
\nu<2 n-\mu-1, \nu<1, \quad \nu=0
\end{gathered}
\]
donc aussi dans ce cas \(v\) sera égal ì une constante.
3) Si \(n=m\). Dans ce cas il peut arriver que le degré de l'une des fonctions
\[
q-p, q+p, q-c^{\prime} p, q+c^{\prime} p
\]
soit moindre que \(n=m\). Soit donc par exemple
\[
q-p=\varphi
\]
où le degré de \(\varphi\), que nous désignerons par \(m-k\), ne pourra surpasser \(m\). On aura en vertu de l'équation (123)
d'où
\[
4 m-k=2 u+4
\]
\[
2 m-\mu=2+\frac{1}{2} k
\]
maintenant si l'on substitue la valeur de \(q=p+\varphi\), on aura
\[
\theta v=\frac{p d q-q l_p}{d x}=\frac{p d_p-\varphi d_p}{d x}
\]
done
\[
\mu+v=m+m-k-1=2 m-k-1
\]
si \(k>0\), et
\[
\mu+\nu=m+m-k-2=2 m-k-2,
\]
si \(k=0\). Dans le premier cas on a
\[
\nu=2 m-\mu-k-1=1-\frac{1}{2} k=0
\]
et dans le second
\[
\nu=2 m-\mu-2=0
\]

Le degré de la fonction entière \(v\) est donc dans tous les ('ns égal à zéro, et par conséquent \(v\) se réduit à une constante. En la désignant par \(\varepsilon\), on allia
\[
\varepsilon r=\frac{d y}{d x} .
\]

Cela posé, l'équation
\[
\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)=\left(\frac{d y}{d x}\right)^2 \varepsilon^{-y}\left(1-x^2\right)\left(1-c^2 x^2\right)
\]
donnera celle-ci:
%568
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)}}=\frac{\varepsilon \cdot d \cdot c}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}
\]
le problème est ainsi ramené à celui de satisfaire de la manière la plus générale à cette équation en supposant \(y\) rationnel en \(x\). En intégrant, on aura
\[
\widetilde{\omega}\left(y, c^{\prime}\right)=\varepsilon \cdot \widetilde{\omega}(x, c)+C .
\]

En comparant ce résultat à ce que nous avons démontré dans le chapitre II, on aura ce théorème:

Théorème VIII. "Si l'oni a une relation quelconque entre un nombre quelconque de fonctions elliptiques, et qu'on désigne par c le module de l'une d'elles prise à volonté, parmi les antres fonctions on en trouvera au moins une, de module \(c^{\prime}\), et telle qu'on ait entre les fonctions de la première espèce, correspondantes respectivement aux modules \(c^{\prime}\) et \(c\), cette relation très simple
\[
\widetilde{\omega}\left(y, c^{\prime}\right)=\varepsilon \cdot \widetilde{\omega}(x, c)+C
\]
où \(y\) est une fonction rationnelle de \(x\) et \(\varepsilon\) une quantité constante."
Ce théorème est de la plus grande importance dans la théorie des fonctions elliptiques.

Il s'agit maintenant de trouver toutes les valeur's de \(y\) et des modules \(c^{\prime}\) et \(c\) propres à satisfaire à l'équation (125). Si la fonction \(y\) contient des puissances de \(x\) supérieures à la première, elle jouira d'une certaine propriété, qui conduira à son expression générale, en supposant connue la solution complète dans le cas où \(y\) ne contient \(x\) qu'à la première puissance. C'est pourquoi nous domnerons d'abord la solution pour ce cas.
\(\S 2\).
Solution ilu problème dans le cas vì \(y=\frac{u+\beta x}{a^{\prime}+\beta^{\prime} x}\).
En substituant cette valeur de \(y\) dans l'équation
\[
\varepsilon^2\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)=\left(1-x^2\right)\left(1-c^2 x^2\right)\left(\frac{d y}{d x}\right)^2
\]
rien n'est plus facile, que de trouver toutes les solutions possibles. Je vais seulement les transcrire:
I. \(c^{\prime}= \pm c, y= \pm x, y= \pm \frac{1}{c x}, \varepsilon= \pm 1\),
%569
II. \(c^{\prime}= \pm \frac{1}{c}, y= \pm c x, y= \pm \frac{1}{x}, \varepsilon= \pm c\),
III. \(c^{\prime}= \pm\left(\frac{1-\sqrt{c}}{1+\sqrt{c}}\right)^2, y= \pm \frac{1+\sqrt{c}}{1-\sqrt{c}} \cdot \frac{1 \pm x \sqrt{c}}{1 \mp x \sqrt{c}}, \quad \varepsilon= \pm \frac{1}{2} \sqrt{-1}(1+\sqrt{c})^2\),
IV. \(c^{\prime}= \pm\left(\frac{1+\sqrt{c}}{1-\sqrt{c}}\right)^2, y= \pm \frac{1-\sqrt{c}}{1+\sqrt{c}} \cdot \frac{1 \pm x \sqrt{c}}{1 \mp x \sqrt{c}}, \quad \varepsilon= \pm \frac{1}{2} \sqrt{-1}(1-\sqrt{c})^2\),
V. \(c^{\prime}= \pm\left(\frac{1-\sqrt{-c}}{1+\sqrt{-c}}\right)^2, y= \pm \frac{1+\sqrt{-c}}{1-\sqrt{-c}} \cdot \frac{1 \pm x \sqrt{-c}}{1 \mp x \sqrt{-c}}, \varepsilon= \pm \frac{1}{2} \sqrt{-1}(1+\sqrt{-c})^2\),
VI. \(c^{\prime}= \pm\left(\frac{1+\sqrt{-c}}{1-\sqrt{-c}}\right)^2, y= \pm \frac{1-\sqrt{-c}}{1+\sqrt{-c}} \cdot \frac{1 \pm x \sqrt{-c}}{1 \mp x \sqrt{-c}}, \varepsilon= \pm \frac{1}{2} \sqrt{-1}(1-\sqrt{-c})^2\),

On voit que le module \(c^{\prime}\) a six valeurs différentes. La fonction \(y\) en aura douze, car à chaque valeur de \(c^{\prime}\) répondent deux valeurs différentes de \(y\). Ces formules nous seront utiles pour la solution du problème général.
\(\$ 3\).
Propriété générale de la fonction rutionnelle \(y\), qui satisficit ì une équation de la forme:
\[
\frac{d y}{d^{\prime} y}=\varepsilon \frac{d x}{d x} \text {. }
\]

Soit pour abréger
l'équation (125), à laquelle il s'agit de satisfaire, prendra la forme
\[
\frac{d y}{I^{\prime} y}=\varepsilon \frac{d_d t}{d_x i} .
\]
oì \(y\) est supposé fonction rationnelle de \(x\). Soit
\[
y=\psi x
\]
la fonction cherchée. Si, en réduisant \(\mu x\) à sa plis simple expression, la variable \(x\) y entre élevée jusqu’à la " "me puissance inclusivement, nous dirons pour abréger que \(\psi x\) est une fonction rationnelle de \(x\) du degré \(\mu\). Sa forme générale sera donc
\[
\psi x=\frac{A_0+A_1 x+A_2 x^2+\cdots+A_\mu x^\mu}{B_0+B_1 x+B_2 x^2+\cdots+B_\mu \cdot v^\mu},
\]
le numérateur n'ayant pas de diviseur commun avec le dénominateur, et les deux coefficiens \(A_\mu\) et \(B_\mu\) n'étant pas nuls à la fois.
7.2
%570
Cela posé, si l'on considère \(x\) comme fonction de \(y\), l'équation \(y=\psi x\) donnera pour \(x, \mu\) valeurs, qui seront nécessairement inégales, en supposant \(y\) arbitraire. Il est évirlent que toutes ces valeurs de \(x\) satisferont également à l'équation différentielle
\[
\frac{d y}{d^{\prime} y}=\varepsilon \frac{d x}{d x} .
\]

En désignant donc par \(x\) et \(x^{\prime}\) deux d'entre elles, on aura en même temps
\[
\frac{d y}{J^{\prime} y}=\varepsilon \frac{d x^{\prime}}{d x^{\prime}} \text {. }
\]

Done, en égalant ces deux valeurs de \(\frac{d y}{I^{\prime} y}\), on anra
\[
\frac{d x^{\prime}}{d x^{\prime}}=\frac{d x}{d x} .
\]

Une telle relation aura done toujours lieu entre deux racines quelconques de l'équation
\[
y=\psi x \text {. }
\]

Il est facile d'en tirer une équation algébrique entre \(x^{\prime}\) et \(x\). En effet l'intégrale complète de cette équation est en vertu de l'équation (36)
\[
x^{\prime}=\frac{x d e+e d x}{1-c^2 e^2 x^2}
\]
\(e\) étant une constante. Maintenant \(x\) et \(x^{\prime}\) étant tous denx racines de l'équation \(y==\psi x\), on arra
done
\[
y=\psi x, y=\psi x^{\prime}
\]
\[
\psi x^{\prime}=\psi x
\]
et puisque \(y\) est variable, cette équation doit nécessairement avoir lieu pour une valeur quelconque de \(x\). On anra donc immédiatement ce théorème:

Théorème IX. "Pour qu'une fonction rationnelle \(y\) de \(x\), du degré " , puisse satisfaire à une équation différentielle de la forme
\[
\frac{d y}{d^{\prime} y}=\varepsilon \frac{d x}{d x},
\]
il fant que cette fonction \(y\) reste invariable, en mettant pour \(x\), " valeurs différentes de la forme
\[
\frac{x d e+e d x}{1-c^2 e^2 x^2}
\]
\(e\) étant constant."
%571
Ce théorème nous conduira, comme on va voir, de la manière la plus simple à l'expression générale de \(y\). Il s'agit seulement de déterminer les valeurs convenables de la constante \(e\); car celles-ci étant trouvées, rien n'est plus facile que de déterminer ensuite tontes les antres conditions nécessaires. Ocempons-nous d'abord de la recherche de cette constante.
\(\$ 4\).
Détermination de toutes les racines de l'équation \(y=\psi \cdot x\).
Faisons pour abréger
\[
\theta x=\frac{x d e+e d x}{1-c^2 e^2 x^2},
\]
nous aurons d'après ce que nous venons de voir (131),
\[
\psi(\theta x)=\psi x,
\]
où le signe du radical \(\mathcal{X} x\) est évidemment arbitraire. Je remarque maintenant que cette équation, ayant lieu pour une valeur quelconque de \(x\), subsistera encore en mettant \(\theta x\) pour \(x\). On aura donc
\[
\psi[\theta(\theta x)]=\psi(\theta x)=\psi x .
\]

En mettant de nouvean \(\theta x\) an lien de \(x\) et ainsi de suite, on aura
\[
y=\psi x=\psi(\theta x)=\psi\left(\theta^2 x\right)=\psi\left(\theta^3 x\right)=\cdots=\psi\left(\theta^* x\right)=\text { etc. }
\]
où l'on a fait pour abréger
\[
\boldsymbol{\theta}^2 x=\boldsymbol{\theta} \theta x, \boldsymbol{\theta}^3 x=\boldsymbol{\theta} \boldsymbol{\theta}^2 x, \ldots \text { etc. } \theta^n x=\boldsymbol{\theta} \boldsymbol{\theta}^{n-1} x
\]

De là il suit que toutes les quantités de la série
\[
x, \theta x, \theta^2 x, \ldots \theta^n x, \ldots
\]
seront des racines de l'équation \(y=\psi x\). Maintenant cette équation n'ayant qu'un nombre limité de racines, savoir ", il fant nécessairement que plusieurs des quantités de la série (134) soient égales entre elles. Il s’agit de savoir si cela serait possible. Pour cela il faut d'abord avoir l'expression générale de \(\theta^n x\) en fonction de \(x\) et \(e\). Regardons pour le moment \(e\) comme variable indépendante. Alors on aura en vertu de l'équation (132),
\[
\begin{gathered}
\theta^n x=\frac{\theta^{n-1} x \cdot d e+e d\left(\theta^{n-1} x\right)}{1-c^2 e^2\left(\theta^{n-1} x\right)^2}, \\
\frac{d\left(\theta^n x\right)}{d\left(\theta^n x\right)}=\frac{d\left(\theta^{n-1} x\right)}{I\left(\theta^{n-1} x\right)}+\frac{d e}{d e}
\end{gathered}
\]
%572
En mettant dans cette équation successivement \(n-1, n-2, \ldots 2,1\) au lien de \(n\), et en supposant, ce qui est permis, que les radicaux \(\boldsymbol{\Lambda}\left(\theta^n x\right), \boldsymbol{\Lambda}\left(\theta^{n-1} x\right)\) ... \(\boldsymbol{\Lambda}(\boldsymbol{\theta} x), \Lambda x\) ont les mêmes signes dans deux équations consécutives, on aura sur le champ
\[
\frac{d\left(\boldsymbol{\theta}^n x\right)}{\Delta\left(\boldsymbol{\theta}^n x\right)}=\frac{d x}{d x}+n \frac{d e}{d e} .
\]

Cela posé, déterminons d'après les règles du paragraphe 4 du chapitre I une fonction rationnelle \(e_n\) de \(e\), telle que
\[
\frac{d e_n}{\Delta e_n}=n \frac{d e}{\Delta e},
\]
on atra
\[
\frac{d\left(\theta^n x\right)}{\Delta\left(\theta^n x\right)}=\frac{d x}{\Delta x}+\frac{d e_n}{d e_n} .
\]

Mais si l'on fait
\[
x^{\prime}=\frac{x \Delta e_n+e_n \Delta x}{1-c^2 e_n^2 x^2},
\]
on a
\[
\frac{d x^{\prime}}{d x^{\prime}}=\frac{d x}{d x}+\frac{d e_n}{d e_n},
\]
donc:
\[
\frac{d\left(\theta^n x\right)}{\Delta\left(\theta^n x\right)}=\frac{d x^{\prime}}{d a^{\prime}} .
\]

Cette dernière équation donne la suivante:
\[
\theta^n x=\frac{x^{\prime} d e^{\prime}+e^{\prime} d x^{\prime}}{1-c^2 e^{\prime 2} x^{\prime 2}},
\]
où \(e^{\prime}\) est me constante.
Pour déterminer cette constante, faisons \(e=0\); on aura alors \(e_n=0\) et \(\Delta e_n=1\). Donc la valeur de \(x^{\prime}\) deviendra: \(x^{\prime}=x\), et par suite celle de \(\theta^n x\) sera
\[
\theta^n x=\frac{x \Delta e^{\prime}+e^{\prime} \Delta x}{1-c^2 e^{\prime 2} x^2} .
\]

Mais ayant \(\theta x=x\), on aura encore \(\theta^n x=x\), donc
\[
x=\frac{x d e^{\prime}+e^{\prime} d x}{1-c^2 e^{\prime 2} x^2} .
\]

Cette équation devant avoir lieu pour une valeur quelconque de \(x\), ne pourra subsister à moins qu'on n'ait séparément \(e^{\prime}=0, \Delta e^{\prime}=1\); done on aura
\[
\boldsymbol{\theta}^n x=x^{\prime}
\]
%573
c'est-à-dire
\[
\theta^n x=\frac{x d e_n+e_n d x}{1-c^2 e_n^2 x^2} .
\]

Telle sera l'expression de \(\theta^{\prime \prime} x\) pour une valeur quelconque du nombre entier n. Comme on le voit, elle a la forme que doit avoir une racine quelconque de l'équation \(y=\psi x\).

Cela posé, soient \(\theta^m x\) et \(\theta^{m+n} x\) deux quantités de la série (134), égales entre elles; il en existera toujours d'après la remarque faite plus haut. On aura donc
\[
\theta^{m+n} x=\theta^m x
\]
mais \(\theta^{m+n} x\) est évidemment la même chose que \(\theta^n\left(\theta^m x\right)\), donc: en mettant \(x\) pour: \(\theta^m x\), il viendra
\[
\theta^n x=x
\]

Une telle équation doit done toujours avoir lieu, quel que soit \(x\). Si elle a lieu effectivement, il est clair que la série (134) ne contiendra que \(n\) termes différens, car, passé \(\theta^{n-1} x\), les termes se reproduiront dans le même ordre, puisqu'on a \(\theta^{n+1} x=\theta x, \theta^{n+2} x=\theta^2 x\) etc. Si l'on suppose, ce qui est permis, que \(n\), dans l'équation \(\theta^n x=x\), a la plus petite valeur possible pour la valeur donnée de \(e\), il est clair également que les \(n\) quantités
\[
x, \theta x, \theta^2 x, \ldots \theta^{n-1} x
\]
seront nécessairement différentes entre elles. Car si l'on avait par exemple
\[
\theta^m x=\theta^{m+\mu} x
\]
il en résulterait \(\theta^\mu x=x\), ce qui est contre l'hypothèse, attendu que " est moindre que \(n\).
Il s'agit donc de satisfaire à l'équation
\[
\theta^n x=x \text {. }
\]

En y substituant l'expression de \(\theta^n x\), donnée par la formule (135), il viendra
\[
x=\frac{x \Delta e_n+e_n \Delta x}{1-c^2 e_n^2 x^2} .
\]

Or il est impossible de satisfaire à cette équation pour une valeur quelconque de \(x\), à moins qu'on n'ait séparément les deux équations:
\[
e_n=0, \lambda e_n=1
\]
et réciproquement, si ces équations sont satisfaites, l'équation \(\theta^n x=x\) le sera également. Or je dis qu'il sera tonjours possible de satisfaire à ces deux équations à la fois.
%574
D'abord si \(n\) est impair, les deux quantités \(e_n\) et \(\frac{d e_n}{d e}\) seront des fonctions rationnelles de \(e\), comme nous l'avons vu chapitre I \(\$ 4\). Si done on désigne par \(e\) une racine quelconque de l'équation
\[
e_n=0
\]
il suffit, pour satisfaire à l'équation \(\Delta e_n=1\), de déterminer le radical \(\Delta e\) de telle sorte que
\[
\Delta e=\frac{\Delta e^i}{\Delta e_n},
\]
après avoir mis le second membre de cette expression sous la forme d'une fonction rationnelle en \(e\). C'est ce qu'on voit en remarquant que si \(e_n=0\), la quantité \(A e_n= \pm \sqrt{\left(1-e_n^2\right)\left(1-c^2 e_n^2\right)}\) ne pourra avoir que l'une des deux valeurs +1 , -1 .

Si au contraire \(n\) est un nombre pair, on a vu que \(\mathcal{A} e_n\) sera une fonction rationnelle de \(e\), de même que \(\frac{\Delta e_n}{1-c^2 e_n^2}\). En désignant cette dernière par \(\varepsilon_n\), on doit avoir, en vertu deś équations (138),
\[
\varepsilon_n=1 \text {. }
\]

Or je dis que si \(e\) est une racine quelconque de cette équation, on anra ì la fois \(e_n=0, \Delta e_n=1\). En effet ayant
\[
\varepsilon_n=\frac{\Delta e_n}{1-c^2 e_n^2}=\frac{\sqrt{1-e_n^2}}{\sqrt{1-c^2 e_n^2}}=1 .
\]
on en tire en carrant,
et cela donne
\[
1-e_n^2=1-c^2 e_n^2
\]
\[
e_n=0
\]
car \(c^2\) est différent de l'unité. Or ayant \(e_n=0\) et \(\varepsilon_n=1\), on aura évidemment \(A e_n=1\); done etc.
On pourra donc satisfaire à la fois aux deux équations
\[
e_n=0, \Delta e_n=1
\]
et l'on aura toujours \(n^2\) valeurs différentes et convenables de \(e\), car en vertu des formules \((51,55)\) les équations \(e_n=0, \varepsilon_n=1\) seront du degré \(n^2\) en \(e\).

Il s'agit maintenant de choisir les valeurs de \(e\) qui rendent toutes les n. quantités \(x, \theta x, \ldots \theta^{n-1} x\) différentes entre elles, car cela est me seconde condition à laquelle doit satisfaire \(e\).
%575
Or pour cela il suffit de rejeter toutes les valeurs de \(e\) qui pourraient donner \(\theta^{\prime \prime} x=x\), où \(\mu\) est moindre que \(n\). On pourra toujours supposer " facteur de \(n\). En effet soit \(k\) le plus grand commun diviseur de "l et \(n\), on pourra trouver: deux nombres entiers \(\mu^{\prime}\) et \(n^{\prime}\) tels que
\[
\mu^{\prime} \mu=n^{\prime} n+k \text {. }
\]

Or l'équation \(\theta^\mu x=x\) domne done
\[
\theta^{\mu^{\prime} \mu} x=x
\]
\[
\boldsymbol{\theta}^{n^{\prime} n+k} x=x=\boldsymbol{\theta}^k \boldsymbol{\theta}^{n^{\prime} n} x
\]
mais en vertu de \(\theta^n x=x\), on a encore
\[
\begin{aligned}
\theta^{n^{\prime} x} x & =x, \\
\theta^k x & =x ;
\end{aligned}
\]
donc enfin
\[
\begin{gathered}
\theta^{n^{\prime} n} x=x \\
\theta^k x=x
\end{gathered}
\]
donc, si \(\theta^\mu x=x\), on aura encore \(\theta^k x=x\), où \(k\) est diviseur de \(n\). Done il suffit de rejeter tontes les valeurs de \(e\) qui pourraient satisfaire en même temps à ces deux équations
\[
e_\mu=0, \quad \perp e_\mu=1
\]
où, \(\boldsymbol{c}\) est un facteur de \(n\); et il faut nécessairement les rejeter tontes, car si l'on a \(\theta^\mu x=x\), on a nécessairement \(\theta^n x=x\).

Ainsi on déterminera aisément une équation en \(e\), dont tontes les racines donneront des valeurs convenables de cette constante. Si \(n\) est un nombre premier iupair, on a, \(\boldsymbol{\imath}=1\); donc la senle racine qu'il faut rejeter de celles de l'équation \(e_n=0\), est celle-ci
\[
e=0 \text {. }
\]
ru degré \(n^2\).
Il y a une remarque essentielle à faire sur les quantités
\[
x, \theta x, \theta^2 x, \ldots \theta^{n-1} x
\]
c'est qu'on aura toujours en même temps

En effet, on a (43)
\[
e_{n-m}=\frac{e_n d e_m-e_m d e_n}{1-e^2 e_n^2 e_m^2}
\]
mais \(e_n=0, \lambda e_n=1\), donc
%576
\[
e_{n-m}=-e_m \text {. }
\]

On aura également (42)
\[
e_n=\frac{e_m \perp e_{n-m}+e_{n-m} \perp e_m}{1-c^2 e_m^2 e_{n-m}^2}=0
\]
donc à cause de \(e_{n-m}=-e_n\), on aura
\[
\Delta e_{n-m}=\Delta e_m
\]

En substituant ces valeurs de \(e_{n-m}, \mathcal{A} e_{n-m}\) dans l'équation
\[
\theta^{n-m} x=\frac{x d e_{n-m}+e_{n-m} \Delta x}{1-c^2 e_{n-m}^2 x^2}
\]
on aura précisément la seconde des équations (142).
Si l'on multiplie entre elles les valeurs de \(\theta^m x\) et \(\theta^{n-m} x\), le produit sera rationnel, et l'on trouvera
\[
\theta^m x \cdot \theta^{n-m} x=\frac{x^2-e_m^2}{1-c^2 e_m^2 x^2} .
\]

On aura de même
\[
\theta^m x+\theta^{n-m} x=\frac{2 x d e_m}{1-c^2 e_m^2 x^2}
\]

Ces formules nous seront utiles dans la suite. I'après ce qui précède, les \(n\) quantités
\[
x, \theta x, \theta^2 x, \ldots \theta^{n-1} x
\]
sont différentes entre elles, et racines de l'équation \(y=\psi x\). Le degré " de cette équation est donc égal à \(n\), s’il ne surpasse pas ce irombre. Nous verrons plus bas qu'il suffira de considérer le cas où \(\boldsymbol{\mu}=n\). On pourra même supposer \(n\) premier.
\(\$ 5\).

Détermination de toutes les valeurs de y qui pourrout répondre aue mêmes valeurs des racines, lor'squion in connciit une reule.
Pour simplitier la solution du problème général, voyons d'abord si plusieurs valeurs différentes de la fonction \(y\) et du module \(e^{\prime}\) pourront répondre aux mêmes racines de l'équation \(y=\psi x\). Rien n'est plás facile que de déterminer toutes les valeurs de \(y\) et \(c^{\prime}\). En effet, soit \(\psi z=\frac{p}{q}\), où \(p\) et \(q\) sont des fonctions entières de \(z\) sans diviseur commun. En désignant par
%577
\[
x, x^{\prime}, x^{\prime \prime} \ldots x^{(\mu-1)}
\]
toutes les racines de l'équation
\[
y=\psi x
\]
on mura
\[
p-q y=(a-b y)(z-x)\left(z-x^{\prime}\right)\left(z-x^{\prime \prime}\right) \ldots\left(z-x^{(\mu-1)}\right)
\]
où \(a\) et \(b\) sont des constantes. Soit maintenant \(y^{\prime}\) une autre valeur de \(y\) qui répond aux mêmes valeurs de \(x ; x^{\prime}, x^{\prime \prime} \ldots\), on allia, en désignant par \(p^{\prime}\) et ' \(q\) ' les valeurs correspondantes des fonctions \(p\) et \(q\),
\[
p^{\prime}-q^{\prime} y^{\prime}=\left(a^{\prime}-b^{\prime} y^{\prime}\right)(z-x)\left(z-x^{\prime}\right)\left(z-x^{\prime \prime}\right) \ldots\left(z-x^{(\mu-1)}\right)
\]
done
\[
\frac{p-q y}{p^{\prime}-q^{\prime} y^{\prime}}=\frac{a-b y}{a^{\prime}-b^{\prime} y^{\prime}} .
\]

En attribuant à \(z\) une valeur constante, il est clair que cette équation donnera pour \(y^{\prime}\) une expression de la forme
\[
y^{\prime}=\frac{\alpha+\beta y}{\alpha^{\prime}+\beta^{\prime} y},
\]
où \(\alpha, \beta, \alpha^{\prime}, \beta^{\prime}\) sont des constantes. En désignant maintenant par \(c^{\prime \prime}\) le morlule qui répond à \(y^{\prime}\), on aura en même temps
donc
\[
\frac{d y^{\prime}}{\sqrt{\left(1-y^{\prime 2}\right)\left(1-c^{\prime \prime 2} y^{\prime 2}\right)}}=\varepsilon^{\prime} \frac{d x}{d x}, \frac{d y}{d^{\prime} y}=\varepsilon \frac{d x}{d x},
\]
\[
\frac{d y^{\prime}}{\sqrt{\left(1-y^{\prime 2}\right)\left(1-c^{\prime 2} y^{\prime 2}\right)}}=\frac{\varepsilon^{\prime}}{\varepsilon} \cdot \frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^{\prime 2} y^8\right)}} .
\]

Fn substituant l'expression de \(y^{\prime}\) en \(y\), on aura les équations nécessaires pour déterminer \(y^{\prime}, c^{\prime \prime}, \varepsilon^{\prime}\). Ce problème est précisément le même que celui du paragraphe 2. On voit done qu'une, seule solution de l'équation
\[
\frac{d y}{d y}=\varepsilon \frac{d x}{d x}
\]
en domnera sur le champ cinq autres, qui seront en général différentes entre elles. La fonction \(y\) aura toujours deux valeurs correspondantes au même module \(c^{\prime}\), savoir \(y\) et \(\frac{1}{c^{\prime} y}\).
%578
\(\S 6\).
Solution complète du problème dans le cas oì \(\mu=n\).
Supposons maintenant que l'équation \(y=\psi x\) n'ait d'autres racines que celles-ci :
\[
x, \theta x, \theta^2 x, \ldots \theta^{n-1} x
\]
ce qui arrive toujours lorsque \(\boldsymbol{\mu}\) est un nombre premier, comme nous le verrons plus bas. On aura alors, si \(p\) et \(q\) signifient la même chose qu'au paragraphe précédent,
\[
p-q y=(a-b y)(z-x)(z-\theta x)\left(z-\theta^2 x\right) \ldots\left(z-\theta^{n-1} x\right) .
\]

En attribuant à \(z\) une valeur particulière, on aura une expression de \(y\) dans laquelle tout est déterminé, excepté trois quantités constantes. Nous allons voir qu'on pourra toujours les déterminer de sorte que l'équation différentielle proposée soit satisfaite. Pour cela considérons deux cas selon que \(n\) est un nombre impair ou non.

Cas I. Si \(n\) est un nombre impair. Faisons dans ce cas \(n=2 u+1\). Alors l'équation (147) domne, en attribuant à \(z\) la valeur particulière zéro,
\[
a^{\prime}-b^{\prime} y=-(a-b y) x \cdot \theta x \cdot \theta^2 x \ldots \theta^{2 \mu} x
\]
d'où
\[
y=\frac{a^{\prime}+a \cdot x \cdot \theta_x \cdot \theta^2 x \ldots \theta^{2 \mu} x}{b^{\prime}+b \cdot x \cdot \theta \cdot x \cdot \theta^2 x \ldots \theta^2 \mu_x} .
\]

En remarquant maintenant qu'en vertu de l'équation (143)
\[
\theta^m x \cdot \theta^{2 \mu+1-m} x=\frac{x^2-e_m^2}{1-c^2 e_m^2 x^2},
\]
il est clair que l'expression précédente de \(y\) sera une fonction ratiomelle de \(x\) du degré \(2 u+1\); donc, puisque cette fonction reste invariable, - en mettant pour \(x\) les \(2 u+1\) valeurs
\[
x, \theta x, \theta^2 x \ldots \theta^{2 \mu} x
\]
ce qui est évident à cause de \(\theta^{2 \mu+1} x=x\), on conclura que l'équation (147) a lieu en mettant pour \(y\) cette fonction et pour \(p\) et \(q\) les valeurs correspondantes en z. Cette équation pourra s'écrire comme il suit:
\[
\begin{array}{r}
p-q y=(a-b y)(z-x)(z-\theta x)\left(z-\theta^{2 \mu} x\right)\left(z-\theta^2 x\right)\left(z-\theta^{2 \mu-1} x\right) \cdots \\
\cdots\left(z-\theta^\mu x\right)\left(z-\theta^{\mu+1} x\right)
\end{array}
\]
%579
Cela posé, faisons
\[
x=1,-1, \frac{1}{c}-\frac{1}{c},
\]
et désignons les valeurs correspondantes de y par
\[
\alpha, \beta, \gamma, \delta \text {. }
\]

Comme on a pour ces valeurs de \(x, 1 x=0\), il s'ensuit en vertu des deux équations (142) du paragraphe 4, que
\[
\theta^m x=\theta^{2 \mu+1-m} x=\frac{x \Delta e_m}{1-c^2 x^2 e_m^2},
\]
d'où l'on voit que les facteurs du second membre de l'équation (149) seront égaux deux à deux, en faisant abstraction du premier facteur \(z-x\). On a done
\[
\left\{\begin{array}{l}
p-q \alpha=(a-b \alpha)(1-z) \cdot \varrho^2, \\
p-q \beta=(a-b \beta)(1+z) \cdot \varrho^{\prime 2} \\
p-q \gamma=(a-b \gamma)(1-c z) \cdot \varrho^{\prime \prime 2} \\
p-q \delta=(a-b \delta)(1+c z) \cdot \varrho^{\prime \prime \prime 2}
\end{array}\right.
\]
où \(\varphi, \varphi^{\prime}, \varphi^{\prime \prime}, \varphi^{\prime \prime \prime}\) seront des fonctions entières de \(z\) du degré \(\mu\). Mais puisqu'on doit avoir
\[
\left(q^2-p^2\right)\left(q^2-c^{\prime 2} p^2\right)=r^2\left(1-z^2\right)\left(1-c^8 z^2\right)
\]
les équations précédentes font voir que les quatre constantes \(\alpha, \beta, \gamma, \delta\) doivent être les mêmes que celles-ci:
\[
+1,-1,+\frac{1}{c^{\prime}},-\frac{1}{c^{\prime}},
\]
et si cette condition a lien, les quatre équations (150) en domneront évidemment une de la forme (151), et par suite on anra
\[
\frac{d y}{d^{\prime} y}=\dot{\varepsilon} \frac{d x}{d x}
\]
en vertu de ce qu'on a vu dans le paragraphe 1 de ce chapitre.
Comme il suffit de comnaitre une seule valeur de \(y\), nous pourrons faire par exemple
\[
\alpha=1, \beta=-1, \gamma=\frac{1}{c^{\prime}}, \delta=-\frac{1}{c^{\prime}} .
\]

Cela posé, il nous reste à satisfaire à ces équations. Or si l'on fait pour un moment
%580
(154) \(\varphi x=x \cdot \theta x \cdot \theta^2 x \ldots \theta^{2 \mu} x=\frac{x\left(x^2-e^2\right)\left(x^2-e_2^2\right) \ldots\left(x^2-e_\mu^2\right)}{\left(1-c^2 e^2 x^2\right)\left(1-c^2 e_2^2 x^2\right) \ldots\left(1-c^2 e_\mu^2 x^2\right)}\),
l'expression de \(y\) deviendra
\[
y=\frac{a^{\prime}+a \cdot \varphi x}{b^{\prime}+b \cdot \varphi x}
\]
d'où l'on déduira, en remarquant que \(\varphi(-x)=-\varphi x\), et faisant \(x=1\), \(-1, \frac{1}{c},-\frac{1}{c}\),
\[
\alpha=\frac{a^{\prime}+a \varphi(1)}{b^{\prime}+b \varphi(1)}, \quad \beta=\frac{a^{\prime}-a \varphi(1)}{b^{\prime}-b \varphi(1)}, \quad \gamma=\frac{a^{\prime}+a \varphi\left(\frac{1}{c}\right)}{b^{\prime}+b \varphi\left(\frac{1}{c}\right)}, \delta=\frac{a^{\prime}-a \varphi\left(\frac{1}{c}\right)}{b^{\prime}-b \varphi\left(\frac{1}{c}\right)},
\]
donc en vertu des équations (153), on aura
\[
\begin{gathered}
a^{\prime}-b^{\prime}+(a-b) \varphi(1)=0, a^{\prime}+b^{\prime}-(a+b) \varphi(1)=0, \\
a^{\prime}-\frac{b^{\prime}}{c^{\prime}}+\left(a-\frac{b}{c^{\prime}}\right) \varphi\left(\frac{1}{c}\right)=0, a^{\prime}+\frac{b^{\prime}}{c^{\prime}}-\left(a+\frac{b}{c^{\prime}}\right) \varphi\left(\frac{1}{c}\right)=0 .
\end{gathered}
\]

Il est impossible de satisfaire à ces équations à moins que l'une des quantités \(a^{\prime}, b^{\prime}\) ne soit zéro. Faisons donc \(a^{\prime}=0\), on aura en même temps \(b=0\). Donc deux des équations précédentes donneront
\[
\frac{b^{\prime}}{a}=\varphi(1)=c^{\prime} \cdot \varphi\left(\frac{1}{c}\right)
\]
d'où l'on tire la valeur de \(c^{\prime}\), savoir:
\[
c^{\prime}=\frac{\varphi(1)}{\varphi\left(\frac{1}{c}\right)} \text {. }
\]

La valeur de \(y\) deviendra
\[
y=\frac{a}{b^{\prime}} \varphi x=\frac{\varphi x}{\varphi(1)} .
\]

Quant aux valeurs de \(\varphi(1)\) et de \(\varphi\left(\frac{1}{c}\right)\), on aura en vertu de l'expression de \(\varphi x\),
\[
\begin{gathered}
\varphi(1)=\frac{1-e^2}{1-c^2 e^2} \frac{1-e_2^2}{1-c^2 e_2^2} \cdots \frac{1-e_\mu^2}{1-c^2 e_\mu^2}, \\
\varphi\left(\frac{1}{c}\right)=\frac{1}{c^{2 \mu+1}} \frac{1-c^2 e^2}{1-e^2} \frac{1-c^2 e_2^2}{1-e_2^2} \cdots \frac{1-c^2 e_\mu^2}{1-e_\mu^2},
\end{gathered}
\]
done
\[
\varphi\left(\frac{1}{c}\right)^{\circ}=\frac{1}{c^{2 \mu+1} \varphi(1)},
\]
et
\[
c^{\prime}=c^{2 \mu+1}[\varphi(1)]^2, \quad \varphi(1)=\frac{\sqrt{c^{\prime}}}{c^{\mu+1}} .
\]
%581
Pour avoir enfin la valeur du coefficient \(\varepsilon\), il suffit de faire \(x=0\), après avoir différentié l'expression de \(y\). On aura
\[
\frac{d y}{d x}= \pm e^2 e_2^2 e_3^2 \ldots e_\mu^2 \frac{1}{\varphi(1)}
\]
nais comme on a
\[
\frac{d y}{d x}=\varepsilon \frac{A^{\prime} y}{d x}
\]
il en résulte, en faisant \(x=0\),
\[
\frac{d y}{d x}= \pm \varepsilon
\]
donc on pourra faire
\[
\varepsilon=e^2 e_2^2 e_3^2 \ldots e_\mu^2 \frac{c^{\mu+\frac{1}{2}}}{\sqrt{c^{\prime}}} .
\]

D'après ce qui précède on pourra maintenant énoncer le théorème suivant:
Théorèmé \(\mathrm{X}\). "Soit \(e\). une racine quelconque de l'équation \(e_{2 \mu+1}=0\), mais qui ne puisse être racine d'une autre équation de la même forme \(e_{2 m+1}=0\), où \(2 m+1\) est diviseur de \(2 \mu+1\). Cela posé, si l'on détermine la fonction \(y\), le module \(c^{\prime}\), et le coefficient \(\varepsilon\), d'après les formules
\[
\begin{aligned}
& y=\frac{c^{\mu+1}}{\sqrt{c^{\prime}}} \frac{x\left(e^2-x^2\right)\left(e_2^2-x^2\right)\left(e_3^2-x^2\right) \ldots\left(e_\mu^2-x^2\right)}{\left(1-c^2 e^2 x^2\right)\left(1-c^2 e_2^2 x^2\right)\left(1-c^2 e_3^2 x^2\right) \ldots\left(1-c^2 e_\mu^2 x^2\right)}, \\
& \begin{array}{l}
c^{\prime}=c^{2 \mu+1}\left(\frac{\left(1-e^2\right)\left(1-e_2^2\right)\left(1-e_3^2\right) \ldots\left(1-e_\mu^2\right)}{\left(1-c^2 e^2\right)\left(1-e^2 e_2^2\right)\left(1-c^2 e_3^2\right) \ldots\left(1-e^2 e_\mu^2\right)}\right)^2, \\
\varepsilon=\frac{c^{\mu+\frac{1}{2}}}{\sqrt{c^{\prime}}} e^2 e_2^2 e_3^2 \ldots e_\mu^2,
\end{array} \\
& \varepsilon=\frac{c^{\mu+\frac{1}{2}}}{\sqrt{c^{\prime}}} e^2 e_2^2 e_3^2 \ldots e_\mu^2, \\
& \frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)}}= \pm \varepsilon \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-e^2 x^2\right)}}, \\
&
\end{aligned}
\]
on aura toujours
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)}}= \pm \varepsilon \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}
\]
en déterminant convenablement le signe du second membre."
Connaissant ainsi un système de valeurs de \(y, c^{\prime}, \varepsilon\), on en aura cinq autres, d'après ce qu'on a vu dans le paragraphe précédent, à l'aide des formules du paragraphe 2. A chaque valeur de \(e\) répondent donc six systèmes de valeurs de \(y, c^{\prime}, \varepsilon\). On aura même douze valeurs de \(y\), car à chaque valeur de \(c^{\prime}\) répondent deux valeurs différéntes de cette fonction. Nous reviendrons plus bas à la question du nombre total des solutions qui répondent à la même valeur de \(\mu\).
Pour donner un exemple des formules ci-dessus, soit \(\mu=1\). Puisque
%582
dans ce cas \(2 \iota+1=3\) est un nombre premier, on pourra, en vertu de ce qu'on a vu plus haut, prendre pour \(e\) une racine quelconque de l'équation \(e_3=0\), excepté la racine zéro. Cette équation est, en vertu de la formule (53), qui donne l'expression de \(x_3\), du huitième degré, savoir:
\[
0=3-4\left(1+c^2\right) e^2+6 c^2 e^4-c^4 e^8 .
\]

La quantité \(e\) étant une racine quelconque de cette équation, on aura
\[
\begin{gathered}
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)}}= \pm \varepsilon \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}, \\
c^{\prime}=c^3\left(\frac{1-e^2}{1-c^2 e^2}\right)^2, \varepsilon=c \sqrt{\frac{c}{c^{\prime}}} e^2, y=\frac{c \sqrt{c}}{\sqrt{c^{\prime}}} \frac{x\left(e^2-x^2\right)}{1-c^2 e^2 x^2} .
\end{gathered}
\]

Puisque \(e^2\) est déterminé en \(c\) par une équation du quatrième degré, le module \(c^{\prime}\) pourra l'être également. Cette équation est
\[
\left(c^{\prime}-c\right)^2=4 \sqrt{c c^{\prime}}\left(1-\sqrt{c c^{\prime}}\right)^2 \text {. }
\]

L'expression générale de \(y\), donnée plus haut (156), est sous forme de produit. Rien n'est plus facile que de décomposer cette fraction en fractions partielles. En effet, puisque les racines de l'équation
\[
0=\frac{c^{\mu+1}}{\sqrt{c^{\prime}}} z\left(z^2-e^2\right)\left(z^2-e_2^2\right) \ldots\left(z^2-e_\mu^2\right)+y\left(1-c^2 e^2 z^2\right) \ldots\left(1-c^2 e_\mu^2 z^2\right)
\]
sont les \(2 \mu+1\) quantités suivantes
\[
x, \theta x, \theta^2 x \ldots \theta^{2 \mu} x,
\]
la somme de ces quantités sera égale au coefficient de \(z^{2 \mu}\), divisé par celui de \(z^{2 \mu+1}\) et pris avec le signe - , done
\[
x+\theta x+\theta^2 x+\cdots+\theta^{2 \mu} x=\frac{(-1)^{\mu+1} c^{2 \mu} e^2 e_2^2 \cdots e_\mu^2}{c^{\mu+\frac{1}{2}} \cdot c^{\prime-\frac{1}{2}}} y
\]
donc, en vertu de l'équation
\[
\theta^m x+\theta^{2 \mu+1-m} x=\frac{2 \Delta e_m \cdot x}{1-c^2 e_m^2 x^2},
\]
on aura l'expression suivante de \(y\) :
(157) \(y=\left(x+\frac{2 d e \cdot x}{1-c^2 e^2 x^2}+\frac{2 d e_2 \cdot x}{1-c^2 e_2^2 x^2}+\cdots+\frac{2 d e_\mu \cdot x}{1-c^2 e_\mu^2 x^2}\right) \frac{\sqrt{c}}{c \mu \sqrt{c^{\prime}}} \frac{(-1)^{\mu+1}}{e^2 e_2^2 \cdots e_\mu^2}\).
Cas II. Si \(n\) est un nombre pair. Faisons \(n=2,1\). Puisqu'on a
\[
\boldsymbol{\theta}^m x=\frac{x \mathcal{A} \rho_m+e_m \Delta x}{1-c^2 e_m^2 x^2}, \quad \theta^{2 \mu-m} x=\frac{x \mathcal{A} e_m-e_m d x^2}{1-c^2 e_m^2 x^2},
\]
%583
on aura, en faisant \(m=\mu\),
\[
\theta^\mu x=\frac{x \cdot d e_\mu+e_\mu d x}{1-c^2 e_\mu^2 x^2}=\frac{x d e_\mu-e_\mu d \cdot x}{1-c^2 e_\mu^2 x^2} .
\]

Cette égalité ne peut subsister, à moins que \(e_\mu\) n'ait une des deux valeurs zéro où l'infini. Cela donne lieu à considérer séparément ces deux cas:
A. Si \(e_\mu=\frac{1}{0}\), on aura
\[
\theta^\mu x= \pm \frac{1}{c x}
\]

En substituant \(\theta^n x\) an lieu de \(x\), on aura
\[
\theta^{\mu+n} x= \pm \frac{1}{c \theta^m x}
\]

Les racines de l'équation \(y=\psi x\) deviendront done
\[
x, \pm \frac{1}{c x}, \theta x, \theta^2 x, \ldots \theta^{\mu-1} x, \theta^{\mu+1} x, \theta^{\mu+2} x, \ldots \theta^{2 \mu-1} x
\]
par conséquent on aura
\[
\begin{array}{r}
p-q y=(a-b y)(z-x)\left(z \mp \frac{1}{c \cdot x}\right)(z-\theta x)\left(z-\theta^{2 \mu-1} x\right) \ldots \\
\ldots\left(z-\theta^{\mu-1} x\right)\left(z-\theta^{\mu+1} x\right) .
\end{array}
\]

En désignant par \(a^{\prime}\) et \(b^{\prime}\) les coefficiens de \(z^{2 \mu-1}\) dans les deux fonctions entières \(p\) et \(q\), on aura
\[
\begin{aligned}
& a^{\prime}-b^{\prime} y=-(a-b y)\left(x \pm \frac{1}{c x}+\theta x+\theta^{2 \mu-1} x+\cdots+\theta^{\mu-1} x+\theta^{\mu+1} x\right) \\
& =(b y-a)\left(x \pm \frac{1}{c \cdot t}+\frac{2 d e \cdot x}{1-c^2 e^2 x^2}+\frac{2 d e_2 x}{1-c^2 e_2^2 x^2}+\cdots+\frac{2 d e_{\mu-1} x}{1-e^2 e_{\mu-1}^2 \cdot x^2}\right) . \\
&
\end{aligned}
\]

L'expression qu'on en tire pour \(y\) sera évidemment une fonction rationnelle de \(x\) du degré 2, , et puisqu'elle reste invariable en mettant pour \(x\) les \(2, u\) quantités*)
\[
x, \theta x, \theta^2 x, \ldots \theta^{8 \mu-1} x
\]
l'équation (158) aura lieu en mettant pour y cette valeur et poul \(p\) et \(q\) les valeurs correspondantes en \(z\).
Nous allons voir qu'on aura me valeur convenable de \(y\) en faisant
\[
a=b^{\prime}=0 \text {. }
\]
*) On a
\[
y=\frac{a^{\prime}+a\left(x+\theta x+\theta^2 x+\cdots+\theta^{2 \mu-1} x\right)}{b^{\prime}+b\left(x+\theta x+\theta^2 x+\cdots+\theta^{2 \mu-1} x\right)} \text { et } \theta^{2, \mu} x=x \text {. }
\]
%584
Cela donne
\[
y=\frac{a^{\prime}}{b} \frac{1}{x \pm \frac{1}{c x}+\frac{2 \Delta e \cdot x}{1-c^2 e^2 x^2}+\cdots+\frac{2 \Delta e_{\mu-1} x}{1-c^2 e_{\mu-1}^2 x^2}},
\]
expression qui est évidemment de la forme
\[
y=A \frac{x\left(1-c^2 e^2 x^2\right)\left(1-c^2 e_2^2 x^2\right) \cdots\left(1-c^2 e_{\mu-1}^2 x^2\right)}{1+a_1 x^2+a_2 x^4+\cdots+a_\mu x^{2 \mu}}=A \cdot \varphi x .
\]

Pour déterminer la valeur de \(A\), remarquons que si l'on fait \(x=1, y\) doit avoir une des valeurs: \(\pm 1, \pm \frac{1}{c^{\prime}}\). Soit par exemple \(y=1\), pour \(x=1\), on aura
\[
A=\frac{1}{\varphi(1)}
\]

Cela posé, faisons dans l'équation (158) \(x=1\). En remarquant que \(a=0\); on allra
\[
q-p=(1-z)(1 \mp c z) \varphi^2
\]
\(\varrho\) étant ine fonction entière de \(z\), car pour \(x=1\) on aura
\[
\theta^m x=\theta^{2 \mu-m} x=\frac{\Delta e_m}{1-c^2 e_m^2} .
\]

En changeant le signe de \(z\) dans l'équation préeédente, on aura, en remarquant que \(q\) est une fonction paire et \(p\) une fonction impaire,
\[
q+p=(1+z)(1 \pm c z) \varphi^{\prime 8} \text {. }
\]

Cela donne .
\[
q^2-p^2=\left(1-z^2\right)\left(1-c^2 z^2\right)\left(\varphi \varphi^{\prime}\right)^2
\]

Maintenant, puisqu'on doit avoir
\[
\left(q^2-\dot{p}^2\right)\left(q^2-c^{\prime 2} p^2\right)=\left(1-z^2\right)\left(1-c^2 z^2\right) r^2
\]
cela fait voir que la fonction \(q^2-c^{\prime 8} p^2\) doit être un carré parfait. Or on pourra toujours déterminer \(c^{\prime}\) de manière que cette condition soit remplie. Faisons dans l'équation (158)
\[
x=\frac{1}{\sqrt{ \pm c}}
\]
on aura
\[
\theta^{\mu+m} x=\theta^m\left(\theta^\mu x\right)=\theta^m\left( \pm \frac{1 \cdot}{c x}\right)=\theta^m\left(\frac{1}{\sqrt{ \pm c}}\right)
\]
done
\[
\boldsymbol{\theta}^{\mu+m} \boldsymbol{x}=\boldsymbol{\theta}^m x
\]
%585
Si done on désigne par \(a\) la valeur de \(y\) qui répond à \(x=\frac{1}{\sqrt{ \pm c}}\), les racines de l'équation \(\alpha=\psi x\), c'est-à-dire de
\[
p-\alpha q=0
\]
seront égales entre elles deux à deux; donc \(p-\alpha q\) sera un carré parfait. En changeant le signe de \(z\), on aura \(p+\alpha q\), qui par conséquent sera également un carré; donc en multipliant, on aura
\[
p^2-\alpha^2 q^2=t^2
\]
où \(t\) est une fonction entière de z. En faisant donc \(\cdot\)
\[
c^{\prime}=\frac{1}{\alpha}
\]
l'équation (161) aura lieu, et par suite on aura
\[
\frac{d v}{d^{\prime} v}=\varepsilon \frac{d z}{d z}, \text { où } \frac{p}{q}=v
\]
c'est-ì-dire, en changeant \(z\) en \(x\)
\[
\frac{d y}{d^{\prime} y}=\varepsilon \frac{d v}{d x}
\]

Pour déterminer le coefficient. \(\varepsilon\) on aura d'abord, en vertn de la dernière équation,
\[
\varepsilon=\frac{d y}{d x}, \text { pour } x=0
\]

Mais l'expression de \(y\) domnera
\[
\frac{d y}{d x}=A=\frac{1}{\varphi(1)}
\]
done
\[
\varepsilon=\frac{1}{\varphi(1)}
\]

Le numérateur de la fraction qui exprime la valeur de y est décomposé en facteurs; savoir si l'on fait \(y=\frac{p^{\prime}}{q^{\prime}}\), on a
\[
p^{\prime}=\frac{1}{\varphi(1)} x\left(1-c^2 e^2 x^2\right)\left(1-c^2 e_2^2 x^2\right) \ldots\left(1-c^2 e_{\mu-1}^2 x^2\right) .
\]

On pourra facilement décomposer de la même manière le dénominateur \(q^{\prime}\), comme on va le voir.

En divisant les membres de la formule (147) par \(y\), il viendra à cause de \(a=0\) :
%586
\[
\frac{p}{y}-q=-b(z-x)(z-\theta x)\left(z-\theta^2 x\right) \ldots\left(z-\theta^{2 \mu-1} x\right)
\]

Cela posé, soit \(\delta\) une valeur de \(x\), qui rende \(y\) infini, c'est-à-dire une des racines de l'équation \(q^{\prime}=0\). On aura
\[
q=b(z-\delta)(z-\theta \delta)\left(z-\theta^2 \delta\right) \ldots\left(z-\theta^{2 \mu-1} \delta^{\prime}\right)
\]

Il suffit donc de connaître une valeur de \(\delta\). Or une telle valeur est \(\frac{1}{\sqrt{\mp c}}\). En effet, puisquion doit avoir \(y=\frac{1}{0}\), et remarquant que
\[
y=\frac{a^{\prime}}{b} \frac{1}{x+\theta x+\theta^2 x+\cdots+\theta^{ \pm \mu-1} x},
\]
on aura
\[
r=x+\theta x+\theta^2 x+\cdots+\theta^{2 \mu-1} x=0 .
\]

Soit pour une valeur quelconque de \(x\)
\[
p_m=\theta^m x+\theta^{2 \mu-m} x+\theta^{\mu+m} x+\theta^{3 \mu-m} x,
\]
on aura évidemment, en remarquant que \(\theta^{2 \mu} x=x\),
\[
p_0+p_1+p_2+\cdots+p_{2 \mu-1}=4 r
\]

Or je dis que si l'on fait
\[
x=\frac{1}{\sqrt{\mp c}},
\]
on allara
\[
p_m=0
\]
pour une valeur quelconque de \(m\). En effet on a d'abord
\[
\theta^m x+\theta^{2 \mu-m} x=\frac{2 x \cdot \Delta e_m}{1-c^2 e_m^2 x^2}
\]
donc en mettant \(\theta^\mu x\) au lieu de \(x\), et remarquant que \(\theta^\mu x= \pm \frac{1}{c x}\),
\[
\theta^{m+\mu} x+\theta^{3 \mu-m} x=\frac{ \pm 2 \Delta e_m}{c x\left(1-e_m^2 x^{-2}\right)} .
\]

En faisant maintenant
\[
x=\frac{1}{\sqrt{ \pm c}}
\]
on aura
\[
\theta^m x+\theta^{2 \mu-m} x=\frac{2 \Delta e_m}{\sqrt{(\mp c)\left(1 \pm c e_m^2\right)}}=-\left(\theta^{m+\mu} x+\theta^{3 \mu-m} x\right)
\]
et par suite
\[
p_m=0 .
\]
%587
On pourra done faire
\[
\delta=\frac{1}{\sqrt{\mp} c} .
\]

En reñarquant que \(q^{\prime}=1\) pour \(x=0\), on aura, en mettant dans l'expression de \(q, x\) au lieu de \(z\),
\[
q^{\prime}=\left(1-\frac{x}{\delta}\right)\left(1-\frac{x}{\theta \delta}\right)\left(1-\frac{x}{\theta^2 \delta}\right) \ldots\left(1-\frac{x}{\theta^{2 \mu-1} \delta}\right) .
\]

D'après ce qui précède on pourra énoncer ce théorème:
Théorème XI. "Soit \(e\) une racine quelconque de l'équation \(e_\mu=\frac{1}{0}\), mais qui ne satisfait pas en même temps à deux équations de la forme \(e_m=\) (), \(\Delta e_m=1\), où \(m\) est facteur de \(2 u\). Cela posé, si l'on détermine les trois quantités \(y, c^{\prime}, \varepsilon\) par les formules
\[
\left\{\begin{array}{l} 
\pm \frac{\varepsilon}{c} \cdot \frac{1}{y}=x \pm \frac{1}{c x}+\frac{2 \Delta e \cdot x}{1-c^2 e^2 x^2}+\frac{2 \Delta e_2 \cdot x}{1-c^2 e_2^2 x^2}+\cdots+\frac{2 \Delta e_{\mu-1 \cdot x}}{1-c^2 e_{\mu-1}^2 x^2} \\
\pm \varepsilon=c\left(1 \pm \frac{1}{c}+\frac{2 \Delta e}{1-c^2 e^2}+\frac{2 \Delta e_2}{1-c^2 e_2^2}+\cdots+\frac{2 \Delta e_{\mu-1}}{1-c^2 e_{\mu-1}^2}\right) \\
\text { on aura toujours } \\
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)}}=\frac{\varepsilon \cdot d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}} \cdot \cdots
\end{array}\right.
\]

Le cas le plus simple de cette formule est celui où,\(\prime=1\). On aura alor's
\[
\left\{\begin{array}{l}
\varepsilon= \pm c\left(1 \pm \frac{1}{c}\right)=1 \pm c \\
y=(1 \pm c) \frac{x}{1 \pm c x^2}, \quad c^{\prime}=\frac{2 \sqrt{ \pm c}}{1 \pm c} \\
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)}}=(1 \pm c) \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}
\end{array}\right.
\]

Après avoir déterminé par le théorème précédent un système de valeurs pour \(y, c^{\prime}, \varepsilon\), on aura cinq autres solutions à l'aide des formules du denxième paragraphe de ce chapitre.
B. Si \(e_\mu=0\), le radical \(\Delta e_\mu\) ne pourra avoir que l'ume des deux valeurs +1 ou -1 ; mais il faut ici prendre \(d c_\mu=-1\), car si l'on avait en même temps \(e_\mu=0, \Delta e_\mu=1\), il en résulterait \(\theta^\mu x=x\), ce qui n'est pas. Mais comme on a
%588
\[
\theta^\mu x=\frac{x \Delta e_\mu+e_\mu \Delta x}{1-c^2 e_\mu^2 x^2}
\]
cela donne
\[
\theta^\mu x=-x
\]
et en mettant \(\theta^m x\) au lieu de \(x\),
\[
\boldsymbol{\theta}^{\mu+m} x=-\boldsymbol{\theta}^m x .
\]

Les racines de l'équation \(y=\psi x\) seront dans ce cas égales deux à deux, mais de signe contraire, et par conséquent \(\psi x\) sera une fonction paire de \(x\). En faisant
\[
\psi z=\frac{p}{q}
\]
on aura
\[
p-q y=(a-b y)\left(z^2-x^2\right)\left[z^2-(\theta x)^2\right]\left[z^2-\left(\theta^2 x\right)^2\right] \ldots\left[z^2-\left(\theta^{\mu-1} x\right)^2\right] .
\]

Si l'on fait \(z=0\), et qu'on désigne les valeurs correspondantes de \(p\) et \(q\) par \(a^{\prime}\) et \(b^{\prime}\), on aura
\[
a^{\prime}-b^{\prime} y= \pm(a-b y)\left(x . \theta x \cdot \theta^2 x \ldots \theta^{\mu-1} x\right)^2
\]
ce qui donne pour \(y\) une expression rationnelle du degré \(2 \mu\). Comme dans les deux premiers cas, on démontrera aisément qu’il sera toujours possible de déterminer les constantes \(a, b, a^{\prime}, b^{\prime}\) de telle sorte que l'équation
\[
\frac{d y}{d^{\prime} y}=\varepsilon \frac{d x}{\Delta x}
\]
soit satisfaite, en attribuant au module \(c^{\prime}\) et au coefficient \(\varepsilon\) des valeurs On aura alors
et par suite
\[
a^{\prime}-b^{\prime} y=(-a+b y) x^2,
\]
\[
y=\frac{a^{\prime}+a x^2}{b^{\prime}+b x^2}
\]

En mettant cette valeur dans l'équation
\[
\frac{d y}{d^{\prime} y}=\varepsilon \frac{d x}{d x}
\]
on trouvera facilement une solution, savoir
\[
y=\frac{1+c x^2}{1-c x^2}, \quad c^{\prime}=\frac{1-c}{1+c}, \varepsilon=(1+c) \sqrt{-1} .
\]

Connaissant ainsi une solution, on en déduira les cinq autres par les formules du deuxième paragraphe, de sorte que l'équation
%589
\[
\frac{d y}{d^{\prime} y}=\varepsilon \frac{d x}{\Delta x}
\]
pourra être satisfaite des six manières suivantes:
\[
c^{\prime}=\frac{1 \pm c}{1 \mp c}, \frac{1 \pm \sqrt{1-c^2}}{1 \mp \sqrt{1-c^2}}, \frac{c \pm \sqrt{c^2-1}}{c \mp \sqrt{c^2-1}} .
\]
\(\S 7\).
Réduction du problème général au cas où le degré de la fonction rationnelle y est un nombre premier.

Soit maintenant \(y=\psi x\) une fonction rationnelle quelconque qui satisfait à l'équation différentielle
\[
\frac{d y}{d^{\prime} y}=\varepsilon \frac{d x}{d x} .
\]

Comme on l'a vu dans le paragraphe 3 , l'équation
\[
y=\psi x
\]
aura toujours \(n\) racines de la forme
\[
x, \theta x, \theta^2 x, \ldots \theta^{n-1} x \text {, où } \theta^n x=x \text {. }
\]

Cela posé, désignons par \(x^{\prime}\) une nouvelle racine, différente de celles-ci, de sorte que

On a
\[
\psi x^{\prime}=\psi x=y
\]
donc: anssi
\[
\begin{gathered}
\psi\left(\theta^m x\right)=\psi \prime x \\
\psi\left(\theta^m x^{\prime}\right)=\psi x^{\prime}=y .
\end{gathered}
\]

Il suit de là que les \(n\) quantités
\[
x^{\prime}, \theta x^{\prime}, \theta^3 x^{\prime}, \ldots \theta^{n-1} x^{\prime}
\]
qui sont différentes entre elles, seront racines de l'équation dont il s'agit. Or toutes ces \(n\) racines sont différentes des racines (167). E'n effet, si l'on avait \(\theta^m x^{\prime}=\theta^{\prime \prime} x\), il en résulterait
\[
\begin{gathered}
\boldsymbol{\theta}^{n-m} \theta^m x^{\prime}=\theta^{n-m+\mu} x, \\
x^{\prime}=\theta^{n-m+\mu} x,
\end{gathered}
\]
ce qui est contre l'hypothèse. Le degré "" de l'équation \(y=y p\) est done:
%590
égal à \(2 n\), ou plus grand que ce nombre. Dans le dernier cas, si l'on désigne par \(x^{\prime \prime}\) une racine différente des \(2 n\) racines précédentes, on aura en même temps celles-ci :
\[
x^{\prime \prime}, \theta x^{\prime \prime}, \theta^2 x^{\prime \prime} \ldots \theta^{n-1} x^{\prime \prime},
\]
qui seront différentes entre elles et des racines \((167,168)\). Donc \(\mu\) sera égal à \(3 n\) ou plus grand que ce nombre. En continuant jusqu'à ce qu'on ait épuisé toutes les racines, on voit que \(\boldsymbol{\mu}\) doit être un multiple de \(n\), et si l'on fait en conséquence
\[
\boldsymbol{\mu}=m \cdot n
\]
les, \(\boldsymbol{\mu}\) racines se distribueront en \(m\) groupes de \(n\) termes chacun, savoir

Cela posé, soit
\[
\psi z=\frac{p}{q},
\]
\(p\) et \(q\) étant des fonctions entières de \(z\), sans diviseur commun. On aura (170)
\[
\begin{aligned}
& p-q y=(a-b y)(z-x)(z-\theta x)\left(z-\theta^2 x\right) \ldots\left(z-\theta^{n-1} x\right) \\
& \times\left(z-x^{\prime}\right)\left(z-\theta x^{\prime}\right)\left(z-\theta^2 x^{\prime}\right) \ldots\left(z-\theta^{n-1} x^{\prime}\right) \\
& \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \\
& \times\left(z-x^{(m-1)}\right)\left(z-\theta x^{(m-1)}\right)\left(z-\theta^2 x^{(m-1)}\right) \cdots\left(z-\theta^{n-1} x^{(m-1)}\right), \\
&
\end{aligned}
\]
et d'après ce qui a été exposé dans le paragraphe précédent, on pourra trouver une fonction rationnclle, \(y_1=\psi_1 x\), telle que les racines de l'équation
\[
y_1=\psi_1 x
\]
soient les \(n\) quantités
\[
x, \theta x, \theta^2 x, \ldots \theta^{n-1} x
\]
et que \(y_1\) satisfasse à une équation différentielle de la forme
\[
\frac{d y_1}{\sqrt{\left(1-y_1^2\right)\left(1-c_1^8 y_1^2\right)}}=\varepsilon_1 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^y x^2\right)}} \text {. }
\]

Faisons
\[
\psi_1 z=\frac{p^{\prime}}{q^{\prime}},
\]
%591
\(l^{\prime}\) et \(q^{\prime}\) étant des fonctions entières du degré \(n\); on aura
\[
p^{\prime}-q^{\prime} y_1=\left(a^{\prime}-b^{\prime} y_1\right)(z-x)(z-\theta x) \ldots\left(z-\theta^{n-1} x\right),
\]
\(a^{\prime}\) et \(b^{\prime}\) étant des constantes.
En mettant au lieu de \(x\) successivement les \(m\) valeurs
\[
x, x^{\prime}, x^{\prime \prime}, \ldots x^{(m-1)}
\]
et puis multipliant entre elles les équations qui en résultent, on obtiendra, en ayant égard à l'équation (170),
\[
\frac{p-q y}{a-b y}=\frac{p^{\prime}-q^{\prime} y_1}{a^{\prime}-b^{\prime} y_1} \cdot \frac{p^{\prime}-q^{\prime} y_2}{a^{\prime}-b^{\prime} y_2} \cdots \frac{p^{\prime}-q^{\prime} y_m}{a^{\prime}-b^{\prime} y_m}
\]
où
\[
y_2, y_3, \ldots y_m
\]
sont les valeurs de la fonction \(y_1\), qui répondent aux valeurs de \(x\).
\[
x^{\prime}, x^{\prime \prime}, \ldots x^{(m-1)}
\]

Cela posé, attribuons à \(x\) deux valeurs particulières \(\alpha, \beta\), telles que
\[
\psi \alpha=0, \psi \beta=\frac{1}{0}
\]
en désignant par
\[
\alpha_1, \alpha_2, \ldots \alpha_m, \beta_1, \beta_2, \ldots \beta_m
\]
les valeurs de \(y_1, y_2, \ldots y_m\), respectivement correspondantes aux valeurs \(\alpha\) et \(\beta\) de \(x\), l'équation (173) donnera
\[
\left\{\begin{array}{l}
p=A^{\prime}\left(p^{\prime}-\alpha_1 q^{\prime}\right)\left(p^{\prime}-\alpha_2 q^{\prime}\right) \cdots\left(p^{\prime}-\alpha_m q^{\prime}\right), \\
q=A^{\prime \prime}\left(p^{\prime}-\beta_1 q^{\prime}\right)\left(p^{\prime}-\beta_2 q^{\prime}\right) \cdots\left(p^{\prime}-\beta_m q^{\prime}\right),
\end{array}\right.
\]
où \(A^{\prime}\) et \(A^{\prime \prime}\) sont deux constantes. En divisant \(p\) par \(q\), on voit que \(\frac{p}{q}=\psi z\) sera fonction rationnelle de \(\frac{p^{\prime}}{q^{\prime}}=\psi_1 z\). En mettant \(x\) au lieu de \(z\), on aura
\[
\frac{p}{q}=y, \frac{p^{\prime}}{q^{\prime}}=y_1
\]
done
\[
y=A \frac{\left(y_1-\alpha_1\right)\left(y_1-\alpha_2\right)\left(y_1-\alpha_3\right) \cdots\left(y_1-\alpha_m\right)}{\left(y_1-\beta_1\right)\left(y_1-\beta_2\right)\left(y_1-\beta_3\right) \cdots\left(y_1-\beta_m\right)},
\]
\(A=\frac{A^{\prime}}{A^{\prime \prime}}\) étant constant.
Qn voit donc que \(y\) pourra être exprimé par une fonction rationnelle de \(y_1\) du degré \(m\).
%592
En combinant maintenant l'équation (171) avec celle-ci:
\[
\frac{d y}{d^{\prime} y}=\varepsilon \frac{d x}{d x},
\]
qui doit avoir lieu, on aura
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)}}=\frac{\varepsilon}{\varepsilon_1} \frac{d y_1}{\sqrt{\left(1-y_1^2\right)\left(1-c_1^2 y_1^2\right)}} ;
\]
donc la fonction \(y\), rationnelle en \(y_1\) et du degré \(m\), doit satisfaire à cette équation. Réciproquement, si cette équation a lieu, l'équation
\[
\frac{d y}{I^{\prime} y}=\varepsilon \frac{d x}{d x}
\]
subsistera également, car la fonction \(y_1\) est déterminée en ' \(x\) de manière à satisfaire à la formule (171). Ainsi le problème général est réduit à satisfaire de la manière la plus générale à l'équation (176). Or ce problème est précisément le même que celui que nous traitons; senlement le degré de la fonction \(y\) en \(y_1\) sera \(m\), tandis que \(y\), comme fonction de \(x\), est du - degré \(m . n\), qui est plus grand que \(m\). On pourra done appliquer à l'équation (176) le même procédé qu'à l'équation \(\frac{d y}{\Delta^{\prime} y}=\varepsilon \frac{d x}{\Delta x}\), et il est évident qu'on parviendra ainsi à l'expression générale de \(y\), car les degrés des fonctions successives vont toujours en décroissant.

Supposons maintenant que le degré \(\mu\) de la fonction \(y\) en \(x\) soit un nombre premier. Puisque \(\boldsymbol{\mu}=m . n\), on a nécessairement \(m=1, \quad \boldsymbol{\mu}=n\). Par suite
\[
y=A \frac{y_1-\alpha_1}{y_1-\beta_1}
\]

On connaît l'expression de \(y_1\) en \(x\) par les formules du paragraphe précédent. En substituant l'expression de \(y\) en \(y_1\) dans l'équation (176), on déterminera à l'aide des formules du paragraphe 2 toutes les solutions possibles.
En vertu de ce qui précède on pourra done énoncer le théorème suivant:
Théorème XII. Soit \(y\) une fonction ratiomelle de \(x\) d'un degré quelconque \(\mu\), qui satisfait à l'équation différentielle
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)}}=\varepsilon \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}},
\]
on pourra toujours décomposer \(\mu\) en deux facteurs \(n\) et \(m\), dont l'un \(n\) est un nombre premier, tels qu'on ait
%593
et
\[
\frac{d y_1}{\sqrt{\left(1-y_1^2\right)\left(1-c_1^2 y_1^2\right)}}=\varepsilon_1 \frac{d x}{\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}}
\]
\[
\frac{d y}{\sqrt{\left(1-y^2\right)\left(1-c^{\prime 2} y^2\right)}}=\frac{\varepsilon}{\varepsilon_1} \frac{d y_1}{\sqrt{\left(1-y_1^2\right)\left(1-c_1^2 y_1^2\right)}},
\]
\(y\) étant une fonction rationnelle de \(y_1\) du degré \(m\), et \(y_1\) une fonction rationnelle de \(x\) du degré \(n\).

Si donc on désigne par \(n, n_1, n_2, \ldots n_v\) des nombres premiers dont le produit est \(\mu\), et qu'on fasse pour abréger
\[
\mathcal{A}(x, c)=\sqrt{\left(1-x^2\right)\left(1-c^2 x^2\right)}
\]
on pourra faire
\[
\frac{d y}{d\left(y, c^{\prime}\right)}=\varepsilon_\nu \frac{d y_\nu}{d\left(y_\nu, c_\nu\right)}=\varepsilon_{\nu-1} \frac{d y_{\nu-1}}{J\left(y_{\nu-1}, c_{\nu-1}\right)}=\cdots=\varepsilon_1 \frac{d y_1}{I\left(y_1, c_1\right)}=\varepsilon \frac{d x}{d x}
\]
\(y_1\) étant une fonction rationnelle de \(x\) du degré \(n\),

En vertu de ce théorème la solution du problème général est ramenée au cas où le degré de la fonction \(y\) est un nombre premier. On aura toutes les solutions qui répondent à ce cas par les formules du paragraphe précédent, et ainsi le problème que nous nous sommes proposé au commencement de ce chapitre pourra être regardé comme résolu.
\(\$ 8\).
Sur la jorme de là finction \(y\).
Désignons par \(x, x^{\prime} x^{\prime \prime} \ldots x^{(\mu-1)}\) les racines de l'équation
\[
y=\psi x \text {. }
\]

Si l'on fait \(\psi z=\frac{p}{q}, p\) et \(q\) étant des fonctions entières de \(z\), on aura
\[
p-q y=(a-b y)(z-x)\left(z-x^{\prime}\right)\left(z-x^{\prime \prime}\right) \ldots\left(z-x^{(\mu-1)}\right),
\]
%594
\(a\) et \(b\) étant des constantés. Cela posé, soit \(\alpha\) une racine de l'équation \(y=0\), on aura en faisant \(x=\alpha\),
\[
p=a(z-\alpha)\left(z-\alpha^{\prime}\right)\left(z-\alpha^{\prime \prime}\right) \ldots\left(z-\alpha^{(\mu-1)}\right) .
\]

Soit de même \(\beta\) une racine de l'équation \(y=\frac{1}{0}\). Cela domera, en faisant \(x=\beta\) après avoir divisé les deux membres de l'équation (177) par \(y\),
\[
q=b(z-\beta)\left(z-\beta^{\prime}\right)\left(z-\beta^{\prime \prime}\right) \ldots\left(z-\beta^{(\mu-1)}\right) .
\]

Ces valeurs de \(p\) et \(q\) domeront, en mettant \(x\) au lieu de \(z\),
\[
y=A \frac{(x-\alpha)\left(x-\alpha^{\prime}\right) \ldots\left(x-\alpha^{(\mu-1)}\right)}{(x-\beta)\left(x-\beta^{\prime}\right) \ldots\left(x-\beta^{(\mu-1)}\right)},
\]
où \(A\) est un coefficient constant, qu'on détermine en remarquant que si l'on fait \(x=1, y\) doit avoir une des valeurs \(\pm 1, \pm \frac{1}{c^{\prime}}\).

Mais il y a deux cas à considérer séparément: savoir, il pourra arriver que l'une des deux quantités \(a\) et \(b\) soit égale à zéro, et dans ce cas l'une des racines des équations \(y=0, y=\frac{1}{0}\) sera nulle ou infinie.
Cas premier, si \(b=0\). On aura
\[
p-q y=a(z-x)\left(z-x^{\prime}\right) \ldots\left(z-x^{(\mu-1)}\right)
\]
et \(p\) sera du degré \(\boldsymbol{\mu}\), et \(q\) seulement du degré \(\boldsymbol{u}-1\). En égalant le coefficient de \(z^{\mu-1}\) dans les deux membres, on aura
\[
a^{\prime}-b^{\prime} y=-a\left(x+x^{\prime}+x^{\prime \prime}+\cdots+x^{(\mu-1)}\right)
\]
\(a^{\prime}\) et \(b^{\prime}\) étant des constantes. Maintenant si
\[
x^{\prime}=\frac{x \Delta e+e \Delta x}{1-c^2 e^2 x^2} .
\]
est une racine de \(y=\psi x\), la quantité
\[
\frac{x \Delta e-e \Delta x}{1-c^2 e^2 x^2}
\]
le sera également; donc si ces deux quantités sont différentes entre elles pour toutes les valeurs de \(e, \mu\) sera un nombre impair, et en faisant \(\mu=2 n+1\), on aura
(183) \(\quad a^{\prime}-b^{\prime} y=-a\left(x+\frac{2 x d e_1}{1-c^2 e_1^8 x^2}+\frac{2 x \Delta e_2}{1-c^2 e_8^8 x^2}+\cdots+\frac{2 x d e_n}{1-c^2 e_n^2 x^2}\right)\).

Maintenant si l'on fait \(x= \pm 1, \pm \frac{1}{c}\), on doit avoir \(y= \pm 1, y= \pm \frac{1}{c^{\prime}}\),
%595
d'où il est facile de conclure que \(a^{\prime}\) sera égal à zéro. Donc \(y\) sera une fonction impaire de \(x\), et de la forme
\[
y=A x\left(1+\frac{2 d e_1}{1-c^2 e_x^2 x^2}+\cdots+\frac{2 d e_n}{1-c^2 e_n^2 x^2}\right)
\]

Cela fait voir que
\[
q=\left(1-c^2 e_1^2 z^2\right) \cdots\left(1-c^2 e_n^2 z^2\right)
\]

Pour avoir \(\gamma\), il suffit de faire dans. l'équation (181) \(x=0\), ce qui donne
\[
p=a z\left(z^2-e_1^2\right) \ldots\left(z^2-e_{\imath}^2\right)
\]
donc on aura
\[
y=a \frac{x\left(e_1^2-x^2\right)\left(e_2^2-x^2\right) \ldots\left(e_n^2-x^2\right)}{\left(1-c^2 e_1^2 x^2\right)\left(1-c^2 e_2^2 x^2\right) \ldots\left(1-c^2 e_n^2 x^2\right)} .
\]

Telle est done la forme de la fonction \(y\) dans le cas où le degré de son numérateir est impair et plus grand que celui du dénominateur.
Si pour quelque valeur de \(e\) les deux quantités
\[
\frac{x \Delta e+e \Delta x}{1-c^3 e^2 x^2}, \frac{x \Delta e-e \Delta x}{1-c^2 e^2 x^2}
\]
étaient égales, on aurait
\[
e=0, \text { ou } e=\frac{1}{0}
\]

Soit d'abord \(e=\frac{1}{0}\), on aura \(x^{\prime}= \pm \frac{1}{c x}\), et par suite le second membre de l'équation (182) serait une fonction impaire de \(x\), dont le degré serait un nombre pair. On trouve que cela donne \(a^{\prime}=0\); donc en faisant \(\mu=2 n\),
\[
y=A\left(x \pm \frac{1}{c \cdot x}+\frac{2 x e_1}{1-c^2 e_1^2 x^2}+\cdots+\frac{2 x d e_{n-1}}{1-c^2 e_{n-1}^2 x^2}\right)
\]
et par suite y sera exprimé en produit de facteurs comme. il suit:
\[
y=\frac{a\left(1-\delta_1^z x^2\right)\left(1-\delta_2^2 x^2\right) \ldots\left(1-\delta_n^2 x^2\right)}{x\left(1-c^2 e_1^2 x^2\right)\left(1-c^2 e_2^2 x^2\right) \ldots\left(1-c^2 e_{n-1}^2 x^2\right)},
\]

Si au contraire \(e=0\), on aura en même temps
\[
x^{\prime}=-x
\]

Done dans ce cas \(y\) sera une fonction paire de \(x\). Mais alors le degré du numérateur doit être le même que celui du dénominateur, comme il est facile de s'en convaincre; par conséquent l'expression (187) appartient à \(y\) toutes les fois que le degré du numérateur est un nombre pair et en même temps plus grand que celui du dénominateur.
%596
Cas second, si \(a=0\). On aura alors
\[
p-q y=b y(z-x)\left(z-x^{\prime}\right) \ldots\left(z-x^{(\mu-1)}\right) .
\]

En raisonnant comme ci-dessus on trouvera aisément que dans le cas où "" est un nombre impair, \(y\) serat une fonction impaire de \(x\) de la forme
\[
y=a \frac{\left(1-c^2 e_1^2 x^2\right)\left(1-c^2 e_2^2 x^2\right) \ldots\left(1-c^2 e_n^2 x^2\right)}{x\left(e_1^2-x^2\right)\left(e_2^2-x^2\right) \cdots\left(e_n^2-x^2\right)} .
\]

Si \(\mu\) est pair, y sera une fonction impare de \(x\) de la forme
\[
y=a \frac{x\left(1-c^2 e_1^2 x^2\right) \ldots\left(1-c^2 e_{n-1}^2 x^2\right)}{\left(1-\delta_1^2 x^2\right) \ldots\left(1-\delta_n^2 x^2\right)} .
\]
\(\$ 9\).
De la fonction \(x_{2 \mu+1}\).
Nous avons vu (ehapitre I paragraphe 4) que l'équation différentielle
\[
\frac{d y}{d y}=(2, u+1) \frac{d x}{d x}
\]
peut être satisfaite, en mettant pour \(y\) une fonction impaire de \(x\) du degré \((2,1+1)^2\) qui s'évanouit avec \(x\). En la désignant comme nous l'avons fait à l'endroit cité par \(x_{2 \mu+1}\), et faisant pour abréger \((2 \mu+1)^2-1=2 n\), cette fonction, en vertu de ce que nous venons de voir dans le paragraphle précédent, doit avoir la forme suivante:
\[
x_{2 \mu+1}=a \frac{x\left(e_1^2-x^2\right)\left(e_2^2-x^2\right) \ldots\left(e_n^2-x^2\right)}{\left(1-e^2 e_1^2 x^2\right)\left(1-c^2 e_2^2 x^2\right) \ldots\left(1-c^2 e_n^2 x^2\right)},
\]
et on aura en même temps
\[
x_{2 \mu+1}=A\left(x+\frac{2 \Delta e_1 \cdot x}{1-c^2 e_1^2 x^2}+\frac{2 d e_2 \cdot x}{1-c^2 e_2^2 x^2}+\cdots+\frac{2 d e_n \cdot x}{1-c^2 e_n^2 x^2}\right)
\]

Pour déterminer les coefficiens \(a\) et \(A\), faisons \(x=\frac{1}{0}\). On trouvera alors
\[
A c^{2 n} e_1^2 e_2^2 \ldots e_n^y=a .
\]

Si l'on fait \(x\) infiniment petit, la première formule donne
\[
x_{2 \mu+1}=a e_1^8 e_2^2 \ldots e_n^2 x
\]
mais l'équation différentielle donne dans ce cas par suite
\[
x_{2 \mu+1}=(2 u+1) x
\]
%597
\[
a e_1^2 e_2^2 \ldots e_n^2=2 u+1
\]

De même si l'on fait \(x\) infiniment grand, la seconde expression de \(x_{2 \mu+1}\) donne \(x_{2 \mu+1}=A x\), mais dans le même cas l'équation différentielle donne
\[
\frac{d x^2, \mu+1}{c x^2{ }_{\mu+1}^2}=\frac{d x}{c A x^2}=(2 \mu+1) \frac{d x^2}{c x^2},
\]
done
\[
A=\frac{1}{2 \mu+1} .
\]

Comnaissant \(A\), on aura ensuite
\[
e_1^2 e_2^2 \ldots e_n^2=\frac{2 \mu+1}{e^n}, a=c^n=e^{2 \mu^2+2 \mu} .
\]

Les quantités \(e_1, e_2, \ldots e_n\) ont entre elles des relations remarquables que nous allons développer. Considérons l'équation
\[
x_{2 \mu+1}=y \text {. }
\]

Les racines de cette équation sont les \((2,1+1)^2\) quantités
\[
x, \frac{x \Delta e_1 \pm e_1 d x}{1-c^2 e_1^2 x^2}, \frac{x d e_2 \pm e_2 d x}{1-c^2 e_2^2 x^2}, \ldots \frac{x d e_n \pm e_n d x}{1-c^2 e_n^2 x^2} .
\]

Soit \(\theta x=\frac{x \Delta e+e \Delta x}{1-e^2 e^2 x^2}\) l'une quelconque de ces racines, les \(2 \mu+1\) quantités
\[
x, \theta x, \theta^2 x \ldots \theta^{2 \mu} x
\]
seront encore des racines et différentes entre elles, si lon prend pour e une quantité qui n'est pas racine d'une équation
\[
x_{2 m+1}=0,
\]
où \(2 m+1\) est facteur de \(2 \mu+1\). Soit de même
\[
\theta_1 x=\frac{x d e^{\prime}+e^{\prime} d x}{1-c^2 e^{\prime 2} x^2}
\]
une autre racine, on aura encore les racines suivantes:
\[
\theta_1 x, \theta_1^2 x, \ldots \theta_1^{2 \mu} x
\]
qui seront différentes entre elles.
Cela posé, faisons
on arira en général
\[
x_{2 \mu+1}=\psi x
\]
\[
\psi\left(\boldsymbol{\theta}^m x\right)=\psi\left(\boldsymbol{\theta}_1^k x\right)
\]
%598
quels que soient les nombres entiers \(m\) et \(k\). En mettant \(\theta^m x\) pour \(x\), aura
\[
\psi\left(\theta_1^k \theta^m x\right)=\psi\left(\theta^{2 m} x\right)=x_{2 \mu+1}
\]
done toute quantité de la forme
\[
\theta_1^k \theta^m x
\]
sera racine de l'équation \(y=\psi x\). Je dis maintenant que si l'on attribue à \(k\) et \(m\) toutes les valeurs entières moindres que \(2 \mu+1\), les valeurs qui en résultent pour la fonction \(\boldsymbol{\theta}_1^k \theta^m x\), seront toutes différentes entre elles. En effet, si l'on avait
\[
\theta_1^k \theta^m x=\theta_1^{k^{\prime}} \theta^{m^{\prime}} x
\]
il en résulterait, en mettant \(\theta^{2 \mu+1-m^{\prime}} x\) pour \(x\) et remarquant que \(\theta^{2 \mu+1} x=x\),
\[
\theta_1^k \theta^{n^{\prime}} \dot{x}=\theta_1^{k^{\prime}} \dot{x}
\]
en posant \(n^{\prime}=m+2 \mu+1-m^{\prime}\).
Cela donne
\[
\theta_1^{2 \mu+1 \rightarrow k} \theta_1^k \theta^{n^{\prime}} x=\theta_1^{k^*} x
\]
en posant \(k^{\prime \prime}=2 \mu+1-k+k^{\prime}\), c'est-à-dire
\[
\begin{gathered}
\boldsymbol{\theta}^{n^{\prime}} x=\boldsymbol{\theta}_1^{k^{\prime \prime}} x, \\
\boldsymbol{\theta}^{n^{\prime} \mu^{\prime}} x=\boldsymbol{\theta}_1^{k^{\prime \prime} \mu^{\prime}} x .
\end{gathered}
\]
et par suite
\[
\theta^{n^{\prime} \mu^{\prime}} x=\theta_1^{k^{\prime \prime} \mu^{\prime}} x
\]

Maintenant, puisque \(2 \mu+1\) est un nombre premier, on pourra faire
\[
k^{\prime \prime} u^{\prime}=(2 \mu+1) \beta+1
\]
done
\[
\theta_1^{(2 \mu+1) \beta} \theta_1 x=\theta_1 x=\theta^{n^{\prime} \mu^{\prime}} x
\]
c'est-à-dire que \(\theta_1 x\) serait nne des quantités
\[
x, \theta x, \ldots \theta^{2 \mu} x
\]
ce qui est contre l'hypothèse.
L'expression \(\theta_1^k \theta^m x\) a done \((2,1+1)^2\) valenrs différentes et par conséquent ces valeurs seront les racines de l'équation
\[
x_{2 \mu+1}=y \text {. }
\]

Soit maintenant
\[
x^{\prime}=\boldsymbol{\theta}_1^k x, x^{\prime \prime}=\theta_1^k \theta^m x, x^{\prime \prime \prime}=\theta^m x .
\]

On aura, en regardant \(e\) et \(e^{\prime}\) comme variables,
\[
\frac{d x^{\prime}}{d x^{\prime}}=\frac{d x}{d x^x}+k \frac{d e^{\prime}}{d e^{\prime}},
\]
%599
\[
\frac{d x^{\prime \prime \prime}}{d x^{\prime \prime \prime}}=\frac{d x}{d x}+m \frac{d e}{d e} .
\]

En mettant dans la première formule \(x^{\prime \prime \prime}\) au lieu de \(x, x^{\prime}\) se changera en \(x^{\prime \prime}\), done
\[
\frac{d x^{\prime \prime}}{d x^{\prime \prime}}=\frac{d x^{\prime \prime \prime}}{d x^{\prime \prime \prime}}+k \frac{d e^{\prime}}{d e^{\prime}}
\]
done
\[
\frac{d x^{\prime \prime}}{d x^{\prime \prime}}=\frac{d x}{d x}+k \frac{d e^{\prime}}{d e^{\prime}}+m \frac{d e}{d e},
\]
et si l'on fait
\[
\begin{aligned}
k \frac{d e^{\prime}}{\Delta e^{\prime}} & =\frac{d e_k^{\prime}}{d e_k^{\prime}}, \quad m \frac{d e}{d e}=\frac{d e_m}{d e_m}: \\
\frac{d x^{\prime \prime}}{d x^{\prime \prime}} & =\frac{d x}{d x}+\frac{d e_k^{\prime}}{d e_k^{\prime}}+\frac{d e_m}{d e_m}
\end{aligned}
\]

Si donc: on fait
\[
\begin{gathered}
e_{m, k}=\frac{e_m d e_k{ }^{\prime}+e_k^{\prime} d e_m}{1-c^2 e_m^2 e_k^{\prime 2}}, \\
\frac{d x^{\prime \prime}}{\Delta x^{\prime \prime}}=\frac{d x}{d x}+\frac{d e_{m, k}}{\Delta e_{m, k}}
\end{gathered}
\]
on aura
\[
\frac{d x^{\prime \prime}}{d x^{\prime \prime}}=\frac{d x}{d x}+\frac{d e_{m, k}}{d e_{m, k}}
\]
d'où, en supposant que \(e_m\) et \(e_k^{\prime}\) s'évanouissent avec \(e\) et \(e^{\prime}\),
\[
x^{\prime \prime}=\frac{x \Delta e_{m, k}+e_{m, k} \Delta x}{1-c^2 e_{m, k}^2 x^2}=\theta_1^k \theta^m x
\]

Toutes les racines de l'équation \(y=x_{2 \mu+1}\) pourront donc être représentées par cette même formule.

Done pour connaître toutes les racines, il suffit d'avoir la valeur des deux quantités \(e\) et \(e^{\prime}\), qui sont deux racines de l'équation
\[
x_{2 \mu+1}=0 \text {. . }
\]
'Toutes les racines de cette équation
\[
x_{2 \mu+1}=0
\]
lesquelles, par ce qui précède, sont les \((2, \mu+1)^2\) quantités
\[
0, \pm e_1, \pm e_2, \ldots \pm e_n
\]
sont done exprimées par la formule
\[
\boldsymbol{e}_{m, k},
\]
en donnant à \(m\) et \(k\) toutes les valeurs moindres que \(2,1+1\). Il est facile de voir qu'on pourra exprimer \(e_{m, k}\) en fonction rationnelle des deux quanti-
%600
tés \(e, e^{\prime}\); donc on voit que toutes les racines de l'équation \(x_{2 \mu+1}=0\), pourront s'exprimer rationnellement par deux d'entre elles et par le module \(c\).

Si l'on veut exprimer \(x_{2 \mu+1}\) à l'aide des fonctions \(\theta_1 x\) et \(\theta x\), un pourra le faire d'une manière fort simple. En effet, en remarquant que le dernier terme d'une équation est le produit de toutes ses racines, on aura sur le champ
\[
\begin{aligned}
& x_{2 \mu+1}=c^{2 \mu^2+2 \mu} \cdot x \cdot \theta x \cdot \theta^2 x \ldots \theta^{2 \mu} x \\
& \\
& \times \theta_1 x \cdot \theta_1 \theta x \cdot \theta_1 \theta^2 x \ldots \theta_1 \theta^{2 \mu} x \\
& \times \theta_1^2 x \cdot \theta_1^2 \theta x \cdot \theta_1^2 \theta^2 x \ldots \theta_1^2 \theta^{2 \mu} x \\
& \cdots \cdots \cdots \cdots \cdots \theta_1^{2 \mu} \theta^{2 \mu} x \\
& \times \theta_1^{2 \mu} x \cdot \theta_1^{2 \mu} \theta x \cdot \theta_1^{2 \mu} \theta^2 x \ldots \ldots
\end{aligned}
\]

On a aussi
\[
x_{2 \mu+1}=\frac{1}{2 \mu+1} \sum_0^{2 \mu} \sum_0^{2 \mu}\left(\theta_1^m \theta^n x\right)
\]
\(\S 10\).
Je l'équation \(x_{2 \mu+1}=0\).
D'après ce qui précède les racines de l'équation \(x_{2 \mu+1}=0\) sont exprimées par \(e_{m, k}\) en donnant à \(m\) et \(k\) toutes les valeurs moindres que \(2 \mu+1\). Une de ces valeurs est zéro, savoir \(e_{0,0}\).

En divisant le numérateur de la fraction \(x_{2 \mu+1}\) par \(x\), on aura, en égalant le quotient à zéro, une équation (198)
\[
P=0
\]
du degré \(4 \mu^2+4 \mu\). Je dis que cette équation peut être résolue à l'aide d'équations du degré \(2 \mu+2\) et du degré \(2 u\).

Soit \(p\) une fonction quelconque symétrique et rationnelle des quantités \(e_1, e_2, \ldots e_{2 \mu}\). En mettant pour \(e_2, e_3, \ldots e_{2 \mu}\) leurs expressions en fonction rationnelle de \(e_1, p\) deviendra de même une fonction rationnelle de cette racine. Faisons
\[
p=\varphi e_1
\]
on aura évidemment
\[
\varphi e_1=\varphi e_2=\psi e_3=\cdots=\psi e_{2 \mu}
\]
équations qui auront lieu quelle que soit la racine \(e\). Cela posé, mettons \(e_{m, 1}\) au lieu de \(e\), il est elair que
%601
\[
e_2, e_3, \ldots e_{2 \mu}
\]
se cliangeront respectivement en
\[
e_{2 m, 2}, e_{3 m, 3}, \ldots e_{2 \mu m, 2 \mu}
\]

Donc on aura
\[
\varphi e_{m, 1}=\varphi e_{2 m, 2}=\cdots=\varphi e_{2 \mu m, 2 \mu} \text {. }
\]

Formons l'équation
\[
\text { (202) }\left\{\begin{array}{l}
\left(p-\varphi e_1\right)\left(p-\varphi e_{0,1}\right)\left(p-\varphi e_{1,1}\right)\left(p-\varphi e_{z, 1}\right) \cdots\left(p-\varphi e_{z \mu, 1}\right) \\
=p^{2 \mu+2}-q_{z \mu+1} \cdot p^{2 \mu+1}+q_{z \mu} \cdot p^{2 \mu}-\cdots-q_1 \cdot p+q_0=0
\end{array}\right.
\]
\(q_0, q_1, \ldots q_{2 \mu+1}\) seront des fonctions symétriques et rationnelles de \(\varphi e_1\), \(\varphi e_{0,1}, \ldots \varphi e_{2 \mu, 1}\). Or on pourra les exprimer rationnellement en \(c_{\text {. En }}\) effet, il suffit d'avoir la valeur de
\[
\left(\varphi e_1\right)^k+\left(\varphi e_{0,1}\right)^k+\cdots+\left(\varphi e_{2 \mu, 1}\right)^k=\varrho_k
\]

En vertu des équations \((200,201)\) cette quantité pourra s'écrire comme il suit :
\[
\begin{aligned}
2 \mu \omega_k & =\left(\varphi e_1\right)^k+\left(\varphi e_2\right)^k+\left(\varphi e_3\right)^k+\cdots+\left(\varphi e_{2 \mu}\right)^k \\
& +\left(\varphi e_{0,1}\right)^k+\left(\varphi e_{0,2}\right)^k+\left(\varphi e_{0,3}\right)^k+\cdots+\left(\varphi e_{0,2 \mu}\right)^k \\
& +\left(\varphi e_{1,1}\right)^k+\left(\varphi e_{2,2}\right)^k+\left(\varphi e_{3,3}\right)^k+\cdots \cdots+\left(\varphi e_{2 \mu, 2 \mu}\right)^k \\
& \ldots \cdots \cdots \\
& +\left(\varphi e_{2 \mu, 1}\right)^k+\left(\varphi e_{4 \mu, 2}\right)^k+\left(\varphi e_{6 \mu, 3}\right)^k+\cdots \cdots+\left(\varphi e_{4 \mu \mu, 2 \mu}\right)^k
\end{aligned}
\]

Or. le second membre de cette équation est une fonction rationnelle et symétrique des racines de l'équation \(P=0\); donc on pourra exprimer \(\varrho_k\) rationnellement par les coefficiens de cette équation, c'est-à-dire par c.

On voit donc que les coefficiens de l'équation (202), \(q_0, q_1, q_y, \ldots\) seront des fonctions rationnelles de \(c\). Donc une fonction symétrique quelconque des racines
\[
e_1, e_2, e_3, \ldots e_{2 \mu}
\]
pourra se déterminer par le module \(c\), à l'aide d'une équation du degré \(2 ı+2\). Cela posé, faisons
\[
\begin{aligned}
\left(e-e_1\right)\left(e-e_2\right) & \cdots\left(e-e_{2 \mu}\right)= \\
& e^{2 \mu}+p_{\mu-1} \cdot e^{2 \mu-2}+p_{\mu-2} \cdot e^{2 \mu-1}+\cdots+p_1 \cdot e^2+p_0=0 .
\end{aligned}
\]

Les coefficiens \(p_0, p_1, p_2, \ldots p_{\mu-1}\) seront des fonctions rationnelles et symétriques de \(e_1, e_2, \ldots e_{2 \mu}\); donc, comme nous venons de le voir, on pourra
%602
les déterminer à l'aide d'équations du degré \(2 \mu+2\). Ainsi, pour avoir les racines de l'équation \(P=0\), il suffira de résoudre des équations du degré \(2 u\) et \(2 \mu+2\).

Ce qui précède est stsceptible d'une application importante. Ise module \(c^{\prime}\), exprimé par la formule (156), est, comme on le voit, une fonction rationnelle et symétrique de \(e, e_2, e_3, \ldots e_{2 \mu}\). Donc, en vertu de la propriété démontrée précédemment, on pourra déterminer le module \(c^{\prime}\) en \(c\) à l'aide d'une équation du degré \(2 u+2\). Cette équation ne paraît guère résoluble algébriquement, excepté lorsque \(2 u+1=3\). Dans ce cas elle sera du quatrième degré.
En appliquant le théorème XII à l'équation
\[
\frac{d x_{2 \mu+1}}{d x_{2 \mu+1}}=(2 \mu+1) \frac{d x}{\Delta x},
\]
on aura, en remarquant que le degré de la fonction \(x_{2 \mu+1}\) est \((2 \mu+1)^2\), et \(2 \mu+1\) un nombre premier,
\[
\frac{d x_{2 \mu+1}}{d x_{2 \mu+1}}=\frac{2 \mu+1}{\varepsilon} \frac{d y}{d^{\prime} y}=(2 \mu+1) \frac{d x}{d x},
\]
\(y\) étant une fonction de \(x\) du degré \(2 \mu+1\), et \(x_{2 \mu+1}\) une fonction de \(y\) du même degré. On aura
\[
y=\frac{c^{\dot{\mu}+\frac{1}{2}}}{\sqrt{c^{\prime}}} \cdot \frac{x\left(e^2-x^2\right)\left(e_2^2-x^2\right) \ldots\left(e_\mu^2-x^2\right)}{\left(1-c^2 e^2 x^2\right)\left(1-c^2 e_2^2 x^2\right) \ldots\left(1-c^2 e_\mu^2 x^2\right)}
\]
et
\[
\begin{gathered}
x_{2 \mu+1}=\frac{c^{\prime \mu+1}}{\sqrt{c}} \cdot \frac{y\left(e^{\prime 2}-y^2\right)\left(e_2^{\prime 2}-y^2\right) \ldots\left(e_\mu^{\prime 8}-y^2\right)}{\left(1-c^{\prime 2} e^{\prime 2} y^2\right)\left(1-c^{\prime 2} e_2^{\prime 2} y^2\right) \ldots\left(1-c^{\prime 2} e_\mu^{\prime 2} y^2\right)}, \\
c^{\prime}=c^{2 \mu+1}\left(\frac{1-e^2}{1-c^2 e^2} \cdot \frac{1-e_2^2}{1-c^2 e_2^2} \cdots \frac{1-e_\mu^2}{1-c^2 e_\mu^8}\right)^2, \\
c=c^{\prime 2 \mu+1}\left(\frac{1-e^{\prime 2}}{1-c^{\prime 2} e^{\prime 2}} \cdot \frac{1-e^{\prime 2}}{1-c_2^{\prime 2} e_2^{\prime 2}} \cdots \frac{1-e^{\prime 2}}{1-c^{\prime 2} e_\mu^{\prime 2}}\right)^2, \\
\varepsilon=\frac{c^{\mu+1}}{\sqrt{c^{\prime}}} e^2 e_2^2 \ldots e_\mu^2 .
\end{gathered}
\]
\(e^{\prime}\) est déterminé de la même manière en \(c^{\prime}\) que \(e\) l'est en \(c\). Done si l'on change \(c\) en \(c^{\prime}\), \(e\) se changera en \(e^{\prime}\). De là il suit que l'équation entre les modules \(c^{\prime}\) et \(c\) doit rester la même si l'on change simultanément \(c\) en \(c^{\prime}\) et \(c^{\prime}\) en \(c\).

Puisque \(c^{\prime}\) dépend d'une équation du degré \(2 \mu+2\), on pourra donner à la fonction \(y, 2 \mu+2\) valeurs différentes.
%603
\(\S 11\).
Des transformations différenles qui répondent à un même degré de la fonction \(y\).
Soit
\[
y=\frac{A_0+A_1 x+A_2 x^2+\cdots+A_\mu x^\mu}{B_0+B_1 x+B_2 x^2+\cdots+B_\mu x^\mu}
\]
et
\[
\frac{d y}{\Delta\left(y, c^{\prime}\right)}=\varepsilon \frac{d x}{\Delta(x, c)} \text {. }
\]

Supposons \(\boldsymbol{\mu}\) premier et d'abord \(\boldsymbol{\mu}=1\). Dans ce cas le module \(\boldsymbol{c}^{\prime}\), en vertu des formules du paragraphe 2 , aura six valeurs différentes, et la fonction \(y\) en aura douze.

Si \(\boldsymbol{\mu}=2\), on aura toutes les solutions possibles en combinant les deux formules \((163,165)\) avec les six formules du paragraphe 2 , ce qui donne 18 valeurs différentes du module \(c^{\prime}\).
Si l'on fait
\[
c_1=\frac{1-c}{1+c}, c_2=\frac{2 \sqrt{c}}{1+c}, c_3=\frac{2 \sqrt{-c}}{1-c},
\]
ces 18 valeurs s'obtiendront en mettant dans les six fonctions
\[
\pm c, \pm \frac{1}{c}, \pm\left(\frac{1-\sqrt{c}}{1+\sqrt{c}}\right)^2, \pm\left(\frac{1+\sqrt{c}}{1-\sqrt{c}}\right)^2, \pm\left(\frac{1-\sqrt{-c}}{1+\sqrt{-c}}\right)^2, \pm\left(\frac{1+\sqrt{-c}}{1-\sqrt{-c}}\right)^2
\]
les trois quantités \(c_1, c_2, c_3\) au lieu de \(c\).
Si \(\mu\) est un nombre premier impair \(2 n+1\), on aura d'abord \(2 n+2\) valeurs du module \(c^{\prime}\) qui répondent à la forme suivante de \(y\) :
\[
y=\frac{c^{n+\frac{1}{x}}}{\sqrt{c^{\prime}}} \frac{x\left(e^2-x^2\right)\left(e^2-x^2\right) \ldots\left(e_n^2-x^2\right)}{\left(1-c^2 e^2 x^2\right)\left(1-c^2 e_2^2 x^2\right) \ldots\left(1-c^2 e_n^2 x^2\right)} .
\]

Or de chaque valeur de \(y\) de cette forme on déduit, en vertu des six formules du paragraphe 2 , cinq antres valeurs de la forme:
\[
\begin{gathered}
c^{\prime} y, \frac{1+\sqrt{c^{\prime}}}{1-\sqrt{c^{\prime}}} \cdot \frac{1 \pm y \sqrt{c^{\prime}}}{1 \mp y \sqrt{c^{\prime}}}, \frac{1-\sqrt{c^{\prime}}}{1+\sqrt{c^{\prime}}} \cdot \frac{1 \pm y \sqrt{c^{\prime}}}{1 \mp y \sqrt{c^{\prime}}}, \frac{1-\sqrt{-c^{\prime}}}{1+\sqrt{-c^{\prime}}} \cdot \frac{1 \pm y \sqrt{-c^{\prime}}}{1 \mp y \sqrt{-c^{\prime}}}, \\
\frac{1+\sqrt{-c^{\prime}}}{1-\sqrt{-c^{\prime}}} \cdot \frac{1 \pm y \sqrt{-c^{\prime}}}{1 \mp y \sqrt{-c^{\prime}}},
\end{gathered}
\]
auxquelles répondent respectivement les modules:
%604
\[
\frac{1}{c^{\prime}},\left(\frac{1-\sqrt{c^{\prime}}}{1+\sqrt{c^{\prime}}}\right)^2, \quad\left(\frac{1+\sqrt{c^{\prime}}}{1-\sqrt{c^{\prime}}}\right)^2, \quad\left(\frac{1+\sqrt{-c^{\prime}}}{1-\sqrt{-c^{\prime}}}\right)^2, \quad\left(\frac{1-\sqrt{-c^{\prime}}}{1+\sqrt{-c^{\prime}}}\right)^2 .
\]

On aura donc en tout \(6(2 n+2)=6(\mu+1)\) valeurs différentes pour le module \(c^{\prime}\). On en aura un nombre double pour la fonction \(y\).
\(\S 12\).
Résolution de" l'équation \(y=\psi \cdot x\).
L'équation algébrique \(y=\psi x x\), où \(\psi x\) est une fonction rationnelle quelconque de \(x\), satisfaisant à une équation différentielle de la forme (205), jouira de la propriété remarquable d'être résoluble par rapport à \(x\) à l'aide de radicaux. C'est ce qu’il est facile de démontrer à l'aide de la forme des racines de cette équation. D'abord si le degré "l est un nombre composé \(=n \cdot n_1 \cdot n_2 \ldots n_v\), on pourra faire comme nous venons de le voir dans le \(\S 7\) :
\[
y=\psi_\nu y_v, y_v=\psi_{v-1} y_{v-1}, \ldots y_2=\psi_1 y_1, y_1=\psi x
\]
\(\psi_\nu, \psi_{\nu-1}, \ldots \psi_1, \psi\) désignant des fonctions rationnelles respectivement des degrés \(n_\nu, n_{v-1}, \ldots n_1, n\), ces derniers nombres étant premiers. On aura donc la valeur de \(x\) en \(y\) à l'aide de la résolution de \(\boldsymbol{v}+1\) équations des degrés \(n, n_1, \ldots n_\nu\) respectivement. Il suffit donc de résoudre l'équation \(y=\psi x\) dans le cas où le degré \(\mu\) est un nombre premier. Si \(\mu=2\), on aura l'expression de \(x\) par les règles connues. Soit donc \(\mu\) impair \(=2 u+1\). Alors les racines de l'équation \(y=\psi x\) seront les \(2 \mu+1\) quantités
\[
x, \theta x, \theta^2 x \ldots \theta^{2 \mu} x .
\]

Cela posé, soit \(\delta\) une racine imaginaire de l'équation
\[
\delta^{2 \mu+1}=1
\]
et faisons
\[
\begin{aligned}
& v=x+\delta \cdot \theta x+\delta^2 \cdot \theta^2 x+\cdots+\delta^{2 \mu} \cdot \theta^{2 \mu} x \\
& v^{\prime}=x+\delta \cdot \theta^{2 \mu} x+\delta^2 \cdot \theta^{2 \mu-1} x+\cdots+\delta^{2 \mu} \cdot \theta \cdot x .
\end{aligned}
\]

En substituant pour les quantités \(\theta^m x\) leurs valeurs
\[
\theta^m x=\frac{x \Delta e_m+e_m \Delta x}{1-c^2 e_m^2 x^2},
\]
et remarquant que
\[
\theta^{2 \mu+1-m} x=\frac{x \Delta e_m-e_m d x}{1-e^2 e_m^2 x^2}
\]
%605
il est clair qu'on aura
\[
v=p+q 1 x, v^{\prime}=p-q \cdot x,
\]
\(p\) et \(q\) étant des fonctions rationnelles de \(x\). Cela fait voir que \(v v^{\prime}\) et \(v^{2 \mu+1}+v^{2 \mu+1}\) sont des fonctions rationnelles de \(x\); or je dis qu'on pourra exprimer ces quantités en fonction rationnelle de \(y\). En effet, en vertu de la forme de \(v\) et \(v^{\prime}\), il est clair que si l'on fait
\[
v v^{\prime}=\varphi x, v^{2 \mu+1}+v^{2 \mu+1}=f x,
\]
les deux fonctions \(\varphi x\) et \(f x\) ne changeront pas de valeur si l'on met pour \(x\) les \(2 u+1\) quantités
\[
x, \theta x, \ldots \theta^{2 \mu} x
\]

Done on aura
\[
\begin{aligned}
& \varphi x=\frac{1}{2 \mu+1}\left(\varphi x+\varphi \theta x+\cdots+\varphi \theta^{2 \mu} x\right)=v v^{\prime} \\
& f x=\frac{1}{2 \mu+1}\left(f x+f \theta x+\cdots+f \theta^{2 \mu} x\right)=v^{2 \mu+1}+v^{2 \mu+1}
\end{aligned}
\]

Ces expressions des quantités \(v v^{\prime}, v^{2 \mu+1}+v^{2 \mu+1}\) sont des fonctions rationnelles et symétriques des racines de l'équation \(y=\psi x\); donc on pourra les exprimer rationnellement par les coefficiens de cette équation, c'est-àdire en \(y\).
Faisons done
\[
\begin{gathered}
v v^{\prime}=s \\
v^{2 \mu+1}+v^{2 \mu+1}=t
\end{gathered}
\]
\(s\) et \(t\) seront des fonctions rationnelles de \(y\). On en tire
\[
v=\sqrt[2 \mu+1]{\frac{t}{2}+\sqrt{\frac{t^2}{4}-s^{2 \mu+1}}}
\]

On connaît donc la fonction \(v\). Cela posé, si l'on désigne par \(v_0, v_1, v_2\), \(\ldots v_{2 \mu}\) les valeurs de \(v\) qui répondent respectivement aux racines \(1, \delta, \delta{ }^2\), \(\delta^3, \ldots \delta^{2 \mu}\) de l'équation \(\delta^{2 \mu+1}=1\), on aurar sur le champ
\[
\begin{aligned}
x & =\frac{1}{2 \mu+1}\left(v_0+v_1+v_2+\cdots+v_{2 \mu}\right), \\
\boldsymbol{\theta}^m x & =\frac{1}{2 \mu+1}\left(v_0+\delta^{-m} v_1+\delta^{-2 m} v_2+\cdots+\delta^{-2 m \mu} v_{2 \mu}\right),
\end{aligned}
\]
ce qui est l'expression générale des racines.
%606
On aura ainsi une classe très étendue d'équations algébriques de tous les degrés qui seront résolubles algébriquement. Nous n'entrerons pas ici dans des détails sur ce sujet, mais nous renvoyons nos lecteurs à la seconde partie de ce mémoire, où nous en donnerons des développemens étendus à cause des belles propriétés des fonctions elliptiques qu'on en peut déduire.
Comme cas particulier on pourra remarquer l'équation
\[
x_\mu=y
\]
où \(x_\mu\) désigne la fonction rationnelle de \(x\) du degré \(\mu^2\), qui satisfera à l'équation
\[
\frac{d x_\mu}{\Delta x_\mu}=\mu \frac{d x}{\Delta x} .
\]

On en pourra donc toujours tirer la valeur de \(x\) en \(y\) à l'aide de radicaux. Si \(\mu\) est un nombre impair, on pourra donner aux racines cette forme très simple:
\[
x=\frac{1}{\mu}\left[a y+\left(p_1+q_1 \Delta y\right)^{\frac{1}{\mu}}+\left(p_2+q_2 \Delta y\right)^{\frac{1}{\mu}}+\cdots+\left(p_{\mu^2-1}+q_{\mu^2-1} \Delta y\right)^{\frac{1}{\mu}}\right]
\]
où \(p_1, p_2, p_3 \ldots\) sont des fonctions entières impaires de \(y\) du degré \(\mu\), et \(q_1, q_2, q_3 \ldots\) des fonctions paires de \(y\) du degré \(\boldsymbol{\mu}-3\). \(p_m\) et \(q_m\) seront déterminés par l'équation
\[
p_m^2-q_m^2\left(1-y^2\right)\left(1-c^2 y^2\right)=\left(y^2-e_m^2\right)^\mu,
\]
où \(e_m\) est une constante, savoir une racine de l'équation \(x_\mu=0\).
CHAPITRE V.
Théorie générale de la transformation des fonctions elliptiques par rapport au module.
A l'aide des théorèmes que nous avons établis dans les chapitres précédens, nous pourrons maintenant donner la solution de ce problème:
"Étant proposée une fonction elliptique d'un module quelconque, expitimer" cette fonction de la manière la plus générale en d'autres fonctions."
%607
\(\S 1\).
Condition générule pour la transformation.
Soit proposée une intégrale de la forme
\[
\int \frac{r d x}{d x}
\]
on demande s'il est possible d'exprimer cette intégrale par des fonctions algébriques, logarithmiques et des fonctions elliptiques, dont les modules sont \(c_1, c_2, \ldots c_m\), en sorte qu'on ait:
\[
\int \frac{r d x}{d x}=A_1 \cdot \psi_1 x_1+A_2 \cdot \psi_2 x_2+\cdots+A_m \cdot \psi_m x_n+V
\]
où \(A_1, A_2, \ldots A_m\) sont des constantes, \(x_1, x_2, \ldots x_m\) des fonctions algébriques de \(x\), et \(V\) une fonction algébrique et logarithmique; \(\psi_1, \psi_2, \ldots \psi_m\) désignent des fonctions elliptiques ayant respectivement \(c_1, c_2, \ldots c_m\) pour modiles.
Cela posé, cette équation domnera en vertu de la formule (86):
\[
\int \frac{r d x}{d x}=k_1 \cdot \psi_1 y_1+k_2 \cdot \psi_2 y_2+\cdots+k_m \cdot \psi_m y_m+V^{\prime}
\]
les quantités
de même que
\[
\begin{gathered}
y_1, y_2, y_3, \ldots y_m \\
\frac{\Delta_1 y_1}{d_x}, \frac{\Delta_2 y_2}{d x}, \frac{\Delta_3 y_3}{d_x}, \ldots \frac{\Delta_m y_m}{d_x}
\end{gathered}
\]
étant des fonctions rationnelles de \(x\).
Si l'on suppose, ce qui est permis, qu'il soit impossible d'exprimer
\[
\int \frac{r d x}{d x}
\]
par un nombre moindre des fonctions \(\psi_1, \psi_2, \ldots \psi_n\), il est clair qu'aucune des quantités \(y_1, y_2, \ldots y_m\) ne pourra être constante.

On doit donc avoir séparément, en vertu du théorème démontré dans le premier paragraphe du chapitre précédent,
\[
\frac{d y_1}{J_1 y_1}=\varepsilon_1 \frac{d x}{d x}, \frac{d y_2}{d_2 y_2}=\varepsilon_2 \frac{d x}{d x}, \cdots \frac{d y_m}{d_m y_m}=\varepsilon_m \frac{d x}{d x},
\]
où \(\varepsilon_1, \varepsilon_2, \ldots \varepsilon_n\) sont des constantes. Cela donne en intégrant,
\[
\widetilde{\omega}\left(y_1, c_1\right)=\varepsilon_1 \widetilde{\omega} x, \widetilde{\omega}\left(y_2, c_2\right)=\varepsilon_2 \widetilde{\omega} x, \ldots \bar{\omega}\left(y_m, c_m\right)=\varepsilon_m \widetilde{\omega} x
\]
%608
sauf une constante qu'il faut ajouter à chacune de ces équations. On pourra donc énoncer ce théorème:

Théorème XIII. Une relation quelconque entre des fonctions elliptiques, ayant \(c, c_1, c_2, \ldots c_m\) pour modules, ne pourra subsister à moins qu'on n'ait entre les fonctions correspondantes de la première espèce, cette relation
\[
\widetilde{\omega}(x, c)=\frac{1}{\varepsilon_1} \widetilde{\omega}\left(y_1, c_1\right)=\frac{1}{\varepsilon_2} \widetilde{\omega}\left(y_2, c_2\right)=\cdots=\frac{1}{\varepsilon_m} \widetilde{\omega}\left(y_m, c_m\right),
\]
où \(\varepsilon_1, \varepsilon_2, \ldots \varepsilon_m\) sont des constantes et \(y_1, y_2, \ldots y_m\) des fonctions rationnelles de la variable \(x\).
On pourra donc encore satisfaire aux équations suivantes:
\[
\left\{\begin{array}{c}
\widetilde{\omega}\left(x_1, c\right)=\varepsilon^{\prime} \widetilde{\omega}\left(x, c_1\right), \\
\widetilde{\omega}\left(x_2, c\right)=\varepsilon^{\prime \prime} \widetilde{\omega}\left(x, c_2\right), \\
\cdots \cdots \cdots \cdots \\
\widetilde{\omega}\left(x_m, c\right)=\varepsilon^{(m)} \widetilde{\omega}\left(x, c_m\right),
\end{array}\right.
\]
\(x_1, x_2, \ldots x_m\) étant des fonctions rationnelles de \(x\); ou bien, si l'on désigne par \(c\) et \(c^{\prime}\) les modules de deux quelconques des fonctions entre lesquelles on a une relation, on pourra toujours satisfaire à l'équation
\[
\widetilde{\omega}\left(x^{\prime}, c^{\prime}\right)=\varepsilon \widetilde{\omega}(x, c)
\]
en supposant \(x^{\prime}\) fonction rationnelle de \(x\), on \(x\) fonction rationnelle de \(x^{\prime}\). Cette équation donne
\[
\frac{d x^{\prime}}{I\left(x^{\prime}, c^{\prime}\right)}=8 \frac{d x}{I(x, c)} .
\]

Soit maintenant \(x^{\prime}\) fonction rationnelle de \(x\); si \(r^{\prime}\) désigne une fonction rationnelle quelconque de \(x^{\prime}\), on pourra transformer \(r^{\prime}\) en une fonction pareille de \(x\). En la désignant par \(r\), on aura donc \(r^{\prime}=r\). Donc en multipliant l'équation différentielle ci-dessus par \(r^{\prime}\), on aura, en intégrant
\[
\int \frac{r^{\prime} d x^{\prime}}{d\left(x^{\prime}, c^{\prime}\right)}=\varepsilon \int \frac{r d x}{d(x, c)} .
\]

Quelle que soit la fonction rationnelle \(r\), on pourra toujours, comme on sait, exprimer
\[
\int \frac{r d x}{d(x, c)}
\]
par des fonctions elliptiques des trois espèces avec le module \(c\). On aura donc ce théorème:
%609
Théorème XIV. Si une fonction elliptique quelconque \(\varphi x\), ayant \(c^{\prime}\) pour module, pent être exprimée par d'autres fonctions dont les modules sont \(c_1, c_2, \ldots c_m\), on pourra toujours exprimer la même fonction \(\varphi x\) par des fonctions elliptiques d'un même morlule \(c, c\) étant l'un quelconque des modules \(c_1, c_2, \ldots c_m\), et cela de la manière suivante:
\[
\varphi y=\int \frac{r d x}{I(x, c)},
\]
où \(y\) et \(r\) sont des fonctions rationnelles de \(x\).
La continuation d'après un manuscrit inćdit.
En vertu de ce théorème tout ce qui concerne la transformation des fonctions elliptiques par rapport au module se réduit à exprimer l'intégrale \(\int \frac{r d x}{I(x, c)}\) par des fonctions elliptiques.
\(\$ 2\).
Transformation des fonctions de la première et de la seconde espèce.
Supposons r'abord que \(\varphi x\) soit une fonction de la première espèce, de sorte qu'on ait
\[
\varphi x=\int \frac{d x}{I\left(x, c^{\prime}\right)} .
\]

Dans ce cas la fonction \(r\) se réduit à une constante, et on alura par suite (212)
\[
\bar{\omega}\left(y, c^{\prime}\right)=\varepsilon \cdot \bar{\omega}(x, c),
\]
où \(y\) est rationnel en \(x\). Cette équation est la même que celle-ci:
\[
\frac{d y}{d\left(y, c^{\prime}\right)}=\varepsilon \frac{d x}{I(x, c)} .
\]

Nous en avons donné la solution dans le chapitre précédent. Passons aux fonctions de la seconde espèce:
%610
\[
\varphi x=\int \frac{x^2 d x}{I\left(x, c^{\prime}\right)}=\widetilde{\omega}_0\left(x, c^{\prime}\right)
\]

On aura alors
\[
\bar{\omega}_0\left(y, c^{\prime}\right)=\varepsilon \int \frac{y^2 d x}{I(x, c)} .
\]

Comme \(y\) est une fonction rationnelle de \(x\), l'intégrale du second membre paraît contenir des fonctions de la troisième espèce, mais nous verrons qu'on pent toujours la réduire à une expression de la forme:
\[
A \cdot \bar{\omega}(x, c)+B \cdot \widetilde{\omega}_0(x, c)+v
\]
où \(v\) est me fonction algébrique de \(x\). Il y a un moyen bien simple de prouver cela, savoir en différentiant l'équation
\[
\widetilde{\omega}\left(y, c^{\prime}\right)=\varepsilon \cdot \widetilde{\omega}(x, c)
\]
par rapport au module \(c\). Cette équation revient à celle-ci:
\[
\int d y\left(1-y^2\right)^{-\frac{1}{2}}\left(1-c^{\prime 2} y^2\right)^{-\frac{1}{2}}=\varepsilon \int d x\left(1-x^2\right)^{-\frac{1}{2}}\left(1-c^2 x^2\right)^{-\frac{1}{2}} .
\]

En la différentiant par rapport à \(c\) et remarquant que les trois quantités \(y\), \(c^{\prime}, \varepsilon\) contiemment cette quantité, on aura
mais on a
\[
\begin{aligned}
& \int \frac{x^2 d x}{\left(1-c^2 x^2\right) /(x, c)}=\frac{1}{c^2-1} \cdot \frac{x\left(1-x^2\right)}{I(x, c)}+\frac{1}{1-c^2} \int \frac{\left(1-x^2\right) d x}{I(x, c)} \\
& \int \frac{y^2 d y}{\left(1-c^{\prime 2} y^2\right)-I\left(y, c^{\prime}\right)}=\frac{1}{c^{\prime 2}-1} \cdot \frac{y\left(1-y^2\right)}{I\left(y, c^{\prime}\right)}+\frac{1}{1-c^{\prime 2}} \int \frac{\left(1-y^2\right) d y}{I\left(y, c^{\prime}\right)}
\end{aligned}
\]

En substituant on aura
\[
\begin{aligned}
\frac{c^{\prime}}{1-c^{\prime 2}} \cdot \frac{d c^{\prime}}{d c}\left\{\widetilde{\omega}\left(y, c^{\prime}\right)\right. & \left.-\widetilde{\omega}_0\left(y, c^{\prime}\right)-\frac{y\left(1-y^2\right)}{I\left(y, c^{\prime}\right)}\right\}+\frac{d y}{d c} \cdot \frac{1}{J\left(y, c^{\prime}\right)} \\
= & \frac{d \varepsilon}{d c} \widetilde{\omega}(x, c)+\frac{c \varepsilon}{1-c^2}\left\{\widetilde{\omega}(x, c)-\widetilde{\omega}_0(x, c)-\frac{x\left(1-x^2\right)}{I(x, c)}\right\}
\end{aligned}
\]
et de là en mettant pour \(\widetilde{\omega}\left(y, c^{\prime}\right)\) sa valeur \(\varepsilon \bar{\omega}(x, c)\),
\[
\widetilde{\omega}_0\left(y, c^{\prime}\right)=A \widetilde{\omega}(x, c)+B \widetilde{\omega}_0(x, c)+p,
\]
où l'on a fait pour abréger
%611
\[
\left\{\begin{array}{l}
A=\varepsilon\left\{1-\frac{c d c\left(1-c^2\right)}{c^{\prime} d c^{\prime}\left(1-c^2\right)}\right\}-\frac{d \varepsilon\left(1-c^2\right)}{c^{\prime} d c^{\prime}}, \\
B=\frac{\varepsilon c\left(1-c^{\prime 2}\right) d c}{c^{\prime}\left(1-c^2\right) d c^{\prime}}, \\
p=\frac{\left(1-c^{\prime 2}\right) d c}{c^{\prime} d c^{\prime}} \cdot \frac{d y}{d c} \cdot \frac{1}{d\left(y, c^{\prime}\right)}+B \frac{x\left(1-x^2\right)}{d(x, c)}-\frac{y\left(1-y^2\right)}{\Delta\left(y, c^{\prime}\right)} .
\end{array}\right.
\]

Or on pourra parvenir plus directement à l'expression de \(\widetilde{w}_0\left(y, c^{\prime}\right)\), savoir en décomposant la fonction rationnelle \(y^2\) en fractions partielles.
Soit \(x-a\) un facteur du dénominateur de \(y\), on aura
\[
y^2=\frac{A}{(x-a)^2}+\frac{B}{x-a}+S
\]
où \(A\) et \(B\) sont des constantes. En faisant \(y=\frac{1}{q x}\), on trouve d'après les règles counues
\[
A=\frac{1}{\left(\varphi^{\prime} a\right)^2} ; \quad B=-\frac{\varphi^{\prime \prime} a}{\left(\varphi^{\prime} a\right)^3} .
\]

Or si l'on met dans l'équation
\[
\frac{d y}{J\left(y, c^{\prime}\right)}=\varepsilon \frac{d x}{d(x, c)}
\]
\(\frac{1}{4 x}\) au lieu de \(y\), il viendra
\[
\begin{aligned}
\left(1-x^2\right)\left(1-c^2 x^2\right)\left(\varphi^{\prime} x\right)^2=\varepsilon^2\left[(\varphi x)^2-1\right]\left[(\varphi x)^2-c^{\prime 2}\right] & \\
& =\varepsilon^2(\varphi x)^4-\varepsilon^2\left(1+c^{\prime 2}\right)(\varphi x)^2+\varepsilon^2 c^{\prime 2}
\end{aligned}
\]

En \(y\) faisant \(x=a\) on a \(\varphi x=0\), donc
\[
\left(1-a^2\right)\left(1-c^2 a^2\right)\left(\varphi^{\prime} a\right)^2=\varepsilon^2 c^2
\]

De même si l'on différentie l'équation (218) par rapport à \(x\) et qu'on fasse ensuite \(x=a\), on aura
\[
2\left(1-a^2\right)\left(1-c^2 a^2\right) \varphi^{\prime} a \cdot \varphi^{\prime \prime} a-\left[2\left(1+e^2\right) a-4 c^2 a^3\right]\left(\varphi^{\prime} a\right)^2=0 ;
\]
on a donc
\[
\left\{\begin{array}{c}
\frac{1}{\left(\varphi^{\prime} a\right)^2}=\frac{\left(1-a^2\right)\left(1-c^2 a^2\right)}{\varepsilon^2 c^{\prime 2}}=A \\
-\frac{\varphi^{\prime \prime} a}{\left(\varphi^{\prime} a\right)^3}=\frac{-\left(1+c^2\right) a+2 c^2 a^3}{\varepsilon^8 c^{\prime 2}}=B
\end{array}\right.
\]

En vertu de ces valeurs de \(A\) et de \(B\) il est facile d'avoir l'expression de \(\int y^2 \frac{d y}{d\left(y, c^{\prime}\right)}\). En effet, en multipliant l'expression de \(y^2\) par \(\frac{d y}{d\left(y, c^{\prime}\right)}=\varepsilon \frac{d x}{77^*}\),
%612
il viendra
\[
\begin{aligned}
\int \frac{y^2 d y}{d\left(y, c^{\prime}\right)}=\frac{1}{\varepsilon c^{\prime 2}} \int\left\{\frac{\left(1-a^2\right)\left(1-c^2 a^2\right)}{(x-a)^2}+\frac{2 c^2 a^3-\left(1+c^2\right) a}{x-a}\right\} & \frac{d x}{d(x, c)} \\
& +\varepsilon \int \frac{S d x}{A(x, c)} .
\end{aligned}
\]

Or si l'on différentie la fonction
\[
\frac{\mathcal{A}(x, c)}{x-a}=r
\]
on trouvera
\[
d r=-\left\{\frac{\left(1-a^2\right)\left(1-c^2 a^2\right)}{(x-a)^2}+\frac{2 c^2 a^3-\left(1+c^2\right) a}{x-a}+c^2 a^2-c^2 x^2\right\} \frac{d i x}{d(x, c)},
\]
done la première des intégrales du second membre de l'équation (220) est la même chose que
\[
\int\left(c^2 x^2-c^2 a^2\right) \frac{d x}{d(x, c)}-\frac{\mathcal{A}(x, c)}{x-a}=\frac{d(x, c)}{a-x^2}-c^2 a^2 \widetilde{w}(x, c)+c^2 \widetilde{w}_0(x, c) .
\]

Donc l'expression de \(\int \frac{y^2 d y}{I\left(y, c^{\prime}\right)}\) deviendra
\[
\int \frac{y^2 d y}{d\left(y, c^{\prime}\right)}=\frac{1}{\varepsilon c^{\prime 2}}\left\{\frac{A(x, c)}{a-x}-c^2 a^2 \widetilde{w}(x, c)+c^2 \widetilde{w}_0(x, c)\right\}+\varepsilon \int \frac{S d x}{I(x, c)} .
\]

En désignant done par \(a_1, a_2, \ldots a_\mu\) toutes les racines de l'équation \(\frac{1}{y}=0\), on aura
\[
\begin{aligned}
\varepsilon c^{\prime 2} \widetilde{\omega}_0\left(y, c^{\prime 2}\right)=\mu c^2 \widetilde{\omega}_0(x, c)- & {\left[c^2\left(a_1^2+a_2^2+\cdots+a_\mu^2\right)-\varepsilon^2 c^{\prime 2} k^2\right] \widetilde{\omega}(x, c) } \\
& +\Lambda(x, c)\left\{\frac{1}{a_1-x}+\frac{1}{a_2-x}+\cdots+\frac{1}{a_\mu-x}\right\}
\end{aligned}
\]
oì \(k\) est une quantité constante, savoir la valeur de \(y\) pour \(x=\frac{1}{0}\).
Cette formule répond à une fonction rationnelle y du degré "", savoir
\[
y=k \frac{\left(x-\alpha_1\right)\left(x-\alpha_2\right)\left(x-\alpha_3\right) \ldots\left(x-\alpha_\mu\right)}{\left(x-a_1\right)\left(x-a_2\right)\left(x-a_3\right) \ldots\left(x-a_\mu\right)}
\]
mais il y a deux cas qu'il faut considérer séparément: il pourra arriver que l'une des quantités \(a_\mu\) et \(\alpha_\mu\) sera infinie. Soit d'abord \(\alpha_\mu=\frac{1}{11}\). Alors on aura \(k=0\). Dans ce cas la fonction \(y\) sera une fonction impaire de \(x\), dont le numérateur sera d'un degré moindre que celui du dénominateur. Si \(\mu\) est pair, on aura en mettant \(2 \mu\) pour \(\mu\),
\[
y=\varepsilon \frac{x\left(1-\beta_1^2 x^2\right)\left(1-\beta_2^2 x^2\right) \cdots\left(1-\beta_{\mu-1}^2 x^2\right)}{\left(1-\delta_1^2 x^2\right)\left(1-\delta_2^2 x^2\right) \cdots\left(1-\delta_\mu^2 x^2\right)}
\]
%613
et la formule (221) deviendra
\[
\begin{aligned}
\varepsilon c^{\prime 2} \widetilde{\omega}_u\left(y, c^{\prime}\right)= & 2 \mu c^2 \widetilde{\omega}_0(x, c)-2 c^2\left\{\frac{1}{\delta_1^2}+\frac{1}{\delta_2^2}+\cdots+\frac{1}{\delta_\mu^2}\right\} \widetilde{\omega}(x, c) \\
& +2 x \cdot \Delta(x, c)\left\{\frac{\delta_1^2}{1-\delta_1^2 x^2}+\frac{\delta_2^2}{1-\delta_2^4 x^2}+\cdots+\frac{\delta_\mu^2}{1-\delta_{\mu 2}^2 r^2}\right\}
\end{aligned}
\]

Si " \("\) est un nombre impair, on aura en mettant \(2 \mu+1\) pour " \("\),
\[
y=\frac{\left(1-c^2 a_1^2 x^2\right)\left(1-c^2 a_2^2 x^2\right) \ldots\left(1-c^2 a_\mu^2 x^2\right)}{x_1\left(a_1^2-x^2\right)\left(a_2^2-x^2\right) \ldots\left(a_\mu^2-x^2\right)} \cdot \frac{a_1^2 \cdot a_2^2 \ldots a_\mu^2}{\varepsilon c^{\prime}}
\]
et la formule (221) deviendra
\[
\begin{aligned}
\varepsilon c^{\prime 2} \widetilde{w}_0\left(y, c^{\prime}\right)=(2, \prime & +1) c^2 \widetilde{w}_0(x, c)-2 c^2\left(a_1^2+a_2^2+\cdots+a_\mu^2\right) \widetilde{w}(x, c) \\
& +2 x /(x, c)\left\{-\frac{1}{2 x^2}+\frac{1}{a_1^2-x^2}+\cdots+\frac{1}{a_\mu^2-x^2}\right\}
\end{aligned}
\]

Supposons maintenant \(a_\mu=0\). On aura alors \(k=\frac{1}{1}\). I La fonction \(y\) sera impaire, mais le dénominateur sera d'un degré plus petit que celui du numérateur. Pour avoir les formules qui répondent à ce cas, il suffit de mettre dans les deux équations \((222,224), \frac{1}{c z}\) au lieu de \(x\). Cela donne
\[
\begin{aligned}
\mathcal{A}(x, c) & =\sqrt{\left(1-\frac{1}{c^y z^z}\right)\left(1-\frac{1}{z^3}\right)}=-\frac{d(z, c)}{c z^y}, \\
\widetilde{\omega}(x, c) & =+\int \frac{d z}{d(z, c)}=+\widetilde{\omega}(z, c), \\
c^2 \widetilde{\omega}_0(x, c) & =+\int \frac{d z}{z^2 d(z, c)}=+c^2 \widetilde{\omega}_0(z, c)-\frac{d(z, c)}{z} .
\end{aligned}
\]

Done en substituant dans la formule (224) et mettant \(z=x\),
\[
\begin{aligned}
& \varepsilon c^{\prime 2} \widetilde{\omega}_0\left(y, c^{\prime}\right)=(2 \mu+1) c^2 \widetilde{\omega}_0(x, c)-2 c^2\left(a_1^2+a_z^2+\cdots+a_\mu^2\right) \widetilde{\omega}(x, c) \\
& +2 x \Delta(x, c)\left\{\frac{c^2 a_1^3}{1-c^2 a_1^2 x^2}+\frac{c^2 a_2^2}{1-c^3 a_2^2 x^2}+\cdots+\frac{c^2 a_\mu^2}{1-c^2 a_\mu^2 x^2}\right\} \text {. } \\
&
\end{aligned}
\]

L'expression de \(y\) sera, en vertu de la formule (223),
\[
y=\frac{\varepsilon}{a_1^2 \cdot a_2^2 \ldots a_\mu^2} \cdot \frac{x\left(a_1^2-x^2\right)\left(a_2^2-x^2\right) \ldots\left(a_\mu^2-x^2\right)}{\left(1-a^2 a_1^2 \cdot x^2\right)\left(1-c^2 a_2^2 x^2\right) \ldots\left(1-r^2 a_\mu^2 x^2\right)} .
\]

Pour domner un exemple soit
\[
c^{\prime}=\frac{2 \sqrt{c}}{1+c}, y=(1+c) \frac{x}{1+c x^2}, \quad \varepsilon=1+c
\]
%614
alors on a \(\boldsymbol{\mu}=2\), et la formule (222) donnera, pour \(\boldsymbol{\mu}=1\),
\[
\widetilde{\omega}_0\left(y, c^{\prime}\right)=\frac{c(1+c)}{2} \widetilde{\omega}_0(x, c)+\frac{1+c}{2} \widetilde{\omega}(x, c)-\frac{1+c}{2} \cdot \frac{x \cdot t(x, c)}{1+c x^2} .
\]
\(\S 3\).
Transformation des fonctions de la troisième espèce.
Soit maintenant
\[
\varphi y=\int \frac{d y}{\left(1-\frac{y^2}{a^{\prime 2}}\right) \Lambda\left(y, c^{\prime}\right)}=\Pi\left(y, c^{\prime}, a^{\prime}\right)
\]

En mettant pour \(\frac{d y}{d\left(y, e^{\prime}\right)}\) sa valeur \(\varepsilon \frac{d x}{d(x, c)}\), on aura

Pour réduire le second membre aux fonctions elliptiques il faut décomposer la fraction rationnelle \(\frac{1}{1-\frac{y^2}{a^{\prime 2}}}\) en fractions partielles. Soit donc d'abord
\[
\frac{1}{a^{\prime}-y}=k^{\prime}+\frac{A_1}{a_1-x}+\frac{A_2}{a_2-x}+\cdots+\frac{A_\mu}{a_\mu-x}=k^{\prime}+\Sigma \frac{A}{a-x},
\]
où il est clair que \(k^{\prime}\) est une constante. Pour déterminer \(A_1, A_2, \ldots\) on aura d'abord
\[
A=\frac{(a-x)}{a^{\prime}-y} \text { pour } x=a
\]
done:
\[
A=\frac{d x}{d y}
\]
or on a
\[
\varepsilon \mathcal{A}\left(y, c^{\prime}\right)=\frac{d y}{d x} \mathcal{A}(x, c)
\]
donc en faisant \(x=a\) et remarquant que la valeur de \(y\) deviendra alors \(a^{\prime}\), on aura
\[
\varepsilon \Lambda\left(a^{\prime}, c^{\prime}\right)=\frac{d y}{d x} \Lambda(a, c)
\]
et par consépuent
\[
A=\frac{I(a, c)}{\varepsilon J\left(a^{\prime}, c^{\prime}\right)} .
\]
%615
En substituant on aura pal conséquent
\[
\frac{1}{a^{\prime}-y}=k^{\prime}+\frac{1}{\varepsilon I\left(a^{\prime}, c^{\prime}\right)}\left\{\frac{I\left(a_1, c\right)}{a_1-c}+\frac{I\left(a_2, c\right)}{a_2-x}+\cdots+\frac{I\left(a_\mu, c\right)}{a_\mu-x}\right\} .
\]

En désignant de même les racines de l'équation \(a^{\prime}+y=0\) par \(b_1, b_2, \ldots\) \(b_\mu\), on atra
\[
\frac{1}{a^{\prime}+y}=k^{\prime \prime}+\frac{1}{\varepsilon\lrcorner\left(a^{\prime}, c^{\prime}\right)}\left\{\frac{I\left(b_1, c\right)}{b_1-v}+\frac{I\left(b_2, c\right)}{b_2-v}+\cdots+\frac{I\left(b_\mu, c\right)}{b_\mu-v}\right\} .
\]

En ajoutant ces valeurs de \(\frac{1}{a^{\prime}-y}\) et \(\frac{1}{a^{\prime}+y}\) on aura celle de \(\frac{2 a^{\prime}}{a^{\prime 2}-y^2} \cdot\) Mais il suffit de considérer la formule (227). En la multipliant par \(\frac{d y}{d\left(y, c^{\prime}\right)}\) et intégrant, il viendra
\[
\mathcal{I}\left(a^{\prime}, c^{\prime}\right) \int \frac{d y}{\left(a^{\prime}-y\right) \mathcal{I}(y, c)}=k_1 \widetilde{w}(x, c)+\Sigma \mathcal{I}(a, c) \int \frac{d x}{(a-x) \cdot I(x, c)} .
\]

Cela posé, ayant \(\frac{1}{a-x}=\frac{a+x}{a^2-x^2}\), on en tire
\[
\int \frac{d x}{(a-x) \lambda(x, c)} \doteq \frac{1}{a} \Pi\left(x, c,(1)+\int \frac{x d x}{\left(a^3-x^2\right) \Lambda(x, c)} .\right.
\]

De même on aura
\[
\int \frac{d y}{\left(a^{\prime}-y\right) \perp\left(y, c^{\prime}\right)}=\frac{1}{a^{\prime}} \boldsymbol{I}\left(y, c^{\prime}, a^{\prime}\right)+\int \frac{y d y}{\left(a^{\prime 2}-y^2\right) \perp\left(y, c^{\prime}\right)} .
\]

Donc la formule (228) donnera en substituant
\[
\left\{\begin{array}{l}
\frac{I\left(a^{\prime}, c^{\prime}\right)}{a^{\prime}} \Pi\left(y, a^{\prime}, c^{\prime}\right)+I\left(a^{\prime}, c^{\prime}\right) \int \frac{y d y}{\left(a^{\prime 2}-y^2\right) J\left(y, c^{\prime}\right)} \\
\quad=k_{c_1} \widetilde{\omega}(x, c)+\Sigma \frac{I(a, c)}{a} \Pi(x, a, c)+\Sigma I(a, c) \int \frac{x d x}{\left(a^y-x^2\right) J(x, c)} .
\end{array}\right.
\]

Les intégrales qui entrent encore dans cette formule seront, comme on le voit, exprimables par des logarithmes.
On aura par conséquent
\[
\frac{\boldsymbol{I}\left(a^{\prime}, c^{\prime}\right)}{a^{\prime}} \Pi\left(y, c^{\prime}, a^{\prime}\right)=k_1 \widetilde{\omega}(x, c)+\geq \frac{I(a, c)}{a} \Pi(x, c, a)+v^{\prime}
\]

Il est à remarquer que cette formule ne contient pas de fouctions de la seconde espèce.

La fonction de la troisième espèce \(I I\left(y, c^{\prime}, a^{\prime}\right)\) est donc ainsi réduite à la fonction de la première espèce \(\widetilde{\varpi}(x, c)\) et à \(" /\) fonctions de la troisième espèce.
%616
Or je dis qu'on pourra toujours exprimer les \(\mu\) fonctions du second membre par une seule. C'est ce qui est facile à prouver à l'aide des formules établies dans les chapitres précédens. D'abord si l'on détermine une quantité \(\alpha\) de sorte que l'équation
\[
(f x)^2-(\varphi x)^2[\mathcal{A}(x, c)]^2=\left(x^2-a_1^2\right)\left(x^2-a_2^2\right) \cdots\left(x^2-a_\mu^2\right)\left(x^2-\alpha^2\right)
\]
soit satisfaite, \(f x\) et \(\varphi x\) étant des fonctions entières de \(x\), dont l'une est paire et l'autre impaire, on aura sur le champ, en vertu de la formule (104),

Donc en substituant:
\[
\begin{aligned}
\frac{I\left(a^{\prime} c^{\prime}\right)}{a^{\prime}} \Pi\left(y, c^{\prime}, a^{\prime}\right)=\left(k_1+k_2\right) \widetilde{w}(x, c)+ & \frac{\mathcal{I}(\alpha, c)}{\alpha} \Pi(x, c, \alpha) \\
& +v^{\prime}-\frac{1}{2} \log \left\{\frac{f x+\boldsymbol{f} x \boldsymbol{I}(x, c)}{f x-\varphi x \boldsymbol{I}(x, c)}\right\} .
\end{aligned}
\]

Quant aux coefficiens des puissances de \(x\) dans les deux fonctions \(f x\) et \(\varphi x\), ils sont déterminés par les "équations suivantes:
\[
\begin{gathered}
f a_1+\varphi a_1 \cdot \mathcal{A}\left(a_1, c\right)=0 \\
f a_2+\varphi a_2 \cdot \mathcal{A}\left(a_2, c\right)=0 \\
\ldots \ldots \ldots \\
f a_\mu+\varphi a_\mu \cdot \mathcal{I}\left(a_\mu c\right)=0
\end{gathered}
\]
auxquelles il faut ajouter celle-ci:
\[
f \alpha+\varphi \alpha \cdot I(\alpha, c)=0
\]
pour déterminer le signe du radical \(\mathcal{I}(\alpha, c)\).
On peut encore réduire les fonctions du second membre de l'équation (230) d'une autre manière: on pourra les exprimer par l'une quelconque d'entre elles, comme nous allons le voir.

Soit a l'une quelconque des quantités \(a_1, a_2, \ldots a_\mu\). Alors comme elles seront les racines de l'équation
\[
a^{\prime}=y=\psi(x)
\]
elles auront, en vertu de ce qui a été démontré dans le troisième paragraphe du cliapitre précédent, toutes la forme
\[
\frac{a-I(e, c)+e I(a, c)}{1-c^2 e^2 a^2}
\]
%617
où \(e\) est une constante indépendante de \(a\). Soit done
\[
a_m=\frac{a d\left(e_m, c\right)+e_m U(a, c)}{1-c^2 e_m^2 a^2},
\]
on aura en vertu de la formule (112)
\[
\begin{aligned}
\frac{\Delta\left(a_m, c\right)}{a_m} \cdot \Pi\left(x, c, a_m\right)= & \frac{\Lambda(a, c)}{a} \Pi(x, c, a) \\
& +\beta_m \widetilde{\omega}(x, c)+\frac{\boldsymbol{U}\left(e_m, c\right)}{e_m} \Pi\left(x, c, e_m\right)+\log _m S_m .
\end{aligned}
\]

La formule (230) deviendra donc en substituant
\[
\begin{aligned}
\frac{\Delta\left(a^{\prime}, c^{\prime}\right)}{a^{\prime}} \Pi\left(y, c^{\prime}, a^{\prime}\right)= & \left(k_1+\beta_1+\beta_2+\cdots+\beta_{\mu-1}\right) \widetilde{\omega}(x, c) \\
& +\mu \frac{\mathcal{A}(a, c)}{a} \Pi(x, c, a)+\Sigma \frac{\Lambda\left(e_m, c\right)}{e_m} \Pi\left(x, c, e_m\right) \\
& +v^{\prime}+\log S_1+\log S_2+\cdots+\log S_{\mu-1} .
\end{aligned}
\]

Je dis maintenant que \(\Sigma \frac{\mathcal{A}\left(e_m, c\right)}{e_m} \Pi\left(x, c, e_m\right)\) se réduit à zéro. En effet, si l'expression de \(a_m\) est racine de l'équation \(a^{\prime}-y=0\), elle le sera encore en mettant \(-e_m\) pour \(e_m\). Si done " \("\) est un nombre impair, les termes qui composent l'expression \(\Sigma \frac{d\left(e_m, c\right)}{e_m} \Pi\left(x, c, e_m\right)\) sont deux-à-deux égales et de signes contraires. Si \(\mu\) est un nombre pair, l'expression dont il s'agit se réduira à un seul terme \(\frac{A(e, c)}{e} \Pi(x, c, e)\), où \(e\) est zéro ou linfini. Si \(e\) est nul, ce terme le sera de même. Si \(e=\frac{1}{0}\), la valeur correspondante de \(a_m\) est \(\pm \frac{1}{c a}\), done en vertu de la formule \((115) \ldots \ldots \ldots \ldots \ldots\)
%618
XXIX.

THÉORÈMES ET PROBLÈMES.

Journal für die reine und angewandte Mathematik, herausgegeben von Crelle, Bd. 2, Berlin 1827.

Théorème. Si la somme de la série infinie
\[
a_0+a_1 x+a_2 x^2+a_3 x^3+\cdots+a_m x^m+\cdots
\]
est égale à zéro pour toutes les valeurs de \(x\) entre denx limites réelles \(\alpha\) et \(\beta\), on aura nécessairement
\[
a_0=0, a_1=0, a_2=0, \ldots a_m=0 \ldots,
\]
de sorte que la somme de la série s'évanouira poir une valeur quelconque de \(x\).
Problème. En supposant la série
\[
f x=a_0+a_1 x+a_2 x^2+\cdots
\]
convergente pour toute valeur positive moindre que la quantité positive \(\alpha\), on propose de tronver la limite vers laquelle converge la valeur de la fonction \(f x\), en faisant converger \(x\) vers la limite \(\alpha\).
Théorème. Si l'équation différentielle séparée
\[
\frac{a d x}{\sqrt{\alpha+\beta x+\gamma x^2+\delta x^3+\varepsilon x^4}}=\frac{d y}{\sqrt{\alpha+\beta y+\gamma y^2+\delta y^3+\varepsilon y^4}},
\]
où \(\alpha, \beta, \gamma, \delta, \varepsilon, a\) sont des quantités réelles, est algébriquement intégrable, il faut nécessairement que la quantité a soit un nombre rationnel.
%619
Problème. Trouver une intégrale algébrique des deux équations séparées:
\[
\begin{aligned}
& \frac{d x \sqrt{3}}{\sqrt{3+3 x^2+x^4}}=\frac{d y}{\sqrt{3-3 y^2+y^4}}, \\
& \frac{d x \sqrt{3}}{\sqrt{1+x^2+x^4}}=\frac{d y}{\sqrt{1-x^2+x^4}} .
\end{aligned}
\]

Juurnal für die reine und angewandte Mathematik, herausgegeben von Crelle, Bd. 3, Berlin 1828.

Problème. Le nombre \(\alpha^{\mu-1}-1\) peut il être divisible par \(\mu^2\), " étant un nombre premier, et \(\alpha\) un entier moindre que " et plus grand que l'unité?

\end{document}